"Whenever I get asked about mangroves, I always say they are my happy place," says Magdalene Ngeve, postdoctoral researcher at UMD in Maile Neel's lab (professor in the Department of Plant Science and Landscape Architecture and Department of Entomology). "They are very fascinating systems to work with. When I went to do my field work for my Master's thesis and got to experience mangroves, be close to the trees, and see how much biodiversity they host, I instantly fell in love and knew this is what I should be studying."Born and raised in Cameroon, Ngeve grew up near the coast, but didn't give her local mangroves much thought until she left to pursue her graduate degrees on a scholarship to the Vrije Universiteit Brussel. After studying zoology for her undergraduate work, Ngeve became a biologist with a specialization in environment, biodiversity, and ecosystems for her Master's and conservation ecology and genetics for her PhD. It was there that her love of mangroves blossomed, and she brought that passion with her to UMD as a Presidential Postdoctoral Fellow."I am so excited we got this study out there, with the collaboration of mangrove experts in Brussels [Belgium] and around the world," says Ngeve. "In conservation, we have limited resources to manage everything on the planet, so we talk about these evolutionary significant units, which are units we should focus on to preserve as much genetic variability as possible to preserve their evolutionary potential and ensure the ecosystem is resilient. This work showed us that we actually have even more distinct populations than we realized, and that is important for conservation."As Ngeve explains it, people don't often think about ocean currents as a way to spread seeds and seedlings (known as propagules), or even pollen. But for many species, water is the primary way seeds are spread and diversity is ensured. "Ocean currents can be genetic barriers, and they can be facilitators of genetic connectivity at the same time," explains Ngeve. "It just depends on how they all come together and connect. In this study, we saw that ocean current patterns maintain genetic diversity of remote island populations like Seychelles, and cause an accumulation of genetic diversity around where the South Equatorial Current [near the equator] splits near the Eastern African coastline. Seychelles and Madagascan populations likely came to existence from ancient dispersal events from present day Australia and Southeast Asia, and these island populations act as an important stepping stone in spreading diversity to the East African coastline, which we found was a much younger population. Splitting currents also create a barrier to genetic connectivity between even nearby northern and southern populations of the East African coast and the Mozambique Channel."This study helps fill in an important gap in the research, since African mangroves, especially the genetics aspects, have been understudied according to Ngeve. For her doctoral work, Ngeve presented some of the first genetic work on the mangroves of the West African coast, so this work expanding to the East African coast is a natural next step. By understanding the genetic diversity of these species locally, researchers can make connections across populations for global conservation.Ngeve is particularly interested in coastal environments, or the intersection of land and sea as a way to look at larger global change phenomena. "Almost everything we do on land affects the ocean, and those intermediate environments are like the bridge," says Ngeve. "We talk a lot about climate change and sea level rise, and coasts and estuaries [like the Chesapeake Bay and Hudson River Estuary] are on the front lines. How are species in these ecosystems surviving and adapting? Foundational species like mangroves and submerged aquatic vegetation, which I also study as a postdoc, are home to so many species and host high biodiversity. Making sure they are resilient means protecting that biodiversity for all that depend on them."Ngeve is also considering how humans depend on the mangroves, and hopes to find ways that rural communities in her home country of Cameroon can protect the mangroves while still providing for their families. Through her start up project called BeeMangrove, she hopes to transition locals from overharvesting the mangroves for wood as a livelihood to raising honey bees that can simultaneously help pollinate the mangroves and produce honey to sell."While studying the Rhizophora racemosa mangrove species which is pollinated by both wind and insects, I had observed that mangroves that are more windward produced more seedlings. From my genetic work, I also observed pollination limitations at study sites. So clearly, there is a pollination problem in the mangroves that don't get the wind," explains Ngeve. "At the same time, there are also mangrove markets where people sell nothing but mangrove wood, and the logging is an issue. It's no doubt that mangroves like other ecosystems are declining, and we are losing so much biodiversity. In rural Cameroon, I began to wonder what these people could do differently. But they are relying exclusively on the mangroves for their livelihood. It's all they have for food, they harvest the wood for building their homes, and sell it to provide for their families and send their children to school -- mangroves are everything to them. How do you tell people so dependent on the system to stop logging? You have to provide an alternative."Ngeve hopes that with future funding, BeeMangrove can be that alternative. She is currently examining perceptions about mangroves in Cameroon. She has worked with local organizations to provide education and outreach to communities, and the first beehive has been installed. The goal is to work with locals from the start to pilot and grow this program with their support.Growing up in Cameroon, this project is very personal to Ngeve. She is grateful for all the support from her family as a researcher. "My mother became a mangrove researcher herself, tending to my juvenile mangrove plants even after my growth experiment was over," she says. Her father, Jacob Ngeve, is in fact an '88 doctoral alum of the UMD Department of Plant Sciences and Landscape Architecture (then Department of Horticulture). As a quantitative plant geneticist, he has had an international career as an agricultural researcher, and his influence is carried through in her work to this day."Growing up in Africa, I remembered seeing photos he would send of him in these very same walls in the College of Agriculture and Natural Resources," says Ngeve. "I never imagined I'd be here one day -- it is a real privilege. My father would always tell me, 'Education is the only thing a father can give his child, because that, no one can take away from you.' And that meant so much to me because I clung to those words, and against all odds, I studied and followed my dreams. I look forward to making an impact here the way he did."Ngeve is also incredibly thankful for the mentorship she has received on her road to this work and to UMD, from Neel as her current mentor, to those in Brussels, to her family. "My mentors are the reason I am here, and I look forward to paying forward all they have invested in me."
The surprise was great when researchers looked at high-resolution images of the sea floor of the Arctic deep sea in detail: Path-like tracks across the sediments ended where sponges were located. These trails were observed to run in all directions, including uphill. "We conclude from this that the sponges might actively move across the sea floor and leave these traces as a result of their movement," reports Dr Teresa Morganti, sponge expert from the Max Planck Institute for Marine Microbiology in Bremen. This is particularly exciting because science had previously assumed that most sponges are attached to the seafloor or are passively moved by ocean currents and, usually down slopes."There are no strong currents in the Arctic deep sea that could explain the structures found on the sea floor," explains expedition leader Prof. Antje Boetius, who works together with deep-sea biologist Dr Autun Purser from the Alfred Wegener Institute, Helmholtz Centre for Polar and Marine Research (AWI) in the HGF-MPG Joint Research Group for Deep-Sea Ecology and Technology. The recently published recordings were made during an expedition at 87 Â°North at the Karasik Seamount about 350 kilometres away from the North Pole with the research icebreaker Polarstern in 2016 with a towed camera system OFOBS (Ocean Floor Observation and Bathymetry System). "With OFOBS we can create 3D models from the deep sea. The seamount's summit was densely populated with sponges. 69 percent of our images showed trails of sponge spicules, many of which led to live animals," reports Autun Purser.Many questions arise from these observations: Why do the sponges move? How do they orient themselves? Possible reasons for locomotion could be foraging, avoiding unfavourable environmental conditions, or to distribute offspring. Searching for food in particular plays a major role in nutrient-poor ecosystems such as the Arctic deep sea. Sponges have an important function there anyway. As filter feeders they can utilize particle and dissolved organic matter and are intensively involved in nutrient and matter recycling by means of their bacterial symbionts. Sponges also provide arctic fish and shrimp useful structures to use as a habitat. However, the scientists still have to investigate the mechanisms of locomotion.
Once land becomes established through dynamic processes like plate tectonics, it begins to weather and add crucial minerals and nutrients to the ocean. A record of these nutrients is preserved in the ancient rock record. Previous research used strontium isotopes in marine carbonates, but these rocks are usually scarce or altered in rocks older than 3 billion years.Now, researchers are presenting a new approach to trace the first emergence of old rocks using a different mineral: "barite."Barite forms from a combination of sulfate coming from ocean water mixing with barium from hydrothermal vents. Barite holds a robust record of ocean chemistry within its structure, useful for reconstructing ancient environments. "The composition of the piece of barite we pick up in the field now that has been on Earth for three and a half billion years, is exactly the same as it was when it when it actually precipitated," says Desiree Roerdink, a geochemist at University of Bergen, Norway, and team leader of the new research. "So in essence, it is really a great recorder to look at processes on the early Earth."Roerdink and her team tested six different deposits on three different continents, ranging from about 3.2 billion to 3.5 billion years old. They calculated the ratio of strontium isotopes in the barite, and from there, inferred the time where the weathered continental rock made its way to the ocean and incorporated itself into the barite. Based on the data captured in the barite, they found that weathering started about 3.7 billion years ago -- about 500 million years earlier than previously thought."That is a huge time period," Roerdink says. "It essentially has implications for the way that we think about how life evolved." She added that scientists usually think about life starting in deep sea, hydrothermal settings, but the biosphere is complex. "We don't really know if it is possible that life could have developed at the same time on land," she noted, adding "but then that land has to be there."Lastly, the emergence of land says something about plate tectonics and the early emergence of a geodynamic Earth. "To get land, you need processes operating to form that continental crust, and form a crust that is chemically different from the oceanic crust," Roerdink says.
However, successful attempts to rewild the landscape hinge on more than just the reintroduction of a plant or animal species, they also require that geography and geology be taken into account, according to new research from the University of Amsterdam and the Dutch State Forestry Service.It is the landscape that ultimately decides the outcome of rewilding efforts, says Kenneth Rijsdijk, an ecologist at the University of Amsterdam, who is presenting the team's results at the European Geosciences Union (EGU) General Assembly 2021.One of the key challenges of rewilding is deciding where to do it, Rijsdijk says, especially given competing land-uses like infrastructure and agriculture. "Clearly, we cannot, and should not, rewild everywhere. It makes sense to pick out specific areas where rewilding is more likely to succeed, taking into account how landscape features, like ruggedness and soil nutrients, can shape ecosystems."Ecologists gauge rewilding success using biodiversity metrics, such as an increase in the abundance and diversity of plant or bird species. But these measurements do not factor in the role of landscape: from the topography and river systems to the soil and underlying geology.These aspects -- known collectively as geodiversity -- furnish all the physical support required for life on Earth. "Landscape plays a pivotal role in defining the ecosystem: determining where vegetation grows, herbivores graze, animals seek shelter, and predators hunt," Rijsdijk says."It's remarkable that, from a conservation standpoint, the landscape itself is significantly undervalued in the success of rewilding projects," says coauthor Harry Seijmonsbergen, an ecologist at the University of Amsterdam.The team aims to build a more holistic index for measuring and predicting rewilding success.Early applications of their approach -- in northwestern Europe, at sites previously marked by the Dutch State Forestry Service as possible candidates for rewilding -- show that more varied landscapes show greater conservation potential.Their index draws on more than a century of geological and geographical map data, which the team have mapped out across 12 sites in northwestern Europe -- combining landscape features such as elevation, forested areas, openness, and quietness in order to compute a metric for landscape quality. They also studied how geodiversity influenced rewilding over time using satellite, aerial, and field data. By tuning their new index against a previously used ecological index, they were able to independently assess the relationship between biodiversity and landscape at each site.As an independent test of landscape ruggedness, they supplemented their workflow with previously collected data from Yellowstone. The park's mountainous and varied terrain hosts niche environments for animals to hunt and shelter.The new research could help decision-makers select future rewilding sites with the right recipe for success. "Conservation biologists have been asking how they can pinpoint sites with the right characteristics for rewilding," Rijsdijk says. "Our research is the first to start building the required toolkit to measure landscape quality and inform that choice."
In the summer of 2016, Dr. Alexander Ziegler from the Institute of Evolutionary Biology and Ecology at the University of Bonn spent several months in the North Pacific aboard the research vessel SONNE. The crew lowered the steel basket to the seabed around 150 times in order to retrieve rocks, sediments, and living creatures. One organism in particular caused a media stir: a dumbo octopus. The animal, about 30 centimeters in size, was found in waters more than 4,000 meters deep. However, the octopus could not be recovered alive: "The deep-sea organism is not adapted to the environmental conditions of the ocean surface," Ziegler explains.Dumbo octopuses are a group of deep-sea-dwelling octopuses that includes 45 species. The name is based on the flying elephant from the Walt Disney movie of the same name, who is made fun of because of his unusually large ears -- the fins of the dumbo octopuses, which are on the sides of the head resemble these elephant ears. However, the dumbo on the research vessel SONNE differed significantly from the known octopus species. "It was clear to me straight away that we had caught something very special," the biologist reports. So Ziegler immediately photographed the unusual animal, took a small tissue sample for DNA analysis, and then preserved the octopus in formalin.Together with his former master's student Christina Sagorny, Ziegler has now published a description of the previously unknown species. Just as unusual as the octopus was the methodology used. The animals are usually dissected by zoologists, as the internal organs are also important for the description of a new species. "However, as this octopus is very valuable, we were looking for a non-destructive method," explains the researcher.The eight-armed cephalopod therefore did not end up under the scalpel, but in the high-field magnetic resonance imaging system of the German Center for Neurodegenerative Diseases (DZNE) in Bonn. This device is routinely used to image test persons' brains. Thankfully, Dr. Eberhard D. Pracht from the DZNE agreed to conduct a high-resolution scan of the dumbo octopus in 3D. As part of her master's thesis, Christina Sagorny then investigated whether high-field MRI can be used to study internal organs and other soft tissues just as well as through conventional dissection. "The quality is actually even better," Ziegler says.One of the few exceptions: the beak and rasping tongue (radula) of the cephalopod are made of hard chitin that does not image well using MRI. The biologists therefore also consulted the micro-computed tomography system of the paleontologists at the University of Bonn. This technique showed the beak and radula razor-sharp and in 3D. "These hard part structures are an integral part of the species description of octopuses," Ziegler explains. The researchers also decoded the animal's genetic material to reconstruct the family relationships. Ziegler: "The DNA showed beyond a doubt that we were looking at a species of the genus Grimpoteuthis."Examination of the reproductive organs revealed the dumbo octopus to be an adult male. Compared to other species of this genus, it displays several special characteristics. For example, an average of 71 suckers were detected on each arm, which the animal needs to catch prey and which reflect body size. The length of the cirri, which are small appendages on the arms that the deep-sea animals presumably use to sense their prey, also differs from species already known.The web that stretches between the arms, with which the dumbo slowly floats down in the water column, catching worms and crustaceans as if in a bell, also only reaches just over halfway from the mouth down the arms. "The web is much longer in dumbo octopus species that mainly float freely in the water column," Ziegler says. This would indicate that the new species lives close to the seafloor, because otherwise the web would be a hindrance to movements on the bottom.As the species-describing researchers, Sagorny and Ziegler had the privilege of naming the new species: they decided on Grimpoteuthis imperator -- in English "Emperor dumbo." Background: the animal was discovered not far from Japan in an underwater mountain range whose peaks are named after Japanese emperors.The combination of non-destructive methods produced a crisp digital copy of the animal. Anybody interested can download it from the online database "MorphoBank" for further research and learning purposes. The preserved octopus itself is kept in the archives of the Museum fÃ¼r Naturkunde in Berlin, Germany. "There, it can then still be analyzed 100 years from now, for example when more modern investigation methods or new questions arise," Ziegler explains. "Our non-destructive approach could set a precedent, especially for rare and valuable animals," said the Bonn-based evolutionary biologist.
It is 2,250 kilometers long, but only 355 kilometers wide at its widest point -- on a world map, the Red Sea hardly resembles an ocean. But this is deceptive. A new, albeit still narrow, ocean basin is actually forming between Africa and the Arabian Peninsula. Exactly how young it is and whether it can really be compared with other young oceans in Earth's history has been a matter of dispute in the geosciences for decades. The problem is that the newly formed oceanic crust along the narrow, north-south aligned rift is widely buried under a thick blanket of salt and sediments. This complicates direct investigations.In the international journal In addition to information from high-resolution seafloor maps and chemical investigations of rock samples, the team primarily used gravity and earthquake data to develop a new tectonic model of the Red Sea basin. Gravity anomalies have already helped to detect hidden seafloor structures such as rift axes, transform faults and deep-sea mountains in other regions, for example in the Gulf of Mexico, the Labrador Sea or the Andaman Sea.The authors of the current study compared gravity patterns of the Red Sea axis with comparable mid-ocean ridges and found more similarities than differences. For example, they identified positive gravity anomalies running perpendicular to the rift axis, which are caused by variations in crustal thickness running along the axis. "These so-called 'off-axis segmentation trails' are very typical features of oceanic crust originating from magmatically more active, thicker and thus, heavier areas along the axis. However, this observation is new for the Red Sea," says Dr. Nico Augustin.Bathymetric maps as well as earthquake data also support the idea of an almost continuous rift valley throughout the Red Sea basin. This is also confirmed by geochemical analyses of rock samples from the few areas that are not overlain by salt masses. "All the samples we have from the Red Sea rift have geochemical fingerprints of normal oceanic crust," says Dr. Froukje van der Zwan, co-author of the study.With this new analysis of gravity and earthquake data, the team constrains the onset of ocean expansion in the Red Sea to about 13 million years ago. "That's more than twice the generally accepted age," Dr. Augustin says. That means the Red Sea is no longer a baby ocean, but a young adult with a structure similar to the young southern Atlantic some 120 million years ago.The model now presented is, of course, still being debated in the scientific community, says the lead author, "but it is the most straightforward interpretation of what we observe in the Red Sea. Many details in salt- and sediment-covered areas that were previously difficult to explain suddenly make sense with our model." While it has thus been able to answer some questions about the Red Sea, the model also raises many new ones that inspire further research in the Red Sea from a whole new scientific perspective.
The research used Synthetic Aperture Radar data obtained by the European Space Agency Sentinel-1 satellite, amongst others, to evaluate Australia-specific case studies.Lead researcher Dr Amy Parker, an ARC Research Fellow from Curtin's School of Earth and Planetary Sciences, said the Sentinel-1 satellite mission provided the first complete global Synthetic Aperture Radar (SAR) dataset and the first opportunity to use this type of data to assess hazards in new locations, including Australia."What makes SAR so valuable is that it provides all-weather and night-and-day capability to remotely monitor the Earth's surface, unlike traditional optical Earth Observation (EO) imagery which is at the mercy of cloud, fog, rainfall and smoke," Dr Parker said."SAR data can be used to precisely map topography, track movements of the ground surface, characterize land-use change, and map damage to infrastructure, all of which can significantly improve how we track and respond to natural disasters."But despite SAR satellites being well-documented as a hazard monitoring tool, the uptake of such data varies, and in Australia the use of SAR data has been limited."The research applied SAR data to nine case studies covering critical issues such as bushfires, floods and earthquakes to assess the power of SAR as a disaster mitigation and prevention tool."For example we looked at the 2016 Wildman Coastal Plains Floods in the Northern Territory and found that SAR has added benefits in mapping flood patterns and floodplain dynamics."Dr Parker said these benefits can also be applied to maintaining mine site safety and better understanding seismic hazards and activity."Globally, Australia is one of the largest users of Earth observation data derived from satellites, which contributes to national hazard monitoring and response and more than 100 state and federal government programs. Our research shows SAR data can effectively complement this." Dr Parker said."Previously SAR data has been considered too expensive to use as a tool for hazard mitigation, but our findings show, through Sentinel-1 we now have economically viable wall-to-wall, consistent sensor imaging of Australia."The uptake of SAR data for hazard applications globally will continue to benefit from validated case studies such as ours, the development of tools that support operational use, and the continued provision of open-access imagery by large-scale satellite missions."
Both images exemplify what a new University of Washington-led study calls "location spoofing." The photos -- created by different people, for different purposes -- are fake but look like genuine images of real places. And with the more sophisticated AI technologies available today, researchers warn that such "deepfake geography" could become a growing problem.So, using satellite photos of three cities and drawing upon methods used to manipulate video and audio files, a team of researchers set out to identify new ways of detecting fake satellite photos, warn of the dangers of falsified geospatial data and call for a system of geographic fact-checking."This isn't just Photoshopping things. It's making data look uncannily realistic," said Bo Zhao, assistant professor of geography at the UW and lead author of the study, which published April 21 in the journal As Zhao and his co-authors point out, fake locations and other inaccuracies have been part of mapmaking since ancient times. That's due in part to the very nature of translating real-life locations to map form, as no map can capture a place exactly as it is. But some inaccuracies in maps are spoofs created by the mapmakers. The term "paper towns" describes discreetly placed fake cities, mountains, rivers or other features on a map to prevent copyright infringement. On the more lighthearted end of the spectrum, an official Michigan Department of Transportation highway map in the 1970s included the fictional cities of "Beatosu and "Goblu," a play on "Beat OSU" and "Go Blue," because the then-head of the department wanted to give a shoutout to his alma mater while protecting the copyright of the map.But with the prevalence of geographic information systems, Google Earth and other satellite imaging systems, location spoofing involves far greater sophistication, researchers say, and carries with it more risks. In 2019, the director of the National Geospatial Intelligence Agency, the organization charged with supplying maps and analyzing satellite images for the U.S. Department of Defense, implied that AI-manipulated satellite images can be a severe national security threat.To study how satellite images can be faked, Zhao and his team turned to an AI framework that has been used in manipulating other types of digital files. When applied to the field of mapping, the algorithm essentially learns the characteristics of satellite images from an urban area, then generates a deepfake image by feeding the characteristics of the learned satellite image characteristics onto a different base map -- similar to how popular image filters can map the features of a human face onto a cat.Next, the researchers combined maps and satellite images from three cities -- Tacoma, Seattle and Beijing -- to compare features and create new images of one city, drawn from the characteristics of the other two. They designated Tacoma their "base map" city and then explored how geographic features and urban structures of Seattle (similar in topography and land use) and Beijing (different in both) could be incorporated to produce deepfake images of Tacoma.In the example below, a Tacoma neighborhood is shown in mapping software (top left) and in a satellite image (top right). The subsequent deep fake satellite images of the same neighborhood reflect the visual patterns of Seattle and Beijing. Low-rise buildings and greenery mark the "Seattle-ized" version of Tacoma on the bottom left, while Beijing's taller buildings, which AI matched to the building structures in the Tacoma image, cast shadows -- hence the dark appearance of the structures in the image on the bottom right. Yet in both, the road networks and building locations are similar.The untrained eye may have difficulty detecting the differences between real and fake, the researchers point out. A casual viewer might attribute the colors and shadows simply to poor image quality. To try to identify a "fake," researchers homed in on more technical aspects of image processing, such as color histograms and frequency and spatial domains.Some simulated satellite imagery can serve a purpose, Zhao said, especially when representing geographic areas over periods of time to, say, understand urban sprawl or climate change. There may be a location for which there are no images for a certain period of time in the past, or in forecasting the future, so creating new images based on existing ones -- and clearly identifying them as simulations -- could fill in the gaps and help provide perspective.The study's goal was not to show that geospatial data can be falsified, Zhao said. Rather, the authors hope to learn how to detect fake images so that geographers can begin to develop the data literacy tools, similar to today's fact-checking services, for public benefit."As technology continues to evolve, this study aims to encourage more holistic understanding of geographic data and information, so that we can demystify the question of absolute reliability of satellite images or other geospatial data," Zhao said. "We also want to develop more future-oriented thinking in order to take countermeasures such as fact-checking when necessary," he said.Co-authors on the study were Yifan Sun, a graduate student in the UW Department of Geography; Shaozeng Zhang and Chunxue Xu of Oregon State University; and Chengbin Deng of Binghamton University.
Researchers have estimated that white shark populations are incredibly small, with only hundreds of large adults and a few thousand white sharks total in any of their global populations. This has made protecting white sharks a priority for conservation with many countries, including the United States and Mexico, having laws in place to prevent the catching and killing of the species.After uncovering a previously unknown white shark hot spot in the central Gulf of California, however, a new study involving University of Delaware assistant professor Aaron Carlisle suggests that these low numbers for eastern north Pacific white sharks, especially those listed in the Gulf of California, might be underestimated. In addition, the researchers found that the mortality rates for these white sharks might be underestimated as well, as an illicit fishery for the species was uncovered in the Gulf of California, suggesting that fishers were killing many more white sharks than has been previously understood.The research findings were published in For this study, Madigan interacted with a small group of local fishermen and over several months that group killed about 14 large white sharks. Of these, almost half could have been mature females. This was a conservative estimate as other groups reportedly killed additional sharks during this time.To show just how significant this new source of mortality might be, Carlisle pointed to a National Oceanic and Atmospheric Administration (NOAA) endangered species act status review on white shark populations from 2012. Using the best available information at the time, the NOAA report estimated that the adult female mortality rate for the entire eastern Pacific was likely around two annually."He found, in just a two-week time period, more mortality in this one location than what we thought for the whole ocean," said Carlisle. "It was pretty clear then that, well, something kind of important is happening here."Carlisle explained that the mortality estimate of the earlier NOAA study could have been off because calculating mortality for animals in the ocean -- figuring out how many die naturally or unnaturally -- is one of the most difficult population metrics to quantify.What makes this finding particularly interesting is that this population of white sharks -- the eastern Pacific population of white sharks -- is perhaps the most well-studied group of sharks on the planet. Here, in the midst of all this scientific research, was a seemingly robust population of white sharks that had eluded scientific study."It's been about 20 years since a new 'population' of white sharks has been discovered," said Carlisle. "The fact that the eastern Pacific has so much infrastructure focused on white sharks and we didn't know that there were these sites in the Gulf of California was kind of mind-blowing."Now that the aggregation has been identified, Carlisle said that there are many more scientific questions that need to be answered.There is a pressing need to study and quantify the population of sharks in the new aggregation site. In particular, it is unknown whether these sharks are part of the other known populations of white sharks in the eastern Pacific, which include populations that occur in Central California and Guadalupe Island Mexico, or whether they belong to a third, unknown population.They are also interested in finding out how long the aggregation sites have been there and how long people have been fishing at the sites."One of the big points of this paper was to raise the red flag and let managers and scientists know that this is going on and this population is here and needs to be studied," said Carlisle. "Hopefully, it will be studied by some local researchers who are invested and working with the local fishing communities because these fishing communities are all heavily dependent on marine resources and fisheries."Carlisle stressed that the researchers are not looking to cause problems for the local fishing communities that they worked with for the study.Instead, perhaps there is an opportunity for these communities to learn about other opportunities with these animals through avenues like eco-tourism, educating them on the fact that these sharks are worth more and could provide a steadier stream of revenue alive rather than dead."This seems like it would be a perfect situation for ecotourism, much like there is at Guadalupe Island," said Carlisle. "There could be huge opportunities to build businesses around these populations of sharks, and that's just from a management point of view. From a science point of view, there's all sorts of fun things you could do."Still, Carlisle said that more than anything, this paper highlights just how little we know about what is going on with sharks in the ocean."Even though we've studied these animals so much, we still know so little," said Carlisle. "How many fish are in the ocean is a very old but very hard question to answer."
Sometimes, the "gate" stops earthquakes in the magnitude 7 range, while ones that pass through the gate grow to magnitude 8 or greater, releasing over 32 times as much energy as a magnitude 7."An earthquake gate is like someone directing traffic at a one-lane construction zone. Sometimes you pull up and get a green 'go' sign, other times you have a red 'stop' sign until conditions change," said UC Riverside geologist Nicolas Barth.Researchers learned about this gate while studying New Zealand's Alpine Fault, which they determined has about a 75 percent chance of producing a damaging earthquake within the next 50 years. The modeling also suggests this next earthquake has an 82 percent chance of rupturing through the gate and being magnitude 8 or greater. These insights are now published in the journal Nature Geoscience.Barth was part of an international research team including scientists from Victoria University of Wellington, GNS Science, the University of Otago, and the US Geological Survey.Their work combined two approaches to studying earthquakes: evidence of past earthquakes collected by geologists and computer simulations run by geophysicists. Only by using both jointly were the researchers able to get new insight into the expected behavior of future earthquakes on the Alpine Fault."Big earthquakes cause serious shaking and landslides that carry debris down rivers and into lakes," said lead author Jamie Howarth, Victoria University of Wellington geologist. "We can drill several meters through the lake sediments and recognize distinct patterns that indicate an earthquake shook the region nearby. By dating the sediments, we can precisely determine when the earthquake occurred."Sedimentary records collected at six sites along the Alpine Fault identified the extent of the last 20 significant earthquakes over the past 4,000 years, making it one of the most detailed earthquake records of its kind in the world.The completeness of this earthquake record offered a rare opportunity for the researchers to compare their data against a 100,000-year record of computer-generated earthquakes. The research team used an earthquake simulation code developed by James Dieterich, distinguished professor emeritus at UC Riverside.Only the model with the fault geometry matching the Alpine Fault was able to reproduce the earthquake data. "The simulations show that a smaller magnitude 6 to 7 earthquake at the earthquake gate can change the stress and break the streak of larger earthquakes," Barth said. "We know the last three ruptures passed through the earthquake gate. In our best-fit model the next earthquake will also pass 82% of the time."Looking beyond New Zealand, earthquake gates are an important area of active research in California. The Southern California Earthquake Center, a consortium of over 100 institutions of which UCR is a core member, has made earthquake gates a research priority. In particular, researchers are targeting the Cajon Pass region near San Bernardino, where the interaction of the San Andreas and San Jacinto faults may cause earthquake gate behavior that could regulate the size of the next damaging earthquake there."We are starting to get to the point where our data and models are detailed enough that we can begin forecasting earthquake patterns. Not just how likely an earthquake is, but how big and how widespread it may be, which will help us better prepare," Barth said.
Their numbers appear to be increasing, following a long period of absence linked to population decline, according to research led by Cefas and the University of Exeter.Marine scientists in the UK and Ireland have analysed multiple datasets, spanning a 16-year period, to document the increase in bluefin, which arrive into the waters of the Celtic Seas and off South West England, the Scilly Isles, and North West Ireland to feed in late summer and autumn.The research is part of the Defra-funded "Thunnus UK" research project.Thunnus UK was established to improve knowledge of this species, as an essential first step in ensuring a positive future for Atlantic bluefin tuna around the UK.Central to the project's success has been a concerted effort to share and combine important data on where people have observed Atlantic bluefin tuna.This will help to identify where and when these fish are found in UK waters.Nearly 1,000 unique observations were recorded between 2013 and 2018 by citizen scientists, scientists, fishers and eco-tour leaders.Researchers found that Atlantic bluefin tuna begin to arrive in May and stay as late as January.However, peak numbers were recorded between August and October each year.The research draws on five key data sources:Lead author Tom Horton, of the University of Exeter, said: "Atlantic bluefin tuna are once again a feature in nearshore waters off the UK and Ireland."We've been able to document this story by using data from a wide variety of sources."We need to work together to ensure a future for Atlantic bluefin tuna, both in the UK and Ireland and more broadly throughout their range in the Atlantic Ocean."This is a really exciting study and the return of these fish suggest an important role in the UK's ecosystem."Jeroen van der Kooij, Principal scientist and Peltic Survey Lead, Cefas, said: "The unique data collected during our annual pelagic ecosystem survey of SW English waters is fundamental to this research."Marine animal observers from MARINELife on board our research vessel recorded not only the arrival, but also a subsequent year-on-year increase in sightings of bluefin tuna in the area."We will continue to collect this information, which, in combination with data on their prey fish and habitat collected during the same survey, will hopefully increase our knowledge of these exciting yet enigmatic animals."
An international team of researchers, including Carnegie Mellon University's Saoirse Foley, set out on an investigation to find the answer to this question. They looked to the transcriptomes, the sum of all the transcripts from the mRNA, of many tarantulas and other spiders from different time periods. Their findings were published online by They used the transcriptomes to build a genetic tree of spiders and then time-calibrated their tree with fossil data. Tarantula fossils are extremely rare, but the software used in the study managed to estimate the ages of older tarantulas relative to the ages of fossils from other spiders.They found that tarantulas are ancient, first emerging in the piece of land now considered the Americas about 120 million years ago during the Cretaceous period. At that time South America would have been attached to Africa, India and Australia as part of the Gondwana supercontinent. The spiders ultimately reached their present destinations due to continental drift, with a few interesting departures.For example, the nature of their entry into Asia suggests tarantulas may also be surprisingly proficient dispersers. The researchers were able to establish two separate lineages of tarantulas that diverged on the Indian subcontinent before it crashed into Asia, with one lineage being predominantly ground dwelling and the other predominantly arboreal. They found that these lineages colonized Asia about 20 million years apart. Surprisingly, the first group that reached Asia also managed to cross the Wallace Line, a boundary between Australia and the Asian islands where many species are found in abundance on one side and rarely or not at all on the other."Previously, we did not consider tarantulas to be good dispersers. While continental drift certainly played its part in their history, the two Asian colonization events encourage us to reconsider this narrative. The microhabitat differences between those two lineages also suggest that tarantulas are experts at exploiting ecological niches, while simultaneously displaying signs of niche conservation," said Foley.Additional study authors include Willam H. Piel and Dong-Qiang Cheng of the Yale-NUS College in Singapore and Henrik Krehenwinkel of UniversitÃ¤t Trier in Germany.
"There were about 10 undergrads involved in the project, spotting cows from space -- not your typical student research and always amusing to see in the lab," McCauley said. They became proficient at discerning the top view of a cow from the top view of rocks or the top view of other animals, he added."After about eight months, we ended up with more than 27,000 cattle annotations across 31 images," said Lacey Hughey, an ecologist with the Smithsonian Conservation Biology Institute who was a Ph.D. student in the McCauley Lab at the time, and the leader of the cow census. "It took a long time."All of the rather comical cow counting had a serious purpose, though: to measure the interactions between wildlife and livestock where their ranges meet or overlap. Roughly a third of the United States' land cover is rangeland, and where these grazing areas abut wildland, concerns over predation, competition and disease transmission are bound to arise.Such is the case at Point Reyes National Seashore, a picturesque combination of coastal bluffs and pastureland about an hour's drive north of San Francisco. As part of a statewide species restoration plan, native tule elk were reintroduced to the park's designated wilderness area in the 1990s, but they didn't stay in their little corner of paradise for very long."Some of them actually ended up swimming across an estero and establishing this herd -- which is known as the Drake's Beach Herd -- near the pastoral zone of the park, which is leased to cattle ranchers," said Hughey, the lead author of a collaborative study with the University of Nevada, Reno, that appears in the journal "So we were wondering, how do elk and cattle co-exist in this landscape?" Hughey said. "The story between elk and cattle is actually pretty complex. We know from other studies that elk and cattle can be competitors, but they can also be facilitators. We also didn't know very much about which habitats elk preferred in this part of the park and how the presence of cattle might influence an elk's decision to spend its time in one place over another."The researchers set out to answer these questions with two large datasets generated by the park -- GPS monitoring data from collared elk, and field-based transect surveys of the elk. What was missing, however, was information on the cows."We knew quite a bit about where the elk were, but we didn't have any information about where the cows were, except that they were inside the fences," she said. Knowing the precise number and location of cows relative to the elk herd would be necessary to understand how both species interact in a pastoral setting."Because the elk data was collected in the past, we needed a way to obtain information on cattle populations from the same time period. The only place we could get that was from archived, high-resolution satellite imagery," Hughey said. Hence, the satellite cowspotting.Their conclusion? Elk have acclimated to cattle at Point Reyes by avoiding cow pastures in general and by choosing separate foraging sites on the occassions that they co-occur. Taken together, these findings suggest that elk select habitat in a manner "that reduce[s] the potential for grazing conflicts with cattle, even in cases where access to forage is limited."In addition to helping shed light on the ecological relationship between cows and tule elk at Point Reyes, satellite imaging can also define their areas of overlap -- an important consideration in the assessment of disease risk, the researchers said."There's a disease of concern that's been found in the elk herd and also in the cattle, called Johne's disease," Hughey said. The bacteria that cause it can persist in the environment for more than a year, she added, so even though cows and elk rarely share space at the same time, there is still a theoretical risk of transmission in this system.According to the researchers, the satellite imaging technique is also widely applicable to other areas on the globe where livestock and wildlife ranges overlap."The issue of livestock and wildlife being in conflict is a major challenge in a bunch of different contexts in the U.S. and beyond," McCauley said. "It has been surprisingly hard to figure out exactly how these wild animals share space with domestic animals."These new methods, he said, "will have a transformative impact on understanding how livestock use wildlands -- and how wildlife use grazing lands."Next stop: Kenya and Tanzania.Working with the National Geospatial Intelligence Agency, Microsoft AI for Good, University of Glasgow, and University of Twente -- and thanks in large part to the data generated by those cow-tracking UC Santa Barbara undergrads -- Hughey and colleagues are training an algorithm to detect and identify animals in the plains of East Africa, such as wildebeest and, of course, cows.Research in the paper was also contributed by Kevin T. Shoemaker and Kelley M. Stewart at the University of Nevada and J. Hall Cushman at the Smithsonian Institution
The Atlantic Coast and Northern Great Plains populations of the piping plover were listed as federally threatened in 1985. The Atlantic coast population is managed in three regional recovery units, or regions: New England, which includes Massachusetts and Rhode Island; Mid-Atlantic, which includes New York and New Jersey; and Southern, which includes Delaware, Maryland, Virginia, and North Carolina.While the Atlantic populations are growing, piping plovers have not recovered as well in the Mid-Atlantic and Southern regions as they have in the New England region. The habitat differences uncovered by the study may be a factor in the unequal recovery."Knowing piping plovers are choosing different habitat for nesting up and down the Atlantic Coast is key information that resource managers can use to refine recovery plans and protect areas most needed for further recovery of the species," said Sara Zeigler, a USGS research geographer and the lead author of the study. "It will also help researchers predict how climate change impacts, such as increased storm frequency, erosion and sea-level rise, could affect habitat for this high-profile shorebird."The researchers found that piping plovers breeding in the New England region were most likely to nest on the portion of the beach between the high-water line and the base of the dunes. By contrast, plovers in the Southern region nested farther inland in areas where storm waves have washed over and flattened the dunes -- a process known as 'overwash.' In the Mid-Atlantic region plovers used both habitats but tended to select overwash areas more frequently.In general, overwash areas tend to be less common than backshore -- shoreline to dunes -- habitats. Nesting pairs that rely on overwash features, such as those in the Mid-Atlantic and Southern regions, have more limited habitat compared to birds in New England that have adapted to nesting in backshore environments.The authors suggest that the differences in nesting habitat selection may be related to the availability of quality food. Piping plover chicks, which cannot fly, must be able to access feeding areas on foot. In New England, piping plovers can find plenty of food along the ocean shoreline, so they may have more options for successful nesting. However, ocean shorelines along the Southern and Mid-Atlantic regions may not provide enough food, forcing adults and chicks to move towards bay shorelines on the interiors of barrier islands to feed. This would explain why so many nests in these regions occurred in overwash areas, which are scarcer than backshore areas but tend to provide a clear path to the bay shoreline.In all three regions, plovers most often chose to nest in areas with sand mixed with shells and with sparse plant life. These materials match the species' sandy, mottled coloring and help the birds blend into the environment, enhancing the camouflage that is their natural defense against predators. Piping plover adults may avoid dense vegetation because it may impede their ability to watch for foxes, raccoons, coyotes and other predators.The U.S. Atlantic Coast population of piping plovers increased from 476 breeding pairs when it was listed in 1985 to 1,818 pairs in 2019, according to the USFWS. The population increased by 830 breeding pairs in New England but only 349 and 163 pairs in the Mid-Atlantic and Southern regions respectively."This study will help us tailor coastal management recommendations in each region," said Anne Hecht, a USFWS endangered species biologist and a co-author of the paper. "We are grateful to the many partners who collected data for this study, which will help us be more effective in our efforts to recover the plover population.""This research will fuel further studies on piping plovers, their habitat-use and food resources," Zeigler added. "Refining the models used in this research will help researchers predict habitat availability with future changes in shorelines, sea level and beach profiles."
That matters because conserving biodiversity requires knowing what diversity exists in the first place. So biologists, led by University of Utah doctoral candidate Monte Neate-Clegg of the School of Biological Sciences, set out to compare four main lists of bird species worldwide to find out how the lists differ -- and why. They found that although the lists agree on most birds, disagreements in some regions of the world could mean that some species are missed by conservation ecologists."Species are more than just a name," Neate-Clegg says. "They are functional units in complex ecosystems that need to be preserved. We need to recognize true diversity in order to conserve it."The results are published in The definition of a species isn't clear-cut. Some scientists define populations as different species if they're reproductively isolated from each other and unable to interbreed. Others use physical features to delineate species, while yet others use genetics. Using the genetic definition produces many more species, but regardless of the method, gray areas persist."Species are fuzzy because speciation as a process is fuzzy," Neate-Clegg says. "It's a gradual process so it's very difficult to draw a line and say 'this is two species' vs. 'this is one species.'"Also, he says, physical features and genetic signatures don't always diverge on the same timescale. "For example," he says, "two bird populations may diverge in song and appearance before genetic divergence; conversely, identical populations on different islands may be separated genetically by millions of years."At this point in the story, it's time to introduce four lists, each of which purports to include all the bird species in the world. They are:"Being active field ornithologists who are always trying to ID bird species means that one is always faced with the issue of some species being on one list but not the other," says Ãa?an ?ekercio?lu, associate professor in the School of Biological Sciences. "So our field experience very much primed us to think about this question and inspired us to write this paper."The lists have different strengths depending on their application. The BirdLife International list, for example, integrates with the IUCN Red List, which reports on species' conservation status. The IOC list is updated by experts twice a year, ?ekercio?lu says. The list is open access with comparisons to other major lists, and changes are documented transparently."But as a birdwatcher, I use eBird all the time, which uses the Clements checklist, and that dataset is very powerful in its own right," Neate-Clegg says. "So there is no single best option."One example of the disagreement between lists might be the common bird In 2020, Neate-Clegg and his colleagues read a study that compared the raptor species on each list, finding that only 68% of species were consistent among all four lists."We thought it would be interesting to investigate taxonomic agreement for all 11,000 bird species," Neate-Clegg says. "More importantly, we wanted to try and work out what species characteristics led to more or less taxonomic confusion."They began by collecting the most recent version of each list (the IOC checklist is updated biannually, the researchers write, and the Clements and BirdLife lists annually, while Howard and Moore has not been updated since 2014) and trimming them down to exclude subspecies and any extinct species. Using a few other data processing rules, they assigned a single name to every possible species across all four lists. Then the comparisons began.The researchers found that the four lists agreed on the vast majority of bird species -- 89.5%. For the remaining 10.5%, then, they started to look for patterns that might explain the disagreement. Some of it was likely geographical. Birds from the well-studied Northern Hemisphere were more likely to find agreement than birds from the relatively understudied Southeast Asia and the Southern Ocean.Some of it was habitat-based. Agreement was higher for large, migratory species in relatively open habitats."I think the most surprising result was that agreement was not lower for highly forest-dependent species," Neate-Clegg says. "We expected these denizens of the rainforest floor to be the most cryptic and hard to study, with more uncertainty on their taxonomic relationships. Yet we found it was actually species of intermediate forest dependency that had lower taxonomic agreement. We believe that these species move about just enough to diverge, but not so much that their gene pools are constantly mixing."And part of the issue with species classification on isolated islands, such as those in Southeast Asia and the Southern Ocean, was a phenomenon called "cryptic diversification." Although islands can foster species diversification because of their isolation, sometimes two populations on different islands can appear very similar, even though their genes suggest that they've been isolated from each other for millions of years. So, depending on the definition, two populations could count as two species or as only one."In addition," Neate-Clegg says, "it's very hard to test the traditional biological species concept on island fauna because we cannot know whether two populations can interbreed to produce fertile young if they are geographically isolated."So what if some people disagree on species designations? Conservation actions are usually on the species level, Neate-Clegg says."If a population on one island goes extinct, people may care less if it's 'just a subspecies,'" he says. "And yet that island is potentially losing a functionally unique population. If it was recognized as a full species it might not have been lost."Neate-Clegg hopes the study points ornithologists towards the groups of species that merit additional attention."We also want conservation biologists to recognize that cryptic diversity may be overlooked," he adds, "and that we should consider units of conservation above and below the species level."
Researchers at UC Santa Barbara led by geneticist Paige Miller sought to uncover the diversity within the guts of these important kelp forest inhabitants. Their results reveal significant differences between the microbiota of the two species, as well as between individuals living in different habitats. The study, which appears in California hosts two common species of sea urchin: red and purple. They generally consume algae, but are actually fairly opportunistic omnivores that will eat decaying plant and animal matter, microbial mats and even other urchins if need be. The microbiome in their guts might help urchins handle such a varied diet, but it hasn't been examined until now."It's very important to understand what animals eat and why," Miller said, "and we think the microbiome could play an important role in why species thrive despite all the variation in food availability that's out there in the ocean." However, scientists are only beginning to investigate the microbiota of ocean animals, let alone the function these microorganisms serve in their hosts.To begin their investigation, Miller and her team collected red and purple urchins from three habitats in the Santa Barbara Channel. Some came from lush kelp forests; others from urchin barrens; and a few came from one of the channel's many hydrocarbon seeps, where they scratch a living feeding on mats of microbes that thrive off of petroleum compounds.Key to this study's success was the researchers' stringent protocol. They used meticulous techniques to remove each specimen's stomach and guts in order to avoid contamination from microbes in the lab, elsewhere on the animal, and even in the sea water.The researchers were then able to sequence a particular region of the genetic code that scientists commonly use to identify microbes. This enabled them to compare what they found with several comprehensive taxonomic databases that scientists use for genetic identification of microbial life.The team found significant differences between the bacterial communities living within the two urchin species. However, they saw just as much variation between the microbiomes of individuals from the same species living in different habitats."Our study is the first to examine the microbiome in these extremely common, and really ecologically important, species," said coauthor Robert (Bob) Miller, a researcher at the university's Marine Science Institute. "We're just scratching the surface here, but our study shows how complex these communities are."One group of bacteria that was prevalent in both species is the same group that helps break down wood in the guts of termites, and could help the urchins digest algae. Previous research indicates that these microbes could potentially be autotrophic. "Some members of this group can create their own food, like photosynthetic plants, for example," explained Paige Miller, "only they don't use sunlight for energy, they use hydrogen."Although the authors caution against jumping to conclusions, ascertaining whether urchins can produce their own food would be a huge revelation. "We know that the urchins can survive a long time without food," Bob Miller said. "And they can survive almost indefinitely in these barren areas that have very low food supplies. So, this could really help them out, if they have their own little farmed food supply in their gut."The findings also stress the oversight of conflating these similar species. People often treat species like the red and purple sea urchins as equivalent when making decisions about resource use and management, Paige Miller explained. Even ecologists can fall into this line of reasoning. "But it's very important to look at how these things actually function," she noted. "And as we saw, the red and purple sea urchins are not necessarily functioning the same way, or eating the same things, if their microbiome is an indicator."Understanding the makeup and function of microbiota could help researchers recognize the subtle differences between superficially similar species. "More recently, people have begun considering the microbiome as another trait that these species have," Bob Miller said. "We wanted to find out whether this is a hidden source of variation that's separating these two species."This study provides a launch point for additional research. In the future, the Millers and their coauthors plan to further investigate the function of the different microbes in urchin guts. For now, there's still more work to do simply identifying what species reside in the prickly critters."This is a new subfield of ecology," said Paige Miller, "trying to understand what these microbiomes do and the role they play in the living organism out in the wild."
"Colombia is a large country with a very distinct geography. The Andes Mountains cross the country from its southwest to northeast corner. Colombian coffee is currently growing in areas with different altitude levels, and climate impacts will likely be very different for low altitude and high altitude regions," says Sandy Dall'Erba, professor in the Department of Agricultural and Consumer Economics (ACE) and director of the Regional Economics Applications Laboratory (REAL) at U of I. Dall'Erba is co-author on the study, published in Other studies on the future of coffee production have either considered the country as a whole, or focused on a few areas within the country.Dall'Erba and lead author Federico Ceballos-Sierra, who recently obtained a Ph.D. from ACE, look at climate and coffee production for the entire country, broken down into 521 municipalities. This high level of detailed information allows them to identify significant regional variations."Colombia is not going to experience reduced productivity overall. But when we look into the impact across municipalities, we see many differences that get lost in the national average. That has important implications for coffee growers who live in one municipality versus another," Ceballos-Sierra says."Low-altitude municipalities will be negatively affected by climate change, and thousands of growers and their families in these areas will see their livelihood jeopardized because productivity is likely to fall below their breakeven point by mid-century," he states.The researchers analyze climate data from 2007 to 2013 across Colombia's 521 coffee-producing municipalities and evaluate how temperature and precipitation affect coffee yield. Subsequently, they model anticipated weather conditions from 2042 to 2061 and future coffee production for each municipal area.At the national level, they estimate productivity will increase 7.6% by 2061. But this forecast covers a wide margin of spatial differences, ranging from a 16% increase in high altitude regions (1,500 meters or 5,000 feet above sea level) to a 8.1% decrease in low altitude regions. Rising temperatures will benefit areas that are now marginal for coffee production, while areas that are currently prime coffee growing locations will be too hot and dry in the future.Ceballos-Sierra grew up on a coffee farm in the Tolima district of Colombia, and he has seen firsthand how changing climate conditions affect production."My family's farm is about 1,900 meters above sea level. Twenty years ago, people would consider that an upper marginal coffee growing area. But now we're getting significant improvements in yield," he says.Meanwhile, coffee growers in lowland areas see decreasing yields, while pests that prey on coffee plants, such as the coffee bean borer, are becoming more aggressive and prevalent.The research findings have important implications both for coffee growers and policymakers."In the future it will be more beneficial to grow coffee higher up in the mountains. So for those who can afford it, buying land in those areas would be a good investment," Dall'Erba states. "The government might want to consider building infrastructures such as roads, water systems, electricity, and communication towers that would allow farmers in more elevated places to easily access nearby hubs and cities where they can sell their crops. We would expect more settlements and an increasing need for public services in those locations."However, because relocation is expensive, it will not necessarily be an option for most of Colombia's 550,000 smallholder coffee growers, who will need to find other ways to adapt. Farmers might be able to implement new strategies, such as more frequent irrigation, increased use of forest shade, or shifting to different coffee varieties or other crops."Our research presents what we anticipate will happen 20 to 40 years from now, given current conditions and practices. Future studies can look into different adaptation strategies and their costs, and evaluate which options are best. Beyond the 40-year horizon we focus on, the prospects might be grimmer without adaptation. Production cannot keep moving to higher levels. Indeed, no mountain top is above 5,800 meters (18,000 feet) in Colombia," Dall'Erba says.Colombia's policymakers can also focus on supporting farmers who no longer will be able to make a living from growing coffee, so they can transition to something else, Ceballos-Sierra states."Looking into these regional estimates allows us to make predictions and provide policy suggestions. Specific place-tailored strategies should guide how coffee production adapts to future climate conditions in Colombia," he concludes.The researchers say their findings may also apply to other coffee growing locations, including Hawaii, California, and Puerto Rico in the United States.
Researchers found that since the late 1970s, winter's boundary with spring has been slowly disappearing, with one-third of 1,065 snow measurement stations from the Mexican border to the Alaskan Arctic recording increasing winter snowmelt. While stations with significant melt increases have recorded them mostly in November and March, the researchers found that melt is increasing in all cold season months -- from October to March.Their new findings, published today in "Particularly in cold mountain environments, snow accumulates over the winter -- it grows and grows -- and gets to a point where it reaches a maximum depth, before melt starts in the spring," said Keith Musselman, lead author on the study and research associate ,at the Institute of Arctic and Alpine Research (INSTAAR) at the University of Colorado Boulder.But the new research found that melt before April 1 has increased at almost half of more than 600 stations in western North America, by an average of 3.5% per decade."Historically, water managers use the date of April 1 to distinguish winter and spring, but this distinction is becoming increasingly blurred as melt increases during the winter," said Noah Molotch, co-author on the study, associate professor of geography and fellow at INSTAAR.Snow is the primary source of water and streamflow in western North America and provides water to 1 billion people globally. In the West, snowy mountains act like water towers, reserving water up high until it melts, making it available to lower elevations that need it during the summer, like a natural drip irrigation system."That slow trickle of meltwater that reliably occurs over the dry season is something that we have built our entire water infrastructure on in the West," said Musselman. "We rely very heavily on that water that comes down our rivers and streams in the warm season of July and August."More winter snowmelt is effectively shifting the timing of water entering the system, turning that natural drip irrigation system on more frequently in the winter, shifting it away from the summer, he said.This is a big concern for water resource management and drought prediction in the West, which depends heavily on late winter snowpack levels in March and April. This shift in water delivery timing could also affect wildfire seasons and agricultural irrigation needs.Wetter soils in the winter also have ecological implications. One, the wet soils have no more capacity to soak up additional water during spring melt or rainstorms, which can increase flash flooding. Wetter winter soils also keep microbes awake and unfrozen during a time they might otherwise lay dormant. This affects the timing of nutrient availability, water quality and can increase carbon dioxide emissions.Across the western U.S., hundreds of thin, fluid-filled metal pillows are carefully tucked away on the ground and out of sight from outdoor enthusiasts. These sensors are part of an extensive network of long-running manual and automated snow observation stations, which you may have even used data from when looking up how much snow is on your favorite snowshoeing or Nordic skiing trail.This new study is the first to compile data from all 1,065 automated stations in western North America, providing valuable statistical insight into how mountain snow is changing.And by using automated, continuously recording snowpack stations instead of manual, monthly observations, the new research shows that winter melt trends are very widespread -- at three-times the number of stations with snowpack declines, according to Musselman.Snowpack is typically measured by calculating how much water will be produced when it melts, known as snow-water equivalent (SWE), which is affected by how much snow falls from the sky in a given season. But because winter snowpack melt is influenced more by temperature than by precipitation, it is a better indicator of climate warming over time."These automated stations can be really helpful to understand potential climate change impacts on our resources," said Musselman. "Their observations are consistent with what our climate models are suggesting will continue to happen."Other authors on this publication include Nans Addor at the University of Exeter and Julie Vano at the Aspen Global Change Institute.
Pine Island Glacier is a region of fast-flowing ice draining an area of West Antarctica approximately two thirds the size of the UK. The glacier is a particular cause for concern as it is losing more ice than any other glacier in Antarctica.Currently, Pine Island Glacier together with its neighbouring Thwaites glacier are responsible for about 10% of the ongoing increase in global sea level.Scientists have argued for some time that this region of Antarctica could reach a tipping point and undergo an irreversible retreat from which it could not recover. Such a retreat, once started, could lead to the collapse of the entire West Antarctic Ice Sheet, which contains enough ice to raise global sea level by over three metres.While the general possibility of such a tipping point within ice sheets has been raised before, showing that Pine Island Glacier has the potential to enter unstable retreat is a very different question.Now, researchers from Northumbria University have shown, for the first time, that this is indeed the case.Their findings are published in leading journal, The Using a state-of-the-art ice flow model developed by Northumbria's glaciology research group, the team have developed methods that allow tipping points within ice sheets to be identified.For Pine Island Glacier, their study shows that the glacier has at least three distinct tipping points. The third and final event, triggered by ocean temperatures increasing by 1.2C, leads to an irreversible retreat of the entire glacier.The researchers say that long-term warming and shoaling trends in Circumpolar Deep Water, in combination with changing wind patterns in the Amundsen Sea, could expose Pine Island Glacier's ice shelf to warmer waters for longer periods of time, making temperature changes of this magnitude increasingly likely.The lead author of the study, Dr Sebastian Rosier, is a Vice-Chancellor's Research Fellow in Northumbria's Department of Geography and Environmental Sciences. He specialises in the modelling processes controlling ice flow in Antarctica with the goal of understanding how the continent will contribute to future sea level rise.Dr Rosier is a member of the University's glaciology research group, led by Professor Hilmar Gudmundsson, which is currently working on a major Â£4million study to investigate if climate change will drive the Antarctic Ice Sheet towards a tipping point.Dr Rosier explained: "The potential for this region to cross a tipping point has been raised in the past, but our study is the first to confirm that Pine Island Glacier does indeed cross these critical thresholds."Many different computer simulations around the world are attempting to quantify how a changing climate could affect the West Antarctic Ice Sheet but identifying whether a period of retreat in these models is a tipping point is challenging."However, it is a crucial question and the methodology we use in this new study makes it much easier to identify potential future tipping points."Hilmar Gudmundsson, Professor of Glaciology and Extreme Environments worked with Dr Rosier on the study. He added: "The possibility of Pine Island Glacier entering an unstable retreat has been raised before but this is the first time that this possibility is rigorously established and quantified."This is a major forward step in our understanding of the dynamics of this area and I'm thrilled that we have now been able to finally provide firm answers to this important question."But the findings of this study also concern me. Should the glacier enter unstable irreversible retreat, the impact on sea level could be measured in metres, and as this study shows, once the retreat starts it might be impossible to halt it."
Extra-terrestrial particles (condensation spherules) recovered on the summit of Walnumfjellet (WN) within the SÃ¸r Rondane Mountains, Queen Maud Land, East Antarctica, indicate an unusual touchdown event where a jet of melted and vaporised meteoritic material resulting from the atmospheric entry of an asteroid at least 100 m in size reached the surface at high velocity.This type of explosion caused by a single-asteroid impact is described as intermediate, as it is larger than an airburst, but smaller than an impact cratering event.The chondritic bulk major, trace element chemistry and high nickel content of the debris demonstrate the extra-terrestrial nature of the recovered particles. Their unique oxygen isotopic signatures indicate that their interacted with oxygen derived from the Antarctic ice sheet during their formation in the impact plume.The findings indicate an impact much more hazardous that the Tunguska and Chelyabinsk events over Russia in 1908 and 2013, respectively.This research, published by The study highlights the importance of reassessing the threat of medium-sized asteroids, as it likely that similar touchdown events will produce similar particles. Such an event would be entirely destructive over a large area, corresponding to the area of interaction between the hot jet and the ground.Dr van Ginneken said: 'To complete Earth's asteroid impact record, we recommend that future studies should focus on the identification of similar events on different targets, such as rocky or shallow oceanic basements, as the Antarctic ice sheet only covers 9% of Earth's land surface. Our research may also prove useful for the identification of these events in deep sea sediment cores and, if plume expansion reaches landmasses, the sedimentary record.'While touchdown events may not threaten human activity if occurring over Antarctica, if it was to take place above a densely populated area, it would result in millions of casualties and severe damages over distances of up to hundreds of kilometres.'
New work published in "Nearly all tectonic plates that make up the seafloor eventually bend and slide down into the mantle -- a process called subduction, which has the potential to recycle surface materials, such as water, into the Earth," explained Carnegie's Peng Ni, who co-led the research effort with Evan Smith of the Gemological Institute of America.Serpentinite residing inside subducting plates may be one of the most significant, yet poorly known, geochemical pathways by which surface materials are captured and conveyed into the Earth's depths. The presence of deeply-subducted serpentinites was previously suspected -- due to Carnegie and GIA research about the origin of blue diamonds and to the chemical composition of erupted mantle material that makes up mid-ocean ridges, seamounts, and ocean islands. But evidence demonstrating this pathway had not been fully confirmed until now.The research team -- which also included Carnegie's Steven Shirey, and Anat Shahar, as well as GIA's Wuyi Wang and Stephen Richardson of the University of Cape Town -- found physical evidence to confirm this suspicion by studying a type of large diamonds that originate deep inside the planet."Some of the most famous diamonds in the world fall into this special category of relatively large and pure gem diamonds, such as the world-famous Cullinan," Smith said. "They form between 360 and 750 kilometers down, at least as deep as the transition zone between the upper and lower mantle."Sometimes they contain inclusions of tiny minerals trapped during diamond crystallization that provide a glimpse into what is happening at these extreme depths."Studying small samples of minerals formed during deep diamond crystallization can teach us so much about the composition and dynamics of the mantle, because diamond protects the minerals from additional changes on their path to the surface," Shirey explained.In this instance, the researchers were able to analyze the isotopic composition of iron in the metallic inclusions. Like other elements, iron can have different numbers of neutrons in its nucleus, which gives rise to iron atoms of slightly different mass, or different "isotopes" of iron. Measuring the ratios of "heavy" and "light" iron isotopes gives scientists a sort of fingerprint of the iron.The diamond inclusions studied by the team had a higher ratio of heavy to light iron isotopes than typically found in most mantle minerals. This indicates that they probably didn't originate from deep-Earth geochemical processes. Instead, it points to magnetite and other iron-rich minerals formed when oceanic plate peridotite transformed to serpentinite on the seafloor. This hydrated rock was eventually subducted hundreds of kilometers down into the mantle transition zone, where these particular diamonds crystallized."Our findings confirm a long-suspected pathway for deep-Earth recycling, allowing us to trace how minerals from the surface are drawn down into the mantle and create variability in its composition," Shahar concluded.
The new findings challenge earlier assumptions that the size of the Earth's global ocean has remained constant over time and offer clues to how its size may have changed throughout geologic time, according to the study's authors.Most of Earth's surface water exists in the oceans. But there is a second reservoir of water deep in Earth's interior, in the form of hydrogen and oxygen attached to minerals in the mantle.A new study in The findings suggest that, since early Earth was hotter than it is today, its mantle may have contained less water because mantle minerals hold onto less water at higher temperatures. Assuming that the mantle currently has more than 0.3-0.8 times the mass of the ocean, a larger surface ocean might have existed during the early Archean. At that time, the mantle was about 1,900-3,000 degrees Kelvin (2,960-4,940 degrees Fahrenheit), compared to 1,600-2,600 degrees Kelvin (2,420-4,220 degrees Fahrenheit) today.If early Earth had a larger ocean than today, that could have altered the composition of the early atmosphere and reduced how much sunlight was reflected back into space, according to the authors. These factors would have affected the climate and the habitat that supported the first life on Earth."It's sometimes easy to forget that the deep interior of a planet is actually important to what's going on with the surface," said Rebecca Fischer, a mineral physicist at Harvard University and co-author of the new study. "If the mantle can only hold so much water, it's got to go somewhere else, so what's going on thousands of kilometers below the surface can have pretty big implications."Earth's sea level has remained fairly constant during the last 541 million years. Sea levels from earlier in Earth's history are more challenging to estimate, however, because little evidence has survived from the Archean eon. Over geologic time, water can move from the surface ocean to the interior through plate tectonics, but the size of that water flux is not well understood. Because of this lack of information, scientists had assumed the global ocean size remained constant over geologic time.In the new study, co-author Junjie Dong, a mineral physicist at Harvard University, developed a model to estimate the total amount of water that Earth's mantle could potentially store based on its temperature. He incorporated existing data on how much water different mantle minerals can store and considered which of these 23 minerals would have occurred at different depths and times in Earth's past. He and his co-authors then related those storage estimates to the volume of the surface ocean as Earth cooled.Jun Korenaga, a geophysicist at Yale University who was not involved in the research, said this is the first time scientists have linked mineral physics data on water storage in the mantle to ocean size. "This connection has never been raised in the past," he said.Dong and Fischer point out that their estimates of the mantle's water storage capacity carry a lot of uncertainty. For example, scientists don't fully understand how much water can be stored in bridgmanite, the main mineral in the mantle.The new findings shed light on how the global ocean may have changed over time and can help scientists better understand the water cycles on Earth and other planets, which could be valuable for understanding where life can evolve."It is definitely useful to know something quantitative about the evolution of the global water budget," said Suzan van der Lee, a seismologist at Northwestern University who did not participate in the study. "I think this is important for nitty-gritty seismologists like myself, who do imaging of current mantle structure and estimate its water content, but it's also important for people hunting for water-bearing exoplanets and asking about the origins of where our water came from."Dong and Fischer are now using the same approach to calculate how much water may be held inside Mars."Today, Mars looks very cold and dry," Dong said. "But a lot of geochemical and geomorphological evidence suggests that early Mars might have contained some water on the surface -- and even a small ocean -- so there's a lot of interest in understanding the water cycle on Mars."
Modelling from the Sydney School of Veterinary Science suggests pressure on ecosystems, climate change and economic development are key factors associated with the diversification of pathogens (disease-causing agents, like viruses and bacteria). This has potential to lead to disease outbreaks.The research, by Dr Balbir B Singh, Professor Michael Ward, and Associate Professor Navneet Dhand, is published in the international journal, They found a greater diversity of zoonotic diseases (diseases transmitted between animals and humans) in higher income countries with larger land areas, more dense human populations, and greater forest coverage.The study also confirms increasing population growth and density are major drivers in the emergence of zoonotic diseases. The global human population has increased from about 1.6 billion in 1900 to about 7.8 billion today, putting pressure on ecosystems.Associate Professor Dhand said: "As the human population increases, so does the demand for housing. To meet this demand, humans are encroaching on wild habitats. This increases interactions between wildlife, domestic animals and human beings which increases the potential for bugs to jump from animals to humans.""To date, such disease models have been limited, and we continue to be frustrated in understanding why diseases continue to emerge," said Professor Ward, an infectious diseases expert."This information can help inform disease mitigation and may prevent the next COVID-19."Other zoonotic diseases that have recently devastated human populations include SARS, avian (H5N1) and swine (H1N1) flu, Ebola and Nipah -- a bat-borne virus.The researchers discovered country-level factors predicting three categories of disease: zoonotic, emerging (newly discovered diseases, or those diseases that have increased in occurrence or occurred in new locations), and human."Countries within a longitude of -50 to -100 like Brazil, developed countries like United States and dense countries such as India were predicted to have a greater diversity of emerging diseases," Professor Ward said.The researchers also noted weather variables, such as temperature and rainfall, could influence the diversity of human diseases. At warmer temperatures, there tend to be more emerging pathogens.The analyses demonstrate that weather variables (temperature and rainfall) have the potential to influence pathogen diversity These factors combined confirm human development -- including human-influenced climate change -- not only damages our environment but is responsible for the emergence of infectious diseases, such as COVID-19."Our analysis suggests sustainable development is not only critical to maintaining ecosystems and slowing climate change; it can inform disease control, mitigation, or prevention," Professor Ward said."Due to our use of national-level data, all countries could use these models to inform their public health policies and planning for future potential pandemics."The authors acknowledge the data relied for this research is incomplete. Reasons include underreporting of some previously known and undiscovered pathogens, particularly in less developed countries. For some of the predictor variables, the latest data available had missing values because recent data had not been updated.
A bird's eye view can reveal much about these changes. Annual aerial surveys conducted by the Colorado State Forest Service and USDA Forest Service have provided yearly snapshots for the state. New collaborative research led by Colorado State University and the University of Wisconsin-Madison now supplements this understanding with even greater spatial detail.The study, "Effects of Bark Beetle Outbreaks on Forest Landscape Pattern in the Southern Rocky Mountains, U.S.A.," analyzed Landsat satellite imagery between 1997-2019 to quantify how outbreaks of three different insect species have impacted forests across high-elevation forests in Colorado, southern Wyoming, and northern New Mexico. The research team found that while these collective beetle outbreaks impacted around 40 percent of the area studied, the effects of these outbreak varied due to differences in forest structures and species composition across the region."In contrast to research that has examined the heterogeneous effects of wildfire on trees, there hasn't been much work on the landscape-level variation in bark beetle effects on forests, particularly across broad areas," said Sarah Hart, co-author and assistant professor in the Forest and Rangeland Stewardship department. "Heterogeneity plays an important role in how these forests will look in the future, where surviving trees will regenerate the forest, and what potential there is for future outbreaks."Their results indicate that most forest stands affected by insects still have mature trees that can be sources for reestablishing seeds and conditions for the next generation of trees to grow. Areas with tree mortality greater than 90 percent were relatively small and isolated. Unlike severe wildfires that can kill all trees in its path, trees typically survive bark beetle outbreaks, facilitating forest recovery in upcoming decades.Widespread outbreaks of three important bark beetle species have occurred in Colorado's forests since the turn of the century: mountain pine beetle, spruce beetle, and the western balsam beetle (that affects various fir tree species). These bark beetles primarily target large trees with reduced defenses due to lower precipitation amounts and higher temperature trends since the turn of the century.This research team combined satellite imagery capable of identifying small groups of dead trees with a decade of extensive field data from nearly 250 plots to develop presence and severity maps for tree mortality caused by bark beetle attacks. Having this data combination gave the research team detailed information about how many trees have died in particular places, and helped to identify what may still be causing the death of individual trees."These maps give us unique insight into the effects of recent insect outbreaks because they span a large area but also show a lot of detail, and we are confident that they are showing us how many trees are dying because technicians counted trees on the ground," Kyle Rodman, lead author and post-doctoral researcher at the University of Wisconsin-Madison said.The maps the team produced indicate that areas most impacted by bark beetles are concentrated in northern and southwestern Colorado due to higher concentrations of old lodgepole pine and spruce forests which were then infested by mountain pine beetle and spruce beetle, respectively. Western balsam beetle impacts were also widespread across the region, but these beetles tended to kill fewer trees in any single location."Satellite data is a crucial bridge that allows us to take detailed information from individual places and extend this localized knowledge to large areas," Rodman said. "In using these maps, we can see how the forest has changed over the past 20 years during each of these outbreaks."Fortunately, much of the 25,000 square kilometer study area showed low to moderate levels of tree mortality, with high tree mortality being contained in small and isolated patches averaging only about nine city blocks in overall size."People tend to notice what has changed, rather than what has stayed the same," Rodman said. "These forests have changed a lot, but I am hopeful. It will just take a little while for them to recover, but many of these beetle-killed forests are likely to recover within a few decades."
Vize Island, located in the northern part of the Kara Sea, is one of the least studied islands of the Russian High Arctic in terms of its biota. Scientists Dr Maria V. Gavrilo of the Arctic and Antarctic Research Institute in Russia and Dr Igor I. Chupin of the Institute of Systematics and Ecology of Animals in Russia visited this ice-free lowland island in the summer of 2020."Our expedition studied the ecology of Ivory Gull," Maria Gavrilo says, "but we also looked for other wildlife." Because of the lack of data, scientists appreciate any observation on insects they can get from the High Arctic.On the island, the team found hundreds of small moths. They were identified by Dr Mikhail V. Kozlov of the University of Turku, Finland, as Larch Budmoths -- the first and only terrestrial invertebrate to ever be observed and collected on Vize Island. Their observations are published in the open-access, peer-reviewed journal The scientists first observed live and freshly dead moths on the sandy banks of a pond near the meteorological station. Then, they saw hundreds of them at the sandy bottom of a river valley with shallow streams. Moths, single or in groups, were mostly found at the water's edge, along with some fine floating debris. Despite extremely low daily temperatures (+2-5Â°C), flying moths were also spotted on several occasions.The larvae of Larch Budmoth feed on the needles of different coniferous trees. Because Vize Island is located 1000 km north of the tree limit, the scientists can be sure about the migratory origin of the moths observed on Vize Island. They were likely transported there on 12-14 July 2020 by strong winds coming from the continent. The nearest potential source population of Larch Budmoth is located in the northern part of the Krasnoyarsk Region, which means they travelled at least 1200 km.Importantly, some moths remained alive and active for at least 20 days after their arrival, which means that long-distance travel did not critically deplete resources stored in their bodies. The current changes in climate are making it easier for more southerly insects to invade species-poor areas in the High Arctic islands -- provided they can reach them and survive there."The successful arrival of a large number of live moths from continental Siberian forests to Vize Island has once more demonstrated the absence of insurmountable barriers to initial colonisation of High Arctic islands by forest insects," concludes Mikhail Kozlov, who has studied Arctic insects for decades. "The Arctic islands will be colonised by forest insects as soon as changing environmental conditions allow the establishment of local populations."
An international research team led by the Weather and Climate Risks Group at ETH Zurich has just published a new study aimed at providing a better understanding of future displacement risks due to flooding from rivers overflowing their banks. Their study also evaluates the influence of climate change as well as demographic and socioeconomic factors on these risks.Using a variety of climate, hydrology and population distribution models, the researchers show that if the population remains stable at its current level, the risk of flood-related displacement increases by more than 50 percent (relative to 2010 levels) for each degree of global warming.However, the world's population is growing. Even if this growth continues towards a more sustainable path, the risk of displacement will still increase significantly: assuming that the world meets the Paris Agreement's goal of limiting global warming to a maximum of 2Â° Celsius, the globally averaged risk is projected to rise by up to 110 percent by the end of this century.However, under "business as usual" climate-change conditions and if the gap between rich and poor continues to widen, the risk is projected to increase even more dramatically. For this scenario, the researchers calculated that the risk of displacement due to flooding would be up to 350 percent higher.According to the study's authors, it is not yet too late to address and manage the risk of flood displacement through spatial and urban planning measures and protective infrastructure such as dams. "Our findings highlight the need for rapid action on both climate mitigation and adaptation agendas in order to reduce future risks, especially to vulnerable populations," says Pui Man Kam, lead author of the study and doctoral student in ETH Professor David N. Bresch's group. "Floods often affect the most socio-economically vulnerable groups, who tend to live in more hazard-prone areas," she explains.To conduct their study, the researchers used a global climate-, hydrology- and inundation-modelling chain to quantify the effect of global warming on displacement risk for both current and projected future population distributions. The study has just been published in the journal "Because floods are a major driver of displacement and due to the fact that they are influenced by climate change, it is imperative that we have a better understanding of how the risks are changing," Kam says.
Gray's beaked whales living in the deep oceans of the Southern Hemisphere are rarely seen alive and their ecology has remained a mystery to scientists until now.The study used genome sequencing of 22 whales washed up on beaches in South Africa, Australia and New Zealand to investigate the history of the population over the past 1.1 million years.Author of the study Dr Kirsten Thompson, of the University of Exeter, said: "The population approximately doubled about 250 thousand years ago, coinciding with a period of increased Southern Ocean productivity, sea surface temperature and a potential expansion of suitable habitat."The current population appears to have high levels of genetic diversity and no "genetic structure" (patterns of genetic similarity in geographical areas), suggesting the whales leave their birth groups and move widely throughout their Southern Hemisphere range.Based on these findings, this perfect match of high genetic diversity, a flexible social system and the rich habitats of Southern Hemisphere mean that Gray's beaked whales could be to be resilient to changing conditions."Human activity is causing rapid ecological change in every habitat on Earth, including the deep oceans," said Dr Thompson."We need to understand how different species might respond to these changes, but we lack detailed knowledge on many animals, particularly deep-sea whales like Gray's beaked whales."Observation data on this species is impossible to obtain -- they are small (five metres), deep-diving whales that spend most of their time below the surface searching and feeding on squid -- whalers nicknamed them "scamperdown whales" due to their elusive behaviour.The study used both mitochondrial DNA to investigate the history of the population, and partial nuclear genomes to estimate population structure."Our findings suggest numbers of Gray's beaked whales have been relatively stable for the last 1.1 million years," Dr Thompson said."The Southern Hemisphere's oceans could potentially support a surprisingly large number of Gray's beaked whales. Good news for one species at least."We show how genomic tools can help to reveal past history, current status and potential near-future changes in animal populations that are enigmatic, rarely observed and beyond the reach of traditional boat surveys."
The results, published March 26 in "Strontium is very similar to calcium, so it gets incorporated into the calcium carbonate shells of marine organisms," explained lead author Adina Paytan, research professor in the Institute of Marine Sciences at UC Santa Cruz.Paytan and her coauthors looked at the ratios of different isotopes of strontium, including radiogenic isotopes (produced by radioactive decay) and stable isotopes, which provide complementary information about geochemical processes. They found that the stable isotope ratio of strontium in the ocean has changed considerably over the past 35 million years, and it is still changing today, implying large changes in seawater strontium concentration."It's not in a steady state, so what's coming into the ocean and what's leaving don't match," Paytan said. "The strontium composition of seawater changes depending on how and where carbonates are deposited, and that is influenced by changes in sea level and climate."The fluctuations in strontium isotope ratios analyzed in this study reflect the combined effect of shifts in the global balance of geologic processes including weathering of rocks on land, hydrothermal activity, and the formation of carbonate sediments in both deep-sea and shallow, nearshore marine environments.Carbonate deposition in the open ocean comes from marine plankton like coccolithophores and foraminifera, which build their shells of the calcium carbonate mineral calcite. In shallow water on the continental shelves, hard corals are more abundant, and they build their skeletons of a different mineral of calcium carbonate, aragonite, which incorporates more strontium than calcite does."When corals form, they remove strontium, and when they are exposed, this strontium washes out and goes back into the ocean," Paytan said. "With changes in sea level, more or less of the continental shelf where corals grow is exposed, so that impacts the strontium composition of seawater."Carbonate deposition also feeds back into the climate system, because the ocean absorbs carbon dioxide from the atmosphere, and carbonate deposition on geological timescales removes carbon from the system. The global carbon cycle and atmospheric carbon dioxide are tightly coupled to climate change, both in the long-term and during the recurring ups and downs of recent ice age cycles."The new type of information we can read from the stable strontium isotopes now allows us to take a close look at the business end of the global carbon cycle, when carbon is removed from the environment and laid down into marine carbonate beds," said coauthor Mathis Hain, assistant professor of Earth and planetary sciences at UCSC."These findings throw open a new window to let us see how the global carbon cycle adjusted to sea level and climate change through geologic time," he added. "We will need these insights in guiding our response to our current climate emergency and to mitigate the worst effects of ocean acidification."The researchers were able to reconstruct a robust and detailed record of strontium isotope variations in seawater based on an analysis of marine barite extracted from deep-sea sediment cores."Records like this are critical to understanding how our earth operates over geologic times," said coauthor Elizabeth Griffith at Ohio State University. "Our international team worked together to both create this unique record and explain its significance through mathematical modeling, so we can reconstruct changes in the past when the climate conditions were different. The hope is to gain insight into how our blue planet might operate in the future."In addition to Paytan, Hain, and Griffith, the coauthors of the paper include Anton Eisenhauer and Klaus Wallmann at the GEOMAR Helmholtz Center for Ocean Research in Germany, and Andrew Ridgwell at UC Riverside. This work was supported by the National Science Foundation.
The new research method, which combines location data from GPS-tagged albatross and commercial fishing vessels, allows researchers to accurately identify bird-vessel encounters and better understand bird behavior, environmental conditions and the characteristics that influence these encounters."It is hard to conceptualize how often birds encounter vessels in the open ocean, but with this new data, it becomes really apparent," said Rachael Orben, an assistant professor in the Department of Fisheries and Wildlife in Oregon State University's College of Agricultural Sciences and the study's lead author. "Some of these birds are in an environment where they see vessels all the time, while others are in an environment where they rarely encounter vessels."The findings were just published in the Albatross are large, long-lived seabirds that roam widely over the open ocean. Three albatross species are found in the North Pacific: the black-footed albatross, the Laysan albatross and the short-tailed albatross. All three species are of high conservation concern and the short-tailed albatross is listed as endangered under the Endangered Species Act.Fishing activity can offer the birds opportunities for foraging, but not without risks, including threat of bycatch. Bycatch is the term for fish, birds or other animals caught unintentionally and includes interactions with fishing vessels and fishing gear.Researchers have been using biologging, the practice of attaching data recording devices to animals, to track individual bird movements at sea for more than 20 years. But they have not had much access to information about the location of vessels, which is a critical piece to understanding the seabird-fishery interaction puzzle, Torres said.Torres learned that Global Fishing Watch was processing and making available data from the Automatic Identification System, or AIS, an automatic tracking system that uses transceivers on ships. The data includes information about vessel size, movement, fishing method and more. Access to the data was a "game-changer," she said."With their data, you can track individual vessels," Torres said. "You can get precise information about a vessel's location, its size, the type of fishing gear it is using and the flag nation of the ship."Global Fishing Watch's goals include making commercial fishing on the high seas more transparent to the public, improving fisheries regulation and ensuring sustainability of ocean resources."This study represents a new frontier in our ability to understand how fisheries impact marine life," said David Kroodsma, director of research and innovation at Global Fishing Watch. "Vessel tracking data, collected by satellites and processed with machine learning, can be a powerful tool to analyze how biodiversity and fishing vessels interact at sea."Members of the research team had previously collected albatross tracking data from adult black-footed albatross and Laysan albatross breeding in the Papah?naumoku?kea Marine National Monument in the Northwest Hawaiian Islands; Laysan albatross nesting on Oahu, Hawaii; and juvenile short-tailed albatross originating from their colonies in Japan.The researchers were able to marry data on fishing vessels with tracking data from the GPS-tagged albatross during the same periods to identify and locate where bird-vessel interactions occur throughout the North Pacific Ocean.When birds are within 30 kilometers of a vessel, the researchers assumed the albatross was aware of the vessel's presence, Orben said. When the bird was within 3 kilometers of the vessel, researchers assumed a close encounter between the two. The research team then modeled the drivers of these close encounters."With these models, we can start to understand why birds sometimes do and sometimes don't interact with a fishing vessel," Torres said. "This information can help identify how and when efforts should be made to make sure these interactions don't go wrong for the bird. As we start to identify patterns, we can potentially help mitigate these bycatch events.""These results indicate that it may be more important to use bycatch mitigation methods from a fishing vessel in low wind conditions," Torres said. "Things like that can help guide efforts to reduce bycatch of seabirds. The best regulations are those that are the least burdensome to fishermen and the most effective."The analysis framework developed by the researchers could be used to study encounters between fishing vessels and other seabirds or marine mammals. Information gathered through the study of these interactions could help inform fisheries management decisions, as well, the researchers said."Our study is really one of the first to look at the fine-scale overlap between fishing vessels and marine animals on the high seas, in international waters," Torres said. "It opens a whole new understanding of the dynamics between animals and vessels. This work can help the fishing community fish better and help these seabirds survive and thrive."
A 12-centimetre-thick sample of a deposit from a cave in the northeast of Greenland offers unique insights into the High Arctic's climate more than 500,000 years ago. The geologist and cave scientist Prof. Gina Moseley collected it during an exploratory expedition in 2015 for her palaeoclimatic research in one of the most sensitive areas of the world to climate change. The cave is located at 80Â° North 35 km from the coast and 60 km from the Greenland Ice Sheet margin. It was part of the Greenland Caves Project, funded by 59 different sponsors including the National Geographic Society. Moseley and her team are interested in the climate and environmental history captured by the unique cave deposit."Mineral deposits formed in caves, collectively called speleothems, include stalagmites and stalactites. In this case we analysed a flowstone, which forms sheet-like deposits from a thin water film," explains Moseley. It is very special to find a deposit of this kind in the High Arctic at all, the geologist continues: "Today this region is a polar desert and the ground is frozen due to permafrost. In order for this flowstone to form, the climate during this period must have been warmer and wetter than today. The period between about 588,000 to 549,000 years before present is generally considered to be globally cool in comparison to the present. The growth of the speleothem at this time, however, shows that the Arctic was surprisingly warm."Gina Moseley therefore highlights the regional heterogeneities that need to be considered when researching climate change especially for future developments in a warmer world. "Our results of a warmer and wetter Arctic support modelling results showing that regional heterogeneities existed and that the Arctic was anomalously warm as a consequence of the Earth's orbital relationship to the sun at the time. Associated with these warmer temperatures was a reduction of the extent of sea ice in the Arctic, thus providing open ice-free waters from which moisture could be evaporated and transported to northeast Greenland," adds the geologist from the University of Innsbruck. The speleothem palaeoclimate record offers the possibility to extend the knowledge of Greenland's past climate and hydrological conditions beyond the 128,000-year-limit of the deep Greenland ice cores. The team used state-of-the-art methods such as uranium-thorium dating which is able to enlarge the timeline much further back. "Since the Greenland ice cores are biased towards the last glacial period and therefore cold climates, the speleothem record provides a nice counter-balance with respect to past warm periods," Moseley says. "The Arctic is warming at more than twice the rate of the global average. Understanding more about how this sensitive part of the world responds in a warmer world is very important."Gina Moseley identified the importance of the caves in northeast Greenland back in 2008 while doing her PhD in Bristol, UK. In 2015, she led a five-person expedition funded by many different sponsors. The expedition was a challenge: The team first tried to fly as far as possible, then crossed a 20-kilometre-wide lake in a rubber boat and then had to hike for three days to get to the caves. This was the first time such climate records had been made from caves in the High Arctic and Gina Moseley was awarded the START Prize from the Austrian Science Fund (FWF) for her research, which enabled her to start a new six-year research project. In July 2019, Moseley and her Greenland Caves Project team returned to northeast Greenland for a three-week expedition.
How high is Mount Everest? 8848 meters? 8844 meters? Or 8850 meters? For years, China and Nepal could not agree. In 2019, Nepal sent a team of geodesists to measure the world's highest mountain. A year later a team from China climbed the peak. Last December the two governments jointly announced the outcome of the new measurement: 8848.86 meters.The fact that both China and Nepal recognize this result must be seen as a diplomatic success. It was made possible by the new International Height Reference System (IHRS), used for the first time by the geodetic specialists conducting the new measurement. Scientists from TUM played a leading role in developing the new system. It establishes a generally agreed zero level as a basis for all future measurements. It thus replaces the mean sea level, which has traditionally served as the zero level for surveyors and thus for all topographical maps. A paper in the The standard used until now -- the mean sea level -- was flawed from the outset: There was never a fixed definition. Every country could use arbitrary tide gauges to define its own zero level. As a result, Germany's official sea level is 31 centimeters higher than Italy's, 50 cm higher than that used in Spain and actually 2.33 m higher than in Belgium, where the zero height is based on low water in Ostend.When topographical maps are only used for hiking, no one is bothered by such differences. But for geodetics specialists trying to arrive at a universally agreed height -- for Mount Everest, for example, half in Nepal and half in China -- the inconsistent zero levels are a bigger problem. And it can be very costly when planners of cross-border structures such as bridges and tunnels forget to check the different coordinates used by the teams and convert them as needed. On the HochrheinbrÃ¼cke, a bridge connecting Germany and Switzerland, a discrepancy of this kind was noticed just in time."The introduction of an internationally valid height reference system was long overdue," says TUM researcher Dr. Laura SÃ¡nchez of the Deutsches GeodÃ¤tisches Forschungsinstitut (DGFI-TUM), who has headed working groups studying theoretical aspects and implementing the new global height reference system at the International Association of Geodesy for several years.What is needed is obvious: a universally accepted zero level. The new International Height Reference System (IHRS) defines how it can be calculated: It takes into account the shape of the Earth -- which is close to spherical, but flattened at the poles and bulging slightly at the equator due to its rotation -- and the uneven distribution of masses in the interior and on the surface. The resulting irregularities in the gravity field are the basis for calculating the height system because the strength and direction of the force determine the distribution of water in the oceans. If we assume that the Earth's surface is completely covered with water, the height of a hypothetical sea level and thus the zero level for the entire globe can be calculated precisely."It became possible to realize the IHRS only with the availability of global data from satellite missions such as the ESA earth observation satellite GOCE (Gravity field and steady-state Ocean Circulation Explorer)," says Prof. Roland Pail of the TUM Chair of Astronomical and Physical Geodesy (APG). His team played an integral role in analyzing the GOCE measurements and using them to calculate global models of the Earth's gravity field. "The information gained in this way provides the basis to calculate the mean sea level for every point on Earth with the new International Height Reference System, regardless of whether it is on a continent or in an ocean, and thus to compute the internationally accepted zero level," explains SÃ¡nchez.Does every map have to be redrawn? "It won't be that dramatic," says SÃ¡nchez. "In the industrial countries, where they have been making gravity measurements for decades, the deviations are quite small -- only in the decimeter range." But with construction projects, for example, even small deviations can cause serious troubles. Consequently, the scientist is confident that the new reference system will gain acceptance quickly.
Using cutting-edge 3D satellite technology, a study led by Florida Atlantic University's Harbor Branch Oceanographic Institute, in collaboration with NOAA's National Marine Fisheries Service; OCEARCH; The South Fork Natural History Museum and Nature Center; and the Wildlife Conservation Society, is providing a unique look into how young white sharks in the North Atlantic Ocean travel and use their habitats. The study also is the first to provide fine-scale analysis of vertical movement behavior in young-of-year (1 to 2 years) and juvenile white sharks (Carcharodon carcharias) in the New York Bight, the only confirmed white shark nursery area in the entire North Atlantic Ocean.Results published in the journal Data from the study simultaneously address many questions on the ecology, behavior and conservation of a highly mobile marine species that has been challenging to explore, and will inform ongoing preservation strategies for this vulnerable white shark population."We have known about the importance of nurseries for young sharks for some time, however, knowledge of the finer scale use of shelf systems by these animals has been limited. This lack of information impacts our understanding of potential shark 'hotspots' within these large ecosystems," said Rachel Shaw, lead author, and a recent graduate from the Fisheries Ecology and Conservation (FEC) Lab, led by Matt Ajemian, Ph.D., co-author and an assistant research professor at FAU Harbor Branch.Between 2016 and 2019, 21 young-of-year and juvenile white sharks were fitted with satellite and acoustic tags to examine their distribution and habitat selection during late summertime (August to October) in the New York Bight -- the coastal region between Montauk, New York and Cape May, New Jersey. Movement data from the 21 young white sharks were collected (11 males and 10 females ranging in size from 54 to 61 inches in length) and linked to environmental measurements from remote sensing platforms.These data sets produced the first-ever glimpse into the 3D movements for these young white sharks alongside oceanographic features like bathymetry (submarine topography), sea surface temperature, chlorophyll-a levels, and sea surface salinity."Undoubtedly, our research shows that young white sharks traverse variable oceanographic features across the continental shelf in the New York Bight, but they certainly have their habitat preferences," said Shaw.The vertical diving behavior and accompanying measurements showed that sharks encountered several areas across the shelf with thermally stratified water column structure. This was most evident around the Hudson Shelf Valley region where some of the coldest bottom temperatures were recorded during the summertime, and is indicative of the "cold pool" that sets up in this region. Further, young white sharks also selected areas with relatively high levels of productivity (i.e., mesotrophic waters) as reflected by salinity and chlorophyll-a concentration. Tagged individuals selected sea surface salinities slightly less saline than oceanic waters, which are typically associated with coastal areas.Altogether, the research suggests young white sharks prefer nearshore habitats, but can exhibit connectivity between the immediate shoreline and mid-continental shelf region, where they play important ecological roles as apex predators on a variety of species. The study improves characterization of essential habitat for young white sharks and provides new insights into their reliance on this productive continental shelf ecosystem, which may provide them with the resources needed to grow quickly as well as a refuge from predators."While the northwest Atlantic white shark population appears to be recovering from historical overfishing, there is considerable uncertainty in their population dynamics, seasonal habitat preferences, ecological roles, and exposure to environmental impacts," said Ajemian. "Understanding species-habitat relationships is critical for predicting the potential impacts of long-term environmental changes including climate change, which is disproportionately affecting this region."
In the Arctic Ocean today, ice sheets exert pressure on the ground below them. That pressure diffuses all the way to the seafloor, controlling the precarious stability in seafloor sediments. But what happens when the ice sheets melt?New research, published on today in Geology, indicates that during the last two global periods of sea-ice melt, the decrease in pressure triggered methane release from buried reserves. Their results demonstrate that as Arctic ice, such as the Greenland ice sheet, melts, similar methane release is likely and should be included in climate models.Pierre-Antoine Dessandier, a postdoctoral scientist at the Arctic University of Norway, and his co-authors were interested in two periods around 20 thousand years ago (ka), known as the Last Glacial Maximum (LGM), and 130 ka, known as the Eemian deglaciation. Because the Eemian had less ice and was warmer than the LGM, it is more similar to what the Arctic is experiencing today, serving as a good analogue for future climate change."The oldest episode recorded (Eemian) is very important because it was a strong interglacial in the Arctic, with very similar climate characteristics to what is happening today," Dessandier said. "The idea with the Eemian interglacial is to... compare that with what could happen in the future. Seafloor methane emission is important to consider for modeling spatial estimations of future climate."To track past methane release, Dessandier measured isotopes of carbon (carbon molecules with slightly different compositions) in the shells of tiny ocean-dwellers called foraminifera. Because the foraminifera build their shells using ingredients from the water around them, the carbon signal in the shells reflects the chemistry of the ocean while they were alive. After they die, those shells are preserved in seafloor sediments, slowly building a record spanning tens of thousands of years.To reach that record, Dessandier and the team needed to drill a deep core off the western coast of Svalbard, a Norwegian archipelago in the Arctic Ocean. The team collected two cores: a 60-meter reference core, which they used to date and correlate stratigraphy, and a 22-meter core spanning the LGM and the Eemian deglaciations. The site for the 22-meter core was chosen based on its "pockmark" feature, marking where the gas escaped violently in the past, and massive carbonate rocks that form where methane is still leaking out today.Carbon isotopes of microscopic shells in the long core revealed multiple episodes of methane release, which geochemists recognize from their distinct spikes in the record. Because methane is still seeping from the sediments, Dessandier needed to to make sure the signal wasn't from modern interference. He compared the shells' carbon isotope values to measurements his colleagues made on carbonate minerals that formed outside the shells, after the foraminifera had died, when methane emission was at its most intense.The isotopic record showed that as ice melted and pressure on the seafloor lessened, methane was released in violent spurts, slow seeps, or -- most likely -- a combination of both. By the time the ice disappeared completely, some thousands of years later, methane emissions had stabilized.How much methane eventually made it to the atmosphere, which is what would contribute to the greenhouse effect, remains uncertain. Part of the problem in quantifying this is the microbial communities that live on the seafloor and in the water, and that use methane to survive."For the microbes, it's an oasis. It's fantastic," Dessandier said. "So they grow like crazy, and some species produce methane and others consume it." That activity complicates the core's detailed carbon record. In sediments, a bustling community with lots of methane recycling could overprint the original signal; in the water column, where nutrients may be less plentiful, methane could get gobbled up or transformed into carbon dioxide before it reaches the atmosphere.Despite modern complications, the team has pinpointed two methane releases associated with ice retreat, like they hypothesize could happen today. The best part for Dessandier was discovering layers of massive bivalves in the cores which, based on modern observations from remotely operated vehicles, can indicate a methane leak. "It was super interesting for us to observe these same sorts of layers at the LGM and the Eemian," he said. "It confirmed what we thought at the beginning, with a methane-rich seafloor allowing this community to develop... We can say that these events are very similar, with similar processes happening during both periods of warming. So this is something to consider for our current warming. It could happen again."
Particles reaching the stratosphere -- the upper layer of the atmosphere -- most often get there through volcanic eruptions. The ash emitted in the more extreme eruptions dims the sun and cools the planet, as well as producing spectacular sunsets. Prof. Ilan Koren of the Weizmann Institute of Science's Earth and Planetary Science Department, who conducted the study together with his former student, Dr. Eitan Hirsch, now the Head of the Environmental Sciences Division at the Israel Institute for Biological Research in Ness Tziona, had noticed an extreme increase in a satellite-based measure of particle loading in the atmosphere called AOD -- or aerosol optical depth. In January 2020, those measurements, plotted in standard deviations, showed a deviation three times the normal -- some of the highest readings ever obtained, higher even than those from Mt. Pinatubo in 1991. But the timing did not coincide with any volcanic activity. They wondered if fires might be to blame, even though it is rare for the smoke from fires to escape the lower layer of atmosphere known as the troposphere in significant amounts. The troposphere extends from the ground to a height of several kilometers, and if smoke particles manage to rise that high, they hit an inversion layer called the tropopause that acts as a sort of ceiling between the troposphere and the stratosphere.Working backwards and using data from several satellites, including, in addition to AOD, LIDAR readings that revealed how the particles were distributed vertically in "slices" of atmosphere, the two were able to prove that the source of the spikes was bushfires -- specifically those burning in Southeastern Australia. Further analysis of satellite data revealed the broad band of haze in the stratosphere spreading to cover the Southern hemisphere, peaking from January to March and persisting through July; reaching all the way around and back to Australia's west coast.How did these smoke particles penetrate through the tropopause ceiling and why did they come from these fires and not the others? One clue, says Hirsch, lay in another, distant forest fire that had occurred several years ago in Canada. Then, too, high AOD levels had been recorded. Both of these fires occurred in high latitudes, away from the equator.The height of the troposphere shrinks at these latitudes: Over the tropics its upper ceiling can reach up to 18 km above the surface, while somewhere above the 45th parallel -- North and South, it takes a sudden step down to around 8-10 km in height. So the first element enabling the particles' trans-layer flight was simply having less atmosphere to cross.Pyrocumulus clouds -- clouds fueled by the fires' energy -- were considered as a means of transporting smoke to the stratosphere. However, when inspecting the satellite data, Hirsch and Koren noticed that pyrocumulus clouds formed only over a small fraction of the fires' duration, and they were mostly seen over fires burning on the central part of the coast. In other words, these clouds could not explain the large amounts found to be transported to the stratosphere, and an additional mechanism for lifting smoke downwind from the sources was missing.This brings up the second element: the weather patterns in the strip known as the mid-latitude cyclone belt that runs through the southern end of Australia, one of the stormiest regions on the planet. The smoke was first advected (moved horizontally) by the prevailing winds in the lower atmosphere to the Pacific Ocean, and then some of it converged into the deep convective clouds there and was lifted in the clouds' core into the stratosphere. An interesting feedback mechanism known as "cloud invigoration by aerosols" can further deepen the clouds. In a previous study, the authors had shown that in conditions such as the pristine environment over the Southern Ocean, the convective clouds are "aerosol limited." The elevated smoke levels could thus act as cloud condensation nuclei, allowing the clouds to develop deeper and thus increasing the number of clouds that able to penetrate the tropopause and inject the smoke in the stratosphere.Up in the stratosphere, the particles found themselves in a different world than the one they had just left. If below they were at the mercy of mixing and churning air currents, up on top the air moves in a steady, linear fashion. That is, there was one strong current, and it was moving them eastwards over the ocean to South America and back over the Indian Ocean toward Australia, and slowly settling around the entire hemisphere. "People in Chile were breathing particles from the Australian fires," says Hirsch. By sailing on an endless air current, these particles remained airborne for much longer than lower atmosphere smoke particles."For people on the ground, the air may have just seemed a bit hazier or the sunsets a bit redder. But such a high AOD -- much, much higher than normal -- means sunlight was getting blocked, just as it does after volcanic eruptions," says Koren. "So the ultimate effect of that smoke on the atmosphere was cooling, though we still do not know how much influence that cooling and dimming may have had on the marine environment or weather patterns."There are always fires burning in California, in Australia and in the tropics," he adds. "We might not be able to stop all of the burning, but we do need an understanding that the precise locations of those fires may grant them very different effects on our atmosphere."Prof. Ilan Koren's research is supported by the de Botton Center for Marine Science; the Sussman Family Center for the Study of Environmental Sciences; the Dr. Scholl Foundation Center for Water and Climate Research; the Ben May Center for Chemical Theory and Computation; Scott Eric Jordan; the Yotam Project; the estate of Emile Mimran; and the European Research Council. Prof. Koren is the incumbent of the Beck / Lebovic Chair for Research in Climate Change.Video: 
A new study published in the journal By using oceanic observations of Î´After accounting for these effects, the authors were up for a surprise: they found much higher numbers for the land to ocean carbon transfer of 900-1900 million tons per year. Most of non-riverine carbon inputs of about 300-1300 million tons of carbon per year occur mostly along the coastlines of the Indian and Pacific Oceans. "This is consistent with the idea that groundwater discharge and coastal ecosystems, the so-called blue carbon, play a fundamental role in the global carbon cycle" says Dr. Kwon.One of the remaining open questions is which oceanic processes are responsible for carrying the dissolved carbon from the coastal zones to the open ocean, where part of it outgases back to the atmosphere. "This question will be addressed in future with a series of new earth system model simulations that we just conducted on our supercomputer Aleph," says Axel Timmermann, co-author of the study and Director of the IBS Center for Climate Physics.
The results of the new study, published recently in the The Northern Sea Route is attracting more tankers and cargo ships travelling from Russia and Asia to Europe, and traffic is expected to increase along the route in tandem with global warming.In the winter, the sea is frozen over, making it inaccessible to ships of a lower Polar Ship Category without the assistance of an icebreaker. Ships can also become beset in ice in the spring and summer, leading to transport delays. At its worst, ice may force a vessel off its course so that it runs aground, with disastrous consequences."This is the first time a comprehensive risk assessment of a besetting event was performed using open data only," says Assistant Professor of Statistics Jarno Vanhatalo, head of the Environmental and Ecological Statistics group and director of the Master's Programme in Life Science Informatics at the University of Helsinki.The researchers used satellite data on ice conditions in Arctic marine areas as well as open data sources on shipping."One of the biggest tasks required the merger of open datasets so that analyses could be conducted. This task was performed by Aalto University. The statistical analyses were carried out at the University of Helsinki, using a traditional generalised linear model, to which a Bayesian approach was applied," Vanhatalo explains."If we know the ice conditions prevailing in a specific area, which can usually be ascertained from satellite images, we can make a prediction for, say, today and for each point along the Northern Sea Route," states Vanhatalo. The prediction indicates the probability of a ship of a particular type becoming beset in ice in a particular area.The Polar Ship Category of a ship has a crucial impact on the probability of besetting. Ships of a lower category are most at risk, and many of them become beset in ice each year.The researchers also analysed the effect of ice concentration on the probability of besetting. Ice concentration indicates the share of the sea covered by ice. In the winter, ice concentration is 100%, whereas in the spring and summer it varies from 0% to 100%, which means that the marine area is a mosaic of ice floes and open water.The probability of a ship becoming beset in ice increases the longer the distance it travels in ice-covered waters and also increases significantly with higher ice concentrations. There are also considerable differences between ships of different Polar Ship Categories. For the best vessels, i.e., Category A ships, the probability of besetting on a journey of 3,000 nautical miles (NM) in 90%-100% ice concentration is just 0.04. Correspondingly, the probability for Category B ships is 7.5 times higher, or 0.3, whereas the probability for Category C ships is 22.5 times higher, or 0.9.The newly published study is part of an international long-term research project funded by the Lloyd's Register Foundation and aimed at improving maritime safety. Launched in 2003, the project will conclude at the end of 2021. Participants in the CEARCTIC and CEPOLAR projects, headed by Aalto University, include not only the University of Helsinki, but also the Norwegian University of Science and Technology (NTNU), the Memorial University of Newfoundland in Canada, and the Hamburg University of Technology in Germany.The University of Helsinki researchers have been responsible for assessing the impact of a potential oil spill on the Arctic environment and biotic communities. Previous publications have focused on species of organisms in the Kara Sea and the effects of an oil spill in the area.Although the research project is coming to a close, before the end of this year it will publish more statistical analyses of uncertainties associated with the modelling."Due to the limited measurement data available from Arctic marine areas, there are major uncertainties concerning shipping, living organisms and the behaviour of oil. Another major uncertainty relates to the natural stochasticity of highly unstable environmental conditions," Vanhatalo adds.Another article currently being written explores the relative significances of factors affecting the overall risk as well as how risk analyses should be carried out and how the conclusions drawn differ depending on what is examined. Does the examination focus solely on the accident risk of vessels or also on the risk they pose to marine biotic communities? The results depend on whether both are examined separately or at the same time.Other upcoming publications include summarising reports on the project as a whole and recommendations based on the research conducted.
"Species that belong to the Micarea genus are known all over the world, including Finland. However, the Micarea species recently described from the Taita Hills have not been seen anywhere else. They are not known even in the relatively close islands of Madagascar or RÃ©union, where species of the genus have been previously studied," Postdoctoral Researcher Annina Kantelinen from the Finnish Museum of Natural History says."The Taita Hills cloud forests are quite an isolated ecosystem, and at least some of the species now discovered may be native to the area or to eastern Africa. Our preliminary findings also suggest that there are more unknown Micarea lichen species there."The Taita Hills are part of the Eastern Arc Mountains that range from south-eastern Kenya to eastern Tanzania. The mountains rise abruptly from the surrounding plain, with the tallest peak reaching over two kilometers. Lush indigenous rainforests are mainly found on the mountaintops, capturing precipitation from clouds and mist developed by the relatively cool air rising from the Indian Ocean.Thanks to ecological isolation and a favourable climate, the area is one of the global hotspots of biodiversity. However, the native cloud forests in the region are shrinking year by year as they are replaced by forest plantations of exotic tree species that are not native to Africa. Compared to 1955, the area of indigenous forests has been diminished to less than half."Planted forests have been found to bind less moisture and be more susceptible to forest fires. Therefore, they can make the local ecosystem drier and result in species becoming endangered. Some lichen species are capable of utilising cultivated forests at least temporarily, but indigenous forests have the greatest biodiversity and biomass," Kantelinen says.The University of Helsinki maintains in the area the Taita Research Station, which is celebrating its tenth anniversary this year.
Corals are marine invertebrates that build tiny exoskeletons, which accumulate to form giant coral reefs. Widely appreciated for their beauty, these reefs are havens for biodiversity and crucial for the economies of many coastal communities. But they are endangered by ocean warming, seawater acidification, extreme storms, pollution, and overfishing.Coral reefs use calcium carbonate to construct their architecture, a process called calcification. For a reef to be healthy, its coral's building activities must exceed erosion, a natural phenomenon that is exacerbated by all the environmental stresses to which human activity is exposing them."Coral reefs are dealing with so many simultaneous threats, many of which directly inhibit their ability to grow at a sustainable rate," Caldeira explained. "If they can't maintain a slow but steady amount of growth, they could get knocked out by rising sea levels in the coming years."However, RomanÃ³ de Orte and Caldeira's research -- with former Carnegie colleagues David Koweek (now at Ocean Visions), Yuichiro Takeshita (now at the Monterey Bay Aquarium Research Institute), and Rebecca Albright (now at the California Academy of Sciences) -- showed that if researchers only make measurements to assess coral health during the daytime, it could lead to false sense of security.Why?Because dead coral is often colonized by algal communities that can also accumulate carbonate minerals during the day. However, most of these deposits dissolve overnight, so the carbonate minerals do not accumulate over time. In contrast, living corals, , which have evolved to build massive carbonate reefs visible from space, can continue to build their skeletons, albeit slowly, even at night."It's long been thought that measuring calcium carbonate production could be linked directly to the health of a coral community," RomanÃ³ de Orte said. "But our findings show that as algae increasingly succeed in overgrowing dead coral, it is going to be more difficult to rely on a once tried-and-true method for assessing whether a reef community is thriving."To gain this critical understanding, the research team -- which also included Tyler Cyronak of Nova Southeastern University, Alyssa Griffin of the Scripps Institution of Oceanography, Kennedy Wolfe of the University of Queensland, and Alina Szmant and Robert Whitehead of University of North Carolina Wilmington -- deployed specially designed, state-of-the-art incubator technology to closely monitor both coral and colonizing algae in an area of Australia's Great Barrier Reef that had been heavily damaged by two tropical cyclones in 2014 and 2015. They were able to monitor both calcification and dissolution of carbonate minerals, as well as the organisms' metabolic activity."This amazing tool allowed us to home in on the specific role that each organism has in an ecosystem's total output, which gives us new insights into how reefs are changing" RomanÃ³ de Orte explained.
An international team of 26 authors, including six at UC Santa Barbara, has just published a study in the prestigious journal The researchers identified specific areas of the ocean that could provide multiple benefits if protected. Safeguarding these regions would protect nearly 80% of marine species, increase fishing catches by more than 8 million metric tons and prevent the release of more than one billion tons of carbon dioxide by protecting the seafloor from bottom trawling, a widespread yet destructive fishing practice.The study is also the first to quantify the potential release of CO"Ocean life has been declining worldwide because of overfishing, habitat destruction and climate change. Yet only 7% of the ocean is currently under some kind of protection," said the study's lead author Enric Sala, an explorer in residence at the National Geographic Society."In this study, we've pioneered a new way to identify the places that -- if protected -- will boost food production and safeguard marine life, all while reducing carbon emissions," Sala said. "It's clear that humanity and the economy will benefit from a healthier ocean. And we can realize those benefits quickly if countries work together to protect at least 30% of the ocean by 2030."To identify the priority areas, the authors -- leading marine biologists, climate experts and economists -- analyzed the world's unprotected ocean waters. They focused on the degree to which they are threatened by human activities that can be reduced by marine protected areas (for example, overfishing and habitat destruction).They then developed an algorithm to identify where protections would deliver the greatest benefits across the three complementary goals of biodiversity protection, seafood production and climate mitigation. They mapped these locations to create a practical "blueprint" that governments can use as they implement their commitments to protect nature."While we consider three key benefits that marine protection is known to confer, this is really just the beginning," said co-author Darcy Bradley(link is external), co-director of the Ocean and Fisheries Program at UC Santa Barbara's Environmental Market Solutions Lab (emLab). "Our approach is a way to bring multiple stakeholders to the table, to show that their interests can be prioritized, and ultimately to demonstrate that solutions that protect large ocean areas and benefit multiple simultaneous objectives exist."The study does not provide a single map for ocean conservation, but it offers a first-in-kind framework for countries to decide which areas to protect depending on their national priorities. However, the analysis supports the claim that 30% is the minimum amount of ocean that the world must protect in order to provide multiple benefits to humanity."There is no single best solution to save marine life and obtain these other benefits. The solution depends on what society -- or a given country -- cares about, and our study provides a new way to integrate these preferences and find effective conservation strategies," said coauthor Juan Mayorga(link is external), a marine scientist at emLab as well as National Geographic Society's Pristine Seas.The study comes ahead of the 15th Conference of the Parties to the United Nations Convention on Biological Diversity, which will gather in May in Kunming, China. The meeting will bring together representatives of 190 countries to finalize an agreement to end the world's biodiversity crisis. The goal of protecting 30% of the planet's land and ocean by 2030 (the "30x30" target) is expected to be a pillar of the treaty. The report follows commitments by the United States, the United Kingdom, Canada, the European Commission and others to achieve this target on national and global scales."Solutions with multiple benefits are attractive to people and leaders alike," said coauthor Jane Lubchenco, a university distinguished professor at Oregon State University. "Our pioneering approach allows them to pinpoint the places that, if protected, will contribute significantly to three big problems at once: food security, climate change, and biodiversity loss. Our breakthrough in methodology can bring multiple benefits to nature and people."The report identifies highly diverse marine areas in which species and ecosystems face the greatest threats from human activities. Establishing marine protected areas with strict regulations in those places would safeguard more than 80% of the ranges of endangered species, up from a current coverage of less than 2%. The authors found that priority locations lie throughout the ocean, with the vast majority of them contained within the 200-mile Exclusive Economic Zones (EEZs) of coastal nations.Additional protection targets are located in the high seas -- those waters governed by international law. These include the Mid-Atlantic Ridge (a massive underwater mountain range); the Mascarene Plateau in the Indian Ocean; the Nazca Ridge off the west coast of South America; and the Southwest Indian Ridge, between Africa and Antarctica."Perhaps the most impressive and encouraging result is the enormous gain we can obtain for biodiversity conservation with only 21% of the ocean being protected, if we carefully chose the location of strictly protected marine areas," said coauthor David Mouillot, a professor at the UniversitÃ© de Montpellier in France. "One notable priority for conservation is Antarctica, which currently has little protection, but is projected to host many vulnerable species in a near future due to climate change."The study finds that wisely placed marine protected areas (MPAs) that ban fishing would actually boost the production of fish at a time when supplies of wild-caught fish are dwindling and demand is rising. In doing so, the study refutes a long-held view that ocean protection harms fisheries. Instead, it opens up new opportunities to revive the industry just as it is suffering from a recession due to overfishing and the impacts of global warming."Some argue that closing areas to fishing hurts fishing interests. But the worst enemy of successful fisheries is overfishing, not protected areas," said lead author Sala. The study finds that protecting the right places could increase the catch of seafood by over 8 million metric tons relative to business as usual."It's simple: When overfishing and other damaging activities cease, marine life bounces back," said co-author Reniel Cabral(link is external), an assistant researcher at UC Santa Barbara's Marine Science Institute and in its Bren School of Environmental Science & Management. "After protections are put in place, the diversity and abundance of marine life increase over time, with measurable recovery within reserves occurring in as little as three years. Target species and large predators come back, and entire ecosystems are restored within MPAs. With time, the ocean can heal itself and again provide services to humankind."The study is also the first to calculate the climate impacts of bottom trawling, a damaging fishing method used worldwide in which boats drag heavy nets across the ocean floor. The researchers found that the amount of CO"The ocean floor is the world's largest carbon storehouse. If we're to succeed in stopping global warming, we must leave the carbon-rich seabed undisturbed," said coauthor Trisha Atwood of Utah State University. "Yet every day, we are trawling the seafloor, depleting its biodiversity and mobilizing millennia-old carbon and thus exacerbating climate change. Our findings about the climate impacts of bottom trawling will make the activities on the ocean's seabed hard to ignore in climate plans going forward."The study finds that countries with large national waters and large industrial bottom trawl fisheries have the highest potential to contribute to climate change mitigation via protection of carbon stocks. The authors estimate that protecting only 4% of the ocean -- mostly within national waters -- would eliminate 90% of the present risk of carbon disturbance due to bottom trawling.The study's range of findings helps to close a gap in our knowledge about the impacts of ocean conservation, which to date had been understudied relative to land-based conservation."The ocean covers 70% of the Earth; yet, until now, its importance for solving the challenges of our time has been overlooked," said coauthor Boris Worm, Killam Research Professor at Dalhousie University in Halifax, Nova Scotia. "Smart ocean protection will help to provide cheap natural climate solutions, make seafood more abundant and safeguard imperiled marine species -- all at the same time."The benefits are clear," he continued. "If we want to solve the three most pressing challenges of our century -- biodiversity loss, climate change and food shortages -- we must protect our ocean."
Thought to be the world's largest source of natural gas, methane hydrate is a potential fuel source, and if it "melts" and methane gas is released into the atmosphere, it is a potent greenhouse gas. For these reasons, knowing where methane hydrate might be located, and how much is likely there, is important.A team of researchers from Sandia National Laboratories and the U.S. Naval Research Laboratory have developed a new system to model the likelihood of finding methane hydrate and methane gas that was tested in a region of seafloor off the coast of North Carolina.While methane hydrate deposits have been found in a variety of locations, there are significant unknowns in terms of how much methane hydrate exists on the seafloor and where. It is challenging to collect samples from the seafloor to find methane hydrate deposits. This is where Sandia's computer modeling expertise comes in."This is the first time someone has been able to approach methane hydrate distribution in the same way we approach weather forecasting," said Jennifer Frederick, a computational geoscientist and lead researcher on the project. "When you hear a weather forecast for a 60% chance of two inches of rain, you don't necessarily expect exactly two inches. You understand that there is uncertainty in that forecast, but it is still quite useful. In most places on the seafloor we don't have enough information to produce an exact answer, but we still need to know something about methane and its distribution. By using a probabilistic approach, similar to modern weather forecasting, we can provide useful answers."The new system combines Sandia's longstanding expertise in probabilistic modeling with machine learning algorithms from the Naval Research Laboratory. The system was tested and refined by modeling the area around Blake Ridge, a hill on the seafloor 90 to 230 miles southeast of North Carolina's Outer Banks with known deposits of methane hydrate and methane gas.The team shared their model for Blake Ridge and compared it with previous empirical data in a paper published on March 14 in the scientific journal The Naval Research Laboratory's Global Predictive Seafloor Model provides site-specific details on seafloor properties, such as temperature, overall carbon concentration and pressure. If data is missing for a certain region, the Naval Research Laboratory's model uses advanced machine-learning algorithms to estimate the missing value based on information about another area that may be geographically distant but similar geologically.The research team imported the data from the Naval Research Laboratory's model into Sandia software that specializes in statistical sampling and analysis, called Dakota. Using Dakota, they determined the most likely value for influential seafloor properties, as well as the natural variation for the values. Then, in a statistical manner, they inserted a value from this expected range for each property into PFLOTRAN, another software maintained and developed at Sandia. PFLOTRAN models how chemicals react and materials move underground or under the seafloor. The team conducted thousands of methane production simulations of the Blake Ridge region. All the software involved in the system is open source and will be available for other oceanographic researchers to use."One of the biggest things we found is that there is almost no formation of methane hydrates shallower than 500 meters, which is to be expected given the temperature and pressure needed to form methane hydrate," said William Eymold, a postdoctoral fellow at Sandia and primary author of the paper. Solid methane hydrate is known to form in low-temperature, high-pressure environments where molecules of methane are trapped within well-organized water molecules.The team also found methane gas formed closer to shore. They were able to compare their model to methane hydrate values calculated by past studies and samples collected a few decades ago by the National Science Foundation's Ocean Drilling Program, he said. For example, methane hydrate was detected in a seafloor sample collected from a hole drilled on Blake Ridge called Site 997."The fact that we predicted methane hydrate formation in similar amounts to past studies and observations really showed that the system appears to be working pretty well, and we will be able to apply it to other geographic locations that may have less data," Eymold said.The location of methane hydrate deposits and methane gas near the seafloor is important to the Navy."Understanding how sound interacts with the seafloor is really important for any kind of naval operation," said Frederick. "Methane gas affects the acoustics dramatically. Even if only 1% or 2% of the pore space in the seafloor sediment is filled with a gas bubble, the speed of sound decreases a hundredfold, or more. This is a very large effect, and if you don't account for it properly, then you're not going to get precise acoustics."Frederick compared a submarine using sonar to the early arcade game Breakout, where a player moves a paddle horizontally in order to keep a ball bouncing to destroy a wall of bricks. In this analogy, the seafloor serves as the "paddle" to reflect or refract sound waves, or the "ball," in order to get a complete view of obstacles in the ocean. If the paddle started to bounce the ball differently -- or held on to the ball for varying lengths of times -- depending on where the paddle was located, the game would become far more challenging.So far, the team has used their system to create models of a region of the Norwegian Sea between Greenland and Norway and the shallow waters of the Arctic Ocean offshore of the North Slope of Alaska, two areas of interest to the Navy.Frederick has also worked with a large team of international experts to assess the amount of methane and carbon dioxide stored in the shallow Arctic seafloor, and how sensitive those deposits would be to rising temperatures.The team has also created a much coarser model of the whole globe and has started looking at the mid-Atlantic, where methane gas was spotted bubbling out of the seafloor a few years ago."It will be interesting to see if our model is able to predict these regions of methane seeps on the seafloor," Frederick said. "We'd like to see if we can predict the distribution of these methane seeps and whether they are consistent with the thermodynamic properties of methane-hydrate stability. When you see a seep, that means that there is a lot of gas beneath the seafloor. That will significantly impact how sound travels through the seafloor, and thus sonar. Also, these deposits could be a source of natural gas for energy production, will impact the ocean ecology and nutrient cycles, and if that gas reaches the atmosphere, it will have climate change implications."This research was funded by Sandia's Laboratory Directed Research and Development program. Frederick is seeking funding to continue the project with her collaborators at the Naval Research Laboratory.
Like many animals unique to the Caribbean, cave-rails became extinct soon after people settled the islands. The last of three known West Indian species of cave-rails -- flightless, chicken-sized birds -- vanished within the past 1,000 years. Florida Museum of Natural History researchers sought to resolve the group's long-debated ancestry by analyzing DNA from a fossil toe bone of the Haitian cave-rail, Nesotrochis steganinos. But they were unprepared for the results: The genus Nesotrochis is most closely related to the flufftails, flying birds that live in sub-Saharan Africa, Madagascar and New Guinea, and the adzebills, large, extinct, flightless birds native to New Zealand.The study presents the first example of a Caribbean bird whose closest relatives live in the Old World, showcasing the power of ancient DNA to reveal a history erased by humans.The discovery was "just mind-blowing," said study lead author Jessica Oswald, who began the project as a postdoctoral researcher at the Florida Museum."If this study had not happened, we might still be under the assumption that the closest relatives of most things in the Caribbean are on the mainland in the Americas," said Oswald, now a postdoctoral researcher at the University of Nevada, Reno and a Florida Museum research affiliate. "This gives us an understanding of the region's biodiversity that would otherwise be obscured."Many animals evolved unusual forms on islands, often making it difficult to classify extinct species based on their physical characteristics alone. But advancements in extracting viable DNA from fossils now enables scientists like Oswald to answer longstanding questions with ancient genetic evidence. Oswald described her work as similar to a forensic investigation, tracing the evolutionary backstory of extinct animals by piecing together fragmented, degraded genetic material."Understanding where all of these extinct species fit into a larger family tree or evolutionary history gives us insight into what a place looked like before people arrived," she said. "That's why my job is so fun. It's always this whodunit."Oswald was just starting her ancient DNA work at the Florida Museum when David Steadman, curator of ornithology and study co-author, suggested the Haitian cave-rail as a good candidate for analysis.Cave-rails share physical characteristics with several types of modern birds, and scientists have conjectured for decades whether they are most closely related to wood rails, coots or swamphens -- birds that all belong to the rail family, part of a larger group known as the Gruiformes. Oswald and Steadman hoped that studying cave-rail DNA would clarify "what the heck this thing is," Oswald said.When preliminary results indicated the species had a trans-Atlantic connection, Steadman, who has worked in the Caribbean for more than 40 years, was skeptical.The genetics also showed that the cave-rail isn't a rail at all: While flufftails and adzebills are also members of the Gruiformes, they are in separate families from rails."It just didn't seem logical that you'd have to go across the Atlantic to find the closest relative," Steadman said. "But the fact that people had a hard time classifying where Nesotrochis was within the rails -- in hindsight, maybe that should have been a clue. Now I have a much more open mind."One reason the cave-rail was so difficult to classify is that when birds lose the ability to fly, they often converge on a similar body plan, Steadman said. Flightlessness is a common adaptation in island birds, which face far fewer predators in the absence of humans and invasive species such as dogs, cats, rats and pigs."You don't have to outfly or outrun predators, so your flying and running abilities become reduced," Steadman said. "Because island birds spend less energy avoiding predators, they also tend to have a lower metabolic rate and nest on the ground. It's no longer life in the fast lane. They're essentially living in a Corona commercial."While sheltered from the mass extinctions that swept the mainland, cave-rails were helpless once people touched foot on the islands, having lost their defenses and cautiousness."Being flightless and plump was not a great strategy during human colonization of the Caribbean," said study co-author Robert Guralnick, Florida Museum curator of biodiversity informatics.How did cave-rails get to the Caribbean in the first place? Monkeys and capybara-like rodents journeyed from Africa to the New World about 25-36 million years ago, likely by rafting, and cave-rails may also have migrated during that timespan, Steadman said. He and Oswald envision two probable scenarios: The ancestors of cave-rails either made a long-distance flight across an Atlantic Ocean that was not much narrower than today, or the group was once more widespread across the continents, with more relatives remaining to be discovered in the fossil record.Other researchers have recently published findings that corroborate the story told by cave-rail DNA: A study of foot features suggested Nesotrochis could be more closely related to flufftails than rails, and other research showed that adzebills are close relatives of the flufftails. Like cave-rails, adzebills are also an example of a flightless island bird extinguished by human hunters."Humans have meddled so much in the region and caused so many extinctions, we need ancient DNA to help us sort out what's related to what," Oswald said.The findings also underscore the value of museum collections, Steadman said. The toe bone Oswald used in her analysis was collected in 1983 by Charles Woods, then the Florida Museum's curator of mammals. At that time, "nobody was thinking about ancient DNA," Steadman said. "It shows the beauty of keeping things well curated in a museum."Ryan Terrill of Occidental College, the Florida Museum's Brian Stucky and Michelle LeFebvre and Julie Allen of the University of Nevada, Reno, and the University of Illinois Urbana-Champaign also co-authored the study.
When they appear along an outer bank, which curves the opposite way, they form "counter-point" bars, which are usually interpreted by geoscientists as an anomaly: a sign that something -- such as a patch of erosion-resistant rocks -- is interfering with the river's usual manner of sediment deposition.But according to research led by The University of Texas at Austin, counter-point bars are not the oddities they're often made out to be. In fact, they're a perfectly normal part of the meandering process."You don't need a resistant substrate, you can get beautiful [counter-point] bars without it," said ZoltÃ¡n Sylvester, a research scientist at UT's Bureau of Economic Geology who led the study.The finding suggests that counter-point bars -- and the unique geology and ecology associated with them -- are more common than previously thought. Building awareness around that fact can help geoscientists be on the lookout for counter-point bars in geological formations deposited by rivers in the past, and understand how they may be influencing the flow of hydrocarbons and water passing though them.The research was published in the The co-authors are David Mohrig, a professor at the UT Jackson School of Geosciences; Paul Durkin, a professor at the University of Manitoba; and Stephen Hubbard, a professor at the University of Calgary.Rivers are constantly on the move. For meandering rivers, this means carving out new paths and reactivating old ones as they snake across a landscape over time.The researchers observed this behavior in both an idealized computer model and in nature, using satellite photos of a stretch of Bolivia's MamorÃ© River, which is known for quickly changing its path. The satellite photos captured how the river changed over 32 years, from 1986 -- 2018.In both the model and the MamorÃ©, counter-point bars appeared. The researchers found that the appearance was linked directly to short, high curvature bends: little spikes in a river's path.The researchers observed that these spikes frequently form when the river's course is abruptly changed, such as when a new oxbow lake forms through cutoff, or after reconnecting with an old oxbow lake.But the sharp bends don't stay put, they start migrating in the downstream direction. And as they rapidly move downstream, they create the conditions for sediment to accumulate around the bend as a counter-point bar.The study shows a number of instances of this happening in the MamorÃ©. For example, in 2010, a sharp bend (bend 2 in the image) forms when an ox-bow lake reconnects with a downstream portion of the river. By 2018, the bend has moved about 1.5 miles downstream, with counter-point deposits along the shoreline marking its path.Geomorphologists and engineers knew for some time that long-term change along a river can be described in terms of local and upstream values of curvature (places where the river seems to wrap around a small circle have high curvatures). In the study, the researchers used a formula that uses these curvature values to determine the likelihood of a counter-point bar forming at a particular location.Sylvester said that he was surprised at how well this formula -- and the simplified models used in part to derive it -- worked to explain what was thought to be a complex phenomenon."Natural rivers, they are actually not that far from what these really simple models predict," Sylvester said.This is not the first time that Sylvester's research has revealed that river behavior can be governed by relatively simple rules. In 2019, he led a study published in Geology that described a direct relationship between bend sharpness and river migration.Superficially, point bars and counter-point bars look quite similar and frequently blend into one another. But counter-point bars are distinct environments: compared to point bars, they have finer sediments and lower topography, making them more prone to flooding and hosting lakes. These characteristics create unique ecological niches along rivers. But they are also geologically important, with ancient counter-point bar deposits preserved underground influencing the flow of fluids, such as water and oil and gas.Mathieu LapÃ´tre, a geoscientist and assistant professor at Stanford University, said that recognizing that counter-point bars can readily form in meandering rivers -- and having a formula for predicting where they will form -- is a significant advancement."Altogether, the results of Sylvester et al. have important implications for a range of scientific and engineering questions," he said.The research was funded by the bureau's Quantitative Clastics Laboratory research consortium.
Marine CFCs have long been used as tracers to study ocean currents, but their impact on atmospheric concentrations was assumed to be negligible. Now, MIT researchers have found the oceanic fluxes of at least one type of CFC, known as CFC-11, do in fact affect atmospheric concentrations. In a study appearing today in the The researchers project that by the year 2075, the oceans will emit more CFC-11 back into the atmosphere than they absorb, emitting detectable amounts of the chemical by 2130. Further, with increasing climate change, this shift will occur 10 years earlier. The emissions of CFC-11 from the ocean will effectively extend the chemical's average residence time, causing it to linger five years longer in the atmosphere than it otherwise would. This may impact future estimations of CFC-11 emissions.The new results may help scientists and policymakers better pinpoint future sources of the chemical, which is now banned worldwide under the Montreal Protocol."By the time you get to the first half of the 22nd century, you'll have enough of a flux coming out of the ocean that it might look like someone is cheating on the Montreal Protocol, but instead, it could just be what's coming out of the ocean," says study co-author Susan Solomon, the Lee and Geraldine Martin Professor of Environmental Studies in MIT's Department of Earth, Atmospheric and Planetary Sciences. "It's an interesting prediction and hopefully will help future researchers avoid getting confused about what's going on."Solomon's co-authors include lead author Peidong Wang, Jeffery Scott, John Marshall, Andrew Babbin, Megan Lickley, and Ronald Prinn from MIT; David Thompson of Colorado State University; Timothy DeVries of the University of California at Santa Barbara; and Qing Liang of the NASA Goddard Space Flight Center.CFC-11 is a chlorofluorocarbon that was commonly used to make refrigerants and insulating foams. When emitted to the atmosphere, the chemical sets off a chain reaction that ultimately destroys ozone, the atmospheric layer that protects the Earth from harmful ultraviolet radiation. Since 2010, the production and use of the chemical has been phased out worldwide under the Montreal Protocol, a global treaty that aims to restore and protect the ozone layer.Since its phaseout, levels of CFC-11 in the atmosphere have been steadily declining, and scientists estimate that the ocean has absorbed about 5 to 10 percent of all manufactured CFC-11 emissions. As concentrations of the chemical continue to fall in the atmosphere, however, it's predicted that CFC-11 will oversaturate in the ocean, pushing it to become a source rather than a sink."For some time, human emissions were so large that what was going into the ocean was considered negligible," Solomon says. "Now, as we try to get rid of human emissions, we find we can't completely ignore what the ocean is doing anymore."In their new paper, the MIT team looked to pinpoint when the ocean would become a source of the chemical, and to what extent the ocean would contribute to CFC-11 concentrations in the atmosphere. They also sought to understand how climate change would impact the ocean's ability to absorb the chemical in the future.The researchers used a hierarchy of models to simulate the mixing within and between the ocean and atmosphere. They began with a simple model of the atmosphere and the upper and lower layers of the ocean, in both the northern and southern hemispheres. They added into this model anthropogenic emissions of CFC-11 that had previously been reported through the years, then ran the model forward in time, from 1930 to 2300, to observe changes in the chemical's flux between the ocean and the atmosphere.They then replaced the ocean layers of this simple model with the MIT general circulation model, or MITgcm, a more sophisticated representation of ocean dynamics, and ran similar simulations of CFC-11 over the same time period.Both models produced atmospheric levels of CFC-11 through the present day that matched with recorded measurements, giving the team confidence in their approach. When they looked at the models' future projections, they observed that the ocean began to emit more of the chemical than it absorbed, beginning around 2075. By 2145, the ocean would emit CFC-11 in amounts that would be detectable by current monitoring standards.The ocean's uptake in the 20th century and outgassing in the future also affects the chemical's effective residence time in the atmosphere, decreasing it by several years during uptake and increasing it by up to 5 years by the end of 2200.Climate change will speed up this process. The team used the models to simulate a future with global warming of about 5 degrees Celsius by the year 2100, and found that climate change will advance the ocean's shift to a source by 10 years and produce detectable levels of CFC-11 by 2140."Generally, a colder ocean will absorb more CFCs," Wang explains. "When climate change warms the ocean, it becomes a weaker reservoir and will also outgas a little faster.""Even if there were no climate change, as CFCs decay in the atmosphere, eventually the ocean has too much relative to the atmosphere, and it will come back out," Solomon adds. "Climate change, we think, will make that happen even sooner. But the switch is not dependent on climate change."Their simulations show that the ocean's shift will occur slightly faster in the Northern Hemisphere, where large-scale ocean circulation patterns are expected to slow down, leaving more gases in the shallow ocean to escape back to the atmosphere. However, knowing the exact drivers of the ocean's reversal will require more detailed models, which the researchers intend to explore."Some of the next steps would be to do this with higher-resolution models and focus on patterns of change," says Scott. "For now, we've opened up some great new questions and given an idea of what one might see."This research was supported, in part, by the VoLo Foundation, the Simons Foundation, and the National Science Foundation.
An international research team led by the University of Leeds has for the first time linked glacier-fed mountain rivers with higher rates of plant material decomposition, a major process in the global carbon cycle.As mountain glaciers melt, water is channelled into rivers downstream. But with global warming accelerating the loss of glaciers, rivers have warmer water temperatures and are less prone to variable water flow and sediment movement. These conditions are then much more favourable for fungi to establish and grow.Fungi living in these rivers decompose organic matter such as plant leaves and wood, eventually leading to the release of carbon dioxide into the air. The process -- a key part of global river carbon cycling -- has now been measured in 57 rivers in six mountain ranges across the world, in Austria, Ecuador, France, New Zealand, Norway and the United States.The findings, funded mainly by the Natural Environment Research Council, are published today (15 March) in the journal Lead author Sarah Fell, of Leeds' School of Geography and water@leeds, said similar patterns and processes were discovered worldwide."We found increases in the rate of organic matter decomposition in mountain rivers, which can then be expected to lead to more carbon release to the atmosphere."This is an unexpected form of climate feedback, whereby warming drives glacier loss, which in turn rapidly recycles carbon in rivers before it is returned to the atmosphere."The retreat of mountain glaciers is accelerating at an unprecedented rate in many parts of the world, with climate change predicted to drive continued ice loss throughout the 21st century.However, the response of river ecosystem processes (such as nutrient and carbon cycling) to decreasing glacier cover, and the role of fungal biodiversity in driving these, remains poorly understood.The research team used artists' canvas fabric to mimic plant materials such as leaves and grass that accumulate naturally in rivers. This was possible because the canvas is made from cotton, predominantly composed of a compound called cellulose -- the world's most abundant organic polymer which is found in plant leaves that accumulate in rivers naturally.The canvas strips were left in the rivers for approximately one month, then retrieved and tested to determine how easily they could be ripped. The strips ripped more easily as aquatic fungi colonised them, showing that decomposition of the carbon molecules proceeded more quickly in rivers which were warmer because they had less water flowing from glaciers.The study's co-author, Professor Lee Brown, also of Leeds' School of Geography and water@leeds, explained: "Our finding of similar patterns of cellulose breakdown at sites all around the world is really exciting because it suggests that there might be a universal rule for how these river ecosystems will develop as mountains continue to lose ice. If so, we will be in much improved position to make forecasts about how river ecosystems will change in future.Co-author Professor Alex Dumbrell, whose team at the University of Essex analysed the fungi from the river samples, added: "Our work showed that measuring a specific gene that underpins the activity of the cellulose-degrading enzyme (Cellobiohydrolase I) meant we could predict cotton strip decomposition better than using information about the abundance of fungal species themselves, which is the more commonly used approach. This opens up new routes for research to improve our predictions about changes in carbon cycling."As algal and plant growth in glacier-fed rivers is minimised by low water temperature, unstable channels and high levels of fine sediment, plant matter breakdown can be an important fuel source to these aquatic ecosystems. In some parts of the world, such as Alaska and New Zealand, glacier-fed rivers also extend into forests that provide greater amounts of leaf litter to river food chains.In addition, because glacier loss means less water flows through the rivers and they are less prone to changing course, it is expected that bankside plants and trees will grow more in these habitats in future, meaning even more leaf litter will accumulate in rivers. This is likely to accelerate the fungal processing of carbon in mountain rivers worldwide even more than at present.
An international team, led by the University of Cambridge, studied the chemical fingerprints in European oak trees to reconstruct summer climate over 2,110 years. They found that after a long-term drying trend, drought conditions since 2015 suddenly intensified, beyond anything in the past two thousand years.This anomaly is likely the result of human-caused climate change and associated shifts in the jet stream. The results are reported in the journal Recent summer droughts and heatwaves in Europe have had devastating ecological and economic consequences, which will worsen as the global climate continues to warm."We're all aware of the cluster of exceptionally hot and dry summers we've had over the past few years, but we needed precise reconstructions of historical conditions to see how these recent extremes compare to previous years," said first author Professor Ulf BÃ¼ntgen from Cambridge's Department of Geography, who is also affiliated with CzechGlobe Centre in Brno, Czech Republic. "Our results show that what we have experienced over the past five summers is extraordinary for central Europe, in terms of how dry it has been consecutively."Most studies attempting to reconstruct past climates are restricted to temperature, but stable isotopes in tree rings can provide annually-resolved and absolutely-dated information about hydroclimatic changes over long periods of time.BÃ¼ntgen and his colleagues from the Czech Republic, Germany and Switzerland studied more than 27,000 measurements of carbon and oxygen isotopic ratios from 147 living and dead European oak trees, covering a period of 2,110 years. The samples came from archaeological remains, subfossil materials, historical constructions and living trees from what is now the Czech Republic and parts of south-eastern Bavaria."Generally, our understanding is worse the further back we go back in time, as datasets looking at past drought conditions are rare," said BÃ¼ntgen, who is a specialist in dendrochronology, the study of data from tree-ring growth. "However, insights before medieval times are particularly vital, because they enable us to get a more complete picture of past drought variations, which were essential for the functioning and productivity of ecosystems and societies."For each ring in each tree, researchers extracted and analysed carbon and oxygen isotopes independently, enabling them to build the largest and most detailed dataset of summer hydroclimate conditions in central Europe from Roman times to the present."These tree-ring stable isotopes give us a far more accurate archive to reconstruct hydroclimate conditions in temperate areas, where conventional tree-ring studies often fail," said co-author Professor Jan Esper from the University of Mainz, Germany.Stable tree-ring isotopes differ from the usual tree-ring measures of ring width and wood density, as they reflect physical conditions and tree responses rather than net stem growth. "While carbon values depend on the photosynthetic activity, oxygen values are affected by the source water. Together, they closely correlate with the conditions of the growing season," said co-author Professor Paolo Cherubini from the Federal Research Institute WSL in Birmensdorf, Switzerland.Over the 2,110-year period, the tree-ring isotope data showed there were very wet summers, such as 200, 720 and 1100 CE, and very dry summers, such as 40, 590, 950 and 1510 CE. Despite these 'out of the ordinary years', the results show that for the past two millennia, Europe has been slowly getting drier.The samples from 2015-2018, however, show that drought conditions in recent summers far exceed anything in the 2,110 years: "We've seen a sharp drop following centuries of a slow, significant decline, which is particularly alarming for agriculture and forestry," said co-author Professor Mirek Trnka from the CzechGlobe Research Centre in Brno, Czech Republic. "Unprecedented forest dieback across much of central Europe corroborates our results."The researchers say that the recent cluster of abnormally dry summers is most likely the result of anthropogenic climate warming, and the associated changes in the jet stream position. "Climate change does not mean that it will get drier everywhere: some places may get wetter or colder, but extreme conditions will become more frequent, which could be devastating for agriculture, ecosystems and societies as a whole," said BÃ¼ntgen.
The research serves as a case study for other rapidly developing and tropical regions of the globe, especially in places struggling to balance forest and wetland conservation with agricultural needs and food security."Broad-scale global studies show that tropical deforestation and wetland destruction is occurring rapidly, which contributes to climate change in multiple ways such as through greenhouses gas increases," said Timothy Beach, the study's co-author and professor in the Department of Geography and the Environment at UT Austin. "These also lead to more runoff and water pollution in much of the Global South. Belize has served as our long-term environmental research laboratory for this global dilemma."In a study published in The Landsat program, which has been recording images of Earth since 1972, is currently on its eighth satellite. To study such broad periods, the authors used images from Landsat 8 and earlier satellites and employed a multitemporal approach, creating composite images from wet and dry seasons over several years for each period. They then trained an algorithm to identify eight distinct land types, including several varieties of forest and wetlands. From this, they generated maps illustrating the LULC for each of the three periods.During the first period (1984-1987), deforestation was limited to small patches resulting from milpa farming -- a system of rotating crops and allowing previous plots to lie fallow in between use to maximize yields.Several protected areas were established in the late 1980s and early 1990s. By the second period examined (1999-2001), forests in these protected areas had regrown but losses to wetlands continued, as did the conversion of nonprotected land to agriculture.The third period mapped (2014-2016) followed a shift to industrial agriculture in the 2000s and showed "alarming" losses to both forest (7.5% loss) and wetlands (28.2% loss) outside of protected areas, said co-author Sheryl Luzzadder-Beach, the founding director of the university's Water Quality & Environmental Hydrology Lab.Population growth contributed to the increase in land used for agriculture. However, it was a greater factor between the first and second periods, when the population nearly doubled, than between the second and third periods, when population grew more slowly, indicating that changes in farming practices had a greater impact on land use.The maps also revealed the importance of conservation efforts in maintaining forests. Of the remaining forest in the study area, 76% is estimated to be on protected lands. These habitats are crucial in housing native flora and fauna and also contain structures from the Maya civilization important to the region's cultural heritage."These ecosystems provide many services such as aiding in the water cycle and preventing flooding," Doyle said. "The conversion of forest to pastureland and industrial agriculture is also a major contributor to increasing greenhouse gas emissions across the tropics."
Yadu Pokhrel, associate professor of civil and environmental engineering in the MSU College of Engineering and a co-author of the study, said climate is the key driver in the current changes to global river flow."It's a noteworthy finding because as climate change impacts extreme flows, it could be worsening flooding or increasing water scarcity during dry seasons," Pokhrel explained.Details of the new study, "Globally observed trends in mean and extreme river flow attributed to climate change," have been published in the journal, Pokhrel said flows in rivers and streams can alter year by year, but they don't change direction over long-time scales without serious influence -- from changing climate or human actions."Previous research has shown that river flows have been changing over time globally but the causes were not known. This study shows that the change in stream flow annually or during droughts was primarily caused by climate change during the past 30 years," Pokhrel said."This suggests that we are on course to lose more and more water in rivers as climate change continues, which could seriously undermine our ability to maintain water supplies for drinking, industries, power generation, and food production."The study used measurements of streamflow at 7,250 locations globally and computer simulations from nine global hydrological models to examine how humanmade climate change affected river flows across the global from 1971 to 2010. It found that climate change affected long-term average river flow as well as the flow during dry seasons."It highlights that it is critical to incorporate climate change impacts on water resource planning and management," Pokhrel added.Lukas Gudmundsson at ETH Zurich, Switzerland, led the research."This study was possible thanks to the great collaboration between researchers and institutions from 12 countries," Gudmundsson said.
The projections also showed that precipitation -- a threat to ice if it manifests as rain -- will likely increase on the peninsula by about 5% to 10% over that same time period.The estimates were published recently in the journal "We are concerned about these findings. We've been seeing overall quite big changes on the peninsula, generally getting warmer and ice shelves and glaciers discharging into the ocean," said David Bromwich, a leading author of the study and a research professor at The Ohio State University Byrd Polar and Climate Research Center and department of geography.The peninsula sticks up like a tail off the northwest side of Antarctica, curving near the southernmost part of South America and Chile.Since the 1950s, the peninsula, along with the rest of the western part of Antarctica, has been one of the fastest-warming regions on Earth. And because it is covered in mountains -- the highest peak is just over 10,600 feet -- standard climate models overlook some of the nuances of how climate change affects the peninsula, Bromwich said."The issue for the Antarctic peninsula is that it's this narrow but high mountain range, and these big models spanning the whole continent don't take that into account. Our goal was to provide more detail in those projections," he said.The analysis found that the greatest increases in temperature -- about 2 degrees Celsius -- were likely to happen in the Antarctic fall and winter, but warmer temperatures projected for summer would cause the most trouble.That could create a double threat to the ice on the peninsula, Bromwich said: Warmer temperatures also mean that some precipitation that might have previously fallen as snow will likely fall as rain.More rain means less snow on top of the ice, which protects ice from the sun's rays by reflecting them back into the sky."But now, if you have bare ice, or ice that's a little bit melting, and the sun beats down on it, a good fraction of that energy goes into melting," Bromwich said. "And we've seen this in the past with other ice shelves -- it's like a hammer, it just shatters."The study's authors also found that, to truly predict what might happen on the peninsula, better, more nuanced climate models are needed.Big climate models -- those that cover the surface of the Earth -- often do not consider other factors specific to smaller regions. In the Antarctic peninsula, Bromwich said, an overlooked factor is the modification of the westerlies, winds that blow from west to east near either pole. The westerlies blow directly over the Antarctic peninsula, creating a sort of micro-climate that big climate models often miss.Those nuances are especially important in the Antarctic peninsula, which has since the late 1970s been considered an important vanguard of what might happen throughout the rest of Antarctica. The peninsula, climate scientists have come to understand, is more susceptible to the effects of climate change. The first person to predict that changes throughout Antarctica would first be seen on the peninsula was another Ohio State researcher, John Mercer, who was known around the world for his work on climate change in Antarctica.
After an oil spill, oil droplets on the ocean surface can be transformed by a weathering process known as photooxidation, which results in the degradation of crude oil from exposure to light and oxygen into new by-products over time. Tar, a by-product of this weathering process, can remain in coastal areas for decades after a spill. Despite the significant consequences of this weathering pathway, photooxidation was not taken into account in oil spill models or the oil budget calculations during the Deepwater Horizon spill.The UM Rosenstiel School research team developed the first oil-spill model algorithm that tracks the dose of solar radiation oil droplets receive as they rise from the deep sea and are transported at the ocean surface. The authors found that the weathering of oil droplets by solar light occurred within hours to days, and that roughly 75 percent of the photooxidation during the Deepwater Horizon oil spill occurred on the same areas where chemical dispersants were sprayed from aircraft. Photooxidized oil is known to reduce the effectiveness of aerial dispersants."Understanding the timing and location of this weathering process is highly consequential. said Claire Paris, a UM Rosenstiel School faculty and senior author of the study. "It helps directing efforts and resources on fresh oil while avoiding stressing the environment with chemical dispersants on oil that cannot be dispersed.""Photooxidized compounds like tar persist longer in the environment, so modeling the likelihood of photooxidation is critically important not only for guiding first response decisions during an oil spill and restoration efforts afterwards, but it also needs to be taken into account on risk assessments before exploration activities" added Ana Carolina Vaz, assistant scientist at UM's Cooperative Institute for Marine and Atmospheric Studies and lead author of the study.
The study, published in the journal It is the gradual cooling and crystallisation of this 'magma ocean' that set the chemistry of Earth's interior -- a defining stage in the assembly of our planet's structure and the formation of our early atmosphere.Scientists know that catastrophic impacts during the formation of the Earth and Moon would have generated enough energy to melt our planet's interior. But we don't know much about this distant and fiery phase of Earth's history because tectonic processes have recycled almost all rocks older than 4 billion years.Now researchers have found the chemical remnants of the magma ocean in 3.6-billion-year-old rocks from southwestern Greenland.The findings support the long-held theory that Earth was once almost entirely molten and provide a window into a time when the planet started to solidify and develop the chemistry that now governs its internal structure. The research suggests that other rocks on Earth's surface may also preserve evidence of ancient magma oceans."There are few opportunities to get geological constraints on the events in the first billion years of Earth's history. It's astonishing that we can even hold these rocks in our hands -- let alone get so much detail about the early history of our planet," said lead author Dr Helen Williams, from Cambridge's Department of Earth Sciences.The study brings forensic chemical analysis together with thermodynamic modelling in search of the primeval origins of the Greenland rocks, and how they got to the surface.At first glance, the rocks that make up Greenland's Isua supracrustal belt look just like any modern basalt you'd find on the sea floor. But this outcrop, which was first described in the 1960s, is the oldest exposure of rocks on Earth. It is known to contain the earliest evidence of microbial life and plate tectonics.The new research shows that the Isua rocks also preserve rare evidence which even predates plate tectonics -- the residues of some of the crystals left behind as that magma ocean cooled."It was a combination of some new chemical analyses we did and the previously published data that flagged to us that the Isua rocks might contain traces of ancient material. The hafnium and neodymium isotopes were really tantalizing, because those isotope systems are very hard to modify -- so we had to look at their chemistry in more detail," said co-author Dr Hanika Rizo, from Carleton University.Iron isotopic systematics confirmed to Williams and the team that the Isua rocks were derived from parts of the Earth's interior that formed as a consequence of magma ocean crystallisation.Most of this primeval rock has been mixed up by convection in the mantle, but scientists think that some isolated zones deep at the mantle-core boundary -- ancient crystal graveyards -- may have remained undisturbed for billions of years.It's the relics of these crystal graveyards that Williams and her colleagues observed in the Isua rock chemistry. "Those samples with the iron fingerprint also have a tungsten anomaly -- a signature of Earth's formation -- which makes us think that their origin can be traced back to these primeval crystals," said Williams.But how did these signals from the deep mantle find their way up to the surface? Their isotopic makeup shows they were not just funnelled up from melting at the core-mantle boundary. Their journey was more circuitous, involving several stages of crystallization and remelting -- a kind of distillation process. The mix of ancient crystals and magma would have first migrated to the upper mantle, where it was churned up to create a 'marble cake' of rocks from different depths. Later melting of that hybrid of rocks is what produced the magma which fed this part of Greenland.The team's findings suggest that modern hotspot volcanoes, which are thought to have formed relatively recently, may actually be influenced by ancient processes."The geochemical signals we report in the Greenland rocks bear similarities to rocks erupted from hotspot volcanoes like Hawaii -- something we are interested in is whether they might also be tapping into the depths and accessing regions of the interior usually beyond our reach," said Dr Oliver Shorttle, who is jointly based at Cambridge's Department of Earth Sciences and Institute of Astronomy.The team's findings came out of a project funded by Deep Volatiles, a NERC-funded 5-year research programme. They now plan to continue their quest to understand the magma ocean by widening their search for clues in ancient rocks and experimentally modelling isotopic fractionation in the lower mantle."We've been able to unpick what one part of our planet's interior was doing billions of years ago, but to fill in the picture further we must keep searching for more chemical clues in ancient rocks," said co-author Dr Simon Matthews from the University of Iceland.Scientists have often been reluctant to look for chemical evidence of these ancient events. "The evidence is often altered by the course of time. But the fact we found what we did suggests that the chemistry of other ancient rocks may yield further insights into the Earth's formation and evolution -- and that's immensely exciting," said Williams.
That may soon change.Work led by research assistant professor TÃ¡rsilo Girona, with the University of Alaska Fairbanks Geophysical Institute, has revealed a method by which scientists -- and the public -- can have perhaps years of advance warning about a potential eruption.The solution lies in regular and widespread monitoring of the radiant temperature of a volcano's flanks before the appearance of any of the usual warning signs, such as glacier melting, sulfur odors, increased gas emissions, quaking and deformation.Girona is the lead author of a paper published today in the journal "This is showing that very large areas in the volcanoes are increasing the release of heat," Girona said. "It's a process which is going on in, we cannot say in the whole volcano itself, but in very large areas in the volcano. It's a large-scale process."Girona also works with the Alaska Volcano Observatory, which is evaluating how best to integrate the research findings into its monitoring of Alaska volcanoes. The AVO is a cooperative organization among UAF, the U.S. Geological Survey and the Alaska Division of Geological and Geophysical Surveys.David Fee, AVO coordinating scientist at UAF, said the findings can bolster volcano monitoring. That's important for the airline industry, particularly in Alaska and especially near Anchorage and other communities potentially in the path of an ash cloud."These results might provide critical information on how best to supplement existing monitoring networks, especially for difficult-to-monitor volcanoes in remote parts of Alaska," he said. "Any advance information on eruptions is helpful."The research focused on five volcanoes that erupted or exploded in the past 20 years, that displayed a wide range of behaviors and characteristics, and that are considered representative of volcanoes worldwide: Mount Redoubt in Alaska, Mount Ontake in Japan, Mount Ruapehu in New Zealand, Calbuco in Chile and Pico do Fogo in Cabo Verde, an island nation off the west coast of Africa.The researchers analyzed 16 Â½ years of thermal infrared radiance data collected by NASA's Terra and Aqua satellites.The satellite data had never been analyzed with an eye toward long-term early awareness of potential volcanic activity.Girona, Realmuto and Lundgren wanted to answer this question: Does volcanic activity underground produce a noticeable increase in radiant temperature at the surface long before an eruption?The data provided the answer for all five of the studied volcanoes: A clear "yes."The researchers wrote that volcanoes can experience thermal unrest "for several years before eruption" and that the unrest "is dominated by a large-scale phenomenon operating over extensive areas of volcanic edifices." They also found that the heat increased regardless of the type of eruption.Mount Redoubt, for example, had an increase of 0.85 degrees Fahrenheit, plus or minus 0.31 degrees (0.47 degrees Celsius, plus or minus 0.17), from mid-2006 to its major eruption of March 2009. Notably, the radiant temperature began increasing approximately one year earlier than the onset of other warning signs. Redoubt's radiant temperature began dropping quickly a year after the eruption and has remained low since 2014.The researchers said their findings will allow scientists to anticipate eruptions that are difficult to forecast through other geophysical and geochemical methods."This is especially relevant for phreatic eruptions (volcanic gas explosions), such as the one at Ontake, Japan, in 2014," Girona said. "Phreatic eruptions are generally very difficult to anticipate with traditional methods."The research, which Girona began at JPL and continued after moving to the Geophysical Institute, also provides insights into the interaction between a volcano's magmatic gases and its subsurface system of superheated water.Lundgren said the new approach, combined with such tools as GPS or satellite radar measurements of surface displacements, can reveal even more about volcano processes.For example, the team integrated surface heat emissions with surface displacements in another recent publication to better understand the behavior of Domuyo, a newly discovered deforming volcano in Argentina.
These new details on the daily life of the highly sought-after migratory fish can help better manage their populations and provide scientists with new information to understand the impacts to the animal from changing environmental conditions.To uncover these important details about the behaviors of mahi-mahi, or dolphinfish, the research team tagged captive spawning fish located at the UM Experimental Hatchery to build predictive spawning models and then used the models with data collected from mahi-mahi tagged in the wild. The study is the first to use acceleration data from remotely transmitting pop-up satellite tags to predict the spawning habitat of a wild marine fish. The UM Experimental Hatchery is the only place in the country where spawning mahi-mahi are kept in captivity.To build the predictive models, the research team tagged five spawning mahi-mahi (Coryphaena hippurus) at the UM Hatchery and waited overnight to record the timing of when they spawned. In total, 40 individual spawning events were tracked in captivity. Then, they paired the acceleration data collected from the tags with the exact time of spawning to estimate when the animals would spawn in the wild.To test the models' capability to estimate where and when the fish spawned in the wild, the researchers tagged 17 wild mahi-mahi off the coast of Miami and two in the Gulf of Mexico.From an analysis of the satellite tag data, the researchers found that wild mahi-mahi spawn at night, primarily during a new moon at depths greater than they would normally be. The Florida Straits appeared to be an important spawning habitat for mahi-mahi, although the models suggest that some limited spawning takes place further north.They found that mahi-mahi typically go deeper in the water column at night and are more surface oriented during the day. However, the phase of the moon had an effect on their nighttime depth distribution with a full moon bringing mahi-mahi closer to the surface at night.They also found that mahi-mahi use behavioral thermoregulation to stay between a relatively narrow temperature window of about 27-28 degrees Celsius (80 -- 82 degrees Fahrenheit). When surface waters are warmer, they move deeper and swim northward with the Gulf Stream to regulate their temperature, while fish tagged in cooler months stayed primarily in surface waters and migrated east and west between Florida and the Bahamas, rather than swimming north. They were also found to be the most active at cooler temperatures and in warm waters during a full moon at night."Mahi-mahi are highly sought after by recreational and commercial fisheries and are economically important," said Lela Schlenker, an alumna of the UM Rosenstiel school and lead author of the study. "It is critical to understand their migrations and the frequency, timing, and location of where they reproduce as well as how changing environmental conditions -- like warmer oceans -- might affect them to manage their populations sustainably now and in the future."The team also found from the satellite tag data that the wild mahi-mahi travel long distances -- up to 107 kilometers (105 miles) per day and dive to depths of 250 meters (820 feet)."Together these findings suggest that as climate change continues to warm ocean waters, mahi-mahi will likely continue to shift northward and deeper throughout their migrations," said Martin Grosell," professor and chair of the Department of Marine Biology and Ecology at the UM Rosenstiel School. "This is important for recreational and commercial landings of mahi-mahi and the ecology of pelagic ecosystems. A fruitful collaboration between scientists from three departments at the Rosenstiel School, as well as colleagues from University of Massachusetts, Dartmouth and access to healthy spawning mahi-mahi in captivity revealed new information about these valuable fish," said Grosell.
The results may help malaria control programs in the region develop better strategies for eliminating malaria infections and educating residents on how to protect themselves from infection.Mosquitos spread the malaria parasite to humans causing infections that can be severe and sometimes deadly. In the area along the Mekong river in Southeast Asia, many residents hunt or harvest wood in the surrounding forests, which can increase their risk of infection. Yet recent outbreaks of malaria in the region have also been linked to deforestation."As countries in the region focus their malaria control and elimination efforts on reducing forest-related transmission, understanding the impact of deforestation on malaria rates is essential," says first author Francois Rerolle, Graduate Student Researcher at the University of California San Francisco (UCSF), US, who works within the UCSF Malaria Elimination Initiative.To better understand the effects of deforestation on malaria transmission, Rerolle and colleagues examined both forest cover data and village-level malaria incidence data from 2013-2016 in two regions within the Greater Mekong Sub-region.They found that in the first two years following deforestation activities, malaria infections increased in villages in the area, but then decreased in later years. This trend was mostly driven by infections with the malaria parasite Plasmodium falciparum. Deforestation in the immediate 1-10-kilometer radius surrounding villages did not affect malaria rates, but deforestation in a wider 30-kilometer radius around the villages did. The authors say this is likely due to the effect that wider deforestation can have on human behaviour. "We suspect that people making longer and deeper trips into the forest results in increased exposure to mosquitoes, putting forest-goers at risk," Rerolle explains.Previously, studies on the Amazon in South America have found increased malaria infections in the first 6-8 years after deforestation, after which malaria rates fall. The difference in timing may be due to regional differences. The previous studies in the Amazon looked at deforestation driven by non-indigenous people moving deeper into the forest, while communities in the current study have long lived at the forest edges and rely on subsistence agriculture."Our work provides a more complete picture of the nuanced effects of deforestation on malaria infections," says senior author Adam Bennett, Program Lead at the UCSF Malaria Elimination Initiative. "It may encourage more in-depth studies on the environmental and behavioural drivers of malaria to help inform strategies for disease elimination."
Multiple factors have been associated with the melting of the ice cover: the primary factor being the greenhouse gas emissions from human activities that cause warming up of the atmosphere and the oceans and the consequent ice melting. Apart from this, atmospheric variations, ocean currents, and wind patterns also play a significant role. Now, a collaborative group of scientists from Japan and Australia -- led by Assistant Professor Kazutoshi Sato from Kitami Institute of Technology and Associate Professor Jun Inoue from National Institute of Polar Research in Japan -- has focused efforts on understanding how fluctuations in these climatic factors affect the warming of the Antarctic. They have documented their findings in a brand-new article published in Previous studies have examined the relationship between the wind dynamics over the Southern Ocean (also called SO; located north of Antarctica) and climate variability in tropical oceans. It was found that heating in tropical regions generates atmospheric waves called "Rossby wave trains" from the tropics to the Antarctic region via the SO, which causes heating of the West Antarctic region. Interestingly, Rossby waves are an attempt of nature to balance heat in the atmosphere as they transfer heat from the tropics to the poles and cold air towards the tropics.On the path of understanding the warming of AP, Dr. Sato points out, Dr. Sato and his team analyzed the temperature data from six stations in AP and the wind and cyclone patterns over the Tasman sea and the SO from 1979 to 2019. They found that even without unusual heating in the tropics, only the heating in the Tasman Sea modifies the wind patterns over the SO and forces the Rossby waves to move even deeper into the Amundsen sea low, a low-pressure area lying to the west of the AP. This larger pressure gradient causes stronger colder winds towards the poles. The meandering wind stream moves towards the AP, resulting in the warming of this region. Additionally, this effect was found to be prominent in the winter months when the cyclones are more active. The ever-increasing warming of the AP -- rather, the whole of Antarctica at large -- is a major concern plaguing climatologists all over the world. Commenting on the serious implications of this rapid rise in temperature and sea levels and the importance of the findings of their study, Dr. Inoue says, Dr. Sato and his team concludes by stating that the findings of their study can also aid the future forecast of ice sheet melting in Antarctica and consequent global sea level rise.
Since 2014, however, California's kelp forests have declined dramatically, and vast areas of the coast where kelp once thrived are now "urchin barrens," the seafloor carpeted with purple sea urchins and little else. This has occurred even in Monterey Bay, which hosts a large population of sea otters.In 2017, UC Santa Cruz graduate student Joshua Smith set out to understand why. "Here in Monterey Bay, we now have a patchy mosaic, with urchin barrens devoid of kelp directly adjacent to patches of kelp forest that seem pretty healthy," Smith said. "We wanted to know how did this sea urchin outbreak happen where there are so many otters, how did the otters respond, and what does that mean for the fate of kelp forests here on the Central Coast?"Working with a team of sea otter researchers at UCSC, the U.S. Geological Survey, and the Monterey Bay Aquarium, Smith conducted intensive underwater surveys along the Monterey Peninsula over a span of three years. The study built on decades of long-term monitoring of sea otter populations and kelp forest ecosystems along the California coast.Smith's findings, published March 8 in It began in 2013 with the outbreak of a mysterious disease called sea star wasting syndrome, which decimated sea stars all along the West Coast. Among the hardest hit species was the sunflower sea star (Pycnopodia helianthoides), a major sea urchin predator. But according to Smith, that was just one factor leading to a massive outbreak of sea urchins."We believe several factors initiated the urchin outbreak," he said. "The loss of a major urchin predator was soon followed by a decline in kelp productivity due to climatic stressors."In kelp forests, sea urchins mostly occupy crevices in rocky reefs on the seafloor where they are protected from predators. Pieces of kelp drift down onto the reef like falling leaves in a forest, delivering food directly to the urchins in their shelters.Kelp thrives where cold, nutrient-rich water wells up along the coast from the ocean depths, and giant kelp (the dominant species on the Central Coast) can grow more than a foot per day in good conditions. In 2014, however, an unprecedented marine heatwave hit the Northeast Pacific. Known as "the blob," it spread over the West Coast from Alaska to Central California. Around the same time, a major El NiÃ±o event brought warm water up the coast from the south.With all that warm water bathing the coast, kelp growth rates dropped dramatically. That meant less kelp detritus drifting into the crevices of the reefs, and sea urchins began to emerge in search of food. With no sea stars around to attack them, the urchins mowed down the living kelp fronds, turning kelp forests into urchin barrens."It happened so fast, before we knew it we had lost over 80 percent of the historic kelp forest cover in Northern California," Smith said. "We also had an urchin outbreak on the Central Coast, but not to the same extent as in the areas north of San Francisco."Smith and his colleagues found that sea otters on the Central Coast responded to the urchin outbreak by increasing their urchin consumption dramatically, eating about three times as many sea urchins as they had prior to 2014. Thanks to an abundance of prey (including an increase in mussels as well as urchins), the sea otter population increased substantially after 2014, from about 270 to about 432 sea otters in the Monterey region at the southern end of Monterey Bay.Yet the urchin barrens remained. A close look at sea otter foraging behavior explained why. Smith's team found that the otters were feeding on urchins in the remaining patches of kelp forest, but not in the urchin barrens."It's easy to see from shore where they are diving repeatedly and coming up with sea urchins," he said.The dive team surveyed those places, as well as areas not being targeted by otters, and collected urchins to examine in the lab. The researchers found that urchins from the kelp beds had much higher nutritional value than those from the urchin barrens, with large, energy-rich gonads. In the barrens, however, the urchins are starved and not worth the effort to a hungry otter."Some people call them zombie urchins," Smith said. "You open them up, and they're empty. So the otters are ignoring the urchin barrens and going after the nutritionally profitable urchins in the kelp forest."By doing this, the sea otters are helping to maintain those patches of healthy kelp forest, which are now crucially important for the persistence of giant kelp along the coast. Spores produced from those remaining patches could eventually reseed the barren areas and restore the kelp beds.Sea otters alone, however, won't disrupt the urchin barrens. Some other factor is needed to clear enough urchins from the barrens to enable new kelp plants to grow there. Smith said another predator could help knock down the urchin population, or a disease, or even a major storm bringing large, bottom-scouring waves. Some groups are even exploring human interventions, sending teams of volunteer divers out to remove sea urchins in an effort to restore the kelp forests.Mark Carr, professor and chair of ecology and evolutionary biology at UC Santa Cruz, said the differences between kelp forests on the southern, central, and northern coasts of California are striking. Carr, who is Smith's adviser but not a coauthor of the PNAS paper, has been studying kelp forests all along the West Coast for years. He said Southern California's kelp beds did not decline to the extent seen on the central and northern coasts."The difference in Southern California is that even though they lost the sea stars, they have other predators like the spiny lobster and California sheephead that are able to control urchin populations and allow the kelp forests to persist," Carr said.Northern California's kelp beds, in contrast, have fared much worse. The absence of sea otters north of San Francisco may be a factor, but it's hard to say because the dominant species of canopy-forming kelp is different, with bull kelp (Nereocystis leutkeana) dominant in the north and giant kelp (Macrocystis pyrifera) dominant on the central and southern coasts."It is possible that the presence of a healthy sea otter population in the north might have made those kelp forests more resilient, but it's hard to speculate," Carr said. "The role of a predator can be very different depending on where you are."The pioneering studies of sea otters and kelp forests conducted in the Aleutian Islands by James Estes, now a professor emeritus of ecology and evolutionary biology at UCSC, showed that as the sea otter population in the Aleutians recovered from near extinction, the otters transformed urchin barrens into kelp forests as they recolonized islands. But those interactions are playing out differently on the Central Coast, and could have yet another outcome in Northern California."This study not only fine tunes our understanding of the role of sea otters in kelp forests, it also emphasizes the importance of animal behavior," Smith said. "So much of this is driven by behavior -- the urchins shifting their behavior to active foraging, and the otters choosing to prey on healthy urchins in the kelp forest -- and these behavioral interactions have implications for the overall fate of the ecosystem."In addition to Smith, the coauthors of the paper include Joseph Tomoleoni and Sophia Lyon at the USGS Western Ecological Research Center, Michelle Staedler and Jessica Fujii at the Monterey Bay Aquarium, and Tim Tinker at UC Santa Cruz. This research was supported by the National Science Foundation.
Scientists at UmeÃ¥ University in Sweden and the Florida Museum of Natural History used paleontological databases to build a multilayered computer model of the history of marine life over the last 500 million years. Their analysis of the fossil record closely echoed a seminal 1981 study by paleontologist J. John Sepkoski -- with one key difference.Sepkoski's ground-breaking statistical work showed abrupt ocean-wide changes in biodiversity about 490 and 250 million years ago, corresponding to two mass extinction events. These events divided marine life into what he called "three great evolutionary faunas," each dominated by a unique set of animals.But the new model reveals a fourth.The fierce fight for survival that played out between predatory marine animals and their prey about 250 to 66 million years ago may have been an equally powerful force, reshaping ocean diversity into what we see today. This third grand transition was much more gradual than its predecessors and driven by organisms, rather than external processes."What we learned is that not all major shifts in animal life have been related to mass extinction events," said study lead author Alexis Rojas, who earned his Ph.D. at the University of Florida. Rojas is now a postdoctoral researcher at the Integrated Science Lab, a hub dedicated to interdisciplinary research at UmeÃ¥ University.Many scientists have long held the view that external factors such as volcanic activity, asteroid impacts or changes in climate are the primary drivers of major shifts in the Earth's biosphere, said study co-author Michal Kowalewski, Rojas' doctoral adviser and the Florida Museum Thompson Chair of Invertebrate Paleontology."The fossil record tells us that some of the key transitions in the history of life were rapid changes triggered by abrupt external factors. But this study shows that some of those major transitions were more gradual and may have been driven by biological interactions between organisms," he said.One reason Sepkoski's work was so revolutionary was that he took a mathematical approach to a practical problem: The fossil record is too big and complex for one person to be able to discern life's underlying patterns by looking at specimens alone."When its components are examined individually or in small groups, the complexity of their form, function, interaction, and history often seems overwhelming, and almost infinite," he wrote in the introduction to his 1981 study.Organizing these components into a hierarchy of systems, he argued, presented a more complete view. Sepkoski's modelling divided 500 million years of ocean life into three great dynasties, each separated by a mass extinction that cleared the way for new groups to flourish and dominate. After the reign of trilobites, clamlike animals known as brachiopods and certain ancient corals and ammonites rose to prominence. After the cataclysmic end-Permian extinction, sometimes known as the "Great Dying," they were in turn replaced by snails, clams, crustaceans, modern corals and various kinds of bony fishes.Sepkoski's hypothesis fundamentally changed how scientists thought about the history of life, Kowalewski said. It offered an organized way of understanding the history of marine ecosystems -- the overarching storyline and plot twists.But as our knowledge of the fossil record grows, so does Sepkoski's dilemma of how to analyze such vast and complex information, said Kowalewski."With millions of fossil specimens now documented, there is simply no feasible way for our brains to process such massive archives of paleontological data," he said. "Fortunately, analytical methods continue to improve, giving us better ways to extract and examine information hidden inside these immensely complex data."Rojas took on this challenge by using the latest advancements in data modelling. Specifically, he was interested in using complex network tools to create a better representation of the fossil record. Unlike other approaches in paleobiology, complex networks use a linked structure of nodes representing physical and abstract variables to uncover underlying patterns in a given system. Network approaches can be applied to social phenomena -- for example, showing a Facebook user's patterns of interactions with friends on the platform -- but they can also be applied to complex natural systems. Like Sepkoski, Rojas is a classically trained paleontologist looking for a fresh perspective on the fossil record."There are many processes happening at the same time at multiple scales: in your neighborhood, your country and across the entire planet. Now imagine the processes that occur in one day, one year or 500 years. What we are doing is trying to understand all these things across time," he said.A simple network might consist of a single layer -- all records of animal life and where they lived. But Rojas and his colleagues' network incorporates different intervals of time as individual layers, a feature lacking in previous research on macroevolution. The result is what Rojas described as a new, abstracted fossil record, a complement to the physical fossil record represented by the specimens in museum collections."It's important because the questions we are asking, the processes we are studying, occur at different scales in time and space," Rojas said. "We've taken some steps back so we can look at the entire fossil record. By doing that, we can explore all sorts of questions."Think of it like navigating a Google Earth that represents the oceans over the last 500 million years. When and where would you go?"Our interactive map of marine life shows smaller groups of animals and their interactions within each evolutionary fauna," Rojas said. "At the most basic levels, this map shows ocean regions with particular animals. The building blocks of our study are the individual animals themselves."This complex network shows what Sepkoski's model could not capture: a gradual transition in ocean life coincident with the Mesozoic Marine Revolution, which started about 150 million years ago during the Mesozoic Era. First hypothesized in the 1970s, this revolution was caused by the rapid increase of marine predators such as bony fish, crustaceans and snails, which have dominated oceans ever since. Their proliferation drove prey to become more mobile, hide beneath the ocean floor or enhance their defenses by thickening their armor, developing spines or improving their ability to regenerate body parts.Sepkoski knew about the Mesozoic Marine Revolution, but his model, limited by the methods and data available at the time, was unable to delineate the ocean ecosystems preceding and following this gradual transition. The study by Rojas and his colleagues demonstrates that both physical and biological processes play key roles in shaping ocean life at the highest levels."We are integrating the two hypotheses -- the Mesozoic Marine Revolution and the three great evolutionary faunas into a single story," Rojas said. "Instead of three phases of life, the model shows four."Joaquin Calatayud, Magnus Neuman and Martin Rosvall of UmeÃ¥ University also co-authored the study.
Led by Northwestern University, the researchers analyzed shells from foraminifera, an ocean-dwelling unicellular organism with an external shell made of calcium carbonate. After analyzing the calcium isotope composition of the fossils, the researchers concluded that massive volcanic activity injected large amounts of carbon dioxide into the Earth system, causing global warming and ocean acidification.They also found that global warming and ocean acidification did not just passively affect foraminifera. The organisms also actively responded by reducing calcification rates when building their shells. As calcification slowed, the foraminifera consumed less alkalinity from seawater, which helped buffer increasing ocean acidity."The formation and dissolution of calcium carbonate help regulate the acidity and alkalinity of seawater," said Northwestern's Andrew Jacobson, a senior author of the study. "Our calcium isotope data indicate that reduced foraminiferal calcification worked to dampen ocean acidification before and across the PETM.""This is a pretty new concept in the field," added Gabriella Kitch, the study's first author. "Previously, people thought that only the dissolution of carbonates at the sea floor could increase alkalinity of the ocean and buffer the effects of ocean acidification. But we are adding to existing studies that show decreased carbonate production has the same buffering effect."The research was published online last week (March 4) in the journal Jacobson is a professor of Earth and planetary sciences at Northwestern's Weinberg College of Arts and Sciences. Kitch is a Ph.D. candidate and National Science Foundation Graduate Research Fellow in Jacobson's laboratory. Northwestern Earth science professors Bradley Sageman and Matthew Hurtgen, as well as collaborators from the University of California-Santa Cruz (UCSC) and the University of Kansas, coauthored the paper with Jacobson and Kitch.To study oceanic conditions during the PETM, the researchers examined the calcium isotope composition of foraminiferal fossils collected from two sites -- one in the southeast Atlantic Ocean and one in the Pacific Ocean -- by the Ocean Drilling Program.Because each fossilized shell is about the size of a single grain of sand, UCSC researchers physically collected the tiny specimens by first identifying them under a microscope. After sorting the shells from bulk sediments, the Northwestern team dissolved the samples and analyzed their calcium isotope composition using a thermal ionization mass spectrometer."The work is very challenging," Jacobson said. "To manipulate these tiny materials, you have to pick them up, one by one, with a wet paintbrush tip under a microscope."As the shells formed more than 56 million years ago, they responded to oceanic conditions. By examining these shells, the Northwestern team found that calcium isotope ratios increased prior to the onset of the PETM."We are looking at one group of organisms that built their shells in one part of the ocean, recording the seawater chemistry surrounding them," Kitch said. "We think the calcium isotope data reveal potential stress prior to the well-known boundary."Other archives indicate that the atmosphere-ocean system experienced a massive carbon dioxide release immediately before the PETM. When atmospheric carbon dioxide dissolves in seawater, it forms a weak acid that can inhibit calcium carbonate formation. Although it is still undetermined, Earth scientists believe the carbon release most likely came from volcanic activity or cascading effects, such as a release of methane hydrates from the seafloor as a result of ocean warming."My suspicion is that it's both of these factors or some sort of combination," Sageman said. "Most big events in Earth's history represent a confluence of many actors coming together at the same time."This is the third study led by Jacobson to find that ocean acidification precedes major environmental catastrophes that correlate with large igneous province eruptions. Last month, Jacobson's team published results finding that volcanic activity triggered a biocalcification crisis prior to an ocean anoxic event that occurred 120 million years ago. Just over a year ago, Jacobson's team published another study finding ocean acidification preceded the asteroid impact leading to the Cretaceous-Paleogene mass extinction event 66 million years ago, which included the demise of dinosaurs.In all three studies, Jacobson's team used sophisticated tools in his laboratory to analyze the calcium isotope composition of calcium carbonate fossils and sediment. Jacobson said a clear pattern is emerging. Influxes of carbon dioxide led to global warming and ocean acidification and, ultimately, to massive environmental changes."In all of our studies, we consistently see an increase in calcium isotope ratios before the onset of major events or extinction horizons," Jacobson said. "This seems to point to similar drivers and common responses.""Perhaps the calcium isotope system has a sensitivity to the earliest phases of these events," Sageman added.Many researchers study the PETM because it provides the best analog for current-day, human-caused global warming. The carbon influx during the PETM is similar to the amount of carbon released during the past two centuries. The timescales, however, differ significantly. Temperatures during the PETM increased by 5 to 8 degrees Celsius over 170,000 years. With human-caused climate change, the same level of warming is projected to occur in less than 200 years, if carbon dioxide emissions remain unabated.Frighteningly, terrestrial and ocean stress, including a major decrease in foraminiferal calcification, accompanied the PETM."The PETM is a model for what happens during major large carbon cycle perturbations," Jacobson said. "A lot of predictions for Earth's future climate rely on understanding what happened during the PETM."
A new study published today in The impact of subsidence combined with sea-level rise has until now been considered a local issue rather than a global one.But the new study shows that coastal inhabitants are living with an average sea level rise of 7.8 mm -- 9.9 mm per year over the past twenty years, compared with a global average rise of 2.6mm a year.And the impacts are far larger than the global numbers reported by the Intergovernmental Panel on Climate Change (IPCC).Lead researcher Prof Robert Nicholls, Director of the UK's Tyndall Centre for Climate Change Research and Chair of Climate Adaptation at the University of East Anglia, said: "Climate induced sea-level rise is caused by melting glaciers and thermal expansion of water due to rising global temperatures."Rapid rates of subsidence in deltas and especially cities on deltas are also human-caused, mostly due to groundwater pumping, also oil and gas extraction, and sediment resupply prevented by upstream dams, flood defences, sand extraction or mining."About 58 per cent of the world's coastal population lives on deltas where land is subsiding. Less than 1 per cent of global coastal population lives where land is uplifting."We wanted to look at the big picture globally, to better understand the impact of global sea-level rise combined with measurements of sinking land."We found that coastal populations live with sea-level rise at three and four times the global average and that the impacts of sea-level rise being experienced today are much larger than the global numbers being reported by the Intergovernmental Panel on Climate Change (IPCC)."Addressing human-induced subsidence is important in the short term, as it is an essential coastal adaptation to protect people and economies," he added.The research team assessed four components of relative sea-level change -- climate induced sea-level change, the effects of glacier weight removal causing land uplift or sinking, estimates of river delta subsidence and subsidence in cities.Sea-level measurements were taken from satellite data. The team then weighted their results by population to show their importance to people.The overall analysis used the Dynamic Interactive Vulnerability Assessment (DIVA) model which is designed for understanding coastal management needs.They found that high rates of relative sea-level rise are most urgent in South, South East and East Asia as the area has many subsiding deltas and coastal flood plains, growing coastal megacities and more than 70 per cent of the world's coastal population.They also found that over the 20th Century, the city of Tokyo experienced net subsidence of 4m, while Shanghai, Bangkok, New Orleans, and Jakarta, have experienced between 2m and 3m subsidence.In Tokyo, Shanghai and Bangkok the subsidence has been stopped or greatly reduced by reduced groundwater extraction, while in other cities there has been little direct response to reduce subsidence.Prof Robert Nicholls said: "One of the main reasons that Jakarta, the capital city of Indonesia, is being moved to Borneo is because the city is sinking due to groundwater extraction from shallow wells."We hope that our analysis improves the understanding of how sea-level rise and subsidence are hand-in hand for science and coastal management policy worldwide. Jakarta might be just the beginning."The research was led by the University of East Anglia (UK) in collaboration with the Global Climate Forum, Berlin (Germany), Humboldt-University, Berlin (Germany), Bournemouth University (UK), Kiel University (Germany), UniversitÃ© de Toulouse (France), the University of Southampton (UK) and East China Normal University, Shanghai (China).It was funded by the EC Horizon 2020 Framework Programme, IDRCEC Seventh Framework Programme, and EC Seventh Framework Programme.
"Irrigation of future biomass plantations for energy production without sustainable water management, combined with population growth, could double both the global area and the number of people experiencing severe water stress by the end of the century, according to our computer simulations," says lead author Fabian Stenzel from the Potsdam Institute for Climate Impact Research (PIK) who developed the research idea in the Young Scientists Summer Program of the International Institute for Applied Systems Analysis (IIASA). "However, sustainable water management could almost halve the additional water stress compared to another analyzed scenario of strong climate change unmitigated by bioenergy production.""Sustainable water management means both political regulation -- such as pricing or water allocation schemes -- to reduce the amounts of water taken from rivers as well as on-farm improvements to make more efficient use of the water," says co-author Sylvia Tramberend from IIASA. This could include cisterns for rainwater collection or mulching to reduce evaporation. "Moreover, sustainable water management includes the preservation of reliable river flows to ensure undisturbed ecosystems in and alongside rivers. Up- and downstream river management may in fact require international cooperation calling for more transboundary river management as well as between different water users -- that's the challenge ahead for integrated water resource management."Largely unmitigated global warming together with population growth would increase the number of people under water stress by about 80% in the simulations. Enhanced use of bioenergy with carbon capture and storage could limit climate change: When plants grow, they take up COIn many scenarios, these are seen as necessary for meeting ambitious climate mitigation targets if direct emission reductions proceed too slowly, and to balance any remaining greenhouse gas emissions that are difficult or impossible to reduce, for instance potentially in aviation, certain types of industry or in livestock production."According to existing scenarios, biomass plantations could increase by up to 6 million square kilometers if global warming is to be limited to 1.5 degrees Celsius by the end of the century, the more ambitious of the two temperature targets of the Paris Agreement," says co-author Dieter Gerten from PIK. "We use these scenario inputs to run simulations in our high-resolution global vegetation and water balance model to explore the freshwater implications. While substantial irrigation implied in a bioenergy plus CCS scenario including population growth suggests a 100% increase in the number of people facing water stress, combining it with sustainable water management brings the number down to 60%. This, of course, is still an increase, so challenging tradeoffs are on the table."Regions that already suffer from water stress today would be most affected in the climate change scenario, like the Mediterranean, the Middle East, northeastern China, South-East and southern West Africa. In the bioenergy plus CCS scenario without sustainable water management, high water stress extends to some otherwise unaffected regions, like the East of Brazil and large parts of Sub-Saharan Africa. Here, large biomass plantation areas in need of irrigation are assumed in the scenario analyzed.Climate mitigation is one of the Sustainable Development Goals (SDGs) the world has agreed to achieve. The water-energy-environment nexus studied in this research highlights that pathways to sustainability must consider all affected SDGs."The numbers show that either way, sustainable water management is a challenge urgently to be addressed," says co-author Wolfgang Lucht, head of PIK's Earth System Analysis research department. "This new study confirms that measures currently considered to stabilize our climate, in this case bioenergy plus CCS, must take into account a number of further dimensions of our Earth system -- water cycles are one of them. Risks and tradeoffs have to be carefully considered before launching large-scale policies that establish biomass markets and infrastructure. The concept of Planetary Boundaries considers the whole Earth system, including but not limited to climate. Particularly the integrity of our biosphere must be acknowledged to protect a safe operating space for humanity."
Now researchers in the College of Natural Resources and Environment and the Department of Biological Systems Engineering are using stream quality data to find new insights into the interactions between the health of our natural spaces and human well-being.Their findings, published in the journal "We started off wanting to explore the general, intuitive relationship between human well-being and ecosystem health," explained Paul Angermeier, professor in the Department of Fish and Wildlife Conservation and assistant unit leader of the Virginia Cooperative Fish and Wildlife Research Unit for the U.S. Geological Survey. "Many of us intuit that healthy ecosystems produce benefits that accrue to people, but that outcome isn't well documented in a quantitative way."To document that relationship, the research team had to break from the environmental quality management processes that too often separate the natural world from human experiences."When we consider natural resources, we tend to think about whether we're managing an environment for nonhuman considerations or human ones," said Associate Professor Leigh-Anne Krometis, of the Department of Biological Systems Engineering, which is in both the College of Engineering and the College of Agriculture and Life Sciences. "For instance, at the state level we have a department of environmental quality and a department of health, which both deal with the subject of water quality, but in different ways. What we wanted to see was how those two perspectives converge."To find correlations across the state, the researchers used two key data sets: water quality measurements provided by the Virginia Department of Environmental Quality and county-level demographics data from the U.S. Census Bureau. They considered 13 indicators of human well-being, four demographic metrics, and two indicators of stream health."We had large data sets that we had to organize and process," explained Professor Marc Stern of the Department of Forest Resources and Environmental Conservation. "Our expectations on finding meaningful relationships between stream health and human factors weren't that high. The fact that they showed up so distinctly was a surprise."What the researchers found is that there is a strong correlation between ecosystem health and human demographics, particularly along the lines of race. Stream conditions were found to be better in counties with higher percentages of white residents. More polluted streams were correlated with higher degrees of overall mortality."The term environmental justice is important to bring into our discussion," noted Stern, a senior fellow in the Center for Leadership in Global Sustainability. "These findings relate to the broader issue of systemic prejudices and the reality that our institutions and social systems do not favor marginalized communities. They get caught up in a cycle of being left behind, and while it's not impossible to break that pattern, it's going to take work."Virginia is a suitable microcosm for revealing such dimensions: the state has high-density urban cities, suburban and rural areas, coastal and mountain geographies, and a broad socio-economic diversity that make it a useful starting point for broader research into the subject of human-environment interactions.A crucial next step for the researchers is understanding how people are interacting with natural environments."We still don't have hard data on how people are interacting with nature," said Angermeier, who, along with Krometis, is an affiliate of Virginia Tech's Global Change Center housed in the Fralin Life Sciences Institute. "For instance, we found that mortality rates for people are correlated with contamination levels in fish. What does that mean? Are people eating contaminated fish, are they merely sharing a polluted water source, or is it something else? A better understanding of the mechanisms by which people are interacting with water will help us draw clearer conclusions about health outcomes."The project was funded by Virginia Tech's Global Change Center, the Institute for Society, Culture, and the Environment, and the Fralin Life Sciences Institute. The contributing faculty members aim to expand their research by looking to see if similar correlations between environment health and human well-being extend across the Mid-Atlantic and the U.S. as a whole.
For the first time, researchers have been able to obtain full-depth glacial meltwater observations in winter, using instruments attached to the heads of seals living near the Pine Island Glacier, in the remote Amundsen Sea in the west of Antarctica.The harsh environmental conditions in the Antarctic limit the use of most traditional observation systems, such as ships and airplanes, especially in winter. But oceanographers working with biologists used data collected by tagged seals to measure water temperature and salinity.The paper, 'Winter seal-based observations reveal glacial meltwater surfacing in the southeastern Amundsen Sea', is published in today the journal The researchers found a highly variable meltwater distribution with two meltwater-rich layers -- one in the upper 250 metres and another at around 450 metres deep -- connected by scattered meltwater-rich columns. The hydrographic signature of meltwater is clearest in winter, when its presence can be unambiguously mapped; this analysis is only possible in winter.The surfacing meltwater provides near-surface heat that helps to maintain areas of open seawater surrounded by sea ice, close to glaciers, and may change the melting rate of these fragile ice shelves. These findings offer important clues to better predicting the future climate system and sea level rise.Pine Island Glacier is rapidly melting, exporting the glacial meltwater into the ocean. Glacial meltwater is thought to play a role in hydrography and sea ice distribution, but until now little has been known about it.Yixi Zheng, a postgraduate researcher in UEA's School of Environmental Sciences, is the lead author of the study. She said: "The temperature and salinity of water change everywhere glacial meltwater exists. Just like looking for a 'fingerprint' of glacial meltwater, we use temperature and salinity data to track the glacial meltwater."The glacial meltwater distribution is very patchy. It doesn't mix well with the ambient water, instead flowing along two meltwater-rich layers in the upper 250 metres and at around 450 metres, connected by meltwater-rich columns."As the glacial meltwater is warmer and fresher than the ambient water, it is lighter than the ambient water and more likely to rise up. It brings heat and nutrients such as iron to the near surface, which may melt the sea ice near glaciers and increase the nutrient level near the surface. This enhances the air-sea interactions, and the meltwater-related nutrient may boost the growth of marine planktons like algae."The winter processes revealed by the study are likely important for bringing nutrients to the near-surface layer prior to the spring bloom, and for bringing heat to the surface to prevent sea ice from forming. This action helps to maintain the open water areas, called polynyas, in front of glaciers.Many glaciers around Antarctica are thinning rapidly, due primarily to basal melting (i.e. melting that occurs at the interface between the ocean and the ice shelf glacier). The strongest melt has been reported in west Antarctic glaciers such as the Pine Island Glacier, where the research took place.The volume of meltwater produced is small in comparison with the volumes of Antarctic shelf seas, but it is believed to exert a disproportionate influence on regional circulation and climate.The heat from the meltwater is likely to prevent sea ice formation, allowing melting of sea ice and thus increasing the extent of open water areas in front of glaciers.The strong offshore wind near the glacier front may also transport warm near-surface water further and expand the meltwater-influenced region. These enlarged polynyas (open-water areas surrounded by ice) can then lead to enhanced air-sea fluxes and have further impacts on iceberg calving and glacier melting.Seven southern elephant seals (Mirounga leonina) and seven Weddell seals (Leptonychotes weddellii) were captured and tagged with CTD-Satellite Relayed Data Loggers around the Amundsen Sea in February 2014. The data were gathered by Marine Mammals Exploring the Oceans Pole to Pole (MEOP). Researchers from the universities of Gothenburg and Rhode Island also contributed.The scientists say further research is required. The study was based on one year of seal-tag data from the Pine Island Glacier, so it can't be used to calculate trends over time or take into account interannual variability such as the El Nino-Southern Oscillation, which may affect the global water temperature.
A new study led by researchers at UC Santa Cruz documents this dramatic shift in the coastal ecosystem and analyzes the events that caused it. This was not a gradual decline, but an abrupt collapse of the kelp forest ecosystem in the aftermath of unusual ocean warming along the West Coast starting in 2014, part of a series of events that combined to decimate the kelp forests.Published March 5 in "There were a lot of disruptions at one time that led to this collapse, and the system now persists in this altered state," said first author Meredith McPherson, a graduate student in ocean science at UC Santa Cruz. "It's a naturally dynamic system that has been really resilient to extreme events in the past, but the die-off of sunflower stars caused the resilience of the ecosystem to plummet. As a result, the kelp forests were not able to withstand the effects of the marine heatwave and El NiÃ±o event combined with an insurgence of sea urchins."The researchers used satellite imagery from the U.S. Geological Survey's Landsat missions going back to 1985 to assess historical changes in kelp forest canopy cover.Bull kelp is the dominant canopy-forming kelp species north of San Francisco Bay, while giant kelp is dominant to the south. Both species thrive when strong upwelling of cold, deep water brings nutrients to the surface along the coast. Marine heatwaves and El NiÃ±o events suppress coastal upwelling, resulting in warm water and low nutrient conditions in which kelp grows poorly."There have been big changes before, when a strong El NiÃ±o has reduced the kelp canopy dramatically, but in the past it's always come back," said coauthor Raphael Kudela, professor and chair of ocean science at UC Santa Cruz. "The loss of resiliency is what made this time different -- the combination of ocean warming and the loss of the sea stars allowed the urchins to take over."Sea star wasting disease first appeared in 2013, affecting all types of sea stars along the West Coast. The sunflower sea star was among the hardest hit species and was recently was listed as critically endangered by the International Union for Conservation of Nature.Late 2014 saw the advent of an unusual marine heatwave in the Northeast Pacific which became known as "the blob" as it spread down the West Coast in 2015. A strong El NiÃ±o event began to develop around the same time, bringing warm water up the coast from the south. The warm water coincided with an increase in sea urchin populations along the North Coast."The alignment of all of those events resulted in an incredibly dramatic loss of kelp," Kudela said.Kelp forests declined all along the California coast, but not to the same extent as in Northern California. Bull kelp is an annual species that regrows each year, which may make it more sensitive to these stressors than giant kelp. But another critical difference in Northern California is the absence of other urchin predators such as sea otters, which have enabled patches of healthy kelp forest to persist in Monterey Bay, for example."Sea otters haven't been seen on the North Coast since the 1800s," McPherson said. "From what we observed in the satellite data from the last 35 years, the kelp had been doing well without sea otters as long as we still had sunflower stars. Once they were gone, there were no urchin predators left in the system."What that means for the future, she said, is that the prospects for recovery of the Northern California kelp forests are poor unless sunflower sea stars or some other urchin predator returns to the system. Even if temperature and nutrient conditions are good for kelp growth, new kelp plants will have a hard time getting established in the midst of the urchin barrens.There have been some efforts to have divers manually remove urchins from selected areas and see if that can help the kelp to recover, led by the Reef Check California Program (which contributed subtidal survey data for the study). An outbreak of sea urchin disease could also potentially lead to mass mortality of urchins and give the kelp a chance to recover. In the absence of some mechanism to reduce the urchin populations, however, it will be hard to restore and maintain the kelp forests, according to McPherson."There's a lot of research and discussion now about the best management strategies for the future," she said. "It's important to understand and monitor the whole system. If we're going to undertake restoration efforts, we need to make sure to do it when the temperature and nutrient conditions are right for the kelp."Kudela said ocean temperatures are beginning to cool down along the coast, after remaining above normal since 2014. "This year we are finally seeing ocean temperatures starting to cool off, so we're hoping that it reverses naturally and the kelp is able to take off again," he said. "There's really not much we can do except to keep monitoring it. Of course, the long-term solution is to reduce our carbon emissions so we don't have these extreme events."
Scientists tracked breeding gannets from Grassholm Island in Wales over 11 years with tiny GPS devices and by measuring isotopic signatures in their blood.Male gannets flew an average of 220km to forage for their chicks, while females averaged 260km. Some birds travelled 1,000km on a single trip.The scientists also found that the two sexes selected different habitats and foraged at different times of day, but some years they were more in sync.Dr Bethany Clark worked on the research during her PhD at the University of Exeter's Environmental and Sustainability Institute, and now works at BirdLife International."Our study used GPS tracking to investigate behaviour and stable isotopes revealed information about their diet," she said."The foraging differences we found might indicate that males and females respond differently to changes in environmental conditions, such as how windy it is."Their dietary preferences were more consistent over the years: males tended to eat larger fish from closer to shore than females."Our results highlight the importance of long-term studies."Stephen Votier, Professor of Seabird Ecology at the Lyell Centre, Heriot-Watt University, in Edinburgh said: "These birds are true ocean wanderers -- travelling thousands of miles at sea throughout their lives to find food. It must be a pretty challenging four and half months raising their chicks each year."The sexes are virtually identical so differences are not due to size. Instead, we think males stay close to home because they establish and maintain the nest and perhaps because of subtle differences in taste."
Ice shelves make up nearly 75% of Antarctica's coastline and buttress -- or hold back -- the larger glaciers on land, said Shujie Wang, assistant professor of geography at Penn State. If the ice shelves were to collapse and Antarctica's glaciers fell or melted into the ocean, sea levels would rise by up to 200 feet."When we try to predict the future contribution of Antarctica to sea-level rise, the biggest uncertainty is ice shelf stability," said Wang, who also holds an appointment in the Earth and Environmental Systems Institute. "There's no easy way to map the depth of fractures in the field over a regional scale. We found that satellite data can capture the depth and surface morphology of ice shelf fractures and thereby allow us to consistently monitor this information over a large range."Wang and her colleagues examined high-resolution data collected by the Ice, Cloud and Land Elevation Satellite (ICESat-2) over the Amery Ice Shelf, which is about the size of West Virginia, between October 2018 and November 2019. The satellite shoots green laser pulses to the land surface and uses reflected photons to determine surface height. Whereas other satellites have a resolution of several thousands of feet, ICESat-2 has a resolution of approximately 56 feet, enabling it to see smaller fractures and the fracture morphology.The researchers then ran the ICESat-2 data through an algorithm that identifies surface depression features to locate and characterize fractures in the ice. They reported their results in the journal The researchers identified three types of fractures -- U-shaped, parabolic-shaped and V-shaped fractures -- up to 164 feet deep in the ice shelf. They also realized that this surface information provides insights into what is happening hundreds of feet below the surface of the ice.Basal fracture morphology -- the shape and size of fractures at the base of the ice shelf -- is proportional to the surface depressions, according to Wang. As the glacier that the ice sheet is buttressing accumulates more snow and ice, the parabolic-shaped fractures flow toward the edges of the ice shelf. Once they cross a certain boundary, those surface fractures have a greater potential to penetrate deeper into the ice as the basal fractures extend upward. These fractures can then become V-shaped, potentially signaling that a rift -- a fracture that penetrates the entire thickness of the ice sheet -- has formed. These rifts are more likely to cause calving events."Incorporating satellite-based vertical information can improve future ice shelf models," Wang said. "It can help us actually predict calving fronts and where an ice shelf is vulnerable to these events."Other contributors to this study included Patrick Alexander and Marco Tedesco, Lamont-Doherty Earth Observatory at Columbia University and NASA Goddard Institute for Space Studies; Qiusheng Wu, University of Tennessee; and Song Shu, Appalachian State University.The National Science Foundation and NASA supported this study.
This look at a critically important period in the life cycle of endangered loggerhead turtles could help inform more comprehensive conservation efforts that encompass regions of the open ocean where young turtles grow, and not just the nesting beaches. It also pinpoints regions of the ocean that are important to study to better understand how to protect sea turtles."To understand where sea turtle hatchlings are being swept to when they enter the open ocean -- and how favorable that habitat is to turtle survival -- we need to simulate smaller scale ocean features, the jets and eddies that transport these younglings," said Cheryl Harrison, a researcher at the University of Texas Rio Grande Valley, who led the study. "The models typically used to simulate global ocean movement are too coarse for us to resolve these important features. The really exciting thing about this study is we were able to use a high-resolution, eddy-resolving model to track where turtles are traveling."The ocean simulation used for the new study, published in the journal The research was funded by the National Science Foundation, which is NCAR's sponsor, NASA, and the U.S. Department of Energy. Harrison began work on the study as a postdoctoral researcher at NCAR, working with oceanographer Matthew Long, who co-authored the study. Harrison is now an assistant professor at the University of Texas Rio Grande Valley.Loggerhead turtles nest on specific beaches scattered around the globe, often where strong currents come close to land. After hatching, the baby turtles head for the ocean, where they spend the next several years as they mature. Once they reach sexual maturity decades later, the turtles eventually return to the beach where they were born to mate and lay their own eggs before the cycle begins again.For the new study, Harrison and her colleagues studied how hatchlings are likely to disperse during the first year of their lives from nesting sites on the coasts of Japan, Florida, Cape Verde, Oman, west Australia, east Australia, Brazil, and South Africa. Because the baby sea turtles must stay near the surface of the ocean to breathe -- and because they are not yet able to swim for significant periods -- the researchers were able to emulate their possible journeys using a method known as particle tracking, which follows how particles "released" into the model move with simulated water trajectories over time.The results show that at many of the nesting sites, strong nearby currents -- including the Kuroshio, Gulf Stream, Brazil, and Agulhas currents -- sweep the turtles poleward to a region of ocean where two circular ocean currents (known as gyres) come together. This boundary between the subpolar and subtropical gyres is warm enough for the hatchlings to survive and also rich with zooplankton and other food that turtles depend on to survive.The study results help demarcate the regions where turtles from each beach are going in their "lost years" when ecologists cannot easily keep tabs on them. For example, turtles born in southeastern Florida travel with the Gulf Stream all the way to the Azores, a productive and warm ocean habitat perfect for nurturing them.At other nesting sites, such as the one on the coast of Oman, the hatchlings do not hitch a ride on a strong current to far-off ocean habitats. Instead, they use a local current that disperses them relatively nearby because the area waters are already suitable for the young turtles. This understanding of where the turtles go allows scientists to better understand what threats the turtles may be facing."Sea turtle hatchlings are very difficult to track and observe as they have high mortality rates and grow out of tags quickly," Harrison said. "Modelling studies help us close this observational gap and predict where they are going in the 'lost years.' Identifying ocean habitat helps us understand what factors are important for their survival in this life stage."
Every year, hundreds of introduced species cause billions of dollars in damage to ecosystems, agriculture and infrastructure in North America alone. The research, led by Stephanie Green, makes a case for working smarter, not harder, to temper the impact of destructive and widespread invasive species using a strategy called functional eradication."Rather than trying to completely eliminate invasive species that have spread over large areas, which is very challenging, functional eradication aims to limit their abundances below levels that damage the ecosystem in priority locations. Resources that might otherwise be wasted on attempting complete eradication can be spread to other areas, protecting more places from impacts," explained Green, assistant professor in the Department of Biological Sciences and Canada Research Chair in Aquatic Global Change Ecology and Conservation.Green partnered with Edwin Grosholz, an ecologist in the Department of Environmental Science and Policy at the University of California, Davis, to survey 232 natural resource managers and invasive species specialists in Canada and the United States."More than 90 per cent of these folks said the most destructive invaders in their regions were spread beyond a scale at which they could eradicate them, and instead local teams were engaged in a long-term battle to suppress or contain the species," explained Green.However, only two per cent said they had identified targets for when they had done enough to manage a species."This points to a major gap between the needs of the people who must make decisions about invasive species, and the information scientists and monitoring programs are collecting," said Grosholz.Managing widespread invasive species is a long-term endeavour, but not one without hope, Green explained."Involving local communities in the functional eradication process is essential for maintaining the capacity needed to continually suppress these invaders."An example of functional eradication at work is invasive lionfish. The beautiful Indo-Pacific fish, which are popular in aquariums, have spread throughout the Caribbean Sea and the Atlantic Ocean, where they prey on many native species. They are now caught and consumed as food, and used in local art. The financial incentives for catching lionfish are also serving to reduce their population below levels that affect native species in the area.Similar strategies can be applied to the European green crab, an invasive species found along the Pacific and Atlantic coasts in Canada and the United States, as well as Prussian carp, which is spreading throughout central Canada, including in Alberta's Bow River."Our study shows that ecologically damaging and widespread invasive species are prime candidates for functional eradication. To effectively keep populations down in priority areas, targets need to be based on how many of the invasive species it takes to cause major changes in the ecosystem," said Green.
The study used NASA's Ice, Cloud and Land Elevation Satellite (ICESat-2) to assemble the largest ever dataset of seasonal water levels in more than 227,000 lakes, ponds and reservoirs worldwide. The data reveal that even though human-managed reservoirs comprise only a small percentage of all water bodies, they account for 57% of the total seasonal water storage changes globally."We tend to think of the water cycle as a purely natural system: Rain and snowmelt run into rivers, which run to the ocean where evaporation starts the whole cycle again," said Sarah Cooley, a postdoctoral researcher at Stanford University who launched the research project while a graduate student at Brown University. "But humans are actually intervening substantially in that cycle. Our work demonstrates that humans are responsible for a majority of the seasonal surface water storage variability on Earth."Cooley led the work with Laurence Smith, a professor of environmental sciences at Brown, and Johnny Ryan, a postdoctoral researcher at the Institute at Brown for Environment and Society.The researchers say the study provides a critical baseline for tracking the global hydrological cycle as climate change and population growth put new stresses on freshwater resources.Launched into orbit in 2018, ICESat-2's primary mission is to track changes in the thickness and elevation of ice sheets around the world. It does so with a laser altimeter, which uses pulses of light to measure elevation to an accuracy of 25 millimeters. Cooley, who has experience using satellites to study water levels in Arctic lakes, was interested in bringing the satellite's precise measurement capacity to bear on lake levels worldwide.Cooley says that ICESat-2's laser altimeter has far greater resolution than instruments used to measure water levels in the past. That made it possible to gather a large, precise dataset that included small ponds and reservoirs."With older satellites, you have to average results over a large area, which limits observations to only the world's largest lakes," Cooley said. "ICESat has a small footprint, so we can get levels for small lakes that we couldn't get close to before. That was important for understanding global water dynamics, since most lakes and reservoirs are pretty small."From October 2018 to July 2020, the satellite measured water levels in 227,386 bodies of water, ranging in size from the American Great Lakes to ponds with areas less than one tenth of a square mile. Each water body was observed at different times of year to track changes in water levels. The researchers cross-referenced the water bodies they observed with a database of reservoirs worldwide to identify which water bodies were human-controlled and which were natural.While countries like the U.S. and Canada gauge reservoir levels and make that information publicly available, many countries don't publish such data. And very few non-reservoir lakes and ponds are gauged at all. So there was no way to do this analysis without the precise satellite observations, the researchers said.The study found that while natural lakes and ponds varied seasonally by an average of .22 meters, human-managed reservoirs varied by .86 meters. Added together, the much larger variation in reservoirs compared to natural lakes means that reservoirs account for 57% of the total variation. In some places, however, human influence was even stronger than that. For example, in arid regions like the Middle East, American West, India and Southern Africa, variability attributed to human control surges to 90% and above."Of all the volume changes in freshwater bodies around the planet -- all the floods, droughts and snowmelt that push lake levels up and down -- humans have commandeered almost 60% of that variability," Smith said. "That's a tremendous influence on the water cycle. In terms of human impact on the planet, this is right up there with impacts on land cover and atmospheric chemistry."As the first global quantification of human impacts on the water cycle, the results will provide a crucial baseline for future research on how the impacts affect ecosystems around the world, the researchers say.In a separate study published recently in Geophysical Research Letters, the research team was able to use ICESat-2 data to shed light on how reservoir water is being used. The study showed that in places like the Middle East, reservoir levels tend to be lower in summer and higher in the winter. That suggests that water is being released in the dry season for irrigation and drinking water. In contrast, the trend in places like Scandinavia was the opposite. There, water is released in the winter to make hydroelectric power for heating."This was an exploratory analysis to see if we can use remote sensing to understand how reservoirs are being used at a global scale," Ryan said.Smith says he expects satellites to play an increasing role in study of the Earth's water cycle. For the past few years, he has been working with NASA on the Surface Water and Ocean Topography mission, which will be dedicated entirely to this kind of research."I think within the next three years we are going to see an explosion of high-quality satellite hydrology data, and we're going to have a much better idea of what's going on with water all over the planet," Smith said. "That will have implications for security, trans-boundary water agreements, forecasting crop futures and more. We're right on the edge of a new understanding of our planet's hydrology."The research was supported by the NASA Studies with ICESat-2 Program (80NSSC20K0963) and the NASA Surface Water and Ocean Topography mission (80NSSC20K1144S).
In recent years strong TCs have been making landfalls in Japan, such as Typhoon Jebi in 2018, which severely hit the Kinki region, and Typhoon Hagibis in 2019, which severely hit eastern Japan. While Japan has suffered from a number of TC impacts throughout its history, meteorological data for these events has been sparse.The team, including Specially Appointed Associate Professor Hisayuki Kubota of the Faculty of Science, Hokkaido University, investigated TC activity over the western North Pacific and TC landfalls in Japan by analyzing a combination of TC tracking and meteorological data observed at weather stations and lighthouses, including rescued and recovered historical observations.The team has collected and recovered TC track and landfall data and meteorological observations in the mid-19th century and later through an approach that rescues, collects and digitizes weather data across the world that has been stored away and often forgotten. To give the data useful consistency, the team developed a new, unified definition for TCs, based on minimum pressure.According to their analysis, TC landfall locations tend to shift to the northeast and then southwest regions of Japan at roughly 100-year intervals. The analysis also shows that annual TC landfall numbers and their intensities have been increasing in recent years, while noting that these increases may be part of an oscillated fluctuation operating on interdecadal time scales.The landfall numbers were relatively small in the late 20th century, and larger at other times. The Tohoku and Hokkaido regions, which experienced small numbers of TC landfalls in the late 20th century, may experience more landfalls in the future.Japan's first official meteorological observation was conducted in Hakodate, Hokkaido, in 1872. There is very little earlier meteorological data obtained by meteorological instruments at terrestrial stations, which makes it difficult to perform long-term meteorological variability analyses. In a new approach, the team focused on foreign ship log weather records from the mid-19th century made with meteorological instruments on vessels sailing through East- and Southeast Asian waters.The team used records from the US Navy expedition fleet to Japan led by Commodore Matthew C. Perry and from British Navy ships that also sailed to Japan to accurately identify the track of a TC moving over the ocean around the Okinawa Islands from 21 to 25 July 1853, and the track of a TC moving north over the East China Sea from 15 to 16 August 1863.The results of the study show for the first time the usefulness of such marine data in identifying weather patterns after the mid-19th century in Asia, where there is much less meteorological data for that time period compared with Western countries. "It is projected that stronger TCs will hit Japan in the future due to global warming. The long-term data from our research is indispensable for knowing the variabilities of TC activities in the past and to prepare for future TCs," says Hisayuki Kubota.
The diverse salmon stocks each have their own migration patterns and timing. They combine to provide the whales with a "portfolio" of prey that supports them across the entire year. The catch is that many of the salmon stocks are at risk themselves."If returns to the Fraser River are in trouble, and Columbia River returns are strong, then prey availability to the whales potentially balances out as the whales have evolved to move rapidly throughout their range," said NOAA Fisheries wildlife biologist Brad Hanson, lead author of the new research. "But if most of the stocks throughout their range are reduced then this could spell trouble for the whales."The researchers examined more than 150 prey and fecal samples collected from the whales from 2004 to 2017. This produced the most comprehensive picture yet of Southern Resident prey over the course of the year."When so many prey species are endangered, then they lose some of that diversity," Hanson said. "The question for managers is how do you support and improve this diverse portfolio of species and stocks."The analysis also revealed that the whales prey almost exclusively on Chinook salmon when they are available in the summer. However, they diversify their diet the rest of the year to include species such as skates, halibut, and lingcod, as well as steelhead, chum, and coho salmon. Most of the salmon the whales consume in winter and spring come from three large river systems: the Columbia, Sacramento, and rivers entering Puget Sound.The researchers note that increased production of hatchery fish could help support the 75 remaining whales, but that this strategy is not without risks.Many hatchery fish are already available at certain times of the year, said Robin Baird, a research biologist at Cascadia Research Collective and a coauthor of the study. Increasing the diversity of hatchery stocks to include stocks that inhabit the whales' range in winter, when they appear to have less food, may be most helpful."We don't need more cookie-cutter fish that all come back during the time when Chinook are most abundant; we need to diversify and increase availability at other times of the year," Baird said.Additional funding was provided through the federal Pacific Salmon Commission and the Washington State Legislature. The funding paid for the release of more than 11.6 million additional hatchery-origin Chinook salmon in 2020, compared to previous years. It will also pay for more than 18.3 million additional fish in 2021.In line with the findings, the hatchery production will help maintain the portfolio of stocks, including those that overlap with the killer whales during the lean times of winter. Biologists also manage the production to avoid risk to naturally produced salmon.The Southern Residents have historically spent much of the summer in the inland waters of the Salish Sea. There they feed almost exclusively on Chinook salmon from the Fraser River and the Skagit, Snohomish, and other rivers entering Puget Sound. In the late summer, fall and early winter, they also turn to coho and chum salmon as Chinook decline in number.Two of the three pods -- K and L pods -- typically move to the outer coast in fall and winter. There they spend much of their time feeding off the Washington coast, with forays south as far as Monterey Bay in California. They likely concentrate near the Columbia River area because of the large number of returning salmon, heavily supplemented by hatchery fish, the scientists said.They also diversify their diet with salmon from potentially as far away as the Taku River in Alaska and other species. Those fish comprise a larger share of the whales' diet than scientists first thought based on observations of the whales feeding at the surface. Biologists collected fecal samples from the whales while tracking them along the coast. The samples revealed the more complete picture, including the ocean species they consume underwater and out of sight.The third pod, J pod, spends more time in inland waters while also traveling along the west coast of Vancouver Island. There they access a mix of salmon traveling a kind of superhighway south to West Coast rivers.The research also explores the Southern Residents' potential competition for prey with Northern Resident killer whales. These whales are a separate population that primarily frequents Canadian waters off Vancouver Island and north. The Northern Residents have increased in number to about 300 as the Southern Residents have declined. These opposing trends may reflect the Northern Residents' greater access to prey.Salmon returning south from waters off Alaska and British Columbia to West Coast rivers pass through Northern Residents' range before reaching the Southern Residents. In comparing their data to results from an earlier Canadian study of Northern Residents, the researchers found that the Northern Residents consumed larger and older salmon. The largest and oldest class of salmon consumed by the Northern Residents were absent from the Southern Residents' diet.The Southern Resident J-pod that forages to the north of the other two pods may also benefit from the same earlier access. J-pod has had a greater reproductive rate than the other pods, the study notes.Chinook salmon are also shrinking over time along the entire West Coast, and other predators may also play a role."The net result is that the consistent consumption of these smaller fish, which have a lower caloric value, may pose an additional challenge to the [Southern Resident killer whale] population's ability to meet their energetic needs," the scientists wrote.NOAA Fisheries has designated the Southern Residents one of nine national Species in the Spotlight. These species are highly endangered and can benefit from focused recovery efforts, including conservation of their prey. NOAA Fisheries West Coast Region has already applied the prey study findings in its proposal to expand critical habitat for the Southern Residents along the West Coast."Knowing what these whales eat throughout the year and across their various habitats helps us focus recovery efforts for both the Southern Residents and the salmon they rely on," says Lynne Barre, Recovery Coordinator for the Southern Residents at NOAA Fisheries West Coast Region.
How many otters are there still in Germany? What habitats do threatened crested newts use on land? And do urban hedgehogs have to deal with different problems than their rural conspecifics? Anyone wishing to effectively protect a species should be able to answer such questions. But this is by no means easy. Many animals remain in hiding -- even their droppings can be difficult to find. Thus, it is often difficult to know exactly whether and at what rate their stocks are shrinking or where the remaining survivors are. "We urgently need to know more about these species," says Dr Annegret Grimm-Seyfarth of the UFZ. "But first we must find them."Remote sensing with aerial and satellite images is useful for mapping open landscapes or detecting larger animals. But when it comes to densely overgrown areas and smaller, hidden species, experts often carry out the search themselves or work with cameras, hair traps, and similar tricks. Other techniques (e.g. analysing trace amounts of DNA) have also been attracting increasing interest worldwide. The use of specially trained detection dogs can also be particularly useful. After all, a dog's sense of smell is virtually predestined to find the smallest traces of the target species. While humans have about six million olfactory receptors, a herding dog has more than 200 million -- and a beagle even 300 million. This means that dogs can perceive an extremely wide range of odours, often in the tiniest concentrations. For example, they can easily find animal droppings in a forest or plants, mushrooms, and animals underground.At the UFZ, the detection dogs have already proven their abilities in several research projects. "In order to be able to better assess their potential, we wanted to know how detection dogs have previously been used around the world," says Grimm-Seyfarth. Together with UFZ employee Wiebke Harms and Dr Anne Berger from the Leibniz Institute for Zoo and Wildlife Research (IZW) in Berlin, she has evaluated 1220 publications documenting the use of such search dogs in more than 60 countries. "We were particularly interested in which breeds of dogs were used, which species they were supposed to track down, and how well they performed," explains the researcher.The longest experience with the detection dogs is in New Zealand, where dogs have been tracking threatened birds since around 1890. Since then, the idea has been implemented in many other regions, especially in North America and Europe. The studies analysed focused mainly on finding animals as well as their habitats and tracks. Dogs have been used to find more than 400 different animal species -- most commonly mammals from the cat, dog, bear, and marten families. They have also been used to find birds and insects as well as 42 different plant species, 26 fungal species, and 6 bacterial species. These are not always endangered species. The dogs sometimes also sniff out pests such as bark beetles or invasive plants such as knotgrass and ragweed."In principle, you can train all dog breeds for such tasks," says Grimm-Seyfarth. "But some of them may require more work than others." Pinschers and Schnauzers, for example, are now more likely to be bred as companion dogs and are therefore less motivated to track down species. And terriers tend to immediately snatch their targets -- which is, of course, not desirable.Pointers and setters, on the other hand, have been specially bred to find and point out game -- but not to hunt it. This is why these breeds are often used in research and conservation projects in North America, Great Britain, and Scandinavia in order to detect ground-breeding birds such as ptarmigans and wood grouse. Retrievers and herding dogs also have qualities that make them good at tracking species. They are eager to learn, easy to motivate, enjoy working with people, and generally do not have a strong hunting instinct. That is why Labrador Retrievers, Border Collies, and German Shepherds are among the most popular detection dogs worldwide.Grimm-Seyfarth's Border Collie Zammy, for example, learned as a puppy how to track down the droppings of otters. This is a valuable contribution to research because the droppings can be genetically analysed to find out which individual it comes from, how it is related to other conspecifics, and what it has eaten. However, even for experienced experts, these revealing traces are not so easy to find. Especially small and dark coloured droppings are easy to overlook. Dogs, on the other hand, sniff even the most unremarkable droppings without distinction. In an earlier UFZ study, they found four times as many droppings as human investigators alone. And the fact that Zammy is now also looking for crested newts makes his efforts even more rewarding.According to the overview study, many other teams around the world have had similarly good experiences. In almost 90% of cases, the dogs worked much more effectively than other detection methods. Compared with camera traps, for example, they detected between 3.7 and 4.7 fold more black bears, pied martens, and bobcats. They are also often reach their destination particularly quickly. "They can find a single plant on a football field in a very short time," says Grimm-Seyfarth. They are even able to discover underground parts of plants.However, there are also cases where the use of detection dogs is not the method of choice. Rhinos, for example, leave their large piles of excrement clearly visible on paths so that humans can easily find them on their own. And animal species that know feral dogs as enemies are more likely to find (and fight) the detection dogs than to be found."However, in most cases where the dogs did not perform so well, poor training is to blame," says Grimm-Seyfarth. She believes that good training of the animal is the most important recipe for success for detection dogs. "If you select the right dog, know enough about the target species, and design the study accordingly, this can be an excellent detection method." She and her colleagues are already planning further applications for the useful detection dogs. A new project that involves tracking down invasive plant species will soon be launched.
The UNESCO report found Australia's six marine World Heritage Sites hold 40 per cent of the estimated 5 billion tons of carbon dioxide stored in mangrove, seagrass and tidal marsh ecosystems within UNESCO sites.The report quantifies the enormous amounts of so-called blue carbon absorbed and stored by those ecosystems across the world's 50 UNESCO marine World Heritage Sites.Despite covering less than 1 per cent of the world's surface, blue carbon ecosystems are responsible for around half of the carbon dioxide absorbed by the world's oceans while it is estimated they absorb carbon dioxide at a rate about 30 times faster than rainforests.Report author and ECU Research Fellow Dr Oscar Serrano said Australia's Great Barrier Reef, Ningaloo Coast and Shark Bay World Heritage areas contained the vast majority of Australia's blue carbon ecosystems."We know Australia contains some of the world's largest stores of blue carbon due to the enormous size and diversity of our marine ecosystems," he said."However here in Australia and around the world, these ecosystems are under threat from human development and climate change."While they're healthy, blue carbon ecosystems are excellent stores of carbon dioxide, but if they are damaged, they can release huge amounts of carbon dioxide stored over millennia back into the atmosphere."In 2011 seagrass meadows in the Shark Bay World Heritage Site in Western Australia released up to nine million tons of stored carbon dioxide after a marine heatwave devastated more than 1000sqkm of seagrass meadows.The UNESCO Report's authors have outlined the potential for the countries including Australia to use the global carbon trading market to fund conservation and restoration efforts at marine World Heritage Sites including here in Australia.Dr Serrano said both Shark Bay and the Great Barrier Reef ecosystems are at risk due to climate change and human development."There are significant opportunities for both the Great Barrier Reef and Shark Bay to be protected and restored to ensure they survive and thrive in the future," he said."Australia also has plenty of marine ecosystems in need of protection not contained within a World Heritage Site which are worthy of our attention.Dr Serrano's previous research has highlighted the millions of dollars in potential conservation and restoration projects of blue carbon ecosystems while also helping Australia and other countries achieve their commitments to the Paris Climate Agreement.The report was led by Professor Carlos Duarte and a team of collaborators from Australia, Saudi Arabia, Denmark, the United States, Kenya and the United Kingdom.The UNESCO Marine World Heritage report is titled 'Custodians of the globes' blue carbon assets' and can be accessed at the UNESCO webpage.
The Acheulean was estimated to have died out around 200,000 years ago but the new findings suggest it may have persisted for much longer, creating over 100,000 years of overlap with more advanced technologies produced by Neanderthals and early modern humans.The research team, led by Dr Alastair Key (Kent) alongside Dr David Roberts (Kent) and Dr Ivan Jaric (Biology Centre of the Czech Academy of Sciences), made the discovery whilst studying stone tool records from different regions across the world. Using statistical techniques new to archaeological science, the archaeologists and conservation experts were able to reconstruct the end of the Acheulean period and re-map the archaeological record.Previously, a more rapid shift between the earlier Acheulean stone tool designs often associated with Homo heidelbergensis -- the common ancestor of modern humans and Neanderthals -- and more advanced 'Levallois' technologies created by early modern humans and Neanderthals, was assumed. However, the study has shed new light on the transition between these two technologies, suggesting substantial overlap between the two.Acheulean stone tool technologies are the longest-lived cultural tradition practiced by early humans. Originating in East Africa 1.75 million years ago, handaxes and cleavers -- the stone tool types which characterise the period -- went on to be used across Africa, Europe and Asia by several different species of early human. Prior to this discovery, it was widely assumed that the Acheulean period ended between 300-150,000 year ago. However, the record was lacking in specific dates, and the timing of its demise has been heavily debated. The Kent and Czech team discovered that the tradition likely ended at different times around the world, varying from as early as 170,000 years ago in Sub-Saharan Africa through to as late as 57,000 years ago in Asia.To understand when the Acheulean ended, the team collected information on different archaeological sites from around the world to find the latest known stone tool assemblages. A statistical technique known as optimal linear estimation -- commonly used in conservation studies to estimate species extinctions -- was used to predict how much longer the stone tool tradition continued after the most recent known sites. In effect, the technique was able to model the portion of the archaeological record yet to be discovered.Dr Alastair Key, a Palaeolithic Archaeologist and the lead author of the study, said: "The earliest archaeological record will always be an incomplete picture of early human behaviour, so we know that the youngest known Acheulean sites are unlikely to actually represent the final instances of these technologies being produced. By allowing us to reconstruct these missing portions of the archaeological record, this technique not only gives us a more accurate understanding of when the tradition ended, but it gives us an indication of where we can expect to find new archaeological discoveries in the future."Dr Roberts added: "This technique was originally developed by myself and a colleague to date extinctions, as the last sighting of a species is unlikely to be the date when it actually became extinct. It is exciting to see it applied in a new context."Their research paper 'Modelling the end of the Acheulean at global and continental levels suggests widespread persistence into the Middle Palaeolithic' is published by 
While the answer to "how many coral species are there?" is 'Googleable', until now scientists didn't know how many individual coral colonies there are in the world."In the Pacific, we estimate there are roughly half a trillion corals," said the study lead author, Dr Andy Dietzel from the ARC Centre of Excellence for Coral Reef Studies at James Cook University (Coral CoE at JCU)."This is about the same number of trees in the Amazon, or birds in the world."The results are crucial for the research and conservation of corals and coral reefs as they decline across the world due to the effects of climate change."We need to know the abundance of a species to assess its risk of extinction," Dr Dietzel said. "However, there is very little data on most of Earth's wild animal and plant species -- not just corals."Dr Dietzel said the eight most common coral species in the region each have a population size greater than the 7.8 billion people on Earth.The findings suggest that while a local loss of coral can be devastating to coral reefs, the global extinction risk of most coral species is lower than previously estimated.Extinctions could instead unfold over a much longer timeframe because of the broad geographic ranges and huge population sizes of many coral species.Co-author Professor Sean Connolly, from Coral CoE at JCU and the Smithsonian Tropical Research Institute, said the study's new analysis of the 80 species considered by the IUCN to have an elevated extinction risk shows that 12 of those species have estimated population sizes of more than one billion colonies."As an example, the finger-coral, Porites nigrescens, ranks amongst the ten most abundant species we examined. It's also not considered to be highly susceptible to coral bleaching -- yet it is currently listed by IUCN as vulnerable to global extinction," Prof Connolly said.Co-author Professor Michael Bode from Coral CoE at JCU and the Queensland University of Technology said, "One third of the rarest species in our analysis -- covering the bottom ten percent of species abundances -- are nonetheless listed by the IUCN as being of Least Concern."The study measured the population sizes of more than 300 individual coral species on reefs across the Pacific Ocean, from Indonesia to French Polynesia. The scientists used a combination of coral reef habitat maps and counts of coral colonies to estimate species abundances.Co-author Professor Terry Hughes from Coral CoE at JCU said the study results have major implications for managing and restoring coral reefs."We counted an average of 30 corals per square metre of reef habitat. This translates into tens of billions of corals on the Great Barrier Reef -- even after recent losses from climate extremes," Prof Hughes said."Coral restoration is not the solution to climate change. You would have to grow about 250 million adult corals to increase coral cover on the Great Barrier Reef by just one percent."He said the study highlights the opportunity for action to mitigate the threats to reef species -- and well before climate change causes global extinctions -- to make an eventual recovery of reef coral assemblages possible."The challenge now is to protect wild populations of corals, because we could never replace more than a tiny percentage of them. Prevention is better than cure," Prof Hughes said."Given the huge size of these coral populations, it is very unlikely that they face imminent extinction. There is still time to protect them from anthropogenic heating, but only if we act quickly on reducing greenhouse gas emissions."
Fairy wrasses diverged in form and colour after repeated sea level rises and falls during the last ice age, finds a new study. Published in top journal Lead author, ichthyologist and PhD candidate at the University of Sydney, Mr Yi-Kai (Kai) Tea, says that the fish's divergence occurred rapidly and over a short amount of time."Although the fairy wrasses split from their most common ancestor some 12 million years ago, it was only within the last 2-5 million years ago that much of their divergences took place, in the Pliocene/Pleistocene epoch," said Mr Tea, a researcher in the School of Life and Environmental Sciences."They developed distinct colours and forms in a sort of evolutionary arms race, putting on dazzling displays in an effort to court females and chase off rival males. Also, sea level changes caused groups to become isolated, and therefore evolve separately. The repeated rise and fall of sea levels acted like a 'species pump', propelling fish into the Indian Ocean and even as far as the Red Sea. Most of this movement, however, occurred in the Pacific Ocean, in particular, around the Indo-Australian Archipelago."Mr Tea completed the work under the supervision of Professors of Molecular Evolution, Simon Ho and Nathan Lo.Despite the vast variation in colour and form, many species of fairy wrasses have highly conserved, or similar, regions of their genome. This poses a challenge in trying to reconstruct their evolutionary history.The current study used an approach that had not been previously attempted on fairy wrasses: by combining genome-wide ultra-conserved elements with mitochondrial DNA, the researchers reconstructed a robust evolutionary tree. Using that, they began to tease apart the reason behind the fish's diversification.In addition to sea level fluctuations, male fairy wrasses (as with many animals, the more colourful sex) developed their bright colours and individual forms to court females."They do a little dance, and they are capable of changing colours, sometimes temporarily flashing bright, iridescent colours. They also do this to ward off rival males," said Mr Tea. "In a reef where multiple species often occur, there is increased pressure for males to attract not only a female's attention, but also the female of the correct species.""We have only just begun scratching the surface of this exciting group, and more work still needs to be done in order to fully understand the drivers of species diversification," he continued.That work, and the present study, might be germane to reef conservation and management, too. For example, the finless 'mutant wrasse', an Australian endemic species restricted to a narrow distribution of reefs in far northwest Western Australia, is listed as vulnerable on the International Union for Conservation of Nature Red List of threatened species. The species has been placed in its own genus, with a single species. However, Mr Tea's study finds strong evidence that this species is simply a derived fairy wrasse, and that its loss of fins likely resulted from it being 'bottlenecked' in a narrow area.Fairy wrasse facts
"The Gulf Stream System works like a giant conveyor belt, carrying warm surface water from the equator up north, and sending cold, low-salinity deep water back down south. It moves nearly 20 million cubic meters of water per second, almost a hundred times the Amazon flow," explains Stefan Rahmstorf from the Potsdam Institute for Climate Impact Research PIK, initiator of the study to be published in Nature Geoscience. Previous studies by Rahmstorf and colleagues showed a slowdown of the ocean current of about 15 percent since the mid-20th century, linking this to human-caused global warming, but a robust picture about its long-term development has up to now been missing: This is what the researchers provide with their review of results of proxy data studies."For the first time, we have combined a range of previous studies and found they provide a consistent picture of the AMOC evolution over the past 1600 years," says Rahmstorf. "The study results suggest that it has been relatively stable until the late 19th century. With the end of the little ice age in about 1850, the ocean currents began to decline, with a second, more drastic decline following since the mid-20th century." Already the 2019 special report on the oceans of the Intergovernmental Panel on Climate Change (IPCC) concluded with medium confidence "that the Atlantic Meridional Overturning Circulation (AMOC) has weakened relative to 1850-1900." "The new study provides further independent evidence for this conclusion and puts it into a longer-term paleoclimatic context," Rahmstorf adds.Because ongoing direct AMOC measurements only started in 2004, the researchers applied an indirect approach, using so-called proxy data, to find out more about the long-term perspective of its decline. Proxy data, as witnesses of the past, consist of information gathered from natural environmental archives such as tree rings, ice cores, ocean sediments, and corals, as well as from historical data, for instance from ship logs."We used a combination of three different types of data to obtain information about the ocean currents: temperature patterns in the Atlantic Ocean, subsurface water mass properties and deep-sea sediment grain sizes, dating back from 100 to ca. 1600 years. While the individual proxy data is imperfect in representing the AMOC evolution, the combination of them revealed a robust picture of the overturning circulation," explains Levke Caesar, part of the Irish Climate Analysis and Research Unit at Maynooth University and guest scientist at PIK.As proxy records in general are subject to uncertainties, statistician Niamh Cahill from Maynooth University in Ireland tested the robustness of the results in consideration of these. She found that in 9 of the 11 data sets considered, the modern AMOC weakness is statistically significant. "Assuming that the processes measured in proxy records reflect changes in AMOC, they provide a consistent picture, despite the different locations and time scales represented in the data. The AMOC has weakened unprecedentedly in over 1000 years," she says.An AMOC slowdown has long been predicted by climate models as a response to global warming caused by greenhouse gases. According to a number of studies, this is likely the reason for the observed weakening. The Atlantic overturning is driven by what the scientists call deep convection, triggered by the differences in the density of the ocean water: Warm and salty water moves from the south to the north where it cools down and thus gets denser. When it is heavy enough the water sinks to deeper ocean layers and flows back to the south. Global warming disturbs this mechanism: Increased rainfall and enhanced melting of the Greenland Ice Sheet add fresh water to the surface ocean. This reduces the salinity and thus the density of the water, inhibiting the sinking and thus weakening the flow of the AMOC.Its weakening has also been linked to a unique substantial cooling of the northern Atlantic over the past hundred years. This so-called cold blob was predicted by climate models as a result of a weakening AMOC, which transports less heat into this region.The consequences of the AMOC slowdown could be manifold for people living on both sides of the Atlantic as Levke Caesar explains: "The northward surface flow of the AMOC leads to a deflection of water masses to the right, away from the US east coast. This is due to Earth's rotation that diverts moving objects such as currents to the right in the northern hemisphere and to the left in the southern hemisphere. As the current slows down, this effect weakens and more water can pile up at the US east coast, leading to an enhanced sea level rise." In Europe, a further slowdown of the AMOC could imply more extreme weather events like a change of the winter storm track coming off the Atlantic, possibly intensifying them. Other studies found possible consequences being extreme heat waves or a decrease in summer rainfall. Exactly what the further consequences are is the subject of current research; scientists also aim to resolve which components and pathways of the AMOC have changed how and for what reasons."If we continue to drive global warming, the Gulf Stream System will weaken further -- by 34 to 45 percent by 2100 according to the latest generation of climate models," concludes Rahmstorf. This could bring us dangerously close to the tipping point at which the flow becomes unstable.
The scientists found that most of the plastic particles in water samples taken from the German Bight, an area in the south-eastern corner of the North Sea which encompasses some of the world's busiest shipping lanes, originate from binders used in marine paints. "Our hypothesis is that ships leave a kind of 'skid mark' in the water which is of similar significance as a source of microplastics as tyre wear particles from cars are on land," Scholz-BÃ¶ttcher says.In the autumn of 2016 and 2017, the Oldenburg team took water samples from various locations in the German Bight with the research vessel "Heincke." Scholz-BÃ¶ttcher and her two colleagues Christopher Dibke and Marten Fischer used stainless steel sieves to filter plastic particles of much less than one millimetre in diameter out of the seawater and then analysed the chemical composition of the collected particles. They used a special analytical method in which the plastic molecules were first heated to temperatures of almost 600 degrees Celsius to break them down into smaller, characteristic fragments, and then separated and assigned to different polymer groups based on their mass and chemical properties. With this method the researchers were also able to quantify the mass of each plastic type. "Previous studies have only measured particle numbers for the North Sea. We, for the first time, also determined the mass distribution, and thus obtained a more comprehensive picture of the emergence of the different plastic types," Scholz-BÃ¶ttcher stresses.The team was surprised by the results: the samples contained above all indicators for polyvinyl chloride (PVC), polymers known as acrylates, and polycarbonates. Their mass accounted for about two-thirds of the total microplastic content in the mean and up to 80 percent in certain samples. Packaging plastics such as polyethylene (PE), polypropylene (PP) and polyethylene terephthalate (PET), which were previously estimated to make up the bulk of microplastics in the sea, accounted for a much smaller percentage. "We weren't expecting this distribution pattern," says Scholz-BÃ¶ttcher.When the researchers conducted a more detailed analysis of the results they observed that PE, PP and PET plastics were found mainly near the coastline, whereas in the open North Sea and in the Elbe estuary -- particularly in the proximity of major shipping routes -- the other types of plastic were predominant. "We believe that these particles originate from ship coatings, where these plastics are used as binders in acrylic paints or epoxy resins, for example," Scholz-BÃ¶ttcher explains. These results suggest that far larger quantities of microplastics are produced directly at sea than previously thought.According to the team, literature studies show that in the European Union alone, several thousand tonnes of paint end up in the marine environment every year. With potentially harmful consequences for the environment: coatings and paints used on ships contain heavy metals and other additives that are toxic to many organisms. These antifouling components are used to protect ships' hulls from barnacles and other subaquatic organisms and are constantly rubbed off by the wind and waves. The team is currently conducting further studies, for example in river estuaries and in sediments, to gain more insights into how these microplastics enter the environment.
The study, recently published in The researchers found that vegetation inside the fence -- that is, areas without dingoes -- had poorer long-term growth than vegetation in areas with dingoes."Dingoes indirectly affect vegetation by controlling numbers of kangaroos and small mammals," says Professor Mike Letnic, senior author of the study and researcher at UNSW's Centre for Ecosystem Science."When dingoes are removed, kangaroo numbers increase, which can lead to overgrazing. This has follow-on effects to the entire ecosystem."The Dingo Fence, which spans across parts of Queensland, NSW and South Australia, was erected in the 1880s to keep dingoes away from livestock. At 5600 kilometres long, it's one of the longest structures in the world.Up until now, most dingo research has been site-based or conducted using drone imagery. But NASA and United States Geological Survey's Landsat program -- which has been taking continuous images of the area since 1988 -- has made landscape-wide analysis possible."The differences in grazing pressure on each side of the fence were so pronounced they could be seen from space," says Prof. Letnic.The satellite images were processed and analysed by Dr Adrian Fisher, a remote sensing specialist at UNSW Science and lead author of the study. He says the vegetation's response to rainfall is one of the key differences between areas with, and without, dingoes."Vegetation only grows after rainfall, which is sporadic in the desert," says Dr Fisher."While rainfall caused vegetation to grow on both sides of the fence, we found that vegetation in areas without dingoes didn't grow as much -- or cover as much land -- as areas outside the fence."Apex predators play an important role in maintaining the biodiversity of an ecosystem.Removing them from an area can trigger a domino effect for the rest of the ecosystem -- a process called trophic cascade.For example, an increase in kangaroo populations can lead to overgrazing, which in turn reduces vegetation and damages the quality of the soil. Less vegetation can hinder the survival of smaller animals, like the critically endangered Plains Wanderer.Changes to vegetation triggered by the removal of dingoes have also been shown to reshape the desert landscape by altering wind flow and sand movement."The removal of apex predators can have far-reaching effects on ecosystems that manifest across very large areas," says Prof. Letnic. "These effects have often gone unnoticed because large predators were removed from many places a long time ago."The Australian dingo fence -- which is a sharp divide between dingo and non-dingo areas -- is a rare opportunity to observe the indirect role of an apex predator."Satellite imagery traditionally only looks at photosynthesizing vegetation -- that is, plants, trees and grass that are visibly green.But the researchers used a model to factor in non-green vegetation, like shrubs, dry grasses, twigs, branches and leaf litter."Non-photosynthesizing vegetation has a different reflectance spectrum to photosynthesizing vegetation," says Dr Fisher."By using the satellite image and a calibrated scientific model, we were able to estimate the non-green vegetation cover -- which is especially important when studying a desert landscape." The model was developed by the Joint Remote Sensing Research Program, a collaborative group that includes UNSW.While there are other contributing factors to the difference in vegetation -- for example, differing rainfall patterns and land use -- the satellite imagery and site analysis showed dingoes played a central role."There were clear differences in landscape on either side of the dingo fence," says Dr Fisher. "Dingoes may not be the whole explanation, but they are a key part of it."Satellite image technology is a powerful tool for assessing large-scale role of not only dingoes, but all kinds of environmental change.In 2019, researchers from UNSW Engineering used powerful satellite radar imaging technology to map severe floods in near real-time -- intelligence that could help emergency services make tactical decisions during extreme weather events.Dr Fisher hopes to next use Landsat imagery -- which is freely available to download -- to study how different amounts of vegetation can influence bushfire frequency."Our study is an example of how satellite technology can be used in big picture environmental research," says Dr Fisher."With over three decades' worth of data, this technology has opened up so many research possibilities."
During transitions from glacials to interglacials, the glaciers on Greenland and in North America and Europe wax and wane over tens of thousands of years. The more water that is stored in the mighty glaciers, the less there is in the oceans -- and the lower the sea level is. Climate researchers are now investigating to what extent the glaciers could melt in the coming centuries due to anthropogenic climate change, and how much the sea level would rise as a result. To do so, they're look back into the past. If they can understand the ice growth and melting during past glacials and interglacials, they'll be able to draw valuable conclusions about the future.However, reconstructing the distant past is no mean feat, because the glaciers' thickness and sea level can't be measured directly. Accordingly, climate researchers have to painstakingly gather evidence that they can then use to form a picture of the past. The problem: different pictures emerge, depending on the types of evidence collected. We can't say with absolute certainty what the situation was actually like ten thousand years ago. This 'missing ice problem' remained unsolved for many years. It describes the incongruity of two different scientific approaches that sought to reconcile sea-level height and glacier thickness at the peak of the last glacial, ca. 20,000 years ago. A team of climate experts led by Evan Gowan from the Alfred Wegener Institute, Helmholtz Centre for Polar and Marine Research (AWI) in Bremerhaven has now solved the problem using a new method. "It looks like we've found a new way to reconstruct the past as far back as 80,000 years," says Dr Gowan, who has been investigating the problem for roughly a decade. These findings have now been published in the journal The 'missing ice problem' is based, on the one hand, on an analysis of sediments from core samples collected from the seafloor in the tropics. These contain traces of corals that can still tell us today to what extent the sea level rose or fell over the millennia. Why? Because corals only live in well-lit waters near the ocean's surface. The sediment cores indicate that 20,000 years ago, the sea level in the tropics implied that sea level was roughly 130 metres lower than it is today. On the other hand, previous models have suggested that the glacial masses weren't large enough 20,000 years ago to explain such a low sea level. To be more precise, for the sea level to be that low, on a global scale an additional volume of water with twice the mass of the Greenland Ice Sheet would have to have been frozen; hence the 'missing ice problem'.With his new method, Gowan has now reconciled sea level and glacier mass: according to his calculations, the sea level at the time was ca. 116 metres lower than it is today. Based on his approach, there is no discrepancy in terms of glacier mass. Unlike the previous global model, Gowan closely examined the geological conditions in the glaciated regions: how steep was the ice surface? Where did glaciers flow? How much did the rocks and sediment at the base of the ice resist ice flow? His model considers all of these aspects. It also takes into account to what extent the ice sheet pressed down on the Earth's crust in the respective areas. "That depends on how viscous the underlying mantle was," Gowan explains. "We base our calculations on different mantle viscosities, and therefore arrive at different ice masses." The resulting ice masses can now be reconciled with the sea level without any discrepancy.The recent article by Gowan and his team critically re-examines the long-established scientific method used to estimate glacier masses: the oxygen isotope method. Isotopes are atoms of the same element that have different numbers of neutrons and therefore different masses. Oxygen, for example, has a lighter 16O isotope, and a heavier 18O isotope. According to conventional theory, the lighter 16O evaporates from the oceans, while the heavier 18O remains in the water. Accordingly, during glacials, when large inland glaciers form and the volume of water in the oceans decreases, the 18O concentration in the oceans should increase. However, as has been shown, this established model produces discrepancies when it comes to reconciling sea-level height and glacier masses for the period 20,000 years ago and earlier. "For many years, the isotope model has been frequently used to determine the ice volume of glaciers up to several million years ago. Our study calls into question the reliability of this method," says Gowan. His aim is to now use his new method to improve the traditional oxygen isotope method.
The new study, led by the University of Leeds, reports that 14 glaciers in the Getz region are thinning and flowing more quickly into the ocean. Between 1994 and 2018, 315 gigatonnes of ice has been lost, adding 0.9 mm to global mean sea level -- equivalent to 126 million Olympic swimming pools of water.The results published today (19/02/2021) in the journal Heather Selley, lead author of the study and a glaciologist at the Centre for Polar Observation and Modelling at the University of Leeds, said: "The Getz region of Antarctica is so remote that humans have never set foot on most of this part of the continent. Satellite radar altimetry records have shown substantial thinning of the ice sheet."However, the high rates of increased glacier speed -- coupled with ice thinning -- now confirms the Getz basin is in 'dynamic imbalance', meaning that it is losing more ice than it gains through snowfall."Using a combination of observations and modelling, we show highly localised patterns of acceleration. For instance, we observe the greatest change in the central region of Getz, with one glacier flowing 391 m/year faster in 2018 than in 1994. This is a substantial change as it is now flowing at a rate of 669 m/year, a 59% increase in just two and a half decades."The research, funded by the Natural Environment Research Council (NERC) and the European Space Agency (ESA), reports how the widely reported thinning and acceleration observed in the neighbouring Amundsen Sea glaciers, now extends over 1,000 km along the West Antarctic coastline into Getz.Dr Anna Hogg, study co-author and climate researcher in Leeds' School of Earth and Environment said: "The pattern of glacier acceleration shows the highly localised response to ocean dynamics."High-resolution satellite observations from satellites such as ESA's Sentinel-1, which collects a new image every six-days, means we can measure localized speed changes with ever greater detail."Consistent and extensive sampling of both ice speed and ocean temperature are needed to further our understanding of the dynamic ice loss, which now accounts for 98.8 % of the Antarctica's sea level contribution."By examining 25 years of ocean measurements, the research team were able to show complex and annual variations in ocean temperatures. These results suggest that the "dynamic imbalance" is mainly caused by longer-term ocean forcing, where increased heat content in the ocean is interacting with the ice and enhancing melt.Pierre Dutrieux, study co-author and climate researcher at British Antarctic Survey, said: "We know that warmer ocean waters are eroding many of West Antarctica's glaciers, and these new observations demonstrate the impact this is having on the Getz region."This new data will provide a new perspective of the processes taking place so we can predict future change with more certainty."
Marshall, assistant professor of geosciences, is the first author of the study, published in the journal The findings help shape understanding of the earth's "Critical Zone," the relatively thin layer of the planet that extends from where vegetation meets the atmosphere to the lowermost extent of weathered bedrock. "Climate and ecosystems determine how quickly bedrock weathers, how soil is produced, how sediment moves on land and in rivers and other factors that shape the landscape," the authors wrote.In cold lands, such as Alaska today, frost can crack or weather rock that is at or near the surface of the earth -- making it more porous and turning solid rock into sediment. By applying a frost-weathering model to North America paleoclimate simulations tracking temperatures during the Last Glacial Maximum approximately 21,000 years ago, Marshall and her team determined that a large swath of North America, from Oregon to Georgia and as far south as Texas and Arkansas, were likely affected by such periglacial processes.While permafrost landscapes like the modern Arctic experience frozen ground for two years or more, periglacial landscapes, though not permanently frozen, experience below-freezing temperature for much of the year. Though the evidence of past periglacial processes is easily hidden by vegetation and/or erased by subsequent geological processes, the teams' results suggest that frost weathering (and by extent other periglacial processes) covered an area about 3.5 times larger than the mapped extent of permafrost during the Last Glacial Maximum. This predicted influence of past cold climates on below ground weathering may significantly influence modern landscape attributes that we depend on such as soil thickness and water storage."Based on the widespread occurrence of glacial-period frost weathering over meter-scale depths, we suggest that past cold climates have had a significant impact on modern landscapes, both through lingering impact on subsurface pathways for water and thus chemical weathering, and the rock damage that contributes to the rate at which rock disaggregates into sediment and potential instability due to non-steady rates of hillslope and river processes," the paper states.
But these ecosystems are under threat. Global pressures, such as rising ocean temperatures, are causing coral to turn ghostly white, a phenomenon called bleaching, and die. One family of coral -- "Coral reefs are very beautiful and have a whole variety of different colors," said Professor Noriyuki Satoh, who leads the Marine Genomics Unit at the Okinawa Institute of Science and Technology Graduate University (OIST). "When we started looking at the different color morphs of The Unit worked with several individuals from the Okinawan community, including Koji Kinjo from Sea Seed, who directs a private aquarium where the different color morphs have been grown for around 20 years. This aquarium was instrumental for the researchers to observe the coral over the last two decades and to determine how resilient this species is to climate change, and the underlying causes.In 2020, Professor Satoh and his collaborators decoded the genome of "At first, we thought the difference in resilience might be linked to the corals housing different kinds of symbiotic algae, which photosynthesize for the coral and thus provide the coral with energy. Previous research has shown that some symbiotic algae are more resilient to climate change than others. But when we looked at the three-color morphs, we found that they all housed very similar algae," explained Professor Satoh.With this in mind, the research group instead focused the expression levels of the proteins that are thought responsible for the coral's color. There are four different groups of these proteins -- green fluorescent proteins (GFP), red fluorescent proteins (RFP), cyan fluorescent proteins (CFP), and non-fluorescent blue/purple chromoproteins (ChrP). The researchers looked at the gene expression levels of five types of GFP, three types of RFP, two types of CFP and seven types of ChrP in several coral in each morph.As can be expected, they found that the green morph expressed high quantities of FGPs, but the researchers found that two of the five were expressed at particularly high levels. More surprising was that these two proteins were expressed at even higher levels during summer, which indicates that they help the coral to withstand warmer temperatures. Specifically, these proteins seemed to protect the symbiotic algae, which meant that this color morph experienced very little bleaching.In contrast, the corals with the brown color morph, which express much lower quantities of these two proteins, bleached by around 50% over July and August 2017.The purple morph was different again. It expressed very little of any of the fluorescent proteins, but much higher levels of Chrp. The corals with this color morph bleached at levels in between that seen in corals with the brown morph and that seen in corals with the green morph."Coral reefs are so important for biodiversity," concluded Professor Satoh. "Finding out more about them will help us to conserve them. Right now, we cannot help so much about the coral reef situation but gathering this fundamental knowledge, understanding how corals work, is very important for long-term conservation."This research has showcased that the color morphology of coral is very much involved in its response to high temperatures. The underlying reasons behind this, such as exactly how the green fluorescent protein protects the symbiosis, will no doubt be the topic of research in the future.Professor Satoh and his Unit worked with people from Umino-Tane Co. LTD, IDEA Consultants, Inc., and Okinawa Environmental Research Co., Ltd., as well as researchers from the University of Tokyo. In addition, OIST's DNA Sequencing Section and Imaging Section were also involved in this project.
In a new article published in the journal Co-lead author University of Helsinki Associate Professor Enrico Di Minin says while it might seem counterintuitive, there is evidence to suggest some recreational hunting can deliver environmental and social benefits.University of Helsinki colleague and co-lead author Dr Hayley Clements says more analysis is needed to understand how and why recreational hunting can work for good, and those areas where it can be detrimental.Flinders University Professor Corey Bradshaw says it's a paradox that goes to the heart of the pros and cons of recreational hunting."We determined the geographic spread and diversity of species hunted around the globe, and investigated and summarized the main topics surrounding recreational hunting to consider both the positive and negative implications of recreational hunting for nature conservation and the livelihoods and well-being of people" says Professor Bradshaw, who leads Flinders' Global Ecology Lab."On the one hand, recreational hunting can reduce the number of individual animals in a population, whereas on the other, diverting land from agricultural or other types of development to priority hunting areas can in fact benefit entire ecosystems," he says.Hunting research has focused mainly on the behaviour and population dynamics of large mammals in North America, Europe and Africa.Dr Clements says evidence is still lacking, however, to answer the pressing questions of why hunting contributes to sustainable conservation of biodiversity in some places and not others."Two-thirds of the hunting research is focussed on mammals. Red deer, white-tailed deer, wild boar, moose and lion are the most well-studied. Of these species, only the lion is of conservation concern, with many recommendations on how hunting can be made sustainable through quotas or seasonal limits," says Dr Clements."Far less research has tried to examine the broader impacts of hunting on ecosystem integrity and function, and how it affects the livelihoods of local people, or to document local people's perceptions about hunting," she continues.For example, approximately 1,394,000 kmAssociate Professor Di Minin, who leads the Helsinki Lab of Interdisciplinary Conservation Science contends future research should focus on the contribution of recreational hunting towards meeting both biodiversity and social objectives."We have outlined a research agenda to assess the role of recreational hunting in diverse social-ecological systems, and to consider local people's values and needs.The need for such evidence is urgent given declining numbers of recreational hunters in some regions and increasing opposition to trophy hunting in others," says Associate Professor Di Minin."We should also expand research beyond charismatic and common species to assess the impact of recreational hunting on threatened and less charismatic species," he concludes
Yet, even it is very important, it is still poorly understood how the carbon pump process works at the molecular level. Scientists of the research group Marine Glycobiology, which is located at the Max Planck Institute for Marine Microbiology and the MARUM -- Center for Marine Environmental Sciences at the University of Bremen, investigate in this context marine polysaccharides -- meaning compounds made of multiple sugar units -- which are produced by microalgae. These marine sugars are very different on a structural level and belong to the most complex biomolecules found in nature. One single bacterium is not capable to process this complex sugar-mix. Therefore a whole bunch of metabolic pathways and enzymes is needed. In nature, this is achieved by a community of different bacteria that work closely and very efficiently together -- a perfect coordinated team. This bacterial community works so well that the major part of microalgal sugars are degraded before they aggregate and start to sink. A large amount of the sequestered carbon therefore is released back into the atmosphere.But, how is it possible that nevertheless a lot of carbon is still transported to the deep-sea? The scientists of the group Marine Glycobiology now revealed a component that may be involved in this process and published their results in the journal A crucial part of the finding is that this microbial resistant sugar formed particles. During growth and upon death unicellular diatoms release a large amount of unknown, sticky long-chained sugars. With increasing concentration, these sugar chains stick together and form molecular networks. Other components attach to these small sugar flakes, such as other sugar pieces, diatom cells or minerals. This makes the aggregates larger and heavier and thus they sink faster than single diatom cells. These particles need about ten days to reach a depth of 1000 meters -- often much longer. This means that the sticky sugar core has to resist biodegradation for at least so long to hold the particle together. But this is very difficult as the sugar-eating bacteria are very active and always hungry.In order to unravel the structures of microalgae polysaccharides and identify resistant sticky sugars, the scientists of the research group Marine Glycobiology are testing new methods. This is necessary because marine sugars are found within complex organic matter mixtures. In the case of this study, they used a method which originates from medical and plant research. It combines the high-throughput capacity of microarrays with the specificity of monoclonal antibody probes. This means, that the scientists extracted the sugar-molecules out of the seawater samples and inserted them into a machine that works like a printer, which doesn't use ink but molecules. The molecules are separately "printed" onto nitrocellulose paper, in form of a microarray. A microarray is like a microchip, small like a fingernail, but can contain hundreds of samples. Once the extracted molecules are printed onto the array it is possible to analyse the sugars present on them. This is achieved by using the monoclonal antibody probes. Single antibodies are added to the arrays and as they react only with one specific sugar the scientists can see, which sugars are present in the samples."The novel application of this technology enabled us to simultaneously monitor the fate of multiple complex sugar molecules during an algal bloom," says Silvia Vidal-Melgosa. "It allowed us to find the accumulation of the sugar FCSP, while many other detected polysaccharides were degraded and did not store carbon." This study proves the new application of this method. "Notably, complex carbohydrates have not been measured in the environment before at this high molecular resolution," says Jan-Hendrik Hehemann, leader of the group Marine Glycobiology and senior author of the study. "Consequently, this is the first environmental glycomics dataset and therefore the reference for future studies about microbial carbohydrate degradation."The discovery of FCSP in diatoms, with demonstrated stability and adhesive properties, provides a previously uncharacterised polysaccharide that contributes to particle formation and potentially therefore to carbon sequestration in the ocean. One of the next steps in the research is "to find out, if the particles of this sugar exist in the deep ocean," says Hehemann. "That would indicate that the sugar is stable and constitutes an important player of the biological carbon pump." Furthermore, the observed stability against bacterial degradation, and the structure and physicochemical behaviour of diatom FCSP point towards specific biological functions. "Given its stability against degradation, FCSP, which coats the diatom cells, may function as a barrier protecting the cell wall against microbes and their digestive enzymes," says Hehemann. And last but not least, another open question to be solved: These sugar particles were found in the North Sea near the island of Helgoland. Do they also exist in the sea of other regions in the world?
When two populations of a species become isolated, their genes no longer intermix and over time, the two populations become increasingly different from each other. What is known as a reproduction barrier has then been formed because the two different populations no longer mate with each other even if they would meet again.For a long time, researchers proposed that new species could be formed only if two populations were separated by a physical barrier over a very long period of time, for hundreds of thousands of generations or more.Today, there are many examples of species being formed without isolation, such as during ongoing genetic exchange. This exchange should prevent two populations to become different and so, understanding how reproductive barriers can still develop is an intriguing question for speciation researchers.Samuel Perini, researcher at the Department of Marine Sciences and author of the new thesis, has studied what happens in species with populations that are genetically different and meet at a contact zone, a boundary area between the two populations."I have investigated reproductive barriers that exist between two different forms of Littorina saxatilis, an intertidal marine snail, and I have analyzed data on reproductive barriers found in several marine species around the mouth of the Baltic Sea," says Perini.In a review of reproductive barriers in 23 different species, including cod, herring and plaice, Samuel Perini found large genetic differences between the Baltic Sea populations and the North Sea populations."These differences are maintained partly because the populations survive differently in different salinities and partly because their reproduction is separated in time or space, or both."For the Littorina saxatilis snail, which is common in the Atlantic along the coasts of both Europe and North America, two different populations or ecotypes have formed under ongoing genetic exchange, according to previous research. One population is known as the "Crab" ecotype and the other population is known as the "Wave" ecotype.Crab snails live in and are adapted to portions of the rocky shore with large stones and crabs, while Wave snails live on portions of the rocky shore with rock slabs exposed to waves. Crab snails and Wave snails meet at the boundary of these two habitats but genetic and phenotypic differences are still maintained between the two populations. Adaptations to the Crab and Wave habitat is strongly driven by natural selection and survival in the non-native environment is low. Hence, natural selection reduces genetic exchange between Crab and Wave snail populations because it decreases the opportunity for a Crab snail to survive and reproduce in the Wave habitat with a Wave snail of the opposite sex (and vice versa).The size of the intertidal marine snail is important for adaptation to the different environments. Large snails are selected for in environments where there are crabs, and small snails are favoured in environments exposed to waves."My studies show that the size of intertidal marine snails is important not only for survival but also for mating. I show in my thesis that mating is more common between snails of similar sizes and that small males have more matings. Both of these factors help to counteract gene exchange between the large Crab snails and the smaller Wave snails when they meet both inside and outside the contact zones."
Go take a hike. Literally.Researchers have long been aware of the positive impact of a connection with nature on psychological health and, according to a new study published in the journal "Thinking about the natural world in an interconnected and harmonious way corresponds to improved psychological health, no matter where you are," says Brian W. Haas, the lead author of the new study and an associate professor in the Behavioral and Brain Sciences Program at the University of Georgia.Haas and his collaborators -- Fumiko Hoeft, a professor of psychological sciences at UConn and director of UConn's Brain Imaging Research Center; and Kazufumi Omura, faculty of Education, Art and Science at Yamagata University in Japan -- used a survey in America and Japan to measure worldviews on nature as well as how much the pandemic impacted people's lives, and their current psychological health.The survey sought to gauge whether the participants had a worldview in harmony with nature -- being in tune or connected with the natural world, or a worldview of mastery over nature -- the belief that people have the ability to control the natural world. They also reported on their stress levels and were asked if the COVID-19 pandemic has affected them personally or impacted their employment or finances.The researchers found that, while participants in general report greater stress levels during the pandemic, individuals with a harmony-with-nature worldview were coping better regardless of whether they lived in Japan or in the United States."Clearly there's great need for study as relates to the pandemic, not just now during COVID, but also of previous pandemics and for possible future pandemics," says Hoeft. "I feel like this is a really great lesson, and a moment for us to really appreciate that things like our relationship with nature do matter and make an impact on more tangible things, like our mental health, which we often forget."The researchers found that the difference between the two cultures, however, became apparent when looking at individuals with a mastery-over-nature worldview."We found that the Americans who believed that humans are, and should be, the masters of the natural world did not tend to cope well during the pandemic," Haas says. "While this was not the case in Japan."Rather, in Japan, having a mastery-over-nature worldview was not correlated with poor coping. The researchers suggest the difference might be rooted in the concept of naÃ¯ve dialecticism -- the acceptance or tolerance of contradiction."In other cultures outside of the United States, people tend to be more comfortable with contradiction; in other cultures, it is generally more accepted to possess conflicting ideas within your mind at the same time," Haas says. "But in the United States, it's not. We can apply this concept to nature and the current global pandemic. For instance, if I hold a view that I am the master of the natural world, and then a global pandemic happens, this is a clear natural disaster. If I believe that I am the master of the natural world, then surely I would never allow a natural disaster to happen. These concepts are inconsistent with one another, and a consequence of inconsistency is often negative mood."While the study offers only a snapshot view of just two cultures, Haas believes other cultures would likely demonstrate a similar positive association with a harmony-with-nature worldviews, predicting that "it's likely a universal phenomenon."Both Haas and Hoeft say that, in an increasingly virtual and technology driven world, taking a moment to appreciate nature has clear benefits regardless of where you live."In Japanese, there's this word called 'forest-bathing,'" Hoeft says. "It's basically when you go out into nature, and enjoy being surrounded by trees. It's usually for forests, but you go walking and it's supposed to refresh you. People often talk about how they went out 'forest bathing.' I love thinking about these kinds of old phrases -- do they have some real impact or real scientific background in the end? And I think this is one of them where this really does have a connection. There is some scientific truth behind this.""Think about taking a step away from Zoom for a moment and taking a walk and listening to the birds chirp," Haas says. "I mean, just the benefit of that, and understanding that we have a role in this natural world, and we're part of it. I think that's really intuitive and it's obvious, but I think it's also really, really important. We're showing very convincingly with empirical data that, during a very difficult time like we are in now, that it's important to do these things to maintain your psychological health."This study was supported with funding from a Global Research Collaboration Grant from the University of Georgia and a National Science Foundation grant, NSF #202937.
Seahorses of the genus Hippocampus emerged about 25 million years ago in the Indo-Pacific region from pipefish, their closest relatives. And while the latter usually swim fairly well, seahorses lack their pelvic and tail fins and evolved a prehensile tail instead that can be used, for example, to hold on to seaweed or corals. Early on, they split into two main groups. "One group stayed mainly in the same place, while the other spread all over the world," says Dr Ralf Schneider, who is now a postdoc-toral researcher at the GEOMAR Helmholtz Centre for Ocean Research Kiel, and participated in the study while working as a doctoral researcher in Axel Meyer's re-search team. In their original home waters of the Indo-Pacific, the remaining species diversified in a unique island environment, while the other group made its way into the Pacific Ocean via Africa, Europe and the Americas.The particularly large amount of data collected for the study enabled the research team to create an especially reliable seahorse tree showing the relationships be-tween species and the global dispersal routes of the seahorse. Evolutionary biologist, Dr Schneider, says: "If you compare the relationships between the species to the ocean currents, you notice that seahorses were transported across the oceans." If, for example, they were carried out to sea during storms, they used their grasping tail to hold on to anything they could find, like a piece of algae or a tree trunk. These are places where the animals could survive for a long time. The currents often swept these "rafts" hundreds of kilometres across the ocean before they landed someplace where the seahorses could hop off and find a new home.Since seahorses have been around for more than 25 million years, it was important to factor in that ocean currents have changed over time as tectonic plates have shift-ed. For example, about 15 million years ago, the Tethys Ocean was almost as large as today's Mediterranean Sea. On the west side, where the Strait of Gibraltar is lo-cated today, it connected to the Atlantic Ocean. On the east side, where the Arabian Peninsula is today, it led to the Indian Ocean.The researchers were able to underscore, for example, that the seahorses were able to colonize the Tethys Ocean via the Arabian Sea just before the tectonic plates shifted and sealed off the eastern connection. The resulting current flowing westward towards the Atlantic Ocean brought seahorses to North America. A few million years later, this western connection also closed and the entire Tethys Ocean dried out. Ralf Schneider: "Until now it was unclear whether seahorses in the Atlantic all traced their lineage to species from the Arabian Sea that had travelled south along the east coast of Africa, around the Cape of Good Hope and across the southern Atlantic Ocean to reach South America. We found out that a second lineage of seahorses had done just that, albeit later."Since the research team gathered 20 animal samples from each habitat, it was also possible to measure the genetic variation between individuals. And this generally revealed: The greater the variation, the larger the population. "We can reconstruct the age of a variation based on its type. This makes it possible to calculate the size of the population at different points in time," the evolutionary biologist explains. This calculation reveals that the population that crossed the Atlantic Ocean to North America was very small, supporting the hypothesis that it have come from just a few animals brought there by the ocean's currents while holding on to a raft. The same data also showed that, even today, seahorses from Africa cross the southern Atlantic Ocean and introduce their genetic material into the South American population.Seahorses not only spread around the world by travelling with the ocean currents, but they were also surprisingly good at settling in new habitats. Seahorses have greatly modified genomes and, throughout their evolution, they have lost many genes, emerged with new ones or gained duplicates. This means: Seahorses change very quickly in comparison to other fish. This is probably why different types of "bony spines" evolved quickly and independently of each other that protect seahorses from predation in some habitats.Some of the genes have been identified that exhibit particular modifications for cer-tain species, but they are not the same for all species. Multiple fast and independent selections led to the development of spines, and although the same genes play a role in this development, different mutations were responsible. This shows that the slower, sessile seahorses were particularly able to adapt quickly to their environments. This is one of the main reasons the research team gives for seahorses being so successful in colonizing new habitats.
Around one million years ago there were no woolly or Columbian mammoths, as they had not yet evolved. This was the time of their predecessor, the ancient steppe mammoth. Researchers have now managed to analyse the genomes from three ancient mammoths, using DNA recovered from mammoth teeth that had been buried for 0.7-1.2 million years in the Siberian permafrost.This is the first time that DNA has been sequenced and authenticated from million-year-old specimens, and extracting the DNA from the samples was challenging. The scientists found that only minute amounts of DNA remained in the samples and that the DNA was degraded into very small fragments."This DNA is incredibly old. The samples are a thousand times older than Viking remains, and even pre-date the existence of humans and Neanderthals," says senior author Love DalÃ©n, a Professor of evolutionary genetics at the Centre for Palaeogenetics in Stockholm.The age of the specimens was determined using both geological data and the molecular clock. Both these types of analyses showed that two of the specimens are more than one million years old, whereas the third is roughly 700 thousand years old and represents one of the earliest known woolly mammoths.Analyses of the genomes showed that the oldest specimen, which was approximately 1.2 million years old, belonged to a previously unknown genetic lineage of mammoth. The researchers refer to this as the Krestovka mammoth, based on the locality where it was found. The results show that the Krestovka mammoth diverged from other Siberian mammoths more than two million years ago."This came as a complete surprise to us. All previous studies have indicated that there was only one species of mammoth in Siberia at that point in time, called the steppe mammoth. But our DNA analyses now show that there were two different genetic lineages, which we here refer to as the Adycha mammoth and the Krestovka mammoth. We can't say for sure yet, but we think these may represent two different species," says the study's lead author Tom van der Valk.The researchers also suggest that it was mammoths that belonged to the Krestovka lineage that colonised North America some 1.5 million years ago. In addition, the analyses show that the Columbian mammoth that inhabited North America during the last ice age, was a hybrid. Roughly half of its genome came from the Krestovka lineage and the other half from the woolly mammoth."This is an important discovery. It appears that the Columbian mammoth, one of the most iconic Ice Age species of North America, evolved through a hybridisation that took place approximately 420 thousand years ago," says co-lead author PatrÃ­cia Pec?nerova?.The second million-year-old genome, from the Adycha mammoth, appears to have been ancestral to the woolly mammoth. The researchers could therefore compare its genome with the genome from one of the earliest known woolly mammoths that lived 0.7 million years ago, as well as with mammoth genomes that are only a few thousand years old. This made it possible to investigate how mammoths became adapted to a life in cold environments and to what extent these adaptations evolved during the speciation process.The analyses showed that gene variants associated with life in the Arctic, such as hair growth, thermoregulation, fat deposits, cold tolerance and circadian rhythms, were already present in the million-year-old mammoth, long before the origin of the woolly mammoth. These results indicate that most adaptations in the mammoth lineage happened slowly and gradually over time."To be able to trace genetic changes across a speciation event is unique. Our analyses show that most cold adaptations were present already in the ancestor of the woolly mammoth, and we find no evidence that natural selection was faster during the speciation process," says co-lead author David Di?ez-del-Molino.The new results open the door for a broad array of future studies on other species. About one million years ago was a period when many species expanded across the globe. This was also a time period of major changes in climate and sea levels, as well as the last time that Earth's magnetic poles changed places. Because of this, the researchers think that genetic analyses on this time scale have great potential to explore a wide range of scientific questions."One of the big questions now is how far back in time we can go. We haven't reached the limit yet. An educated guess would be that we could recover DNA that is two million years old, and possibly go even as far back as 2.6 million. Before that, there was no permafrost where ancient DNA could have been preserved," says Anders GÃ¶therstrÃ¶m, a professor in molecular archaeology and joint research leader at the Centre for Palaeogenetics.
The study, led by the British Geological Survey and involving an international team from the UK, South Africa, France, Nigeria, and America, developed a dataset of 134 existing recharge studies for Africa for the period from 1970 to 2019 to create a valuable resource providing an overview of the recharge pattern across the continent. Long-term average recharge values were evaluated, and each data source was critically reviewed. The recharge data were then analysed using a linear model, to map across Africa. The resulting dataset provides the first such ground-based approximation of the renewability of groundwater storage in Africa. The results have been published today in the IOP Publishing journal Lead author of the paper, BGS Hydrogeologist Professor Alan MacDonald explains the need for this research: "In many parts of the world, rapid increases in groundwater pumping have led to unsustainable conditions, characterised by falling water tables and problems with water quality. Consequently, quantifying the scale of groundwater recharge is critical to characterise the resilience of groundwater supplies to both increased use and climate change."Estimating groundwater recharge is difficult, as the authors outline: "There is no one method that can directly quantify the volume of rainwater that reaches the water-table, so the focus of the research has been to combine many different methods, each appropriate to the different environments in Africa and then aggregate them using statistical techniques."The results show that at a continental scale, long-term average rainfall predicts groundwater recharge but there are differences at a local scale due to soil and landcover and from year to year, due to the variability in the intensity of rainfall. Approximately 2% of all groundwater storage is replenished in Africa every decade and recharge can occur even in semi-arid areas. This research turns around some widely held perceptions and provides hope for the continent as it rapidly grows in population and infrastructure development.The new groundwater maps show an interesting pattern for Africa. Most African countries with little groundwater storage (such as Liberia, Guinea and Burundi) have high rainfall and therefore regular recharge and, conversely, many north African countries with negligible rainfall, usually considered as water insecure, have considerable groundwater storage.It is hoped that the groundwater recharge maps will help show where there is potential to sustainably develop more groundwater and where it could be wise to invest effort in monitoring groundwater that may be at risk of depletion or susceptible to drought. The research could also help countries locate where new more detailed studies should be focused and how to design these studies, identifying which methods may be the best to use.Professor MacDonald adds: "The maps of groundwater recharge and storage help uncover the hidden water security situation in Africa. For several countries with high groundwater storage, particularly in North Africa, groundwater pumping can increase current water security but, ultimately, at the expense of future generations. Countries with low groundwater storage are common in Africa because of the geology -- however for most of these countries this groundwater storage is replenished regularly and is a reliable source of water. Only if people pump out too much (for example for large scale irrigation) will the groundwater be in danger of drying up during droughts."Professor Seifu Kebede from the University of KwaZulu Natal, a co-author of the paper adds: "This effort brought together extensive African knowledge with expertise from other countries to provide information to sustainably develop water resources and overcome some of the most pressing issues countries often face, such as drought, deprivation, and starvation."This research was funded by the UPGro research programme, co-funded by the Natural Environment Research Council, UK Foreign, Commonwealth & Development Office and the Economic and Social Research Council.The maps and data will be added to the online groundwater Atlas, a gateway for groundwater information for African countries
But it doesn't take wildfires to reveal the landslide danger, University of California, Berkeley, researchers say. Aerial surveys using airborne laser mapping -- LiDAR (light detection and ranging) -- can provide very detailed information on the topography and vegetation that allow scientists to identify which landslide-prone areas could give way during an expected rainstorm. This is especially important for predicting where shallow landslides -- those just involving the soil mantle -- may mobilize and transform as they travel downslope into destructive debris flows.The catch, they say, is that such information cannot yet help predict how large and potentially hazardous the landslides will be, meaning that evacuations may target lots more people than are really endangered by big slides and debris flows.In a new paper appearing this week in the journal Yet, while the model is better at identifying areas prone to larger and potentially more dangerous landslides, the researchers discovered factors affecting landslide size that can't easily be determined from aerial data and must be assessed from the ground -- a daunting task, if one is concerned about the entire state of California.The key unknowns are what the subsurface soil and underlying bedrock are like and the influence of past landslides on ground conditions."Our studies highlight the problem of overprediction: We have models that successfully predict the location of slides that did occur, but they end up predicting lots of places that didn't occur because of our ignorance about the subsurface," said Dietrich, UC Berkeley professor of earth and planetary science. "Our new findings point out specifically that the spatial structure of the hillslope material -- soil depth, root strength, permeability and variabilities across the slope -- play a role in the size and distribution and, therefore, the hazard itself. We are hitting a wall -- if we want to get further with landslide prediction that attempts to specify where, when and how big a landslide will be, we have to have knowledge that is really hard to get, but matters."Decades of studies by Dietrich and others have led to predictive models of where and under what rainfall conditions slopes will fail, and such models are used worldwide in conjunction with weather prediction models to pinpoint areas that could suffer slides in an oncoming storm and warn residents. But these models, triggered by a so-called "empirical rainfall thresholds," are conservative, and government agencies often end up issuing evacuation warnings for large areas to protect lives and property.Dietrich, who directs the Eel River Critical Zone Observatory -- a decade-long project to analyze how water moves all the way from the tree canopy through the soil and bedrock and into streams -- is trying to improve landslide size prediction models based on the physics of slopes. Airborne laser imaging using LiDAR can provide submeter-scale detail, not only of vegetation, but also of the ground under the vegetation, allowing precise measurements of slopes and a good estimate of the types of vegetation on the slopes.Slopes fail during rainstorms, he said, because the water pressure in the soil -- the pore pressure -- pushes soil particles apart, making them buoyant. The buoyancy reduces the friction holding the soil particles against gravity, and once the mass of the slide is enough to snap the roots holding the soil in place, the slope slumps. Shallow slides may involve only the top portion of the soil, or scour down to bedrock and push everything below it downslope, creating deadly debris flows that can travel several meters per second.Each wet year along the Pacific Coast, homes are swept away and lives lost from large landslides, though the threat is worldwide. As illustrated by a landslide in Sausalito exactly two years ago, landslides can originate just a short distance upslope and mobilize as a debris flow traveling meters per second before striking a house. The size of the initial landslide will influence the depth and speed of the flow and the distance it can travel downslope into canyons, Dietrich said.With earlier computer models, Dietrich and his colleagues were able to pinpoint more precisely the places on hillslopes that would suffer landslides. In 2015, for example, Bellugi and Dietrich used their computer model to predict shallow landslides on a well-studied hillslope in Coos Bay, Oregon, during a sequence of landslide-triggering rainstorms, based solely on these physical measures. Those models employed LiDAR data to calculate steepness and how water would flow downslope and affect pore pressure inside the slope; the seasonal history of rainfall in the area, which helps assess how much groundwater is present; and estimates of the soil and root strength.In the new paper, Bellugi and David Milledge of Newcastle University in Newcastle upon Tyne in the United Kingdom tested the landslide prediction model on two very different landscapes: a very steep, deeply etched and forested hillside in Oregon, and a smooth, grassy, gently sloped glacial valley in England's storied Lake District.Surprisingly, they found that the distribution of small and large shallow landslides were quite similar across both landscapes and could be predicted if they took into account one extra piece of information: the variability of hillslope strength across these hillsides. They discovered that small slides can turn into major slides if the conditions -- soil strength, root strength and pore pressure -- do not vary sufficiently over short distances. Essentially, small slides can propagate across the slope and become larger by connecting isolated slide-prone areas, even if they're separated by more solid slope."These areas that are susceptible to shallow landslides, even though you may be able to define them, may coalesce, if close enough to each other. Then you can have a big landslide that encompasses some of these little patches of low strength," Bellugi said. "These patches of low strength may be separated by areas that are strong -- they may be densely forested or less steep or drier -- but if they are not well separated, then those areas can coalesce and make a giant landslide.""On hillsides, there are trees and topography, and we can see them and quantify them," Dietrich added. "But starting from the surface and going down into the ground, there is a lot that we need in models that we can't now quantify over large areas: the spatial variation in soil depth and root strength and the influence of groundwater flow, which can emerge from the underlying bedrock and influence soil pore pressure."Getting such detailed information across an entire slope is a herculean effort, Dietrich said. On the Oregon and Lake District slopes, researchers walked or scanned the entire area to map vegetation, soil composition and depth, and past slides meter by meter, and then painstakingly estimated root strength, all of which is impractical for most slopes."What this says is that to predict the size of a landslide and a size distribution, we have a significant barrier that is going to be hard to cross -- but we need to -- which is to be able to characterize the subsurface material properties," Dietrich said. "Dino's paper says that the spatial structure of the subsurface matters."The researchers' previous field studies found, for example, that fractured bedrock can allow localized subsurface water flow and undermine otherwise stable slopes, something not observable -- yet -- by aerial surveys.They urge more intensive research on steep hillsides to be able to predict these subsurface features. This could include more drilling, installing hydrologic monitoring equipment and application of other geophysical tools, including cone penetrometers, which can be used to map soil susceptible to failure.Other co-authors of the paper are Lauren Larsen and Kurt Cuffey, UC Berkeley professors of geography.The work was supported by a Gordon and Betty Moore Foundation Data Driven Discovery Investigator Award to Bellugi and Larsen. Dietrich is supported by a National Science Foundation grant for the Eel River Critical Zone Observatory (EAR-1331940). Cuffey was supported by the Martin Family Foundation.
"We wanted to find out where and how much House Sparrows might be declining here," explains lead author Liam Berigan, who did this work while at the Cornell Lab and who is now a Ph.D. student at the University of Maine. "We also explored whether the declines would match up with an increase in hawk populations, as is true in European studies. Surprisingly, they didn't."FeederWatchers record observations during the non-breeding season when House Sparrows gather in flocks. Reports from nearly 12,500 sites were used and cross-referenced with the National Land Cover database to determine whether the U.S. sightings came from rural or urban locations.Findings for the U.S. and Canada:House Sparrows were introduced in Brooklyn in 1851. They expanded rapidly to become one of the most common species in the U.S. and Canada. Latest estimates peg the population at 82 million individuals. The global breeding population is estimated at 740 million (Partners in Flight)."When even a bird as common as the House Sparrow is experiencing population declines, this is probably a reflection on the state of the environment," says Berigan. "In Europe, a lack of urban green space and nesting sites are threats. It's likely some of those same factors are at work in North America and contribute to House Sparrow declines here."
Sawfish, named after their unique long, narrow noses lined by teeth, called rostra, that resemble a sawblade, were once found along the coastlines of 90 countries but they are now among the world's most threatened family of marine fishes, presumed extinct from 46 of those nations. There are 18 countries where at least one species of sawfish is missing, and 28 more where two species have disappeared.According to SFU researchers Helen Yan and Nick Dulvy, three of the five species of sawfish are critically endangered, according to the International Union for Conservation of Nature (IUCN) Red List of Threatened Species, and the other two are endangered.Their teeth on their rostra are easily caught in fishing nets. Sawfish fins are among the most valuable in the global shark fin trade and rostra are also sold for novelty, medicine and as spurs for cockfighting.The current presence of all sawfishes world-wide is unknown, but Dulvy warns complete extinction is possible if nothing is done to curb overfishing and to protect threatened habitats, such as mangroves, where sawfish can thrive."Through the plight of sawfish, we are documenting the first cases of a wide-ranging marine fish being driven to local extinction by overfishing," Dulvy says. "We've known for a while that the dramatic expansion of fishing is the primary threat to ocean biodiversity, but robust population assessment is difficult for low priority fishes whose catches have been poorly monitored over time. With this study, we tackle a fundamental challenge for tracking biodiversity change: discerning severe population declines from local extinction."The study recommends that international conservation efforts focus on eight countries (Cuba, Tanzania, Columbia, Madagascar, Panama, Brazil, Mexico and Sri Lanka) where conservation efforts and adequate fishing protections could save the species. It also found Australia and the United States, where adequate protections already exist and some sawfish are still present, should be considered as "lifeboat" nations."While the situation is dire, we hope to offset the bad news by highlighting our informed identification of these priority nations with hope for saving sawfish in their waters," says Yan. "We also underscore our finding that it's actually still possible to restore sawfish to more than 70 per cent of their historical range, if we act now."
The scientists also discovered that fish from different hemispheres intermingle and sometimes breed with each other.Published Tuesday in Albacore in the North and South Pacific Oceans are currently managed as separate stocks. The OSU study affirms this approach while also opening the door to more research into overlap and interbreeding that can be used to refine management strategies throughout the Pacific."Albacore support one of the world's largest and most valuable fisheries and one that is particularly important on the west coast of North America," said Kathleen O'Malley, an associate professor in the OSU College of Agricultural Sciences. "There's been a lot of work done to understand stock structure of the albacore globally, but research in the Pacific hasn't been very fine-tuned and has tended to generate as many questions as answers."O'Malley, who is also the fisheries geneticist for the state of Oregon, noted that previous research involving tagged fish has revealed no movement of albacore from one side of the equator to the other. At the same time, previous genetic data have yielded no way to tell if a fish was from the North Pacific or South Pacific -- hence the lack of understanding regarding the connectivity between the two populations.O'Malley and postdoctoral research associate Felix Vaux, who led the study, looked at DNA from 308 fish from 12 locales around the Pacific. They identified nearly 13,000 genetic markers -- DNA sequences with known physical locations on chromosomes -- and learned that fewer than 100 of those markers told the tale of what part of the ocean a fish came from."We identified 12,872 markers and were able to discriminate between North and South Pacific albacore by using only 84 of them," Vaux said.Those 84, he added, appear to be "under selection" and may reflect adaptive differences between the two albacore stocks. In any population, individuals with locally adapted traits tend to be the most successful reproductively, meaning that over time selection will increase the prevalence of those traits. With continuing, intense selection, adaptive traits become universal or close to it in a population or species."There is no complete genome for albacore to compare our data against, so we weren't able to determine which genes underlie these likely adaptive differences," O'Malley said. "In addition, we found that some fish have mixed genetic backgrounds -- indicating that albacore from the North and South Pacific sometimes spawn at the same time and place and breed together. Also, we detected albacore with South Pacific genetic profiles in the North Pacific, providing evidence for migration across the equator that had earlier gone undetected via physical tagging data."Future studies, she added, will use these genetic markers to more deeply investigate interbreeding between North and South Pacific albacore as well as migration between hemispheres.O'Malley, who directs the State Fisheries Genomics Lab at OSU's Hatfield Marine Science Center, says that both genetic and demographic connectivity, while important for effective management and conservation strategies, are not well understood in most marine species.Genetic diversity is an important tool for populations trying to adapt to climate change and other environmental perturbances, she said. With more variation, it is more likely that some individuals in a population will be suited to withstand the changes and produce offspring that are also able to thrive in the modified environment.
A team of scientists from NOAA's Pacific Islands Fisheries Science Center, the University of Hawai'i (UH) at Manoa, Arizona State University and elsewhere have discovered that a diverse array of marine animals find refuge in so-called 'surface slicks' in Hawai'i. These ocean features create a superhighway of nursery habitat for more than 100 species of commercially and ecologically important fishes, such as mahi-mahi, jacks, and billfish. Their findings were published today in the journal Surface slicks are meandering lines of smooth surface water formed by the convergence of ocean currents, tides, and variations in the seafloor and have long been recognized as an important part of the seascape. The traditional Hawaiian mele (song) Kona Kai `?pua describes slicks as Ke kai ma`oki`oki, or "the streaked sea" in the peaceful seas of Kona. Despite this historical knowledge and scientists' belief that slicks are important for fish, the tiny marine life that slicks contain has remained elusive.To unravel the slicks' secrets, the research team conducted more than 130 plankton net tows inside the surface slicks and surrounding waters along the leeward coast of Hawai'i Island, while studying ocean properties. In these areas, they searched for larvae and other plankton that live close to the surface. They then combined those in-water surveys with a new technique to remotely sense slick footprints using satellites.Though the slicks only covered around 8% of the ocean surface in the 380-square-mile-study area, they contained an astounding 39% of the study area's surface-dwelling larval fish; more than 25% of its zooplankton, which the larval fish eat; and 75% of its floating organic debris such as feathers and leaves.Larval fish densities in surface slicks off West Hawai?i were, on average, over 7 times higher than densities in the surrounding waters.The study showed that surface slicks function as a nursery habitat for marine larvae of at least 112 species of commercially and ecologically important fishes, as well as many other animals. These include coral reef fishes, such as jacks, triggerfish and goatfish; pelagic predators, for example mahi-mahi; deep-water fishes, such as lanternfish; and various invertebrates, such as snails, crabs, and shrimp.The remarkable diversity of fishes found in slick nurseries represents nearly 10% of all fish species recorded in Hawai?i. The total number of taxa in the slicks was twice that found in the surrounding surface waters, and many fish taxa were between 10 and 100 times more abundant in slicks."We were shocked to find larvae of so many species, and even entire families of fishes, that were only found in surface slicks," said lead author Dr. Jonathan Whitney, marine ecologist at NOAA, former postdoctoral fellow at the Joint Institute for Marine and Atmospheric Research (JIMAR) in UH Manoa's School of Ocean and Earth Science and Technology (SOEST). "This suggests they are dependent on these essential habitats.""These 'bioslicks' form an interconnected superhighway of rich nursery habitat that accumulate and attract tons of young fishes, along with dense concentrations of food and shelter," said Whitney. "The fact that surface slicks host such a large proportion of larvae, along with the resources they need to survive, tells us they are critical for the replenishment of adult fish populations."In addition to providing crucial nursing habitat for various species and helping maintain healthy and resilient coral reefs, slicks create foraging hotspots for larval fish predators and form a bridge between coral reef and pelagic ecosystems.What's more, the slicks host larvae and juvenile stages of many forage fishes like flying fishes that are critical to pelagic food webs."These hotspots provide more food at the base of the food chain that amplifies energy up to top predators," said study co-author Dr. Jamison Gove, a research oceanographer for NOAA. "This ultimately enhances fisheries and ecosystem productivity."While slicks may seem like havens for all tiny marine animals, there's a hidden hazard lurking in these ocean oases: plastic debris. Within the study area, 95% of the plastic debris collected into slicks, compared with 75% of the floating organic debris. Larvae may get some shelter from plastic debris, but it comes at the cost of chemical exposure and incidental ingestion."Until we stop plastics from entering the ocean," Whitney said, "the accumulation of hazardous plastic debris in these nursery habitats remains a serious threat to the biodiversity hosted here."In certain areas, slicks can be dominant surface features, and the new research shows these conspicuous phenomena hold more ecological value than meets the eye."Our work illustrates how these oceanic features (and animals' behavioral attraction to them) impact the entire surface community, with implications for the replenishment of adults that are important to humans for fisheries, recreation, and other ecosystem services," said Dr. Margaret McManus, co-author, Professor and Chair of the Department of Oceanography at UH Manoa. "These findings will have a broad impact, changing the way we think about oceanic features as pelagic nurseries for ocean fishes and invertebrates."
The study, whose lead author is litter researcher Dr Francois Galgani from IFREMER, concludes that, despite the well-known increase in the volume of plastics making their way to the marine domain from land, most studies indicate constant amounts of litter in coastal marine systems in recent years until 2019. For instance, collections of marine litter by Continuous Plankton Recorders showed relatively unchanged amounts trapped annually in the North East Atlantic since the year 2000, following a steady increase since the 1950s. For some components of marine litter, such as industrial pellets, policy-making seems to be effective given that measures taken to reduce their use in industrial practices seem to have translated into smaller volumes of this component being detected within the marine domain.Although a prima facie a surprising find, this 'steady state' scenario could be indicative of:a transfer of plastic litter to remote areas of the global ocean, where human monitoring programmes are non-existent or subdued, such that the same litter does not feature in statistics and/orthe degradation into smaller fragments (micro- and nanoplastics) of the same litter which can go undetected due to its small size (e.g. fibres within microplastic nets) or since they are within marine biota.The published study emanated from Chapter 12 of the UN's Second World Ocean Assessment, which is imminently set to be released by the UN in the coming months. Prof. Deidun features as a co-author within two different chapters in such an Assessment, including the ones on marine alien species and on benthic invertebrates. The same study concludes by soliciting, within the current UN Decade for Ocean Sciences, a greater research effort to be invested in identifying the sources of the marine litter as well as in the degradation pathways for different components of the same litter, as otherwise our capacity to identify temporal trends in marine litter will not progress further.Statistics related to marine plastic litter make for sobering reading. For instance, according to the Ocean Conservancy, an estimated 8 million tons of plastic enter seas worldwide each year, on top of the 150 million plastic tons already roaming the same seas. A staggering 380 million tons of plastic are produced annually, of which an estimated 50% is Single-Use Plastic (SUP), including the 500 billion plastic bags sold worldwide each year and which, on average, have a lifetime of just 15 minutes.
"Whenever there is a large volcanic eruption, there is a chance that if a flank of the volcano is unstable there could be a collapse," said Judit Gonzalez-Santana, a doctoral student in the Department of Geosciences. "To better explore this hazard, we applied an increasingly popular and more sensitive time-series method to look at these movements, or surface deformation, over longer time periods."Using the time-series technique, the scientists found surface deformation related to flank motion had occurred at Pacaya, an active volcano in Guatemala, from 2011 to 2013 when the volcano was largely quiet, and increased leading up to an eruption in 2014. Previous work had not identified flank motion during this time, the scientists said."People have looked at that volcano with satellite remote sensing but did not detect this long-term flank motion or creep," said Christelle Wauthier, associate professor of geosciences. "Because the surface deformation changes are pretty small per year, it can easily be below the detection limits of conventional methods, but still within the limits of Judit's work using a time-series approach."Scientists track surface deformation using radar satellites sensitive enough to spot changes of just a few inches on the ground. Comparing two of these images using the conventional Interferometric Synthetic Aperture Radar (InSAR) technique creates an interferogram, essentially a map of surface movement. But the quality of the InSAR results decreases with the time separating two images and can be affected by even small changes, like from vegetation growth or a buildup of ash spewed from a volcano, the scientists said.The team instead conducted an InSAR time-series analysis using hundreds of satellite images taken over years and identifying surface deformation between each."You can use many of these short-term surface movement maps to give you information of surface displacement over a long time period," Gonzalez-Santana said. "Then you can look at the surface deformation maps and see how much each pixel has been moving since the date the first image was acquired, for example."The results, published in the "This kind of creep is not uncommon and not particularly dangerous on its own, but if you have extra forcings like from magma being pressurized and pushing against the wall of the chamber or intrusion, it can trigger a catastrophic collapse," Wauthier said. "To be able to understand the behavior of the instability and potentially detect changes in rates of motion is very critical for monitoring that potential collapse."The method shows promise for identifying deformation particularly at volcanoes that lack expensive real-time monitoring networks and those located in tropical areas with thick vegetation that create problems for traditional InSAR, the scientists said.Flank instability is often studied at oceanic volcanoes, where a collapse could trigger a deadly tsunami, according to the scientists. But collapses also happen inland, including prominently at Mount St. Helens in 1980.Pacaya itself experienced a collapse sometime around 1,000 years ago, creating a debris avalanche that traveled more than 15 miles, and leaving a prominent scar on the volcano. Subsequent eruptions have built the volcano back up and it could someday again collapse, the scientists said."More than 10,000 people live within about three miles of the volcano," Gonzalez-Santana said. "If you take into consideration the last avalanche traveled 15 miles away, anyone living in the valleys around the volcano could be at risk."A NASA Earth Surface and Interior grant, a Future Investigators in NASA Earth and Space Science and Technology grant, and an Institute for Computational and Data Sciences seed grant funded this research.
The surveys were conducted by the IEO and the FAO -- in the framework of their EAF-Nansen and CCLME projects -- along the continental shelf and slope off Morocco, Western Sahara, Mauritania, Senegal, The Gambia, Guinea-Bissau, Guinea, and Cabo Verde, between 2004 and 2012. In all these surveys, the EcoAfrik research team (UVIGO-IEO) led the development of a program focused on benthos intensive sampling. During these surveys a huge amount of quantitative biological data, environmental parameters of the water column and seabed, and important collections of benthic invertebrates were obtained.After several years devoted to taxonomic study and the exhaustive review of the existing literature, an updated checklist of 138 cephalopods species was generated for the whole CCLME area. Besides, the known geographical distributions of several species have been expanded, as some deep-sea octopuses (such as Muusoctopus januarii, Bathypolypus valdiviae or Cirrothauma murrayi) and many oceanic squids (such as Abralia siedleckyi, Magnoteuthis magna or Chtenopteryx sicula), some recorded for the first time in the area.The CCLME hosts one of the four major marine upwelling systems and is the third concerning primary productivity worldwide, supporting the largest fisheries of the Atlantic African coast, with an annual production of approximately 2-3 million tonnes. Among the main target commercial species are included some cephalopod groups as squids, cuttlefishes and octopuses.Although most of the cephalopod species with commercial value in the region have been well-studied, many aspects of the systematic, distribution, biogeography and ecology of other cephalopods are practically unknown.The EcoAfrik collections represent an exceptional source of information that will provide a global view on the biodiversity, composition and distribution of cephalopods from Northwest Africa.
Published in "The warming oceans absorb about one-third of the additional CO"We know that many species are negatively affected in their behaviour and physiology by ocean acidification. But we found that in this species of temperate fish -- the common triplefin -- both males and females had larger gonads under conditions of ocean acidification. This meant increased egg and sperm production and therefore more offspring."The team used natural volcanic COThey found that there were no negative effects of ocean acidification for the triplefins. The larger gonads did not come at a physiological cost."We found males were eating more. They showed intensified foraging on more abundant prey -- which was more abundant because of the increased biomass of algae that grows under the elevated CO"The females, on the other hand, did not eat more. They instead reduced their activity levels to preserve energy and then invested this in larger ovaries."We also found there were more mature males under elevated COThe researchers found that other, less dominant, fish species did not show such an effect of reproductive output, perhaps due to their less competitive nature."We think it likely that the triplefin and similar species will do very well under increased ocean acidification," says co-author Professor Sean Connell. "The study shows that some, more dominant, species will be able to capitalise on changes to ecosystems under ocean acidification, increasing their population."
Dr Emma Brownlee, Department of Archaeology, University of Cambridge, examined how a key change in Western European burial practices spread across the continent faster than previously believed -- between the 6th -- 8th centuries AD, burying people with regionally specific grave goods was largely abandoned in favour of a more standardised, unfurnished burial."Almost everyone from the eighth century onwards is buried very simply in a plain grave, with no accompanying objects, and this is a change that has been observed right across western Europe," said Dr Brownlee.To explore this change, Emma examined over 33,000 graves from this period in one of the largest studies of its kind. Statistical analysis was used to create a 'heat map' of the practice, tracking how it changed in frequency over time.The results of this analysis, published in the journal "The most important finding is that the change from burial with grave goods to burial without them was contemporary across western Europe," said Dr Brownlee. "Although we knew this was a widespread change before, no one has previously been able to show just how closely aligned the change was in areas that are geographically very far apart."Crucially, this contemporary transition provides strong evidence that early Medieval Europe was a well-connected place, with regular contact and exchange of ideas across vast areas.Evidence of increasing long-distance trade is seen around this period, which may have been how these connections were facilitated. As the idea spread between communities, social pressure drove more people to adopt it. As more people did, this pressure grew -- explaining why the spread of unfurnished funerals appeared to accelerate over time.With people sharing more similarities, this likely reinforced the connections themselves as well."The change in burial practice will have further reinforced those connections; with everyone burying their dead in the same manner, a medieval traveller could have gone anywhere in Europe and seen practices they were familiar with," said Dr Brownlee.An interconnected Europe with long-distance trade and travel facilitating the spread of new ideas to create a shared culture may sound modern, but in reality, Europe has been 'global' for over a millennium.
How species adapt to the environment is of fundamental importance in biology. Genetic changes that facilitate survival in individuals occupying new or variable environments provides the foundation for evolutionary change. These changes can be revealed as differences in the frequency of gene variants between subgroups within species. Alternatively, individuals may respond to changing environments through physiological change without genetic change, a process known as phenotypic plasticity. For example, eels adjust their osmoregulation when migrating from marine waters to freshwater."Eels have a truly fascinating life history and go through several stages of metamorphosis," explains Dr. HÃ¥kan WickstrÃ¶m, from the Swedish University of Agricultural Sciences and one of the co-authors. "Spawning takes place in the Sargasso Sea, then offspring drift as leptocephali larvae until they reach the European or African continent where they metamorphose into glass eels. Glass eels become yellow eels after entering into brackish or freshwater and later develop into reproductively mature silver eels before returning to the Sargasso Sea for spawning, completing a second crossing of the Atlantic. After that they all die.""To the best of our knowledge all eels spawn in the Sargasso Sea, but that did not exclude the possible existence of subpopulations," explains Dr. Mats Pettersson, Uppsala University, one of the shared first authors. "For instance, northern eels may spawn in a different region, or at a different depth, or during a different period than southern eels, or they may simply have the ability to recognise conspecifics from the same climatic region. In this study, we wanted to provide the ultimate answer to the important question whether European eels belong to a single panmictic population or not. We have done that after sequencing the entire genomes of eels collected across Europe and North Africa.""When comparing the DNA sequences of eels from different parts of Europe and North-Africa we do not find any significant differences in the frequency of gene variants," states Mats Pettersson. "We therefore conclude that European eels belong to a single panmictic population and that their ability to inhabit such a wide range of environments must be due to phenotypic plasticity.""Eels are an enigmatic species that have long captured the imagination of society. Modern genomic analysis allows us to track the evolutionary history of eels, and it is rather impressive that adult eels can inhabit such a range of environments without becoming isolated into genetic subpopulations. It is amazing to think that even with millions of genetic variants we cannot distinguish an eel in a lake in Sweden from an eel in a North-African river. This provides just another clue in a long history of uncovering the life history of this fascinating species," said Dr. Erik Enbody, Uppsala University, and shared first author. "An important implication of these findings is that preventing eel population declines requires international cooperation, as this species constitutes a single breeding population."In many other marine fish species, subpopulations living in different environments undergo genetic changes associated with local adaptation to that environment. Recent research from the same group in December on the Atlantic herring revealed extensive local adaptation related to, for instance, salinity and water temperature at spawning. European eels are exposed to a much broader range of environmental conditions than the Atlantic herring, but do not have the associated genetic changes. How is this lack of genetic adaptation in eels possible?"Our hypothesis is that this striking difference between Atlantic herring and Europeans eels is explained by the fact that all eels are spawning under near identical conditions in the Sargasso Sea. Atlantic herring, on the other hand, are spawning in different geographic areas under diverse environmental conditions, with regard to salinity, temperature and season. These conditions require local genetic adaptations because fertilization and early larval development is the most sensitive period during the life of a fish," explains Professor Leif Andersson, Uppsala University and Texas A&M University, who led the study."An important topic for future studies is to explore how eels are able to cope with such diverse environmental conditions. It is likely that eels for millions of years have had a life history where spawning takes place under very similar conditions whereas most part of the lifecycle takes place under diverse environmental conditions. Mechanisms for handling this challenge may thus have evolved by natural selection," Leif Andersson ends.
The research focuses on kiyis, which inhabit Lake Superior at depths of about 80 to over 200 meters deep. These fish, known to scientists as "Coregonus kiyi," belong to a group of closely related salmonids known as ciscoes.In contrast to three other Lake Superior ciscoes that dwell and feed in shallower regions of water, the kiyis are far more likely to carry a version of the rhodopsin gene that probably improves vision in dim "blue-shifted" waters, the study concludes. Every one of 21 kiyis the team examined from this deep-water population carried only this variant of the gene.The adaptation appears to mark a return to an ancient state: Some 175 million years ago, the kiyis' ocean-dwelling forebears likely harbored the same genetic variant, according to a reconstruction of the species' evolutionary history.Then, as ancestral fish populations moved from blue-shifted marine waters into shallower, "red-shifted" streams and lakes, a form of rhodopsin that's beneficial in those habitats became more common, scientists say. Finally, the kiyis, reaching the deep waters of Lake Superior, adapted again to the "blue-shifted" color of the waters they now inhabit.The study was published online Nov. 28 in the journal "Evolution is often thought of as a one-way process, at least over deep time, but in this example, over 175 million years, we have this reversal back to a much earlier ancestral state," says Trevor Krabbenhoft, PhD, assistant professor of biological sciences in the UB College of Arts and Sciences and a faculty member in the UB RENEW Institute. Krabbenhoft led the research with first author Katherine Eaton."Fishery biologists are trying to restore native fish populations in the Great Lakes, so it's important to understand the adaptations that species have," says Eaton, a PhD student at Auburn University who completed the study at UB as an undergraduate in biological sciences. "Knowledge of a species' adaptations can help us restore them in environments that are better suited to their biology."It's unclear whether the kiyis' ancestors completely lost the blue-shifted gene variant before re-evolving it, or if the variant simply became less frequent in this fish lineage before re-emerging to become more prolific again.Either way, today, "There is a really clear distinction between the deep-water and shallow-water species," Eaton says.Whereas all of the kiyis studied had the blue-shifted form of rhodopsin, the shallower water ciscoes sampled -- Coregonus artedi, Coregonus hoyi and Coregonus zenithicus -- primarily had the version of the gene that may be helpful in red-shifted waters.Eaton notes that the same blue-shifted variant of rhodopsin is present in a number of other fish that live in the sea or deep lake water. This repeated "parallel" evolution can indicate that an adaptation has an important function: in this case, probably helping fish see in different environments, she says.These insights are important because light in the Great Lakes is changing, Krabbenhoft says. For example, invasive zebra and quagga mussels, which filter organic matter from lakes, are increasing the clarity of the water in places.The knowledge is also valuable as scientists look to restore native fish populations. In addition to the rhodopsin research, Krabbenhoft is a co-author of a study examining the genetics, morphology and ecology of ciscoes more broadly. That work, also funded by the Great Lakes Fishery Commission, was led by MoisÃ©s Bernal, PhD, now an assistant professor of biological sciences at Auburn University. The study results were posted on Dec. 16 to the preprint server bioRxiv, and have not yet been published in a peer-reviewed journal."Collectively, these projects have implications for restoring the native biodiversity in the Great Lakes toward a healthy ecosystem," Krabbenhoft says. "Ciscoes were once much more abundant and diverse across the five Great Lakes, but some species went extinct due to overfishing, sea lamprey invasion and pollution. Our data are informing restoration strategies as these fish are being re-established in places where they were lost or highly reduced in number, such as in Lake Ontario.""Ciscoes were once the dominant native prey species in the Great Lakes, supporting top predators such as lake trout and walleye. They remain an important component of the tribal, commercial and recreational fisheries, which are valued at more than $7 billion annually," says Bill Taylor, PhD, Commissioner for the Great Lakes Fishery Commission and a University Distinguished Professor in Global Fisheries Systems at Michigan State University. "Research to better understand their biology and morphology is critical to designing successful restoration efforts in the future."
For this research, the satellite Worldview 3 used high-resolution imagery to capture African elephants moving through forests and grasslands. The automated system detected animals with the same accuracy as humans are able to achieve.The algorithm that enabled the detection process was created by Dr Olga Isupova, a computer scientist at the University of Bath in the UK. The project was a collaboration with the UK's University of Oxford and the University of Twente in the Netherlands.Dr Isupova said the new surveying technique allows vast areas of land to be scanned in a matter of minutes, offering a much-needed alternative to human observers counting individual animals from low-flying airplanes. As it sweeps across the land, a satellite can collect over 5,000 kmÂ² of imagery every few minutes, eliminating the risk of double counting. Where necessary (for instance, when there is cloud coverage), the process can be repeated the next day, on the satellite's next revolution of Earth.The population of African elephants has nose-dived over the past century, mainly due to poaching and habitat fragmentation. With approximately 415,000 African savannah elephants left in the wild, the species is classified as endangered."Accurate monitoring is essential if we're to save the species," said Dr Isupova. "We need to know where the animals are and how many there are."Satellite monitoring eliminates the risk of disturbing animals during data collection and ensures humans are not hurt in the counting process. It also makes it simpler to count animals moving from country to country, as satellites can orbit the planet without regard for border controls or conflict.This study was not the first to use satellite imagery and algorithms to monitor species, but it was the first to reliably monitor animals moving through a heterogeneous landscape -- that is, a backdrop that includes areas of open grassland, woodland and partial coverage."This type of work has been done before with whales, but of course the ocean is all blue, so counting is a lot less challenging," said Dr Isupova. "As you can imagine, a heterogeneous landscape makes it much hard to identify animals."The researchers believe their work demonstrates the potential of technology to support conservationists in their plight to protect biodiversity and to slow the progress of the sixth mass extinction -- the ongoing extinction event triggered by human activity."We need to find new state-of-the-art systems to help researchers gather the data they need to save species under threat," said Dr Isupova.African elephants were chosen for this study for good reason -- they are the largest land animal and therefore the easiest to spot. However, Dr Isupova is hopeful that it will soon be possible to detect far smaller species from space."Satellite imagery resolution increases every couple of years, and with every increase we will be able to see smaller things in greater detail," she said, adding: "Other researchers have managed to detect black albatross nests against snow. No doubt the contrast of black and white made it easier, but that doesn't change the fact that an albatross nest is one-eleventh the size of an elephant."The researchers involved in this project were Dr Olga Isupova from the University of Bath, Isla Duporge, Dr Steven Reece, and Professor David W. Macdonald from the University of Oxford, and Dr Tiejun Wang from the University of Twente.
The research, published in The UNSW study discovered partially protected areas in southern Australia had no more fish, invertebrates or algae and no difference in the mix of users -- and they were not valued any more highly by users than areas outside reserves (open areas).The social and ecological researchers found fully protected areas (no-take or sanctuary zones), by comparison, had more fish, higher biodiversity of marine life and were an attraction to many coastal users both for their ecological and protection values.Lead author John Turnbull, UNSW Science researcher, said partially protected areas appear to be the "red herrings" of marine conservation as they distract us from achieving more effective protection."Marine protected areas are the umbrella term for managed marine areas and can be fully or partially protected. They are a primary tool for the stewardship, conservation and restoration of marine ecosystems but globally, 69 per cent of marine protected areas are open to some form of fishing," Mr Turnbull said."This is a surprise to many people -- almost half of the people we surveyed in partially protected areas (42 per cent) mistakenly thought they were in a reserve that protected fish."Just 12 per cent of people knew they were in a partially protected area, compared to 79 per cent of people in fully protected areas who correctly identified they were in one."This is not a small issue; three-quarters of Australia's marine protected area is open to fishing. Most partially protected areas in Australia even allow commercial fishing, which, on an industrial scale, is contrary to international ("IUCN" -- International Union for Conservation of Nature) guidelines."The UNSW study spanned 7000km of coast and five states. The authors assessed 19 fully protected areas, 18 partially protected areas and 19 open areas. They each had different rules and marine communities but they all had broadly stated goals, such as the conservation of biodiversity and ecosystem integrity.The researchers conducted 439 interviews and 190 observation surveys to gauge the social impact of each area (human use, perceptions and values), and analysed existing data from 625 underwater visual census Reef Life Surveys to determine the ecological impact of protection on marine communities (fish, invertebrates and algae).Mr Turnbull said the research team found no social or ecological benefits for partially protected areas relative to open areas. For example, the ecological data revealed that fish species richness and biomass were higher in fully protected areas, but not in partially protected areas. There were 1.3x more fish species, 2.5x more fish biomass and 3.5x more large (20+ cm) fish biomass in fully protected areas compared to open areas.Mr Turnbull said: "Global studies support our findings: there is a lot of research that shows a reduced, if any, impact of partial protection and it depends on the strength of that partial protection."Despite this, fully protected areas are often a very small percentage of a marine park; for example, Sydney's recently proposed marine park had less than three per cent designated as fully protected sanctuary zone, meaning 97 per cent of the area would be open to fishing if the park was approved. This is the degree of 'red herring' we are experiencing."Mr Turnbull said their research also busted the myth that fully protected areas were unpopular."On the contrary, 92 per cent of people we surveyed said they supported protected areas that restrict fishing. We believe our research reflects the general views of coastal users, because we designed our sampling to represent all the different types of user at each site; people swimming, walking, diving, fishing and so on."And there was virtually no difference in support for protected areas between people who fish and people who don't -- just one per cent."Mr Turnbull said the researchers also found most people were passionate about their local coastal areas."People want to see their area looked after and properly protected, especially with sanctuary zones. Often, people specifically visited these because they knew the area was fully protected, and they had personally observed the improvement in marine life" he said."In fully protected areas, we found a higher number of certain types of users; twice as many divers and over three times as many snorkelers. This showed people were directly experiencing the values of fully protected areas and acknowledged them and were attracted to them. This was not the case for partially protected areas; the mix and number of users in these areas were no different to open areas."Study co-author and UNSW Dean of Science Professor Emma Johnston said if governments were going to allocate conservation resources to protect marine areas, they needed to be sure the "investment" was paying off."The current trend towards downgrading fully protected areas to partially protected areas in many parts of the world, including Australia, may be wasting precious conservation resources. Partially protected areas could still be useful but only for specific purposes; for example, to support traditional management practices, protect a particular threatened species, or to create a buffer zone for a fully protected area," Prof. Johnston said."But the results of our substantial study suggest that partially protected areas may be overused and represent a distraction from true conservation measures. The public are confused by partially protected areas and the general biodiversity is no better off."Prof. Johnston said she hoped the researchers' findings would encourage decisionmakers to consider whether their conservation approach was fit for purpose."If we are going to truly protect our planet, partially protected areas must be monitored regularly and the results made public, because if they are failing to provide social or ecological returns, those areas should be upgraded to the level of protection that we know works," she said.
The study describes for the first time the outstanding role of the Posidonia as a filter and trap for plastics in the coastal areas, and it is pioneer in the description of a natural mechanism to take and remove these materials from the sea. Other authors of the study are the experts Miquel Canals, William P. de Haan and Marta Veny, from the Research Group on Marine Geosciences of the UB, and Javier Romero, from the Faculty of Biology and the Biodiversity Research Institute (IRBio) of the UB.The According to the analyses, she continues, the trapped microplastics in the prairies of the This marine phanerogam has a vegetative structure made by a modified stem with a rhizome shape from which the roots and leaves appear. When the leaves fall, its bases (pods) are added to rhizomes and give them a feather-like appearance. "As a result of the mechanical erosion in the marine environment, those pods under the seafloors are progressively releasing lignocellulosic fibres which are slowly added and intertwined until they make agglomerates in a ball-shape, known as The polluting footprint of plastics that come from human activity is a serious environmental problem affecting coastal and ocean ecosystems worldwide. Since plastics were created massively in the 20th century fifties, these materials have been left and accumulated at the sea -- seafloors act as a sink for microplastics -- and are transported by ocean currents, wind and waves. "The plastics we find floating in the sea are only a small percentage of everything we have thrown onto the marine environment," warns Anna SÃ nchez-Vidal.The paper published in the journal "This is why we need to protect and preserve these vulnerable ecosystems. However, the best environmental protection strategy to keep oceans free of plastic is to reduce landfills, an action that requires to limit its use by the population," conclude the experts.
But to reach their destination, these ungulates must successfully navigate the more than 6,000 kilometers (3,728 miles) of fencing that crisscrosses the region. That's enough distance to span nearly twice the length of the U.S.-Mexico border.In a new study, wildlife biologists at the University of California, Berkeley, combined GPS location data of tagged mule deer and pronghorn with satellite imagery of fences to find out just how often these animals encounter fences, and what happens when they do. The results, published on Jan. 7 in the Along with the study, the team is also publishing a software package that will help wildlife managers around the world quickly analyze GPS tracking data to identify fences and other barriers that might be impeding the vital movements of animals."We need fences -- they help keep livestock safe, can help keep livestock and wildlife separate, and mark property boundaries," said Arthur Middleton, an assistant professor of wildlife management and policy at UC Berkeley and senior author of the paper. "So, the question becomes, how do you identify which fences are really important, and which are problematic from a wildlife standpoint, and then seek some way to mitigate the impacts?"Fences don't always pose an insurmountable barrier to wildlife, and different species find different ways to get around them. Mule deer are willing to jump over fences that are low enough. Pronghorn antelope, however, are reluctant to jump over fences and instead must seek out areas where they can move underneath.Wenjing Xu, a Ph.D. student at UC Berkeley and lead author of the paper, took these different behaviors into account when creating the software package that compares animal tracking data with fence maps. The program can categorize different types of behaviors that animals might engage in when they encounter a fence, such as quickly crossing over the fence, pacing back and forth along the fence, or turning around and walking away from the fence.To understand how fences are impacting mule deer and pronghorn, Xu started by painstakingly comparing fencing maps from the federal Bureau of Land Management and the U.S. Forest Service with satellite imagery, adding in fences that were not included in the government surveys. When all the fences were accounted for, Xu was surprised at the sheer amount of fencing in the region."The total length of fences is really, really striking, especially with what we know about the different types of wide-ranging animals that live in that area," Xu said.Xu then compared these maps to GPS tracking data that collected locations every two hours for 24 tagged female mule deer and 24 pronghorn antelope.Each year, mule deer encountered fences an average of 119 times, Xu found. Pronghorn antelope encountered fences at more than twice that rate, about 248 times per year. About 40% of these fence encounters resulted in a change in the animals' behavior."Anybody who's spent time in the West knows you'll find a lot of fences. But, seeing such frequent encounters, 40% of which result in a failure to cross, is kind of mind-blowing -- especially when you multiply those numbers across whole populations and landscapes," Middleton said.Some of these fences are currently being used by ranchers to protect livestock or mark property lines. Others are relics of a bygone era when sheep farming was popular in the state, Middleton said.The best way to mitigate the impact of these fences on animal migration is to remove them, or to replace them with more "wildlife-friendly" fences that mule deer can jump over or that pronghorn can duck under. However, both of these options require money and labor. According to Xu, a recent fencing modification project in Wyoming spent more than $10,000 per mile of fencing to make the fences more permeable to pronghorn.The software package developed by Xu is able to create maps that highlight the fences that pose the greatest impediment to animal movement, helping to prioritize fences to be modified or removed."There is such a strong need for this kind of data," Xu said. "Modifying fences is really, really expensive, and the amount of fencing that might need to be fixed is just so large. [Wildlife managers] really want to find ways to prioritize their resources."Brandon Scurlock, a wildlife management coordinator for the Pinedale region of the Wyoming Game and Fish Department, is working to designate a protected migration "corridor" that connects the summer and winter ranges of pronghorn antelope in western Wyoming. Similar migration corridors for mule deer were established by the state earlier this year.Scurlock's team is already using the study results to identify fences that might create barriers along these routes, and prioritize those for modification."It's been interesting noticing the characteristics of some of these fences that this study has pointed out as being not very permeable for Pronghorn," said Scurlock, who was not a member of the study team. "We recommend the bottom wire of a fence be at least 18 inches above the ground. And, when looking at some of the particularly bad fences that that these methods highlight, we almost invariably see that they have barbed wires that are too close to the ground."One option for offsetting the cost of fence mitigation throughout this region, which is part of the Greater Yellowstone Ecosystem, could consist of imposing a small "conservation fee" on visitors to the area's parks, which include the extremely popular Yellowstone National Park and Grand Teton National Park. Middleton and co-authors, including Berkeley Law professor Holly Doremus, explored the feasibility of this approach in a study published last month in the journal "Fine-scale movement data has helped us see much further into animals' lives, including the challenges we've imposed," Middleton said. "I hope this work helps open people's eyes to the scale of fence effects. Our next steps are to better understand the actual biological cost that all these fence-related behavioral changes have on wildlife populations, and find ways to mitigate those effects at a really large scale."
Now, researchers at MIT and the Woods Hole Oceanographic Institution (WHOI), in collaboration with oceanographers and marine biologists in Cuba, have identified microbes living within the slimy biofilms of some coral species that may help protect the coral against certain nutrient imbalances.The team found these microbes can take up and "scrub out" nitrogen from a coral's surroundings. At low concentrations, nitrogen can be an essential nutrient for corals, providing energy for them to grow. But an overabundance of nitrogen, for instance from the leaching of nitrogen-rich fertilizers into the ocean, can trigger mats of algae to bloom. The algae can outcompete coral for resources, leaving the reefs stressed and bleached of color.By taking up excess nitrogen, the newly identified microbes may prevent algal competition, thereby serving as tiny protectors of the coral they inhabit. While corals around the world are experiencing widespread stress and bleaching from global warming, it seems that some species have found ways to protect themselves from other, nitrogen-related sources of stress."One of the aspects of finding these organisms in association with corals is, there's a natural way that corals are able to combat anthropogenic influence, at least in terms of nitrogen availability, and that's a very good thing," says Andrew Babbin, the Doherty Assistant Professor in Ocean Utilization in MIT's Department of Earth, Atmospheric and Planetary Sciences. "This could be a very natural way that reefs can protect themselves, at least to some extent."Babbin and his colleagues have reported their findings in the the Babbin's group studies how marine communities in the ocean cycle nitrogen, a key element for life. Nitrogen in the ocean can take various forms, such as ammonia, nitrite, and nitrate. Babbin has been especially interested in studying how nitrogen cycles, or is taken up, in anoxic environments -- low-oxygen regions of the ocean, also known as "dead zones," where fish are rarely found and microbial life can thrive."Locations without enough oxygen for fish are where bacteria start doing something different, which is exciting to us," Babbin says. "For instance, they can start to consume nitrate, which has then an impact on how productive a specific part of the water can be."Dead zones are not the only anoxic regions of the ocean where bacteria exhibit nitrogen-feasting behavior. Low-oxygen environments can be found at smaller scales, such as within biofilms, the microbe-rich slime that covers marine surfaces from shipwrecked hulls to coral reefs."We have biofilms inside us that allow different anaerobic processes to happen," Babbin notes. "The same is true of corals, which can generate a ton of mucus, which acts as this retardation barrier for oxygen."Despite the fact that corals are close to the surface and within reach of oxygen, Babbin wondered whether coral slime would serve to promote "anoxic pockets," or concentrated regions of low oxygen, where nitrate-consuming bacteria might thrive.He broached the idea to WHOI marine microbiologist Amy Apprill, and in 2017, the researchers set off with a science team on a cruise to Cuba, where Apprill had planned a study of corals in the protected national park, Jardines de la Reina, or Gardens of the Queen."This protected area is one of the last refuges for healthy Caribbean corals," Babbin says. "Our hope was to study one of these less impacted areas to get a baseline for what kind of nitrogen cycle dynamics are associated with the corals themselves, which would allow us to understand what an anthropogenic perturbation would do to that system."In exploring the reefs, the scientists took small samples from coral species that were abundant in the area. Onboard the ship, they incubated each coral specimen in its own seawater, along with a tracer of nitrogen -- a slightly heavier version of the molecules found naturally in seawater.They brought the samples back to Cambridge and analyzed them with a mass spectrometer to measure how the balance of nitrogen molecules changed over time. Depending on the type of molecule that was consumed or produced in the sample, the researchers could estimate the rate at which nitrogen was reduced and essentially denitrified, or increased through other metabolic processes.In almost every coral sample, they observed rates of denitrification were higher than most other processes; something on the coral itself was likely taking up the molecule.The researchers swabbed the surface of each coral and grew the slimy specimens on Petri dishes, which they examined for specific bacteria that are known to metabolize nitrogen. This analysis revealed multiple nitrogen-scrubbing bacteria, which lived in most coral samples."Our results would imply that these organisms, living in association with the corals, have a way to clean up the very local environment," Babbin says. "There are some coral species, like this brain coral Diploria, that exhibit extremely rapid nitrogen cycling and happen to be quite hardy, even through an anthropogenic change, whereas Acropora, which is in rough shape throughout the Caribbean, exhibits very little nitrogen cycling. "Whether nitrogen-scrubbing microbes directly contribute to a coral's health is still unclear. The team's results are the first evidence of such a connection. Going forward, Babbin plans to explore other parts of the ocean, such as the tropical Pacific, to see whether similar microbes exist on other corals, and to what extent the bacteria help to preserve their hosts. His guess is that their role is similar to the microbes in our own systems."The more we look at the human microbiome, the more we realize the organisms that are living in association with us do drive our health," Babbin says. "The exact same thing is true of coral reefs. It's the coral microbiome that defines the health of the coral system. And what we're trying to do is reveal just what metabolisms are part of this microbial network within the coral system."This research was supported, in part, by MIT Sea Grant, the Simons Foundation, the MIT Montrym, Ferry, and mTerra funds, and by Bruce Heflinger '69, SM '71, PhD '80.
Seafood is the world's most highly traded food commodity, and reports of seafood mislabeling have increased over the past decade. However, proof of the environmental effects of mislabeled seafood has been scant as has research. So, Arizona State University researcher Kailin Kroetz and her colleagues analyzed the impact of seafood mislabeling on marine population health, fishery management effectiveness, and habitats and ecosystems in the United States, the world's largest seafood importer.The results of the study were published in the The study found that approximately 190,000 to 250,000 tons of mislabeled seafood are sold in the United States each year, or 3.4% to 4.3% of consumed seafood. What's more, the substituted seafood was 28% more likely to be imported from other countries, which may have weaker environmental laws than the United States."In the United States, we're actually very good at managing our fisheries," said Kroetz, assistant professor in ASU's School of Sustainability. "We assess the stock so we know what's out there. We set a catch limit. We have strong monitoring and enforcement capabilities to support fishers adhering to the limit. But many countries we import from do not have the same management capacity."The authors used the Monterey Bay Aquarium Seafood Watch scores for wild-caught product pairs to assess marine population health and fishery management effectiveness."Although we would like to do a global assessment in the longer run, we focused on the U.S. first because Seafood Watch assesses about 85% of U.S. seafood consumed," Kroetz explained. "The data we were able to access in the U.S. were much more detailed than what we could access on the global scale."The study found that substitute species came from fisheries that performed worse in terms of population impacts 86% of the time. The population impact metric accounted for fish abundance, fishing mortality, bycatch and discards -- that is, fish thrown back to sea after being caught. In addition, 78% of the time the substituted seafood fared worse than the expected products listed on the label when it came to fishery management effectiveness.Prior studies have focused on the rates at which specific seafood is mislabeled. But it's the quantity of substituted fish consumed that is key to determining environmental impacts."The rates themselves don't tell us the full story about the impact of mislabeling," Kroetz said. That's because some fish that have high rates of substitution have low levels of consumption and vice versa. In fact, the majority of pairs have relatively low rates of substitution and low consumption.Good examples are shrimp and snapper. The researchers found that giant tiger prawns are substituted for white leg shrimp more than any other seafood product -- and Americans eat more shrimp than any other type of seafood, opening the door to potentially substantial environmental impacts. Meanwhile, snapper has a higher rate of mislabeling, but Americans consume much less of it than shrimp.At the very minimum, mislabeling fish undermines good population management, and in turn, sustainable fisheries.Mislabeling can shake consumer confidence in their quest to eat only sustainable, local seafood. That's because substituted fish is more likely to be imported and come from poorly managed fisheries, thereby creating a market for fish that shouldn't be liberally consumed.For example, you might think you're getting this wonderful local blue crab, supporting local fisheries, and experiencing local cuisine, but in reality, you could be eating something that was imported from Indonesia. Learning about mislabeling might reduce the amount you'd pay for blue crab in the future or result in you not consuming it at all."The expected species is often really well managed," Kroetz said. "Consuming fish from a fishery shouldn't have a negative impact in terms of the population now or in the future if the management is good. But if you're consuming fish from poorly managed fisheries, that's not sustainable."This study was funded by the Paul M. Angell Family Foundation and Resources for the Future. The work was also supported by the National Socio-Environmental Synthesis Center under funding received from the U.S. National Science Foundation.
"We know more about the settlement of Polynesia than we do about the settlement of the Mariana Islands," says first author Irina Pugach, a researcher at the Max Planck Institute for Evolutionary Anthropology in Leipzig, Germany. The researchers wanted to find out where people came from to get to the Marianas and how the ancestors of the present Mariana Islanders, the Chamorro, might be related to Polynesians.To address these questions the researchers obtained ancient DNA data from two skeletons from the Ritidian Beach Cave site in northern Guam, dating to around 2,200 years ago. "We found that the ancestry of these ancient skeletons is linked to the Philippines," says Pugach. "These findings strengthen the picture that has emerged from linguistic and archaeological studies, pointing to an Island Southeast Asia origin for the first settlers of the Marianas," says co-author Mike T. Carson, an archaeologist at the Micronesian Area Research Center at the University of Guam."We also find a close link between the ancient Guam skeletons and early Lapita individuals from Vanuatu and Tonga in the Western Pacific region," adds Pugach. "This suggests that the Marianas and Polynesia may have been colonized from the same source population, and raises the possibility that the Marianas played a role in the eventual settlement of Polynesia."The researchers point out that while the new results provide interesting new insights, they are based on only two skeletons that date from around 1,400 years after the first human settlement in Guam. "The peopling of Guam and the settlement of such remote archipelagos in Oceania needs further investigation," says senior author Mark Stoneking of the Max Planck Institute for Evolutionary Anthropology.
Blue whales are the largest animals that have ever lived on our planet, and they are found around the globe in all oceans. All blue whales sing very low-pitched and recognizable songs, and conveniently for researchers, every population has its own unique song. In a recently published paper in the journal Dr. Salvatore Cerchio, Director of the African Aquatic Conservation Fund's Cetacean Program and Visiting Scientist at the New England Aquarium, led the analysis of recordings of the whale from three locations in the western Indian Ocean. Dr. Cerchio first recorded the novel song in 2017, during research focused on Omura's whales in the Mozambique Channel off Madagascar, and he recognized it as a blue whale song that had never been described. Cerchio was also working with a team of scientists collecting acoustic recordings off the coast of Oman in the Arabian Sea. This is part of a research effort focused on the highly endangered Arabian Sea humpback whale, an ongoing collaboration between the Environment Society of Oman, Five Oceans Environmental Services LLC, Oman's Environment Authority and Oman's Ministry of Agriculture, Fisheries and Water Resources.While analyzing the Oman acoustic data, the team recognized the same unusual song. This novel blue whale song was recorded even more prevalently off Oman than Madagascar, and it became clear to the researchers that they had found what was likely a previously unrecognized population of blue whales in the western Indian Ocean."It was quite remarkable," said Cerchio, "to find a whale song in your data that was completely unique, never before reported, and recognize it as a blue whale." Blue whale song has been extensively studied globally, and several blue whale populations have been identified based on their distinct songs throughout the Indian Ocean."With all that work on blue whale songs, to think there was a population out there that no one knew about until 2017, well, it kind of blows your mind," Cerchio said.In 2018, the team reported their findings to the Scientific Committee of the International Whaling Commission (IWC), which was in the process of evaluating the status of blue whale populations in the Indian Ocean. The finding created quite a bit of excitement at the meeting, and raised many new questions about blue whale population movements and structure in the Indian Ocean. Emmanuelle Leroy and Tracey Rogers of the University of New South Wales, in Sydney, Australia, were also conducting acoustic research on blue whales in the Indian Ocean. Upon reading the IWC report on the new song, Leroy recognized that they also had recorded the same song off the Chagos Archipelago in the central Indian Ocean."Shortly after we made the first report at IWC," said Cerchio, "I received an email from Emmanuelle saying, 'Hey Sal, I think we have that Oman song off the Chagos!'"The collaborative team grew, and analysis of data from all three sites suggested that the population may spend most of its time in the northwestern Indian Ocean, in the Arabian Sea and to the west of the Chagos. It has long been recognized that a unique population of blue whales resides in the Northern Indian Ocean, but it was assumed that whales in the Arabian Sea belonged to the same population that has been studied off Sri Lanka and ranges into the southcentral Indian Ocean. However, the songs tell a different story."Before our recording effort off Oman, there were no acoustic data from the Arabian Sea, and so the identity of that population of blue whales was initially just a guess," said Andrew Willson from Five Oceans Environmental Services LLC, who led the deployment of the recording units. "Our work shows that there is a lot more to learn about these animals, and this is an urgent requirement in light of the wide range of threats to large whales related to expanding maritime industries in the region."Blue whales were hunted to near extinction around the globe during the 20th century, and populations have only started to recover very slowly over the past several decades following the global moratorium on commercial whaling. The Arabian Sea was targeted by illegal Soviet whaling in the 1960's, an activity that nearly eradicated what were already likely to be small populations of humpback whales, blue whales, sperm whales, and Bryde's whales.Some researchers consider both the northern Indian Ocean blue whales and Arabian Sea humpback whales to comprise unique subspecies, not simply populations, making them particularly special and important to biodiversity."These populations appear to be unique among baleen whales, in the case of the Arabian Sea humpback whales because of their year-round residency in the region without the same long-range migration of other populations," Willson points out."For 20 years we have focused work on the highly endangered Arabian Sea humpback whale, for which we believe only about 100 animals remain off the coast of Oman," says Suaad Al Harthi, Executive Director of the Environment Society of Oman. "Now, we are just beginning to learn more about another equally special, and likely equally endangered, population of blue whale."
Analysis of the 66 camps shows the Roman army had a larger presence in the region than previously thought during the 200-year battle to conquer the Iberian Peninsula.The discovery of camps of different sizes -- used for training and shelter -- has allowed experts to map how soldiers attacked indigenous groups from different directions and to learn more about the footprint of the Roman military presence in the northern fringe of the River Duero basin -- the LeÃ³n, Palencia, Burgos and Cantabria provinces.Experts analysed aerial photography and satellite images, created three-dimensional models of the terrain from LiDAR data and used drones to create detailed maps of the sites. This included resources from the Spanish National Geographic Institute (IGN) and geoportals such as Google Earth or Bing Maps. Pinpointing locations allowed fieldwork to then take place.These temporary occupations usually left fragile and subtle traces on the surface. The ditches or the earth and stone ramparts protecting these fortifications have been filled in and flattened. Combining different remote sensing images and fieldwork shows the perimeter shape of the temporary Roman military camps, often a rectangle like a playing card.These new sites are located at the foothills of the Cantabrian Mountains, where the conflict between Romans and natives was focused at the end of the 1st century BC. This suggests soldiers crossed between lowlands and uplands, using ridges in the mountains to stay out of site and give themselves more protection.The fact there were so many army camps in the region shows the immense logistical support which allowed soldiers to conquer the area. Sites were used to aid movement to remote locations and to help soldiers stay in the area over the cold winter months. Some of the camps may have housed soldiers for weeks or months, and overs overnight.The aim of the occupation was to expand the empire and to be able to exploit natural resources such as tin and gold.The research, published in the journal Dr Fonte said: "We have identified so many sites because we used different types of remote sensing. Airborne laser scanning gave good results for some sites in more remote places because it showed earthworks really well. Aerial photography worked better in lowland areas for the detection of cropmarks.""The remains are of the temporary camps that the Roman army set up when moving through hostile territory or when carrying out manoeuveres around their permanent bases. They reveal the intense Roman activity at the entrance to the Cantabrian Mountains during the last phase of the Roman conquest of Hispania."There is an important concentration of 25 sites along the valleys of northern Palencia and Burgos, as well as southern Cantabria. In the province of LeÃ³n, as many as 41 sites have been documented in different valleys. These range from small forts of a few hundred square meters to large fortified enclosures of 15 hectares.Most of these Roman military sites were located in close proximity of later important Roman towns. SasamÃ³n, a village in Burgos that was probably where nearby the Emperor Augusto established his camp during his presence in the front.The research will continue so experts can examine the relationships the Romans established with indigenous communities, named Vaccaei, Turmogi, Cantabri, Astures and Callaeci, according to the Greek and Latin sources.The team is currently developing a project to catalogue and document all the Roman camps in the province of LeÃ³n by means of drones, in order to gain a better understanding of their structures or the evolution of their state of conservation. Work is also continuing in Burgos and in SasamÃ³n, including a study of the Cerro de CastarreÃ±o settlement and its conquest in the 1st century BC.
"There is a lot of concern about companies that operate on the high seas, simply because there they are beyond the reach of any nation's laws and regulations," says Jennifer Jacquet, an associate professor in NYU's Department of Environmental Studies and lead author of the peer-reviewed study. "By connecting those boats with specific companies, this study takes a first step in enhancing transparency -- we now know a lot more about who is profiting from fish catches in the global commons."The findings illuminate a significant element of commercial fishing. Previously, researchers could only identify which countries reported catching fish on the high seas, which account for 60 percent of the world's oceans and therefore represent a substantial proportion of waters that lie beyond the reach of national jurisdiction."We also have a much better sense of what we don't know," adds first author Gabrielle Carmine, a doctoral candidate at Duke University's Nicholas School of the Environment who worked with Jacquet as an NYU undergraduate. "The corporate actors we know vary by fishing gear type and by location in the high seas. For example, we know far more about the trawling fleet than the longline fleet and more about the Atlantic Ocean than the Western Tropical Pacific."Species caught on the high seas are fished by industrial fleets and destined mainly for high-end markets in the U.S and Europe. Past assessments of high seas fish populations show that fishing in these waters has led to extraordinary declines in the abundance of many open-ocean species, including several species of tuna, swordfish, and marlin. While fish catches are reported by nations, many companies catch and profit from fish in the global ocean, where fishing is subject to few regulations because the high seas lie beyond national jurisdiction.Combining data that detects fishing vessels made available from Global Fishing Watch with other public databases, such as regional fisheries management organizations and shareholder information, the team's analysis showed 1,120 corporations owned nearly 2,500 high seas fishing vessels in 2018 -- or approximately two-thirds of the total detected fishing effort in these waters.However, high seas fishing is notably concentrated among a small number of entities. The Korean companies Sajo Group and Dongwon, which owns the U.S. subsidiary Starkist, were in the top 10 of the most active corporations on the high seas, along with a handful of Chinese corporations and one U.S. corporation based in Hawaii. Approximately 100 companies, based in the United States, the United Kingdom, China, Taiwan, Russia, Spain, the Netherlands, and South Korea, among other nations, accounted for more than one-third of high seas fishing during the studied period."These results provide a unique lens through which to view accountability for the use and protection of global ocean biodiversity," observes Jacquet.These results come in advance of the fourth United Nations Intergovernmental Conference on Marine Biodiversity of Areas Beyond National Jurisdiction, which was postponed and is expected sometime in 2021.
Hatchery-reared Atlantic salmon (Salmo salar) have been released to support the wild salmon stocks in the Baltic Sea for decades. During their feeding migration, salmon are exposed to organohalogen compounds (OHCs). Here, we investigated the OHC levels and transcriptome profiles in the liver of wild and hatchery-reared salmon collected from the Baltic main basin, the Bothnian Sea, and the Gulf of Finland and examined whether salmon origin and OHC levels contributed to the hepatic transcriptome profiles.There were no differences in the OHC concentrations and transcriptome profiles between wild and hatchery-reared fish but there were large differences among the areas.Several transcript levels were associated with polychlorinated biphenyls, chlordanes, and dichlorodiphenyltrichloroethane in a concentration-dependent manner. When comparing the different areas, lipid metabolism, environmental stress, cell growth and death-related pathways were enriched in the liver transcriptome. Coinertia analysis, a multivariate method, showed that the covariation in the OHC levels and the transcriptome were significantly similar.These results suggest that the hepatic transcriptomes in wild and hatchery-reared salmon are more affected by the OHC level than the salmon's origin. This paper was published in an American Chemical Society Journal, 
"Long-distance seafaring between Egypt and Punt, two sovereign entities, was a major milestone in human history because it drove the evolution of maritime technology. Trade in exotic luxury goods, including baboons, was the engine behind early nautical innovations," explains lead author Nathaniel J. Dominy, the Charles Hansen Professor of Anthropology at Dartmouth College."Many scholars view trade between Egypt and Punt as the first long maritime step in a trade network known as the spice route, which would go on to shape geopolitical fortunes for millennia. Other scholars put it more simply, describing the Egypt-Punt relationship as the beginning of economic globalization," he added. "Baboons were central to this commerce, so determining the location of Punt is important. For over 150 years, Punt has been a geographic mystery. Our analysis is the first to show how mummified baboons can be used to inform this enduring debate."Ancient Egyptians revered baboons throughout their history, with the earliest evidence dating from 3,000 B.C. Baboons were even deified, entering the pantheon of gods as manifestations of Thoth, a god associated with the moon and wisdom. One species, Papio hamadryas (the sacred baboon), was often depicted in wall paintings and other works, as a male, in a seated position with its tail curled to the right of its body. The species was among the types of baboons that were mummified in this very position with the linens carefully wrapped around its limbs and tail. Another species, Papio anubis (the olive baboon), was also mummified but it was typically wrapped in one big cocoon in a manner reflecting far less care. Baboons have never however, existed naturally in the Egyptian landscape and were a product of foreign trade in the region.The study focused on mummified baboons from the New Kingdom period (1550-1069 B.C.) available in the British Museum and specimens from the Ptolemaic period (305-30 B.C.) available in the Petrie Museum of Egyptian Archaeology at University College London. In addition, the authors examined tissues from 155 baboons from 77 locations across eastern Africa and southern Arabia, encompassing every hypothesized location for Punt. The team measured oxygen and strontium isotope compositions and used a method called isotopic mapping to estimate the geographic origins of specimens recovered from the New Kingdom and Ptolemaic sites in Egypt.Strontium is a chemical element that is found in bedrock, which is specific to a geographic location. As strontium erodes, its composition is absorbed into the soil and water and enters the food web. As animals drink the water and eat the plants, their teeth, and hair and bones, obtain a geographic signature reflecting where they have lived in the past and most recently, respectively.Baboons must drink water every day and are considered obligate drinkers. Their bodies reflect the oxygen composition of water in the landscape. The enamel of an animal's adult teeth reflect the unique strontium composition of its environment when the teeth formed in early life. In contrast, hair and bone have isotope signatures that reflect the preceding months (hair) or years (bone) of dietary behavior. Similar to strontium, oxygen compositions (specifically, isotopes) of water can also vary by geographic location but the researchers found data from the specimens in this category were inconclusive, and only reflected values specific to Egypt.The findings demonstrate that the two mummified P. hamadryas baboons from the New Kingdom period, EA6738 and EA6736, were born outside of Egypt. They had most likely come from a location in Eritrea, Ethiopia or Somalia, which narrows down the location of Punt.The data suggest that EA6736, a P. hamadryas baboon, must have died shortly, day or months, after arriving in Egypt, as results indicate that its enamel and hair did not have sufficient time to convert to the local oxygen signature of drinking water.Five species of mummified P. anubis from the Ptolemaic period reflected strontium levels that are consistent with an Egyptian origin, which provides tantalizing hints of a captive breeding program for baboons at this time, probably in Memphis, an ancient capital in Lower Egypt, northwest of the Red Sea.As the researchers explain in the study, their estimated location of Punt is still provisional but the role that baboons played in the Red Sea trade network and their geographic distribution is one that is integral to understanding the historic origins of international maritime commerce.The study was co-authored by Salima Ikram at American University in Cairo; Gillian L. Moritz at Dartmouth; Patrick V. Wheatley at Lawrence Berkeley National Laboratory; Jonathan W. Chipman at Dartmouth; and Paul L. Koch at the University of California in Santa Cruz.
The fossilized burrow dates back to the Late Pleistocene Epoch, about 115,000 years ago, and is located on the island of San Salvador -- best known as the likely spot where Christopher Columbus made his first landfall in his 1492 voyage."San Salvador is one of the outer-most islands in the Bahamas chain and really isolated," says Anthony Martin, a professor in Emory's Department of Environmental Sciences and senior author of the Martin's specialty is ichnology -- the study of traces of life, such as tracks, nests and burrows. He documents modern-day traces to help him identify trace fossils from the deep past to learn about prehistoric animal behaviors.The current discovery was made during a class field trip to San Salvador as part of the course "Modern and Ancient Tropical Environments," co-taught by Martin and Melissa Hage, an assistant professor of environmental science at Emory's Oxford College and a co-author of the paper. Co-authors also include two former undergraduates from the class: Dottie Stearns (now in medical school at the University of Colorado) and Meredith Whitten (who now works in fisheries management for the state of North Carolina)."No matter how much you read about things in a textbook, a lot of concepts in geology just don't click until you see them in real life," Hage says. "It sparks a lot of excitement in students when they experience the process of scientific discovery in the field.""Students get to actually see the connections of the past and the present," Martin adds. "On the north point of San Salvador, for instance, the undulating landscape consists of ancient sand dunes that turned into rock. We can walk across these ancient dunes to look at the rock record and get an idea of how the island changed over time."During a stop on the shoreline road on the south end of the island, Martin happened to notice what looked like the trace of a fossil iguana burrow on a limestone outcrop exposed by a roadcut.The fossil record for iguanas goes back to the Late Cretaceous in South America. Today iguanas are found in tropical areas of Mexico, Central America, South America, the Caribbean and the Bahamas.Iguanas can grow up to six feet in length, including their tails. Despite their large size, formidable claws and fierce-looking spikes arrayed on their backs, iguanas are mostly herbivores.The now endangered San Salvador rock iguana, Cyclura riyeli riyeli, and other Cyclura species were plentiful throughout the Bahamas before 1492, when European ships began introducing rats, pigs and other invasive species that feed on the lizards' eggs."One of the cool things about iguanas is that they are survivors," Martin says. "And one of the main ways that they survive is through burrowing. Digging burrows has helped them survive hurricanes, droughts and other bad things that might be in their environment, like most predators. But burrows are not as helpful when it comes to rats and pigs."After further investigation, Martin and his co-authors determined that the trace fossil he noticed on the limestone outcrop was that of a nesting iguana burrow. Ample evidence, including a nearby fossil land-crab burrow discovered by Hage, showed that the outcrop was a former inland sand dune, where iguanas prefer to lay their eggs.The iguana trace revealed the distinctive pattern of a female creating a nest. "Iguanas have evolved a behavior where a female actually buries herself alive in sand, lays her eggs, and then 'swims' out, packing the loose sand behind her as she leaves the burrow to hide the eggs from predators," Martin says.This backfilling technique created compaction zones that weathered out over time from the surrounding limestone because they were more durable. "It's like when you pack sand to build a sandcastle at the beach," Martin explains. "It's a similar principle but, in the case of the iguana burrow, it happens underground."The lack of burrows from hatchlings digging their way to the surface, however, suggests that the nest failed and that the eggs never produced young.The researchers were able to date the iguana trace to about 115,000 years ago due to tell-tale red paleosols, or fossilized soils. "The red indicates oxidized iron minerals and there are no native iron minerals in that area," Martin explains. "But whenever there is a drop in sea level, the Sahara expands in size creating big dust storms. The trade winds take this red dust across the Atlantic and deposit it in the Caribbean."The oldest iguana skeletons found on San Salvador only date back less than 12,000 years, in the Holocene Epoch, so the discovery of the iguana trace pushes their presence on the islands back significantly.Most of the Bahamian islands sit on a relatively shallow platform, making it easy to imagine how iguanas might have migrated there during sea-level lows. San Salvador, however, is a small, isolated island surrounded by deep ocean, setting up the mystery for how the first iguanas arrived there at least 115,000 years ago."We're hoping researchers who study iguana evolution will be inspired by our paper to dig deeper into this question," Martin says.The researchers also hope that the paper draws attention to the plight of modern-day San Salvador rock iguanas. "When it comes to species preservation, many people think of panda bears and other cuddly mammals," Hage says. "Making the connection between how long iguanas have been on the island and how the modern-day San Salvador rock iguanas are endangered may help more people understand why they are worth preserving."Additional authors on the paper include Michael Page, a geographer in the Emory Department of Environmental Sciences and the Emory Center for Digital Scholarship; and Arya Basu; a visual information specialist and research scientist in the Emory Center for Digital Scholarship.
Diego CardeÃ±osa -- an FIU postdoctoral researcher in the Institute of Environment -- led a new study in collaboration with scientists in Hong Kong that uses DNA analysis to track where fins in the global shark fin trade originate. They focused on silky sharks (Testing revealed 99.8 percent of the fins sampled from retail markets in Hong Kong and China originated from the Indo-Pacific Ocean. Virtually none came from the Atlantic Ocean, which provides the first evidence that conservation efforts could be making an impact.According to FIU research, around 100 million sharks are killed every year. Nearly one-third of the shark species in the global shark fin trade are at risk of extinction.Open ocean sharks, like silky sharks, face a considerable risk of overexploitation because they get caught in nets and longlines set by fishing fleets targeting tuna. High demand for shark fins in Asia means that although they are considered accidental by-catch, they are by-catch worth keeping.Silky sharks are protected under Convention on International Trade in Endangered Species of Wild Fauna and Flora (CITES) -- an international agreement protecting animals and plants from overexploitation in international trade. Listed in Appendix II, all trade of these sharks requires permits certifying they were legally caught, catch is sustainable, and traceable through the supply chain.The Regional Fisheries Management Organizations oversees fishing regulations and shark management decisions. In 2011, one of these organizations -- the International Commission for the Conservation of Atlantic Tuna (ICCAT) -- prohibited the fishing, retention and transshipment of silky sharks by all fisheries operating under its jurisdiction. Only developing nations are allowed to fish for these sharks as a source of food."This study shows that there is good news for ICCAT and the Atlantic silkies," said CardeÃ±osa, who was recently named a Distinguished Postdoctoral Scholar in the College of Arts, Sciences & Education. "While it doesn't necessarily mean that the Atlantic population is recovering or that fishing mortality is decreasing, it's a good assessment that there's high compliance with the retention and export ban by ICCAT parties."The long-term goal of CardeÃ±osa's research is to provide information about where shark fins originate in order to better direct more concentrated shark conservation efforts and fisheries management. This study emphasizes the need for increased monitoring, as well as better implementation of CITES regulations. The reality is illegal, unreported trade continues to happen.In fact, earlier this year Hong Kong customs officials intercepted an illegal shipment lacking proper CITES documentation from Ecuador that included silky and pelagic thresher shark fins. The secret tool behind this historic seizure of shark fins was a DNA testing kit co-developed by CardeÃ±osa and Demian Chapman, an FIU marine scientist in the Institute of Environment. Created with funding from the Paul G. Allen Family Foundation, the tool is being used in airports and shipping ports to help customs officials identify protected shark species."Understanding which species are most prevalent in the shark fin trade can help identify the species in need of conservation intervention," CardeÃ±osa said. "Tracing the populations of origin can help identify the key management jurisdictions that can lead proper interventions."The research is supported by the Pew Charitable Trusts and the Pew Fellowship Program. The findings were published in 
Yet scores of species have lost that extraordinary ability, particularly on islands.On the small islands that lie halfway between Antarctica and continents like Australia, almost all the insects have done so.Flies walk, moths crawl."Of course, Charles Darwin knew about this wing loss habit of island insects," says PhD candidate Rachel Leihy, from the Monash University School of Biological Sciences."He and the famous botanist Joseph Hooker had a substantial argument about why this happens. Darwin's position was deceptively simple. If you fly, you get blown out to sea. Those left on land to produce the next generation are those most reluctant to fly, and eventually evolution does the rest. VoilÃ ."But since Hooker expressed his doubt, many other scientists have too.In short, they have simply said Darwin got it wrong.Yet almost all of these discussions have ignored the place that is the epitome of flight loss -- those 'sub-Antarctic' islands. Lying in the 'roaring forties' and 'furious fifties', they're some of the windiest places on Earth."If Darwin really got it wrong, then wind would not in any way explain why so many insects have lost their ability to fly on these islands," said Rachel.Using a large, new dataset on insects from sub-Antarctic and Arctic islands, Monash University researchers examined every idea proposed to account for flight loss in insects, including Darwin's wind idea.Reporting today in Windy conditions make insect flight more difficult and energetically costly. Thus, insects stop investing in flight and its expensive underlying machinery (wings, wing muscles) and redirect the resources to reproduction."It's remarkable that after 160 years, Darwin's ideas continue to bring insight to ecology," said Rachel, the lead author of the paper.Professor Steven Chown, also from the School of Biological Sciences, added that the Antarctic region is an extraordinary laboratory in which to resolve some of the world's most enduring mysteries and test some of its most important ideas.
The ocean is a big place full of natural resources including fossil fuels, minerals, and of course, fish. The problem is that many of these resources are on the ocean floor in places we have yet to find. Ocean exploration is therefore necessary, and currently automated vehicles, sonar, and satellites are all used with varying advantages and disadvantages. At RIKEN BDR, scientists led by Yo Tanaka are developing a completely different system that relies on the natural swimming behavior of electric rays and sting rays."Electric rays and sting rays are benthic animals, meaning that they spend most of their time swimming around the ocean floor in deep places," explains Tanaka. "By combining simple pinger technology and digital cameras with this natural behavior, we think we can use rays to map the ocean floor, and at the same time collect meaningful data about ocean wildlife, biota, and resources." Additionally, this method could be much more cost effective as Tanaka and his team have already shown that electric rays can use their own electricity to power the small pingers.A pinger is a device that emits and ultrasonic sound. When a pinger's sound is picked up by several receivers, the position of the receivers and the time when the sound is detected can be used to calculate the position of the pinger. By placing cameras on rays and linking the timing of the recorded video to the timing and locations determined by the pingers, the researchers believe they can create accurate maps of the ocean floor. In their proof-of-concept study, the team conducted two experiments that showed that their idea to use rays is feasible.The first study took place in a large water tank. A setup with cameras in three planes -- front, side, and top -- verified that both types of ray swam near the bottom of the tank. The images taken by the camera allowed 3-D reconstruction of movements over time. They also verified that a camera could be attached the rays to record video of their exploration. With these positive results, the team was ready to test their system out in the real world -- an area off the coast of Okinawa in Japan. As this was a proof-of-concept experiment, they chose an area with a relatively flat seabed.They attached pingers to both sting rays and electric rays and lowered them into the ocean from a large boat along with four ultrasound receivers. The depth of the ocean was about 20 m (60 ft) and the rays were allowed to swim about 40 m (120 ft) out from the boat. The researchers recorded the pinger-derived positions as the rays swam near the boat for about two hours. Afterward, they compared the data with a seabed map of the area that already exists and confirmed that the rays' positions were within about 10 cm of those in the public map. Similar results from both types of ray were important because rays are seasonal animals"In our ocean experiment, in addition to the pinger positioning, we were able to confirm that electric rays actually move around the seabed," says Tanaka. "In the near future we will test the system for long-term monitoring." Long-term monitoring will require pingers that the electric rays can self-charge as well as wearable battery packs for the sting rays. The next test will also monitor an area with a more varied seabed with complex geometry.
Their research, which relies on mathematical modelling, is published today in The Earth is our home and over its 4,500,000,000 (4.5 billion) year history has evolved to form the environment we live in and the resources on which we depend.However, the early history of Earth, covering its first 1.5 billion years remains almost unknown and, consequently, poorly understood."This was the time of formation of the first continents, the emergence of land, the development of the early atmosphere, and the appearance of primordial life -- all of which are the result of the dynamics of our planet's interiors," said lead study author ARC Future Fellow Dr Fabio Capitanio from the Monash University School of Earth, Atmosphere and Environment."Reproducing the conditions of the early Earth in computer-generated numerical models, we show that the release of internal primordial heat, three to four times that of the present-day, caused large melting in the shallow mantle, which was then extruded as magma (molten rock) onto the Earth's surface," he said.According to the researchers, the shallow mantle left behind by this process was dehydrated and rigid and formed the keels of the first continents."Our results explain that continents remained weak and prone to destruction in their infancy, ~4.5 to ~4.0 billion years ago, and then progressively differentiated and became rigid over the next billion years to form the core of our modern continents," Dr Capitanio said."The emergence of these rigid early continents resulted in their weathering and erosion, changing the composition of the atmosphere and providing nutrients to the ocean seeding the development of life."Dr Capitanio specialises in investigating the dynamics of the Earth's tectonics and plate motions to better understand the mechanisms that force single plates or whole-Earth changes.The work adds to the knowledge on supercontinent formation and its fragmentation into the present-day continents.The quantitative model used in the study explains the enigmatic melt degrees and layered structures observed in most cratons on Earth.The process shows that continents remain weak and prone to destruction in their infancy, then progressively melt and differentiate to become stable continents.This accounts for the transition from the Hadean, covering the first 500 million years of Earth history, in which crust was completely recycled, to the Archean (four to three billion years ago), when rigid continental keels built up and remain preserved through time."The geological record suggests that the very early continents did not survive and were recycled in the planet's interiors, yet this trend dramatically inverted approximately four billion years ago, when the most enduring piece of continents, cratons, appeared," Dr Capitanio said.Only tiny crystals remain from Earth's earliest continental crust, formed more than 4 billion years ago. The mysterious disappearance of this crust can now be explained. The very process that formed new crust, replacing the old one, is critically related to how the continents became stable. By extracting melt from the Earth's interior, rigid rafts in the mantle form beneath the new crust, shielding it from further destruction. The crust formed in this way is still preserved in the core of today's continents, the cratons.The cratons keep record of early life on our planet and are currently a very small fraction of the surface.Australia hosts three cratons, the Yilgarn, the Pilbara, and the Gawler cratons.
Public and philanthropic sources currently supply most of the funds for protecting and conserving species and ecosystems. However, the private sector is now driving demand for market-based mechanisms that support conservation projects with positive environmental, social and financial returns. Examples of projects that can support this triple bottom line include green infrastructure for stormwater management, clean transport projects and sustainable production of food and fiber products."The reality is that public and philanthropic funds are insufficient to meet the challenge to conserve the world's biodiversity," said Garvin Professor and Senior Director of Conservation Science at Cornell University Amanda Rodewald, the report's lead author. "Private investments represent a new path forward both because of their enormous growth potential and their ability to be flexibly adapted to a wide variety of social and ecological contexts."Today's report examines the legal, social and ethical issues associated with innovative conservation finance and offers resources and guidelines for increasing private capital commitments to conservation. It also identifies priority actions that individuals and organizations working in conservation finance will need to adopt in order to "mainstream" the field.One priority action is to standardize the metrics that allow practitioners to compare and evaluate projects. While the financial services and investment sectors regularly employ standardized indicators of financial risk and return, it is more difficult to apply such indicators to conservation projects. Under certain conservation financing models, for example, returns on investment are partially determined by whether the conservation project is successful -- but "success" can be difficult to quantify when it is defined by complex social or environmental changes, such as whether a bird species is more or less at risk of going extinct as a result of a conservation project.Another priority action is to establish safeguards and ethical standards for involving local stakeholders, including Indigenous communities. In the absence of robust accountability and transparency measures, mobilizing private capital in conservation can result in unjust land grabs or in unscrupulous investments where profits flow disproportionately to wealthy or powerful figures. The report offers guidelines for ensuring that conservation financing improves the prosperity of local communities.According to co-author Peter Arcese, a professor at the University of British Columbia and adjunct professor at Cornell University, opportunities in conservation finance are growing for patient investors who are interested in generating modest returns while simultaneously supporting sustainable development."Almost all landowners I've worked with in Africa and North and South America share a deep desire to maintain or enhance the environmental, cultural and aesthetic values of the ecosystems their land supports," Arcese said. "By creating markets and stimulating investment in climate mitigation, and forest, water and biodiversity conservation projects, we can offer landowners alternative income sources and measurably slow habitat loss and degradation."Rodewald sees a similar landscape of interest and opportunity. "No matter the system -- be it a coffee plantation in the Andes, a timber harvest in the Pacific Northwest, or a farm in the Great Plains -- I am reminded again and again that conservation is most successful when we safeguard the health and well-being of local communities. Private investments can be powerful tools to do just that," said Rodewald.Report: Amanda Rodewald, 
Now, a collaboration between researchers from Cornell University and the University of Wisconsin-Madison has found that small, community-based reserves in Thailand's Salween River Basin are serving as critical refuges for fish diversity in a region whose subsistence fisheries have suffered from decades of overharvesting.The team's paper, "A Network of Grassroots Reserves Protects Tropical River Fish Diversity," published Nov. 25 in The lead author is Aaron Koning, a former postdoctoral fellow with the Cornell Atkinson Center for Sustainability who is currently a postdoctoral researcher at the University of Nevada, Reno. The project was overseen by Pete McIntyre, the Dwight Webster Sesquicentennial Faculty Fellow and associate professor of natural resources and environment at Cornell University.Freshwater ecosystems across the world have experienced rapid species declines compared to ecosystems on land or in the ocean. One of the leading causes is overfishing, particularly in regions where fish are a vital source of human nutrition.Koning launched his work in Thailand as a doctoral student with McIntyre at the University of Wisconsin-Madison, with the goal of testing whether the benefits documented from marine conservation reserves might also apply to freshwater systems. Both researchers came to Cornell in 2018 and continued to work on the project with their collaborators at UW-Madison.They focused on the Mae Ngao River along Thailand's border with Myanmar, because Southeast Asia has an unusually long history of freshwater conservation reserves. In 2012, Koning began documenting more than 50 reserves spread over 1,000 square kilometers of the river valley. Each of these reserves had been created by a local community to support its own nearby fishing grounds."It was really striking to see this largely uncoordinated effort of grassroots actors who pursued this fascinating conservation strategy of their own volition, and they keep doing it because they can see the benefits in their catches," Koning said. "That really motivated me to ask the questions: Why does this work and could it work elsewhere?"The researchers surveyed fish communities in 23 separate reserves that ranged in length from 300 meters to 2 kilometers. Compared to adjacent areas where fishing is unrestricted and intense, the grassroots reserves contained on average 27% more fish species and 124% higher fish density, with a more than twentyfold increase in overall biomass."Generally, we think of rivers as systems where things flow through and fish move around constantly, so what effect could a small reserve possibly have?" Koning said. "But just having a few hundred meters where people aren't fishing, while they're fishing like crazy everywhere else, can consistently produce these big changes."One of the key characteristics for successful reserves was location. When reserves are placed within view of local villages, the community members can enforce conservation rules and deter poachers."Residents can literally see the large fish from their homes -- it's pretty compelling," McIntyre said.Fish longer than 20 centimeters (approximately 8 inches) were almost entirely restricted to the reserves, and larger reserves saw the biggest bump in fish diversity and size. Community members reported that having the reserves over time helped them to catch larger fish. This indicates the reserves not only protect biodiversity but can also bolster the food security of local populations, especially during the dry season when farmers have collected their crops and turn to subsistence fishing to supplement their families' diets."As if the local benefits were not amazing enough, we were fascinated to see a further benefit of having other reserves nearby. These fish populations appear to be linked, yielding synergistic gains when the ad hoc network of reserves allows exchange among protected areas," McIntyre said.The team's findings aligned with the theoretical predictions made by marine conservation models, which led the researchers to suspect the grassroots reserves could be a successful strategy for other regions that have been overharvested, such as in the Mekong, Amazon and Congo rivers, where intensive fisheries feed millions of people."This is a great example of communities engaging in conservation on their own, and being successful," Koning said. "If we can take that reality, mix it with what we already know from marine systems, then maybe we can marry these things and design a system of small reserves that maximize conservation benefits while improving fishery benefits for communities, too."Koning is now working with Zeb Hogan, an aquatic ecologist at the University of Nevada-Reno who hosts the National Geographic network program "Monster Fish," to study this conservation approach at larger scales in the Mekong River basin.The research was supported by the National Science Foundation, the Mustard Seed Foundation, and the David and Lucile Packard Foundation, in addition to the Cornell Atkinson Center for Sustainability.
It is hoped that the study will provide the basis for developing 'intelligent pesticides', that act with surgical precision by tapping into locust-specific signals in the nervous system, to either kill or disable their swarming behaviour, without harming other organisms.The full set of genetic information for the desert locust could have major international implications for countries such as East Africa, the Arabian Peninsula and South-West Asia, which this year have been suffering the most devastating desert locust crises in decades despite wide-spread control operations that are still ongoing.According to the Food and Agricultural Organisation (FAO), a swarm of locusts can contain around 40 million insects per square kilometre, which each day can eat the same amount of food as 35,000 people. The FAO estimates that 42 million people are currently facing severe food insecurity caused specifically by the desert locust.Dr Tom Matheson said:"The incredible devastation that these voracious insects can cause to food crops and pastures affects the livelihoods of hundreds of thousands of farmers and exacerbates the risks of starvation for the wider population in already vulnerable regions."The desert locust genome provides key information that could be a complete game-changer for the developing world, and a huge economic step forward for countries struggling to feed their populations."Tackling locust infestations and controlling swarms will never be easy because of the challenging conditions across the huge areas affected, but with the right information and research at hand, we hope that future approaches can become more effective."He added:"If climate change causes locust plagues to become the 'new normal', we will need all hands on deck by way of in-depth research and improved technology to help in the fight to control swarms."Desert locust swarms are a major economic issue in more than 65 countries, across more than 20 per centof the world's total land surface. Authorities in affected countries have been carrying out aerial spraying of pesticides, but the scale of the infestation is often beyond local capacity as desert locusts can travel up to 150km (95 miles) in a day, crossing national borders and rugged terrain in regions with little road infrastructure.While locust swarms are infamous for the great damage they inflict to agriculture, their genetic material ('genome') is famed amongst researchers for its enormous size. At more than 8.8 billion base pairs of DNA (8.8 'giga-bases'), the desert locust genome is the largest insect genome sequenced to date and over 2.8 times larger than the human genome.Dr Swidbert Ott added:"We do not yet understand the genetic instructions that make locusts behave so differently from ordinary grasshoppers, and to such damaging effect. Until now, a major stumbling block has been the lack of the desert locust genome sequence that holds the answer to what makes a grasshopper a locust."We hope that our data can facilitate the development of novel, more sustainable methods of managing swarm outbreaks. With the information in our research now available, there is a unique opportunity for innovators to create an intelligent pesticide that targets locusts, but not other insects crucial to the ecosystem, such as pollinators."
"Our observations truly surprised us," said Astrid Leitner, lead author on the study, who conducted this work as graduate researcher in the UH Manoa School of Ocean and Earth Science and Technology (SOEST). "We had never seen reports of such high numbers of fishes in the sparsely-populated, food-limited deep-sea."The researchers, including Leitner, Jennifer Durden (NOC) and professors Jeffrey Drazen (Leitner's doctoral research advisor) and Craig Smith, made the observation on an expedition to the Clarion Clipperton Zone (CCZ). The CCZ is a large region stretching nearly from Hawai'i to Mexico, which is being explored for deep sea mining of nodules containing metals such as copper, cobalt, zinc and manganese.Abyssal seamounts, deep underwater mountains whose summits are 9,800 ft (3,000 m) below the sea surface, dot the deep seascape and are some of the least explored habitats on the planet. During the expedition, the research team sampled three of these seamounts and their surrounding plains as part of an effort to establish an ecological baseline prior to extraction activities.On the summit of one of the three previously unmapped and completely unexplored seamounts, the team captured on video a swarm of 115 cutthroat eels (Family Synaphobranchidae) at a small bait package containing about two pounds (1 kg) of mackerel. A few eels were caught in a baited trap and identified to be of the species Ilyophis arx, a poorly known species with fewer than 10 specimens in fish collections worldwide.These eels were observed at the top of all of the seamounts, but not on the surrounding abyssal plain. The findings provide evidence for an abyssal seamount effect (where these mountains can support much higher numbers of animals than other surrounding habitats), and also indicate these eels are likely to be seamount specialists.After returning from the expedition, the team determined they had documented the highest number of fishes ever been recorded at one time in the abyssal ocean -- almost double the previous record."If this phenomenon is not just isolated to these two seamounts in the CCZ, the implications on deep sea ecology could be widespread," said Leitner, who is now a postdoctoral researcher at the Monterey Bay Aquarium Research Institute. "Our findings highlight how much there is still left to discover in the deep sea, and how much we all might lose if we do not manage mining appropriately."
"People think of bees as just honey bees, bumble bees, and maybe a few others, but there are more species of bees than of birds and mammals combined," says senior author John Ascher, an assistant professor of biological sciences at the National University of Singapore. "The United States has by far the most species of bees, but there are also vast areas of the African continent and the Middle East which have high levels of undiscovered diversity, more than in tropical areas."Many plants and animals follow a pattern, known as a latitudinal gradient, where diversity increases toward the tropics and decreases toward the poles. Bees are an exception to this rule, having more species concentrated away from the poles and fewer near the equator, a pattern known as a bimodal latitudinal gradient. There are far fewer bee species in forests and jungles than in arid desert environments because trees tend to provide fewer sources of food for bees than low-lying plants and flowers."When it rains in the desert, there are these unpredictable mass blooms that can literally carpet the entire area," says first author Michael Orr, a postdoctoral fellow at the Institute of Zoology, Chinese Academy of Sciences. "There's a much higher turnover in the desert because of how patchy the resources are year after year. So there's a lot of potential for new species there."To create their maps, Ascher, Orr, Hughes, and colleagues compared data about the occurrence of individual bee species with a massive checklist of over 20,000 species compiled by Dr. Ascher and accessible online at the biodiversity portal DiscoverLife.org. Cross-referencing multiple datasets with complementary coverage resulted in a much clearer picture of how the many species of bees are distributed in different geographic areas. This is an important first step in assessing the distribution and potential declines of bee populations."We're extremely interested in abundance of bees, but that's something that has to be done in relation to a baseline," says Ascher, "We're trying to establish that baseline. We really can't interpret abundance until we understand species richness and geographic patterns."While some of these patterns had been hypothesized by previous researchers such as Charles Michener, they were difficult to prove because of inaccurate, incomplete, or difficult-to-access data. "Cleaning" these data was a major hurdle for the researchers."I was surprised how terrible most of the prior global data really was about bee diversity," says Alice Hughes (@AliceCHughes), an associate professor of conservation biology at Xishuangbanna Tropical Botanical Garden, Chinese Academy of Sciences and another author on the paper. "A lot of the data were just too patchy or too concentrated on a small number of countries that have prioritized data sharing to be able to use these resources for any large-scale analysis."While there remains a lot to learn about what drives bee diversity, the research team hopes their work will help in the conservation of bees as global pollinators."Many crops, especially in developing countries, rely on native bee species, not honey bees," says Hughes. "There isn't nearly enough data out there about them, and providing a sensible baseline and analyzing it in a sensible way is essential if we're going to maintain both biodiversity and also the services these species provide in the future."The authors view this research as an important first step towards a more comprehensive understanding of global bee diversity and an important baseline for future, more detailed bee research.
The discovery, based on analysis of 30 years' worth of sightings, photographs and underwater sound recordings, is crucial evidence in learning how the species is recovering following a ban on commercial whaling in the 1960s. The findings are published today (19 November) in the journal Blue whales were abundant off South Georgia before early 20th century industrial whaling between 1904 and 1971 killed 42,698 of them there. Most of these were killed before the mid-1930s.The species all but vanished from the region -- dedicated whale surveys from ships off South Georgia resulted in only a single blue whale sighting between 1998 and 2018 -- but more recent surveys suggest blue whales are making a comeback.A 2020 survey in February resulted in 58 blue whale sightings, and numerous acoustic detections.Lead author Susannah Calderan of the Scottish Association for Marine Science (SAMS), Oban said: "The continued absence of blue whales at South Georgia has been seen as an iconic example of a population that was locally exploited beyond the point where it could recover."But over the past few years we've been working at South Georgia, we have become quite optimistic about the numbers of blue whales seen and heard around the island, which hadn't been happening until very recently. This year was particularly exciting, with more blue whale sightings than we ever could have hoped for."As well as looking for whales, the researchers used listening devices, which can detect the loud, low frequency calls of whales over long distances and can also work in rough weather. The team also had records of whale sightings reported to the South Georgia Museum by mariners and tourist ship passengers, and photographs of blue whales, which enable individual animals to be identified.In total, 41 blue whales have been photo-identified from South Georgia between 2011 and 2020, although none of these matched the 517 whales in the current Antarctic blue whale photographic catalogue.Susannah Calderan added: "We don't quite know why it has taken the blue whales so long to come back. It may be that so many of them were killed at South Georgia that there was a loss of cultural memory in the population that the area was a foraging ground, and that it is only now being rediscovered."There are limited opportunities for dedicated whale surveys in the region, known for its harsh weather and inaccessibility but such surveys are crucial to the future management of South Georgia's seas.Co-author and whale ecologist Dr Jennifer Jackson of British Antarctic Survey, who led the 2020 whale expedition, said: "This is an exciting discovery and a really positive step forward for conservation of the Antarctic blue whale."With South Georgia waters designated as a Marine Protected Area by the Government of South Georgia and the South Sandwich Islands, we hope that these increased numbers of blue whales are a sign of things to come and that our research can continue to contribute to effective management of the area."The team's analysis was funded by South Georgia Heritage Trust and Friends of South Georgia Island, who also funded the collection of some of the data used. Acoustic and sightings data come from expeditions led by British Antarctic Survey, with funding from the Darwin Initiative and EU BEST; from the Swiss Polar Institute Antarctic Circumnavigation Expedition (funded by the ACE Foundation, Ferring Pharmaceuticals and the Australian Antarctic Division), and Government of South Georgia and South Sandwich Islands.This international collaboration includes scientists from the SAMS, BAS, Australian Antarctic Division, US NOAA, International Fund for Animal Welfare, Government of South Georgia and South Sandwich Islands, South Georgia Heritage Trust, University of Washington, Texas A&M University at Galveston, Woods Hole Oceanographic Institution.South Georgia blue whales five decades after the end of whaling by Susannah V. Calderan, Andy Black, Trevor A. Branch, Martin A. Collins, Natalie Kelly, Russell Leaper, Sarah Lurcock, Brian S. Miller, Michael Moore, Paula A. Olson, Ana Å irovi?, Andrew G. Wood, Jennifer A. Jackson is published in the journal Video: * Antarctic blue whales are currently classified as Critically Endangered under the IUCN Red List 
A McGill University-led team of biologists found, in an article published today in (Populations are groups of individuals of the same species living in a particular area, and therefore decreases in population size will precede loss of species.)It all comes down to math, modeling and different approaches to calculating averages.It has typically been estimated that vertebrate populations have declined on average by more than 50% since 1970, based on historical wildlife monitoring data. "However, given previous mathematical methods used to model vertebrate populations, this estimate could arise from two very different scenarios: widespread systematic declines, or a few extreme declines," explains Brian Leung a McGill ecologist, the UNESCO Chair in Dialogues for Sustainability, and the senior author on the study. In this paper the researchers approached the question differently.Using a dataset of over 14,000 vertebrate populations from around the globe collated in the Living Planet Database, the researchers identified about 1% of vertebrate populations which have suffered extreme population declines since 1970 (such as reptiles in tropical areas of North, Central and South America, and birds in the Indo-Pacific region). When this extreme 1% was accounted for, the researchers found the remaining vertebrate populations were neither generally increasing nor decreasing, when grouped all together."The variation in this global aggregate is also important. Some populations really are in trouble and regions such as the Indo-Pacific are showing widespread systematic declines. However, the image of a global 'biodiversity desert' is not supported by the evidence." says Leung. "This is good, as it would be very discouraging if all of our conservation efforts over the last five decades had little effect.""We were surprised by how strong the effect of these extreme populations was in driving the previous estimate of average global decline," adds co-author Anna Hargreaves, a professor in the Biology Department at McGill. "Our results identify regions that need urgent action to ameliorate widespread biodiversity declines, but also reason to hope that our actions can make a difference."
The two ships, a German U-boat and a Nicaraguan freighterJohnson, who grew up spending summers on a small Connecticut island only accessible by boat, jumped at the opportunity to join the research team analyzing the data gathered during the 2016 joint mission, even though she was not able to participate in the mission herself. The expedition team -- led by the paper's other coauthors -- had fitted the manned submersibles with advanced video and laser scanning equipment, which elicited high-definition three-dimensional imagery requiring extensive processing and analyzing. The project lent itself well to Johnson's long-standing interest in the underwater world, and she, like the rest of the team, was surprised by the extent of fish life thriving on the wrecks.According to Avery Paxton, Ph.D., a co-author on the study and a research associate at the NOAA National Centers for Coastal Ocean Science (NCCOS) in Beaufort, N.C., the findings raise questions about how fish find these remote sites in the first place. "Since the shipwrecks are such small islands of habitat on the sandy seafloor, it was surprising to see so many large-bodied groupers, like snowy and Warsaw grouper, occupying the shipwrecks," Paxton said. "This phenomenon warrants further study to determine how common this may be in other deep habitats."The researchers used lasers to acquire 3D snapshots of fish to a millimeter level of precision. For instance, the detailed photos allowed the team to measure the size of a grouper hovering beside the rivet of the U-boat's hull or to document the position of a wreckfish beside the barrel of the deck gun.For fish community ecologists, these kinds of details are essential. They can explain why fish populations decide to call a shipwreck home rather than a rocky reef, for example, and whether the thousands of shipwrecks and other submerged human-made structures scattered on the ocean floor could serve as a significant source of fish habitat in the future."Seeing so many large predators on such a relatively small habitat begs the question of how and whether they are feeding on these sites," said Chris Taylor, Ph.D., a research ecologist at NCCOS and a co-author of the study. "We know some related species aggregate in very large numbers to spawn, and some species like Goliath grouper tend to aggregate on artificial habitats. But we don't think that's happening here."The success of the joint archaeological-ecological mission has opened the door to additional collaborative ventures, which could potentially be carried out by unmanned underwater vehicles in the future.
Cymothoids are a family of isopods (a type of crustacean) that are ectoparasites of fish. Some species in this family are also known as tongue-biter or tongue-eating louse (e.g., Assistant Professor Ryota Kawanishi and Dr. Shinpei Ohashi from Hokkaido University have reported the discovery of an extremely rare species of cymothoid, Cymothoids are a diverse family of more than 300 species of parasites, and parasitize a wide variety of fish, from freshwater to the deep sea. A recent study into the genetics of the family has shown that it is highly likely that they evolved in the deep sea and diversified. A number of deep sea cymothoids, however, are poorly studied, primarily due to the difficulty of deep sea sampling.In the current study, the scientists discovered the specimen of This discovery is important as it shows the distribution of This study indicates that there is much that remains to be investigated when it comes to deep sea cymothoids. The scientists also propose using existing specimens of fish in museums across the world to reveal the distribution of cymothoids; from a broader perspective, this work suggests the hidden value of museum natural history collections in studying parasites.
The study makes use of data from tagging programs, in which researchers tag fish and release them into the wild. When those fish are caught, and the tag information is returned to the researchers, it can give scientists information that informs fishery policies."Fisheries researchers who work in tagging programs have long noticed that certain fish seem to get caught repeatedly, and we set out to determine the implications of this phenomenon," says Jeff Buckel, co-author of the study and a professor of applied ecology at North Carolina State University.To that end, researchers examined decades' worth of Atlantic coast tagging datasets on four fish species: black sea bass (Centropristis striata), gray triggerfish (Balistes capriscus), red grouper (Epinephelus morio), and Warsaw grouper (Hyporthodus nigritus). Using a computational model, the researchers determined that -- for the black sea bass and both types of grouper -- survival was significantly higher after the second, third, and fourth release as compared to the first release."Think of it this way," says Brendan Runde, first author of the study and a Ph.D. student at NC State. "Let's say you tagged 1,000 fish and recaptured 100 of them for a first time. After re-releasing those 100 fish, you would only expect to recapture 10 of them a second time. But that's not what we're seeing. We're seeing much higher numbers of fish getting recaptured after the second time."Our hypothesis is that this increase in catch rate stems from selection for robust individuals," Runde says.In other words, because some fish don't survive the first release, and you can't catch a dead fish, the fish that were robust enough to survive their first encounter were more likely to survive following catch-and-release events.The finding could have a significant impact on stock assessments, which inform fishery policies."One might assume that every catch and release in a recreational fishery is a unique fish," Buckel says. "So that if 5 million black sea bass were caught and released in a given year, that would mean there were at least 5 million black sea bass in a fishery. For these three species of fish and likely many others, that's just not true. At least some of those 5 million catches were the same fish getting caught over and over again.""Reliable estimates of how many unique fish are released are critical to accurately assessing the health of the population," says Kyle Shertzer, a co-author of the study and stock assessment scientist at NOAA Fisheries."On the positive side, the study also suggests that for many species fish mortality from being released appears lower than we thought," Buckel says. "For those species, if a fish survives its first release, it has an even better chance of surviving subsequent releases.""We think that the issues raised by our findings are likely relevant for many marine fish stock assessments that rely on catch-and-release data -- though this will vary based on the species and the details of how each stock assessment is performed," Runde says.The work was done with support from NOAA, under grants NA14NMF4540061, NA09NMF4720265 and NA09NMF4540140; and from North Carolina Sea Grant Fishery Resource Grant projects 07-FEG-01 and 11-FEG-04.
The Henderson Sandpiper, a small wading bird that has been extinct for centuries, is described in an article in the The newly-described bird is formally named Prosobonia sauli after Cook Islands-based ornithologist and conservationist Edward K Saul.A team of researchers from New Zealand, Australia, Denmark, Switzerland, the Netherlands and China, led by Canterbury Museum Research Curator Natural History Dr Vanesa De Pietri, described the Henderson Sandpiper from 61 fossilised bones cared for by the Natural History Museum at Tring in England.Canterbury Museum Visiting Researcher Dr Graham Wragg collected the bones from caves and overhangs on Henderson Island in 1991 and 1992 during the Sir Peter Scott Commemorative Expedition to the Pitcairn Islands.Prosobonia sauli is the fifth known species of Polynesian sandpiper. All but one of the species, the endangered Tuamotu Sandpiper (Prosobonia parvirostris), are extinct."We think Prosobonia sauli probably went extinct soon after humans arrived on Henderson Island, which archaeologists estimate happened no earlier than the eleventh century," says Dr De Pietri."It's possible these humans brought with them the Polynesian rat, which Polynesian sandpiper populations are very vulnerable to."DNA of the living Tuamotu Sandpiper and the extinct Tahiti Sandpiper (Prosobonia leucoptera), which is known only from a skin in the Naturalis Biodiversity Center in the Netherlands, was used to determine how Polynesian sandpipers are related to other wading birds."We found that Polynesian sandpipers are early-diverging members of a group that includes calidrine sandpipers and turnstones. They are unlike other sandpipers in that they are restricted to islands of the Pacific and do not migrate," says Dr De Pietri.Comparisons with the other two extinct Polynesian sandpiper species, the Kiritimati Sandpiper (Prosobonia cancellata) and the Mo'orea Sandpiper (Prosobonia ellisi), are complicated. These birds are known only from illustrations primarily by William Wade Ellis, an artist and Surgeon's Mate on Captain James Cook's third expedition, who probably saw the birds alive in the 1770s.Compared to the Tuamotu Sandpiper, its geographically closest cousin, the Henderson Sandpiper had longer legs and a wider, straighter bill, indicating how it foraged for food. It probably adapted to the habitats available on Henderson Island, which are different to those on other islands where Polynesian sandpipers were found.Henderson Island is the largest island in the Pitcairn Group, in the middle of the South Pacific Ocean. It has been uninhabited since around the fifteenth century and was designated a World Heritage Site by the United Nations in 1988.Dr Paul Scofield, Canterbury Museum Senior Curator Natural History and one of the study's co-authors, says Henderson Island is home to a number of unique species, a handful of which are landbirds like the Henderson Sandpiper."The island is really quite remarkable because every landbird species that lives there, or that we know used to live there, is not found anywhere else," he says.Dr De Pietri says the study shows the need to protect the one remaining Polynesian sandpiper species, the Tuamotu Sandpiper."We know that just a few centuries ago there were at least five Polynesian sandpiper species scattered around the Pacific. Now there's only one, and its numbers are declining, so we need to ensure we look after the remaining populations."This research was supported by a grant from the Marsden Fund Council, managed by the Royal Society Te Ap?rangi, as well as the R S Allan Fund managed by Canterbury Museum.
The study found that mangrove forests, their large biodiversity and the coastal protection they provide are under pressure from three distinct threats -- sea-level rise, lack of mud and squeezed habitats.The research, conducted by an international team of experts including Dr Barend van Maanen from the University of Exeter, identifies not only how these coastal forests get pushed against their shores, but also what causes the loss of their diversity.It shows the negative effects of river dams that decrease the supply of mud that could otherwise raise mangrove soils, while buildings and seawalls largely occupy the space that mangroves require for survival.The study is published in Coastal mangrove forests are valuable, highly biodiverse ecosystems that protect coastal communities against storms.Mangroves withstand flooding by tides and capture mud to raise their soils. But as the mangrove trees cannot survive if they are under water for too long, the combination of sea-level rise and decreasing mud supply from rivers poses a serious threat.New computer simulations show how coastal forests retreat landward under sea-level rise, especially in coastal areas where mud in the water is declining. The simulations include interactions among tides, mud transport and, for the first time, multiple mangrove species.Dr van Maanen, senior lecturer at the University of Exeter and supervisor of the project, said: "Both mangrove coverage loss and diversity loss go hand in hand when that landward retreat is limited by expanding cities, agriculture or flood protection works."The model also shows that mangrove trees with dense roots trap mud more effectively and can stop it from reaching forest areas further inland.Danghan Xie, PhD researcher at Utrecht University and lead author of the study said: "This makes the more landward-located trees flood for longer periods of time, an effect that is intensified by sea-level rise."Increasing landward flooding then seriously reduces biodiversity."Human land use prevents the mangroves 'escaping' flooding by migrating inland, narrowing the mangrove zone and further endangering biodiversity."A narrow mangrove zone is much less effective in protecting the coast against storms, or in the worst case loses its protective properties altogether.Co-author Dr Christian Schwarz, environmental scientist at the University of Delaware, added: "The loss of mangrove species will have dramatic ecological and economic implications, but fortunately there are ways to help safeguarding these ecosystems."It is essential to secure or restore mud delivery to coasts to counter negative effects of sea-level rise."For coasts where mud supply remains limited, removal of barriers that obstruct inland migration is of utmost importance to avoid loss of mangrove forests and biodiversity."The publication Mangrove diversity loss under sea-level rise triggered by bio-morphodynamic feedbacks and anthropogenic pressures is published in 
A new international study published in BMJ Global Health reveals dangers including falls, traffic accidents, animal attacks, and fights, which can result in broken bones, spinal injuries, lacerations, and other physical injuries.And women are most likely to sustain such injuries -- highlighting the social the social and gender inequities of a hidden global health challenge.Dr Jo-Anne Geere, from UEA's School of Health Sciences, said: "Millions of people don't have the luxury of clean drinking water at their home, and they face many dangers before the water even touches their lips."Global research on water has largely focused on scarcity and health issues related to what is in the water, but the burden and risks of how water is retrieved and carried has been overlooked until now."We wanted to better understand the true burden of water insecurity."The new study was led by Northwestern University in the US, in collaboration with UEA, the University of Miamii and the Household Water Insecurity Experiences Research Coordination Network (HWISE RCN).The research team used a large global dataset to understand what factors might predict water-fetching injuries. The work draws on a survey of 6,291 randomly selected households across 24 sites in 21 low- and middle-income countries in Asia, Africa, Latin America, and the Caribbean.They found that 13 per cent of the respondents reported some sort of injury while collecting water, and that women were twice as likely to be hurt as men.Dr Sera Young, from Northwestern University, said: "Thirteen percent is a big number, but it is probably an underestimate. It's highly likely that more people would have reported injuries if the survey had more detailed questions.Prof Paul Hunter, from UEA's Norwich Medical School, said: "This reinforces how the burden of water scarcity disproportionately falls on women, on rural populations, and on those who do not have water sources close to home."It highlights the importance of safe interventions that prioritise personal physical safety alongside traditional global indicators of water, sanitation, and hygiene."The researchers say that keeping track of such safety measures -- in addition to the usual measures of water quality and access -- could help better assess progress towards the United Nations' Sustainable Development Goal 6.1, which sets out "to achieve universal and equitable access to safe and affordable drinking water for all" by 2030.Dr Vidya Venkataramanan, also from Northwestern University, said: "It seems likely that water-fetching can contribute considerably to the global Water, Sanitation and Hygiene (WaSH) burden, but it usually goes unmeasured because we typically think about access and water quality. It is, therefore, a greatly underappreciated, nearly invisible public health challenge."It's really important that data on water-fetching injuries are systematically collected so that we can know the true burden of water insecurity. Currently, all of the broken bones, spinal injuries, lacerations and other physical injuries are not accounted for in calculations about the burden of water insecurity."
Australian researchers observed the starfish emerging from their shelters in the afternoons so they could feed on coral during the night before returning home at dawn."The crown-of-thorns starfish often partied all night, slept-in and only those with a well-stocked larder found their way home -- so it's very much a teenager model of behaviour," said lead author Dr Scott Ling from the Institute for Marine and Antarctic Studies at the University of Tasmania."Their preferred prey is Acropora corals," said co-author Professor Morgan Pratchett from the ARC Centre of Excellence for Coral Reef Studies at James Cook University (CoralCoE at JCU). Acropora is an important coral species -- for the past two million years they have been the building blocks of reefs across the world."When populations of Acropora dropped, the starfish didn't return home," Prof Pratchett said. "Their behaviour is directly linked to the local abundance of Acropora."The results of the study show healthy reefs with a high cover of these corals may encourage crown-of-thorns aggregations and outbreaks. The outbreaks cause extensive, widespread and sustained coral loss throughout the Indo-Pacific region.Similar examples of predator infestations driving environmental devastation include sea urchins overgrazing on kelp forests and coral reef fishes munching through patches of seagrass.The researchers used in-situ time-lapse photography to track the movements of 58 starfish in the northern and southern Great Barrier Reef during an outbreak in 2015. In the absence of their preferred Acropora coral prey, starfish were typically homeless and instead roamed up to 20 metres per day."Unlike sea urchins that can switch diet once they overgraze kelp forests, results of the time-lapse monitoring indicate that the starfish will consume available Acropora and ultimately eat themselves out of house and home before dispersing in search of new feeding grounds," Dr Ling said.Previous outbreaks on the Great Barrier Reef were recorded in 1962, 1979, 1993 and 2009. Though mass-coral bleaching due to global warming is now the greatest threat to coral reefs worldwide, the combined impact of mass-bleaching and crown-of-thorns outbreaks is potentially catastrophic for coral reefs."By better understanding the behaviour of these starfish we can help prevent and control their outbreaks, which will help alleviate the pressures on coral reefs," Prof Pratchett said.
It's believed this magma 'conveyor belt,' created by shifts in the seabed, continuously made space available for the molten rock to flow for millions of years, beginning around 120 million years ago.Research lead Qiang Jiang, a PhD candidate from Curtin's School of Earth and Planetary Sciences, said the studied volcanoes were in the Kerguelen Plateau, located in the Indian Ocean, about 3,000 kilometres south west of Fremantle, Western Australia."Extremely large accumulations of volcanic rocks -- known as large volcanic provinces -- are very interesting to scientists due to their links with mass extinctions, rapid climatic disturbances, and ore deposit formation," Mr Jiang said."The Kerguelen Plateau is gigantic, almost the size of Western Australia. Now imagine this area of land covered by lava, several kilometres thick, erupting at a rate of about 0.2 millimetres every year."0.2 millimetres of lava a year may not sound like much but, over an area the size of Western Australia, that's equivalent to filling up 184,000 Olympic-size swimming pools to the brim with lava every single year. Over the total eruptive duration, that's equivalent to 5.5 trillion lava-filled swimming pools!"This volume of activity continued for 30 million years, making the Kerguelen Plateau home to the longest continuously erupting supervolcanoes on Earth. The eruption rates then dropped drastically some 90 million years ago, for reasons that are not yet fully understood."From then on, there was a slow but steady outpouring of lava that continued right to this day, including the 2016 eruptions associated with the Big Ben volcano on Heard Island, Australia's only active volcano."Co-researcher Dr Hugo Olierook, also from Curtin's School of Earth and Planetary Sciences, explained such a long eruption duration requires very peculiar geological conditions."After the partial breakup of the supercontinent Gondwana, into the pieces now known as Australia, India and Antarctica, the Kerguelen Plateau began forming on top of a mushroom-shaped mantle upwelling, called a mantle plume, as well as along deep sea, mid-oceanic mantle ridges," Dr Olierook said."The volcanism lasted for so long because magmas caused by the mantle plume were continuously flowing out through the mid-oceanic ridges, which successively acted as a channel, or a 'magma conveyor belt' for more than 30 million years."Other volcanoes would stop erupting because, when temperatures cooled, the channels became clogged by 'frozen' magmas."For the Kerguelen Plateau, the mantle plume acts as a Bunsen burner that kept allowing the mantle to melt, resulting in an extraordinarily long period of eruption activity."Research co-author, Professor Fred Jourdan, Director of the Western Australia Argon Isotope Facility at Curtin University, said the team used an argon-argon dating technique to date the lava flows, by analysing a range of black basaltic rocks taken from the bottom of the sea floor."Finding this long, continuous eruption activity is important because it helps us to understand what factors can control the start and end of volcanic activity," Professor Jourdan said."This has implications for how we understand magmatism on Earth, and on other planets as well."The Curtin-led research was a collaboration with Uppsala University in Sweden and the University of Tasmania.
The researchers say that counting them as four separate species will aid in their conservation because it will make it easier to monitor any decline in numbers.Gentoo penguins, with the Latin name The researchers suggest these two sub species should be raised to species level and two new species created, which they have named P. poncetii after the Australian seabird conservationist Sally Poncet, and P. taeniata in recognition of a former proposal for this name dating to the 1920s.Their study, published in the journal They used genome data to create an evolutionary tree to understand the relationship between the different populations. When they combined these data with measurements of museum specimens from each of the populations, they found clear morphological (physical) and genetic differences between the four populations.Dr Jane Younger, Prize Fellow from the Milner Centre for Evolution at the University of Bath, led the study. She said: "For the first time, we've shown that these penguins are not only genetically distinct, but that they are also physically different too."Gentoos tend to stick close to their home colonies, and over hundreds of thousands of years have become geographically isolated from each other to the point where they don't interbreed with each other, even though they could easily swim the distance that separates them."The four species we propose live in quite different latitudes -- for example PhD student Josh Tyler said: "They look very similar to the untrained eye, but when we measured their skeletons we found statistical differences in the lengths of their bones and the sizes and shape of their beaks."It's a similar story to giraffes, which were revealed in 2016 to be four genetically distinct species."The scientists say that regarding the four populations as separate species, gives conservationists a better chance of protecting their diversity because if there's a decline in one of them it will change the threat status as defined by the IUCN Red List.Dr Younger said: "Currently gentoo penguins are fairly stable in numbers, however there is some evidence of the northern populations moving further south as the climate gets warmer, so we need to watch them closely."The proposed changes to the classification of gentoos will be reviewed by an international committee of scientists which will assess all the evidence in the scientific literature before the new taxonomy is accepted.The study was funded by the American Ornithological Society, Linnean Society, American Museum of Natural History and the Evolution Education Trust. The research team was a collaboration led by the University of Bath (UK) with scientists from Loyola University Chicago, Cornell University and the University of Minnesota (USA).
The formation of craters by asteroid and comet impact has always been a fundamental process in the solar system, explains Kenkmann. As the planets developed along with their moons, these impacts played an important part in accreting planetary mass, shaping the surfaces of planetary bodies, and later also influencing their development. And larger meteorite impacts eventually affected the development of life on Earth.Today, mapping of what can still be seen of the impact structures on the Earth's surface can be done by satellites in low Earth orbit. From 2010 to 2016, the DLR successfully measured the Earth's surface with the radar satellites of the TanDEM-X mission. The acquired data allowed, for the first time, to derive a worldwide terrain model with a height accuracy of up to one meter. From this global digital elevation model the authors have been able to produce this complete topographic atlas of 600 pages with information about all terrestrial impact craters known to date.
Micah Freedman, a graduate student at the Center for Population Biology at UC Davis, took a deep dive into museum collections to see how migration has shaped the species. Monarchs are native to North America, but have also established non-migrating populations in the Caribbean, Central and South America, and islands in the Pacific and Atlantic oceans. These island-hopping butterflies may have been blown by storms before being lucky enough to reach dry land.Monarchs that established new, non-migrating populations also had those larger wings. But over time, the wings of these colonists got smaller.The shift between longer and shorter wings shows two opposite selection forces at work, Freedman and colleagues wrote in a paper published this week in Alternatively, wing size could be influenced by other environmental factors depending on where butterflies are hatched and grow up. To test this, Freedman raised Monarch butterflies from non-migrating populations in Hawaii, Guam, Australia and Puerto Rico outdoors in Davis, California alongside native migrating Monarchs. The non-migrating butterflies retained their smaller wings, showing that the effect is due to genetics and not the rearing environment."Our findings provide a compelling example of how migration-associated traits may be favored during the early stages of range expansion, and also the rate of reductions in those same traits upon loss of migration," the authors wrote.
MIT researchers think so. They've built a battery-free pinpointing system dubbed Underwater Backscatter Localization (UBL). Rather than emitting its own acoustic signals, UBL reflects modulated signals from its environment. That provides researchers with positioning information, at net-zero energy. Though the technology is still developing, UBL could someday become a key tool for marine conservationists, climate scientists, and the U.S. Navy.These advances are described in a paper being presented this week at the Association for Computing Machinery's Hot Topics in Networks workshop, by members of the Media Lab's Signal Kinetics group. Research Scientist Reza Ghaffarivardavagh led the paper, along with co-authors Sayed Saad Afzal, Osvy Rodriguez, and Fadel Adib, who leads the group and is the Doherty Chair of Ocean Utilization as well as an associate professor in the MIT Media Lab and the MIT Department of Electrical Engineering and Computer Science.It's nearly impossible to escape GPS' grasp on modern life. The technology, which relies on satellite-transmitted radio signals, is used in shipping, navigation, targeted advertising, and more. Since its introduction in the 1970s and '80s, GPS has changed the world. But it hasn't changed the ocean. If you had to hide from GPS, your best bet would be underwater.Because radio waves quickly deteriorate as they move through water, subsea communications often depend on acoustic signals instead. Sound waves travel faster and further underwater than through air, making them an efficient way to send data. But there's a drawback."Sound is power-hungry," says Adib. For tracking devices that produce acoustic signals, "their batteries can drain very quickly." That makes it hard to precisely track objects or animals for a long time-span -- changing a battery is no simple task when it's attached to a migrating whale. So, the team sought a battery-free way to use sound.Adib's group turned to a unique resource they'd previously used for low-power acoustic signaling: piezoelectric materials. These materials generate their own electric charge in response to mechanical stress, like getting pinged by vibrating soundwaves. Piezoelectric sensors can then use that charge to selectively reflect some soundwaves back into their environment. A receiver translates that sequence of reflections, called backscatter, into a pattern of 1s (for soundwaves reflected) and 0s (for soundwaves not reflected). The resulting binary code can carry information about ocean temperature or salinity.In principle, the same technology could provide location information. An observation unit could emit a soundwave, then clock how long it takes that soundwave to reflect off the piezoelectric sensor and return to the observation unit. The elapsed time could be used to calculate the distance between the observer and the piezoelectric sensor. But in practice, timing such backscatter is complicated, because the ocean can be an echo chamber.The sound waves don't just travel directly between the observation unit and sensor. They also careen between the surface and seabed, returning to the unit at different times. "You start running into all of these reflections," says Adib. "That makes it complicated to compute the location." Accounting for reflections is an even greater challenge in shallow water -- the short distance between seabed and surface means the confounding rebound signals are stronger.The researchers overcame the reflection issue with "frequency hopping." Rather than sending acoustic signals at a single frequency, the observation unit sends a sequence of signals across a range of frequencies. Each frequency has a different wavelength, so the reflected sound waves return to the observation unit at different phases. By combining information about timing and phase, the observer can pinpoint the distance to the tracking device. Frequency hopping was successful in the researchers' deep-water simulations, but they needed an additional safeguard to cut through the reverberating noise of shallow water.Where echoes run rampant between the surface and seabed, the researchers had to slow the flow of information. They reduced the bitrate, essentially waiting longer between each signal sent out by the observation unit. That allowed the echoes of each bit to die down before potentially interfering with the next bit. Whereas a bitrate of 2,000 bits/second sufficed in simulations of deep water, the researchers had to dial it down to 100 bits/second in shallow water to obtain a clear signal reflection from the tracker. But a slow bitrate didn't solve everything.To track moving objects, the researchers actually had to boost the bitrate. One thousand bits/second was too slow to pinpoint a simulated object moving through deep water at 30 centimeters/second. "By the time you get enough information to localize the object, it has already moved from its position," explains Afzal. At a speedy 10,000 bits/second, they were able to track the object through deep water.Adib's team is working to improve the UBL technology, in part by solving challenges like the conflict between low bitrate required in shallow water and the high bitrate needed to track movement. They're working out the kinks through tests in the Charles River. "We did most of the experiments last winter," says Rodriguez. That included some days with ice on the river. "It was not very pleasant."Conditions aside, the tests provided a proof-of-concept in a challenging shallow-water environment. UBL estimated the distance between a transmitter and backscatter node at various distances up to nearly half a meter. The team is working to increase UBL's range in the field, and they hope to test the system with their collaborators at the Wood Hole Oceanographic Institution on Cape Cod.They hope UBL can help fuel a boom in ocean exploration. Ghaffarivardavagh notes that scientists have better maps of the moon's surface than of the ocean floor. "Why can't we send out unmanned underwater vehicles on a mission to explore the ocean? The answer is: We will lose them," he says.UBL could one day help autonomous vehicles stay found underwater, without spending precious battery power. The technology could also help subsea robots work more precisely, and provide information about climate change impacts in the ocean. "There are so many applications," says Adib. "We're hoping to understand the ocean at scale. It's a long-term vision, but that's what we're working toward and what we're excited about."This work was supported, in part, by the Office of Naval Research.
Bio-logging is a technique involving the mounting of small lightweight video cameras and/or other data-gathering devices onto the bodies of wild animals. The systems then allow researchers to observe various aspects of that animal's life, such as its behaviors and social interactions, with minimal disturbance.However, the considerable battery life required for these high-cost bio-logging systems has proven limiting so far. "Since bio-loggers attached to small animals have to be small and lightweight, they have short runtimes and it was therefore difficult to record interesting infrequent behaviors," explains study corresponding author Takuya Maekawa."We have developed a new AI-equipped bio-logging device that allows us to automatically detect and record the specific target behaviors of interest based on data from low-cost sensors such as accelerometers and geographic positioning systems (GPS)." The low-cost sensors then limit the use of the high-cost sensors, such as video cameras, to just the periods of time when they are most likely to capture the specific target behavior.The use of these systems in combination with machine learning techniques can focus data collection with the expensive sensors directly onto interesting but infrequent behaviors, greatly increasing the likelihood that those behaviors will be detected.The new AI-assisted video camera system was tested on black-tailed gulls and streaked shearwaters in their natural environment on islands off the coast of Japan. "The new method improved the detection of foraging behaviors in the black-tailed gulls 15-fold compared with the random sampling method," says lead author Joseph Korpela. "In the streaked shearwaters, we applied a GPS-based AI-equipped system to detect specific local flight activities of these birds. The GPS-based system had a precision of 0.59 -- far higher than the 0.07 of a periodic sampling method involving switching the camera on every 30 minutes."There are many potential applications for the use of AI-equipped bio-loggers in the future, not least the further development of the systems themselves. "These systems have a huge range of possible applications including detection of poaching activity using anti-poaching tags," says Maekawa. "We also anticipate that this work will be used to reveal the interactions between human society and wild animals that transmit epidemics such as coronavirus."
In forests, the most common species can be essential to ecosystem structure and function, which crumble with the decline of these pivotal trees, known collectively as foundation species.In an effort to identify forest foundation species and elevate their conservation status before they disappear, a unique research collaboration between Chinese and American scientists has synthesized long-term biodiversity data from 12 immense forest study plots spanning 1,500 miles, from China's far north to its southern tropics.Their results, published today in the journal The study comes on the heels of the latest "Red List" published by Botanic Gardens Conservation International, which showed that 36 out of the 158 maples species worldwide -- nearly a quarter of all maples -- are at high risk of extinction in the near future in the wild. Fourteen of those high-risk species exist only in China."Foundation species are the species upon which ecosystems are built and supported, just like the foundation of your house," explains Aaron Ellison, Senior Research Fellow at the Harvard Forest and a co-author of the study. "But they can be so common that they hide in plain sight, overlooked because they lack the cachet and appeal of rarities."The study was led by Xiujuan Qiao, an Associate Professor at the Wuhan Botanical Garden of the Chinese Academy of Sciences, who spent all of 2019 in residence at the Harvard Forest facilitating this global collaboration. She adds, "We should pay more attention to foundation species, identifying and protecting them before their inevitable decline."
When a fish dies in the ocean it sinks to the depths, sequestrating all the carbon it contains with it. This is a form of 'blue carbon' -- carbon captured and stored by the world's ocean and coastal ecosystems."But when a fish is caught, the carbon it contains is partly emitted into the atmosphere as COMr Mariani led a world-first study showing how ocean fisheries have released at least 730 million metric tons of COCo-author Professor David Mouillot from the ARC Centre of Excellence for Coral Reef Studies at James Cook University (CoralCoE at JCU) and the University of Montpellier said the carbon footprint of fisheries is 25 percent higher than previous industry estimates."Fishing boats produce greenhouse gases by consuming fuel," Prof Mouillot said. "And now we know that extracting fish releases additional COLarge fish such as tuna, sharks, mackerel and swordfish are about 10 to 15 percent carbon."When these fish die, they sink rapidly," Prof Mouillot said. "As a result, most of the carbon they contain is sequestered at the bottom of the sea for thousands or even millions of years. They are therefore carbon sinks -- the size of which has never been estimated before."He says this natural phenomenon -- a blue carbon pump -- has been increasingly and greatly disrupted by industrial fishing.The authors also say the phenomenon has not only been overlooked until now, but it happens in areas where fishing is not economically profitable: in the Central Pacific, South Atlantic, and North Indian Oceans."Fishing boats sometimes go to very remote areas -- with enormous fuel consumption -- even though the fish caught in these areas are not profitable and fishing is only viable thanks to subsidies," Mr Mariani said.For the authors of the study, the new data strongly supports more reasoned fishing."The annihilation of the blue carbon pump represented by large fish suggests new protection and management measures must be put in place, so that more large fish can remain a carbon sink and no longer become an additional CO"We need to fish better," Prof Mouillot said.
"Marine protected areas are tools commonly used to conserve marine biodiversity by closing parts of the ocean to fishing," said Reniel Cabral, an assistant researcher at UC Santa Barbara's Environmental Market Solutions Lab. "This creates a potential dilemma when closures cause fishers to lose access to fishing grounds."A new study indicates that this need not be the case. The paper outlines where the benefits of fishing restrictions could enable a fishery to become more productive, even with the closures. The research, published in the The benefits of a well-considered marine protected area (MPA) can bolster the productivity of surrounding fisheries, especially when those fisheries are overexploited. The refuge enables populations to rebuild and then spill over into surrounding waters. Protecting an area from fishing also enables resident fish to grow older and larger, and scientists have found that these fish are proportionately more fertile than their smaller counterparts.What's more, fishing is not well regulated in many regions. The activity can be decentralized and target many different species using a variety of methods. Managing the industry can be nearly impossible, especially for agencies that are underfunded and underpowered. In this context, designating an MPA is relatively simple, especially compared to other management strategies."Past studies have shown that MPAs can improve catch when designed well and under the right fishery conditions," said Cabral, the study's lead author. "We asked how you could design a network of marine protected areas to improve fishery productivity, and what the results would be."Cabral and his colleagues at UC Santa Barbara, the Hawai?i Institute of Marine Biology, and the National Geographic Society began constructing a model of global fisheries that would account for both biologic and economic factors. They leveraged a database of 4,000 fishery stocks, their ecological characteristics, management status and global distributions in combination with a wealth of information on fisheries catch and fisher behavior in response to marine protected areas.The resulting bio-economic model forecasts how fish populations would respond to the creation of new MPAs based on a variety of factors such as the location and status of fisheries and species mobility and growth rates. This enabled the team to project harvest outcomes over a variety of different reserve designs. The researchers could then see where MPAs would be most beneficial."We found that there are a lot of places where you can get food benefits," said coauthor Steve Gaines, dean of UCSB's Bren School of Environmental Science & Management. "So, rather than having this traditional battle between fisheries and conservation, we can now identify the strategic places where we can potentially get both conservation and fishery benefits."Currently, only 2.5% of the ocean is covered by highly protected MPAs. The study found that strategically protecting an additional 5% of the ocean could increase future catch by 20%, or 9 to 12 million metric tons of fish.The most promising locations tended to cluster around the South Pacific, southeast Africa and the temperate coasts of North and South America. These are regions where well-placed MPAs have the greatest potential for increasing local catch, whether due to the ecology of the stocks, poor fishery regulation or a combination of the two.The results offer a rubric for determining what the best strategies will be and what regions will yield the best return. It's a gestalt look at the interplay between marine protected areas and fisheries that can be further developed in the future.The projections also come only from stocks that scientists have data on. There are plenty of species that don't have enough data for analysis, and they're likely to be in far worse shape than those we do have a tab on, Gaines explained. For these reasons, the team believes the benefits to fisheries would likely exceed the predictions in their paper.The model's strength lies in its ability to highlight areas where a marine reserve could have high potential benefits for fishing. "Our model can identify areas where MPAs would really improve fishery productivity," said Cabral, "but designing those at the local level will need to be site specific."In addition to being a relatively simple management tool, marine protected areas can provide a great starting point for getting communities involved in fishery management and encouraging ocean stewardship. "MPAs can encourage community participation, which increases the attention they pay to improving their management for fisheries that are not protected," Cabral said.Of course, to have this effect, governments need to actively include communities in the planning process. When done well, these stakeholders become active participants in shaping the future of their own resources.The Environmental Market Solutions Lab is currently applying this model at the country level as well. The results will establish a framework for individual nations to understand the potential benefits of their own marine protected areas.The team has also taken an active role in applying its research to real-world MPAs. "We are working with multiple countries around the world to support their efforts to place hundreds of thousands of square kilometers of ocean area under protection," said Darcy Bradley, one of the paper's coauthors and the co-director of the lab's Ocean and Fisheries Program.The group helps with spatial prioritization -- leveraging studies like this one -- as part of the planning process. They also collaborate with national agencies to design fishery monitoring programs and perform fishery assessments. "In each of these engagements, our goal is to take the best available MPA science and translate it into practical outputs to support thriving ocean ecosystems and economies," she said.
The number of green sea turtle nests on central and southern Brevard County, Florida beaches monitored by University of Central biologists were way up during a year they should have been down based on nearly 40 years of historical data."Usually, green turtles alternate between high years and low years, but this year they defied expectations," says Chris Long, a doctoral candidate and research assistant with UCF's Marine Turtle Research Group. "Green turtles had the fifth highest year on the Archie Carr Refuge that we've recorded since 1982. There is no evidence pointing to high nesting as a result of fewer people on the beaches or anything pandemic-related like that. It's difficult to know why nesting differed from expectation."East-Central Florida's coastline (from Brevard to Indian River County) is among the most important nesting areas in the world for loggerhead sea turtles, and it also hosts about one-third of all green turtle nests in the state. The region is at the northern end of a "hotspot" for leatherbacks, which nest on the local beaches at a smaller scale as well. All sea turtles in the U.S. are protected under the Endangered Species Act.UCF has run a sea turtle monitoring and research program on the beaches of the Archie Carr National Wildlife Refuge (ACNWR) in southern Brevard County for more than 35 years. UCF findings about sea turtle abundance and behavior are among the reasons the refuge was created in 1991. The UCF Marine Turtle Research Group focuses on long-term nesting beach and coastal juvenile sea turtle research in Brevard and Indian River counties locally. The group also studies the oceanic "lost years" tracking turtles in the Gulf of Mexico, North and South Atlantic, and Indian Oceans.All sea turtles saw an increase in nests along the coastline this year compared to recent years. Here's a look at the numbers recorded by the UCF Marine Turtle Research Group's covering the 13 northernmost miles of the Archie Carr National Wildlife Refuge. Final counts won't be tallied until Oct. 31:Green turtle nests:Loggerhead nests:Leatherback nests:
"The biomes of the region we studied, which includes all the countries south of the Sahara, are divided into two fairly distinct types: savannah at about 70 per cent and tropical forest for the rest," said Aleman, co-author of a major new study on African biomes.Involving some 30 researchers, several from Africa itself, the study is published this week in the "When we analyze the assemblage of tree species in each biome, we find that each is extremely different," Aleman said. "Moreover, if we look closely at the history of these biomes, we realize that they have been fairly stable for 2,000 years. Reforestation with tropical forest species in areas that are more associated with savannahs would therefore be a mistake."Without wanting to point the finger at countries that might make this mistake, Aleman pointed out that reforestation plans include the planting of billions of trees. Even the intention is good, countries must try to avoid artificially creating tropical forests where savannahs have dominated for several millennia, she said.Moreover, the choice of species selected is decisive. Acacias are more associated with open environments, for example, whereas celtis trees are specific to forests. In some cases, eucalyptus plantations have proved to be "ecological disasters," according to Aleman.She does her work at UdeM's paleoecology laboratory, whose mission under director Olivier Barquez is to retrace the past of biomes. Aleman's main collaborator, Adeline Fayolle, a professor at the University of Liege, in Belgium, assembled the floristic data (lists of tree species) for the new study."To do this, we conducted a kind of old-fashioned data mining, in the sense that we analyzed a large amount of existing data, published and sometimes archived in forgotten documents, buried in dust, as well as data recently acquired in the field, to try to understand the history of the region," said Aleman.The study takes taken equal account floristic, environmental and paleoecological data to better understand the ecological functioning of forests and savannas, helped by analysing 753 sites in both environments. The environmental factors having the greatest impact on these environments are rainfall and its seasonality, as well as temperature, the researchers found.One of the most remarkable phenomena in the savannah is the frequency of disturbances that affect them. Brushwoods can flare up to three times a year in some places, for example. To protect public health, local governments sometimes want to limit these fires. These decisions are legitimate, but can have significant ecological consequences, the co-authors say.That's because, for the most part, large trees are unaffected by the flames, and the ashes regenerate the soil.The impact of human activity can be seen wherever the researchers carried out their research, but mainly in Tanzania, Congo and the Central African Republic. In some cases, some areas are almost devoid of wildlife.As early as 2017, when she published an article in the African edition of the online platform The Conversation, Aleman has been steadily trying to alert public opinion to the threats to African ecosystems. The Conversation.She believes that the situation is not desperate but that governments must be careful in how they intervene so as to not makes things worse. Aleman hopes that the new study will lead to a better understanding of the biological reality of the African continent."This is a rather theoretical contribution,: she said, "but I believe that we can use it to inform reforestation policies."
The reef was first found on Oct. 20, as a team of scientists led by Dr. Robin Beaman from James Cook University was conducting underwater mapping of the northern Great Barrier Reef seafloor. The team then conducted a dive on Oct. 25 using Schmidt Ocean Institute's underwater robot SuBastian to explore the new reef. The dive was live-streamed, with the high-resolution footage viewed for the first time and broadcast on Schmidt Ocean Institute's website and YouTube channel. [Editor's note: see link below.]The base of the blade-like reef is 1.5km-wide, then rises 500m to its shallowest depth of only 40m below the sea surface. This newly discovered detached reef adds to the seven other tall detached reefs in the area, mapped since the late 1800s, including the reef at Raine Island -- the world's most important green sea turtle nesting area."This unexpected discovery affirms that we continue to find unknown structures and new species in our Ocean," said Wendy Schmidt, co-founder of Schmidt Ocean Institute. "The state of our knowledge about what's in the Ocean has long been so limited. Thanks to new technologies that work as our eyes, ears and hands in the deep ocean, we have the capacity to explore like never before. New oceanscapes are opening to us, revealing the ecosystems and diverse life forms that share the planet with us.""We are surprised and elated by what we have found," said Dr. Beaman. "To not only 3D map the reef in detail, but also visually see this discovery with SuBastian is incredible. This has only been made possible by the commitment of Schmidt Ocean Institute to grant ship time to Australia's scientists."The discovery of this new coral reef adds to a year of underwater discoveries by Schmidt Ocean Institute. In April, scientists discovered the longest recorded sea creature -- a 45m siphonophore in Ningaloo Canyon, plus up to 30 new species. In August, scientists discovered five undescribed species of black coral and sponges and recorded Australia's first observation of rare scorpionfish in the Coral Sea and Great Barrier Reef Marine Parks. And the year started with the discovery in February of deep sea coral gardens and graveyards in Bremer Canyon Marine Park."To find a new half-a-kilometer tall reef in the offshore Cape York area of the well-recognized Great Barrier Reef shows how mysterious the world is just beyond our coastline," said Dr. Jyotika Virmani, executive director of Schmidt Ocean Institute. "This powerful combination of mapping data and underwater imagery will be used to understand this new reef and its role within the incredible Great Barrier Reef World Heritage Area."The Northern depths of the Great Barrier Reef voyage will continue until Nov. 17 as part of Schmidt Ocean Institute's broader year-long Australia campaign. The maps created will be available through AusSeabed, a national Australian seabed mapping program, and will also contribute to the Nippon Foundation GEBCO Seabed 2030 Project.
Debris flows are fast-moving slurries of soil, rock, water, and vegetation that are especially perilous because they usually occur without any warning. Some debris flows are powerful enough to cart off everything in their paths, including trees, boulders , vehicles -- and even homes.Two years ago in Montecito, California, 23 people were killed and more than 400 homes damaged by a series of debris flows spawned by intense rain falling on hills scorched by what at the time had been the largest fire in California history.To better understand the origin of these hazards, researchers at the U.S. Geological Survey (USGS) studied slope failure at two sites in Southern California's San Gabriel Mountains. The first site burned in 2016 during the San Gabriel Complex fire, whereas a second, nearby site was charred during the 2014 Colby fire. The findings, presented Wednesday during the annual meeting of The Geological Society of America, indicate there were major differences in slope failure between the first and the third years following incineration. The results will help inform land managers and residents about when and where debris flows and other types of slope failure are more likely to occur."In the first year after each fire, we observed debris flows generated by rainfall runoff," says Francis Rengers, a USGS research geologist who led the study. "But as we continued monitoring, we were surprised to see that a storm with a higher rainfall intensity than the first year's storms, resulted in more than 280 shallow landslides, rather than debris flows, in the third year."In contrast to debris flows, which have fluid-like behavior, landslides glide as cohesive masses along a rupture plane. The researchers, including scientists from the University of Arizona, the Desert Research Institute, the USGS, and the German Research Centre (GFZ) believe this difference is due to changes in how much water can infiltrate into the ground during storms that follow wildfires. Because severe wildfires make soils more water-repellent, Rengers says, rainfall tends to run off burned ground. "If water is not soaking in," he explains, "it's flowing over the surface." By removing ground cover, wildfires also reduce a hillslope's roughness, which helps the slurry pick up speed. Incineration can also allow rainfall on bare soil to create what he calls a "surface seal" that further increases runoff.Because landslides have much shorter runouts than debris flows, they pose different hazards. "The landslides we observed would primarily impact local infrastructure in the forest, such as roads, transmission lines, and culverts," Rengers explains. By contrast, he says, debris flows move sediment much further downstream and therefore pose a hazard beyond the steep, mountainous hillslopes. "Runoff-generated debris flows threaten lives and property, including homes," he says.The results offer a ray of hope that the threat of slope failure has a limited duration: the researchers found that within five years, the density of landslides on burnt slopes in the San Gabriels was nearly equal to the density in unburned regions. This indicates the vegetation in this region recovers within half a decade.Based on these observations, the researchers have developed a new conceptual model of post-wildfire slope failure that has three distinct stages. During the 'no-recovery' phase, increased runoff makes debris flows more prevalent. Within a couple of years, increasing water percolation, combined with the decay of roots from vegetation destroyed in the fire, make the slopes more susceptible to landsliding during the 'initial recovery' stage. After about five years, new roots become established enough to stabilize the hillside in the final 'fully recovered' phase.In the future, the researchers plan to investigate whether this same model applies to other regions, such as the Rockies and the Pacific Northwest, which also experienced severe wildfires this year. For now, the results have immediate and practical applications for land managers who are dealing with the 2020 aftermath. "Our model suggests that debris flows will be the primary concern during the next one to two years, at least in the burn scars in Southern California, and after that the concern will shift toward shallow landslide hazards" says Rengers. "I hope our work offers land managers useful expectations regarding how these processes are likely to evolve and helps them prioritize post-wildfire mitigation and planning."
"During long periods of the Earth's history, we've had small tidal ranges. But in the Late Silurian and Early Devonian, they seem to have been large in some parts of the world. These results appear highly robust, because even if we changed model variables such as ocean depth, we got the same patterns," says Per Ahlberg, professor of evolutionary organismal biology at Uppsala University.Between 420 and 380 million years ago (Ma) -- that is, during the end of one geological period, the Silurian, and beginning of the next, the Devonian -- Earth was a completely different world from now. Instead of today's well-known continents there were other land masses, clustered in the Southern Hemisphere. Stretching across the South Pole was the huge continent of Gondwana. North of it was another big one known as Laurussia, and squeezed between the two were a few small continents. Other salient differences compared with now were that Earth's day lasted only 21 hours, since our planet revolved faster on its own axis, and the Moon looked much larger because its orbit was closer to Earth.Life on land had gradually begun to get established. But the vertebrates, then consisting only of various kinds of fish, were still to be found only in the oceans. Then, during the Devonian, immense diversification of fish took place. One group to emerge was the bony fish, which make up more than 95 per cent of all fish today but were also the ancestors of terrestrial vertebrates. The earliest bony fish were the first animals to evolve lungs. What set off the evolution of bony fish, and how some of them started to adapt to a life on land, has not been clarified. One theory is that it happened in tidal environments where, in some periods, fish had been isolated in pools as a result of particularly large tides. This challenging habitat may have driven the evolution of lungs and, later on, the transformation of fins into front and hind legs.To test this tidal theory, researchers at Uppsala University, in collaboration with colleagues from the Universities of Oxford and (in Wales) Bangor, used an established mathematical model of the tidal system for the first time to simulate, in detail, the tides in the Late Silurian and Early Devonian. Data on the positions of the continents, the distance of the Moon, the duration of Earth's day, our planet's gravity and the physical properties of seawater were fed into the model. These simulations showed unequivocally that the period, just like that of the present day, was one when large tides occurred in some places. The small continent of South China on the Equator showed a difference of more than four metres in sea level between high and low tide. The existence of tides at the time has previously been verified through studies of geological strata, but determining the extent of the difference between low and high tide has not been feasible. To researchers this news has been interesting, since fossil finds indicate that it was specifically around South China that bony fish originated."Our results open the door to further and even more detailed tidal analyses of key episodes in Earth's past. The method can be used to explore the possible role of tides in other evolutionary processes of vertebrate development. And perhaps, conversely, whether tides, with their influence on ocean dynamics, played a part in the big marine extinctions that have taken place again and again in Earth's history," Ahlberg says.
Floating gardens are essentially rafts built on a frame of plastic caging, wrapped in coconut husks, and filled in with native plantings. As plants grow, they extend their roots into the water, growing hydroponically. On Chicago's North Branch of the Chicago River, non-profit Urban Rivers and partners are developing a mile-long, floating eco-park. Dubbed the Wild Mile, the re-development of this former industrial canal is Urban Rivers' flagship project. As part of the park, floating gardens, attached to shore, are being installed.The primary intent of the floating gardens is beautification. But the Illinois State team, from the University's Department of Geology, Geography, and the Environment, saw an ideal setup for a controlled experiment. "We got involved because it's the perfect opportunity to see if there's an impact on water quality," explains lead author Abigail Heath.Heath will present the results of the study in an online talk on Tuesday during the Geological Society of America's annual meeting.The study is novel: previous studies have explored floating gardens' impact on water quality over time, primarily in wastewater treatment ponds, but not over space, in moving water. The project also meshes well with Urban Rivers' broader goals. "The city is interested in water quality," says Phil Nicodemus, Urban Rivers Director of Research. "Happily, Illinois State got involved."Starting in spring 2018, Heath and co-authors have sampled water immediately upstream and downstream of a narrow 3 meter by 50 meter floating garden installed along the shoreline. Samples are collected weekly, at the surface and from 0.3 meters deep, the depth where roots reach from the garden's base into the water. Although the garden is set at the edge of Chicago's urban core, water quality is also impacted by upstream agriculture. Analyses are focused on nutrients including nitrate as nitrogen, chloride, sulfate, and phosphate.Could this small slice of human-made paradise improve water quality? An average of data collected over the course of the study show modest but definitive improvement. For example, nitrate as nitrogen dropped from 4.69 milligrams per liter in surface water just upstream of the garden to 4.43 milligrams per liter just downstream, a drop of about 1 percent. Phosphate was also lower downstream of the garden."Despite how small this garden was there was measurable improvement in water quality from upstream to downstream, especially for nitrates," notes Heath. She and colleagues see this as a scalable model for how larger floating gardens might help remediate water in similar settings. "Even this tiny garden makes a difference," she says.
While microplastics in groundwater likely affect human health, only a handful of studies have examined the abundance and movement of microplastics in groundwater. This gap means the potential for adverse health effects remains largely unknown.At the Geological Society of America's 2020 Annual Meeting today at 1:30, Teresa Baraza Piazuelo, a Ph.D. candidate at Saint Louis University, will help fill that knowledge gap by presenting new research on groundwater microplastics in a karst aquifer. "There hasn't been that much research looking at [micro]plastics and groundwater," Baraza says. "It's a very new topic. There's been a boom of research on microplastics in the ocean, even in soils... but to fully understand something, you have to explore it in all its aspects."Microplastics pose multiple physical and chemical risks to the ecosystems where they're present, and those risks are exacerbated by plastics' longevity in natural environments. "Since they're plastic, they're very durable," Baraza says, "which is why plastic is great. But it doesn't degrade easily." Microplastics' ability to linger in their environments for decades or longer likely has cumulative detrimental effects on both the organisms and quality of the ecosystem. Their chemical threat stems largely from their ability to transport harmful compounds on their surfaces; when organisms at the base of the food chain ingest microplastics, they ingest the toxins, too. As larger organisms consume the smaller ones, the toxins can build up (a process called bioaccumulation), eventually resulting in responses like organ dysfunction, genetic mutation, or death. "Cave ecosystems are known for being super fragile to begin with," she explains. "All the cave organisms -- salamanders, blind fish -- are sensitive, so any contaminants that are introduced could damage those ecosystems."Groundwater can stay in the same aquifer for tens to hundreds of years, or even longer. Combining that long residence time with plastics' resistance to degradation means that those chemical effects could effectively build up in the water and in any organisms within it, increasing the likelihood of toxic bioaccumulation. Together, these could result in long-term contamination of water sources with poorly-understood health effects and ecosystem damage.To understand where microplastics in groundwater come from and how they move through aquifers, Baraza and her Ph.D. advisor have been sampling groundwater from a Missouri cave weekly, all year long, and analyzing its chemistry and microplastics load. Because previous groundwater-microplastics studies have been limited to low-rainfall conditions, they're also studying how flooding events affect microplastics concentrations in groundwater.So far, they've found that while microplastics do increase in groundwater during a flood event, there's also a second peak in microplastics after the flooding has begun to wane. Their explanation is that there are two sources of microplastics for groundwater: those that are already in the subsurface, and those that are newly delivered from the surface. "Finding so much plastic later on in the flood, thinking that it could be coming from the surface... is important to understand the sourcing of microplastics in the groundwater," Baraza says. "Knowing where the plastic is coming from could help mitigate future contamination."Their current flood results are only based on one event, but Baraza will continue sampling through the rest of the year -- weather permitting. "Flood sampling is hard," she says, "especially in St. Louis, where the weather is so unpredictable. Sometimes we think it's going to rain and then it doesn't rain, and then sometimes it doesn't seem like it's going to rain, but it does... we caught a flood a week ago, and we are expecting to catch a couple more floods." The effort is worth it to determine if flooding events -- which are becoming more common under climate change -- are highly-effective deliverers of microplastics in groundwater reservoirs.
UC researchers discovered evidence of a filter system at the Corriental reservoir, an important source of drinking water for the ancient Maya in what is now northern Guatemala.A multidisciplinary team of UC anthropologists, geographers and biologists identified crystalline quartz and zeolite imported miles from the city. The quartz found in the coarse sand along with zeolite, a crystalline compound consisting of silicon and aluminum, create a natural molecular sieve. Both minerals are used in modern water filtration.The filters would have removed harmful microbes, nitrogen-rich compounds, heavy metals such as mercury and other toxins from the water, said Kenneth Barnett Tankersley, associate professor of anthropology and lead author of the study."What's interesting is this system would still be effective today and the Maya discovered it more than 2,000 years ago," Tankersley said.UC's discovery was published in the journal The Maya created this water filtration system nearly 2,000 years before similar systems were used in Europe, making it one of the oldest water treatment systems of its kind in the world, Tankersley said.Researchers from UC's College of Arts and Sciences traced the zeolite and quartz to steep ridges around the Bajo de AzÃºcar about 18 miles northeast of Tikal. They used X-ray diffraction analysis to identify zeolite and crystalline quartz in the reservoir sediments.At Tikal, zeolite was found exclusively in the Corriental reservoir.For the ancient Maya, finding ways to collect and store clean water was of critical importance. Tikal and other Maya cities were built atop porous limestone that made ready access to drinking water difficult to obtain for much of the year during seasonal droughts.UC geography professor and co-author Nicholas Dunning, who has studied ancient civilizations most of his career, found a likely source of the quartz and zeolite about 10 years ago while conducting fieldwork in Guatemala."It was an exposed, weathered volcanic tuff of quartz grains and zeolite. It was bleeding water at a good rate," he said. "Workers refilled their water bottles with it. It was locally famous for how clean and sweet the water was."Dunning took samples of the material. UC researchers later determined the quartz and zeolite closely matched the minerals found at Tikal.UC assistant research professor Christopher Carr, an expert in geographic information system mapping, also conducted work on the UC projects at Bajo de AzÃºcar and Corriental."It was probably through very clever empirical observation that the ancient Maya saw this particular material was associated with clean water and made some effort to carry it back," Dunning said.UC anthropology professor emeritus Vernon Scarborough, another co-author, said most research on ancient water management has tried to explain how civilizations conserved, collected or diverted water."The quality of water put to potable ends has remained difficult to address," Scarborough said. "This study by our UC team has opened the research agenda by way of identifying the quality of a water source and how that might have been established and maintained."Of course, reconstructing the lives, habits and motivations of a civilization 1,000 years ago is tricky."We don't have absolute proof, but we have strong circumstantial evidence," Dunning said. "Our explanation makes logical sense.""This is what you have to do as an archaeologist," UC biologist and co-author David Lentz said. "You have to put together a puzzle with some of the pieces missing."Lentz said the filtration system would have protected the ancient Maya from harmful cyanobacteria and other toxins that might otherwise have made people who drank from the reservoir sick."The ancient Maya figured out that this material produced pools of clear water," he said.Complex water filtration systems have been observed in other ancient civilizations from Greece to Egypt to South Asia, but this is the first observed in the ancient New World, Tankersley said."The ancient Maya lived in a tropical environment and had to be innovators. This is a remarkable innovation," Tankersley said. "A lot of people look at Native Americans in the Western Hemisphere as not having the same engineering or technological muscle of places like Greece, Rome, India or China. But when it comes to water management, the Maya were millennia ahead."
A University of Washington engineer who analyzed the event's aftermath began to investigate the circumstances that can make landslides so deadly. The resulting study shows that certain human actions increase the chance of surviving a devastating event, and suggests simple behavioral changes could save more lives than expensive engineering solutions.The open-access study, published in the October issue of "There are in fact some really simple, cost-effective measures that can be taken that can dramatically improve the likelihood that one will survive a landslide," said senior author Joseph Wartman, a UW professor of civil and environmental engineering.Worldwide, landslides cause on average more than 4,000 deaths a year recently, with about 25 to 50 of those deaths occurring each year in the U.S. These events may become more frequent as wildfires fueled by warmer temperatures can leave slopes bare and more vulnerable to slides.Wartman and a UW graduate student compiled and analyzed records of 38 landslides that affected occupied buildings. Most of the data came from the U.S., but it included landslides from around the world for which there were detailed records.The authors recorded the geologic details of each landslide, as well as the reports from survivors of the events. They used newspaper articles, scientific papers, medical examiner reports and other documents to produce a detailed catalog of fatalities caused by landslides hitting occupied buildings. The events, spanning from 1881 to 2019, included the Oso mudslide and the 2018 mudslide in Southern California, as well as events in Bangladesh, Philippines, China, Malaysia, Australia and New Zealand.Their analysis showed behavioral factors, such as a having an awareness of local landslide hazards and moving to a higher floor of a building during an event, had the strongest association with survival."Simply by being on an upper floor, an individual can increase their odds of survival by up to a factor of twelve. This is a powerful finding that we need to consider when we design the layout and vertical access routes in homes," said first author William Pollock, who did the work for his UW doctorate in civil and environmental engineering and is now a lecturer in the department.The analysis showed many things they predicted would be important, including the size or the intensity of landslide events, made little difference to the death toll for landslides below about 20 feet depth. Similarly, the distance between a building and the landslide slope, or an inhabitant's age and gender, didn't make a big difference to their survival.But the researchers found some behaviors, despite being performed by only a small number of people, often save lives. According to their results, those actions are:The results suggest practical ways to lower the number of lives lost to landslides in the United States, Wartman said. He hopes the information can be incorporated in education and community awareness programs."This is a message of hope," Wartman said. "What this work suggests is that a modest investment put toward social science, policy and education could have a very marked effect in protecting people from landslides."Residents who want to know if they are vulnerable to landslides can contact a local agency, such as the Washington State Department of Natural Resources, to learn more about local risks. Federal legislation is pending to make this information more easily accessible across the United States, Wartman said.The study was funded by the National Science Foundation.
"We tend to study rocks that are millions to billions of years old, but in this case we can show what's happening in the deep crust, nearly 19 miles below the surface of the Earth, in what geologically speaking is the modern day," said Jacob Cipar, a graduate student in geosciences at Penn State. "And we have linked what's preserved in these rocks with tectonic processes happening today that may represent an important step in the development of stable continents."The team, led by Penn State scientists, found evidence that heat from the mantle is melting the lower crust at the rift, where tectonic forces are pulling apart and thinning the lithosphere, or the crust and upper mantle that make up the rigid outer layer of Earth.Heating the continental crust is considered important to its development. But the process is often associated with crustal thickening, when continental plates collide and form mountains like the Himalayas, the scientists said."Our research suggests that these rocks that have been thought of as related to mountain building may have actually been cooked by a thinning lithosphere like what's happening in the modern-day Rio Grande rift," Cipar said. "And more broadly, thinning lithosphere may be more important than previously recognized for stabilizing continents and preventing them from sinking back into the mantle."The researchers recently reported their findings in the journal Earth's continents feature a unique silicon-rich, buoyant crust that allows land to rise above sea level and host terrestrial life, the scientists said. The crust also contains heat-producing elements like uranium that could destabilize it over geological time.Heating the crust creates molten rock that carries those elements toward the surface, resulting in a cooler and stronger lower crust that can protect continents from being absorbed into the mantle, the scientists said. But questions remain about the sources of that heat."We are suggesting that thinning of the lithosphere is really the removal of a barrier that keeps that heat away from the crust," said Andrew Smye, assistant professor of geosciences at Penn State and Cipar's adviser. "Removing or thinning that barrier at the Rio Grande rift appears to be what is generating the heat needed to initiate this process of stabilizing continental crust. And this has been overlooked in our understanding of how continents become so stable."The scientists tapped into rocks brought to the surface 20,000 years ago by volcanoes in New Mexico. The rocks are considered geologically young and are significant because they retain the context of the lower crust, the scientists said."In contrast, what we see in the rock record around the world is that oftentimes what it takes to get them up to the surface has disrupted their original relationship with the lower crust," said Joshua Garber, a postdoctoral researcher at Penn State. "This makes it really challenging to use older rocks to try to understand tectonics, and it makes the Rio Grande probably the best place to do this research."The scientists used analytical techniques to link the age of minerals in the rocks to the pressure and temperature they faced as they made their way through the crust.Similarities between the pressure and temperature path from the Rio Grande lower crust and rocks from other locations suggest that a thinning lithosphere is important for stabilizing Earth's continents, the scientists said."The snapshots of data we do have from other locations really nicely aligns with what we found in the Rio Grande rift," Garber said. "So that tells us this is not just happening now in the western United States. This shows the guts of continents have probably undergone this globally at least for the last billion years."
In a new study published in Located at the threshold of monsoonal Asia, the Thar Desert marks the eastern extent of the desert belt that stretches westwards across Arabia and the Sahara. While this desert belt is typically thought of as inhospitable to early humans, it is becoming increasingly clear that during humid phases in the past human populations have prospered in these landscapes. This is perhaps best known in western South Asia from studying the Indus Civilisation (also known as the Harappan Civilisation) which flourished at the margins of the Thar Desert along the course of the now-seasonal Ghaggar-Hakra River between 3200-1500 BCE, and is thought to have inspired the mythological Saraswati River mentioned in the Rig Veda.Yet the potential importance of 'lost' rivers for earlier inhabitants of the Thar Desert have been overlooked. "The Thar Desert has a rich prehistory, and we've been uncovering a wide range of evidence showing how Stone Age populations not only survived but thrived in these semi-arid landscapes," says Jimbob Blinkhorn of MPISHH. "We know how important rivers can be to living in this region, but we have little detail on what river systems were like during key periods of prehistory."Studies of satellite imagery have shown a dense network of river channels crossing the Thar Desert. "These studies can indicate where rivers and streams have flown in the past, but they can't tell us when" explains Prof Hema Achyuthan of Anna University, Chennai. "To demonstrate how old such channels are, we had to find evidence on the ground for river activity in the middle of the desert."A deep deposit of river sands and gravels was studied by the team, which had been exposed by quarrying activity near the village of Nal, just outside of Bikaner. By studying the different deposits, the researchers were able to document different phases of river activity. "We immediately saw evidence for a substantial and very active river system from the bottom of the fluvial deposits, which gradually decreased in power through time" explained Achyuthan. "Standing in the middle of the desert, the question we had to answer was 'How old was this river?'."The researchers used a method called luminescence dating to understand when quartz grains in the river sands were buried. The results indicated that the strongest river activity at Nal occurred at approx. 172 and 140 thousand years ago, at a time when the monsoon was much weaker than today in the region. River activity continued at the site between 95 to 78 thousand years ago, after which only limited evidence for the presence of a river at the site, with evidence for a brief reactivation of the channel 26 thousand years ago.The age of this river flowing in the middle of the desert is of particular interest. The river was flowing at its strongest during a phase of weak monsoonal activity in the region, and may have been a life-line to human populations enabling them to inhabit the Thar Desert. The timeframe over which this river was active also overlaps with significant changes in human behaviour in the region, which have been linked with the earliest expansions of Homo sapiens from Africa into India. "This river flowed at a critical timeframe for understanding human evolution in the Thar Desert, across South Asia and beyond" says Blinkhorn, adding "This suggests landscape in which the earliest members of our own species, Homo sapiens, first encountered the monsoons and crossed the Thar Desert may have been very different to the landscape we can see today."The next phase of research is to demonstrate where the river flowed from. Studies of satellite images have suggested a potential connection with a Himalayan source, such as the Sutlej. "We can't demonstrate where the river flowed from at present" says Blinkhorn, adding "but the Indira Ghandi Canal, sourced from the Sutlej River, gives us some insight into what happens when a river flows through the centre of the Thar Desert -- plants and wildlife flourish, providing ideal conditions for early human populations."
A new University of Washington and NOAA Fisheries study found that sea lions have the largest negative effect on early-arriving endangered Chinook salmon in the lower Columbia River. The results of this study will publish Oct. 18 in the Opportunistic sea lions have learned that by swimming as far as 145 miles upriver, they can easily feast on migrating salmon, including those hindered by the Bonneville Dam."We investigated whether mortality rates varied depending on the specific threatened Chinook salmon population, determined by when they arrive in the river," said lead author Mark Sorel, a doctoral student at the UW School of Aquatic and Fishery Sciences. "We found that, based on their individual return timing and the abundance of sea lions in the river when they return, individual populations experience different levels of sea lion-associated mortality."Researchers learned that the earliest arriving populations of Chinook salmon experienced an additional 20% mortality over previous years, and the later arriving populations experienced an additional 10%. This increase in mortality was associated with increased sea lion abundance at those times of year in the period of 2013 to 2015 compared to the period of 2010 to 2012.The numbers of California sea lions are highest at the mouth of the Columbia in early spring, before they depart for their breeding grounds in southern California. The researchers also discovered that the earliest arriving salmon migrate through the lower Columbia River more slowly than those arriving later in the season, thereby increasing their exposure to predation."This information on how different populations are affected by sea-lion associated mortality is key because recovery of endangered Chinook salmon requires multiple of the individual populations to be healthy," said Sorel.California sea lions have seen their numbers rebound along much of the U.S. West Coast since the passage of the Marine Mammal Protection Act of 1972, which protects them from being killed, captured and harassed. The increased presence of sea lions is now at odds with the endangered salmon populations on which they feed, putting managers in a difficult position.Researchers are concerned that something must be done quickly as these hunting behaviors are learned, and the problem could continue to grow exponentially. In August, the National Marine Fisheries Service granted approval for Washington, Idaho, Oregon and several Pacific Northwest tribes to capture and euthanize both problematic California and Steller sea lions within a larger area of the lower Columbia and Willamette Rivers. Previously, only California sea lions could be killed in these rivers if managers deemed them a threat to salmon.This complicated decision was enacted after non-lethal methods, such relocation and hazing, to limit the impact sea lions have on salmon -- plus some targeted lethal removal -- were met with limited success."This is often a challenging management problem as both sea lions and salmon are of strong interest to the public, and both are protected under federal statutes," said Sorel. "Management must consider multiple social values and operate within existing legal frameworks."Continued monitoring will help to reduce the remaining uncertainty about the effects of sea lions on salmon and the expected outcomes of alternative management actions.
Antarctic Krill, Euphausia superba, is a five-centimetre-long, reddish, shrimp-like animal which at first glance, may not appear as an impressive inhabitant of the Southern Ocean. But krill make up for their small individual sizes with the sheer number of their entire population. There is an estimated 300-500 billion Mt of krill in the Southern Ocean comprised of some hundreds of trillions of individuals. This massive biomass makes krill a key component of the local ecosystem. It is the main food source for many predators from fish, penguins and seabirds to seals and whales.Humans have also developed an interest in krill over the past decades. Norway, along with Korea, China, Chile, the Ukraine and Japan trawl for krill in the Southern Ocean. But the fishing industry has become more efficient at catching krill using not only traditional fishing nets, but new continuous pumping systems. The demand for krill will likely increase, driven by at least two industries. First the increasing production of carnivorous fish through aquaculture, such as salmon, and the subsequent increase in demand for fish meals and marine byproducts. Second, the increasing demand for high value pharma- and nutraceutical products from krill oil and krill meals, such as wound ointment and krill oil capsules for human use and pet food.The krill fishery is managed by the Commission for the Conservation of Antarctic Marine Living Resources (CCAMLR), which was founded in 1982. This body uses surveys and model calculations to determine how much krill may be caught and where it may be caught. The Atlantic sector of the Southern Ocean has the highest concentration of both krill stocks and fishing fleets. This region alone has a maximum allowable catch of 620,000 tons per year distributed over different fishing areas.This is only a fraction of krill that are estimated to live in the ocean around Antarctica. CCAMLR had long assumed that the established catch limits would not cause serious damage, but krill experts like Bettina Meyer now see things differently. "The problem is that the catch regulations have, so far, been aimed primarily at protecting the krill eaters," explains the researcher. "Too little attention, has been paid to possible risks for the krill stocks themselves.This is due to the fact that relatively little is still known about some aspects of the biology of these small crustaceans." Financed by the Federal Ministry of Food and Agriculture (BMEL), Bettina Meyer, her colleague Dr. Ryan Driscoll and her research group are trying to shed more light on this issue. In a new publication, krill experts from around the globe summarize why there are several reasons to worry about the future of this key species.In brief, krill abundances in some regions fluctuate greatly from year to year. However, the causes of these fluctuations are not yet clear and the current management of krill does not adjust the catch accordingly. Furthermore, it is likely that only a small part of the population, limited to a relatively small area, provide the offspring for the entire Atlantic part of the Southern Ocean. Finally, little is known about where the new generation migrate to in their first year. This means that it is possible that the most important parts of the population, the future parents and their offspring, will be overfished.In 2019 CCAMLR decided to develop a new krill management system to address these issues. The committee is advised by the "Krill Action Group" under the umbrella of the Scientific Committee of Antarctic Research (SCAR), which was founded in 2018. It currently consists of 46 international members, half of which are established and half early career scientist. "Our goal is to provide CCAMLR with the latest knowledge on the size, distribution and dynamics of krill stocks." explains Bettina Meyer, who heads this expert group.The future of krill management will require answering lingering question in key areas of krill biology. For example, understanding how krill populations in different regions are connected and how adults and juveniles differ in their location and movement. Also unknown are the environmental conditions responsible for determining good or bad krill years. The Atlantic sector of the Southern Ocean is warming rapidly and so understanding how krill will adapt to climate change is crucial. As for the latter, "CCAMLR's previous models do not take this plasticity into account," explains Bettina Meyer, "But we need to know more about this if we are to be able to predict future changes in the ecosystem."Bettina Meyer and her colleagues have some concrete ideas about how the missing data can be collected. Since space and availability for scientific expeditions aboard research ships are limited, scientists could rely on the support of the fishing fleets. Together, these fishing vessels have the potential to collect a substantial amount of krill data which can help close critical knowledge gaps.In addition, new technology may help scientists advance their understanding of krill stocks and their distribution. For example, autonomous underwater gliders, which look like mini gliders with a wingspan of about 1.50 metres, can be equipped with cameras, sensors, and echosounders to search for krill. They can roam the ocean from the surface down to 1000 metres for several months, collecting data on the density and distribution of krill.Another promising technology are advanced moorings, equipped with arrays of sensors to measure water properties and krill density. These stationary devices can provide important information almost year-round in areas critical to the management of the krill fishery. Even krill predators, the whales, seals or penguins, can be recruited to help using attached camera systems and probes equipped with GPS."All of this can provide us with valuable new information for better krill management," says Bettina Meyer who is convinced by this approach. But in order to cover large areas of the Southern Ocean it is important to coordinate these research efforts internationally: "As a lone warrior, nobody can answer the complex questions of krill research."
Recently published research in the journal "The stopover-to-passage ratio is an indicator of the number of migrants that stop to rest during migration and those that continue heading north or south, depending on the season. The ratio varies from site to site," said co-author Kyle Horton, assistant professor at Colorado State University and an alumnus of UD's College of Agriculture and Natural Resources. "It's highly useful, from a conservation standpoint, to know if the majority of birds fly over a site or predominantly stop at a site to refuel or rest. The answer to this question can have important implications for what action is ultimately done on-the-ground to help migratory birds.""Characterization of stopover habitat use relative to passage represents a fundamental gap in our knowledge," said Emily Cohen, lead author and assistant professor at the University of Maryland Center for Environmental Science, Appalachian Laboratory. "This gap primarily exists because a methodology to collect broad-scale information about distributions of birds in terrestrial habitats during the day and in the airspace at night has only recently become possible with weather surveillance radar."Archived since the mid-1990s but only freely available since 2004, weather radar data collected by NOAA, the National Oceanic and Atmospheric Administration, now enables researchers to map the nocturnal habits of migratory bird populations. It is a herculean effort to process and synthesize these vast data sets; scientists must distinguish bird movement from precipitation data on the radar based on density, speed and knowledge of the natural history of bird behavior. Calculating both the traffic patterns of the birds in flight and their activity in stopover sites, the research team created migration maps and calculated the stopover-to-passage ratio along the entire U.S. Gulf Coast."Our findings were not what we expected," said Jeff Buler, University of Delaware associate professor of wildlife ecology and senior author on the paper. "We understand the phenology of migration quite well, so we know the absolute number of birds moving through an area at the peak of migration. The density of birds on the ground also peaks around the same time. When looking at stopover-to-passage ratio, we thought that we would see more birds stopping during the peak of migration but we actually found the opposite."Even though fewer birds migrate outside of the peak window, a larger percentage of that bird population stops at particular resting and foraging sites, indicating that those lands are of critical importance at that time."We saw a high stopover-to-passage ratio in the panhandle of Florida, which was unexpected because in the spring there aren't as many birds moving through that area," said Buler. "What that tells us is that the birds that are moving through that area need to stop, and it actually is indirect evidence that these are likely migrants that are coming from South America. They're flying over the Caribbean and the Atlantic Ocean, so they're making a farther journey than those that are just crossing the Gulf of Mexico. That first place to land in Florida is really important to them and most of them have to stop because they've run out of gas. From a conservation perspective, this really opens up a question of whether we need to rethink how we prioritize conserving stopover areas."Currently, breeding ground habitat receives far more conservation attention and protection than migratory stopover habitat. However, with migratory bird populations facing rapid declines due to many interacting factors including light pollution, climate change, and habitat loss and degradation, researchers hope that the stopover-to-passage ratio can offer additional insight and renewed interest in often overlooked stopover sites."These results show the critical importance of the habitats around the U.S. coast of the Gulf of Mexico and Florida for sustaining North America's migratory birds. We show for the first time that over half of the birds migrating through these coastlines stop there," said Cohen. "Further, disparities in disproportionate selection and absolute abundance at stopover sites revealed potential migratory bottlenecks where geography or restricted habitat may disproportionately concentrate birds along migration routes, highlighting that density of use alone is not a comprehensive measure of the conservation value of a stopover site for migrating birds, a topic that has not been addressed during migration. The areas where the stopover-to-passage ratio is high are potentially more important for migrating birds than was previously thought.""Linking aerial and terrestrial habitats with this new metric provides a unique opportunity to understand how migrating birds, in this case very large numbers of them, use a region where we know drastic and rapid changes are occurring," said co-author Andrew Farnsworth of the Cornell Lab of Ornithology. "Whether for prioritization of critical areas or for developing dynamic conservation planning, this kind of quantitative science is invaluable for supporting decision-making that can safeguard this incredible region and the spectacular movements of birds that occur here annually."
Texas A&M University researchers have developed analytical tools that can help characterize the movements of floating but anchored wave-energy devices. Unlike complicated simulations that are expensive and time-consuming, they said their technique is fast, yet accurate enough to estimate if wave-energy devices will turn over in an ever-changing ocean environment."Wave-energy converters need to take advantage of large wave motions to make electricity. But when a big storm comes, you don't want big wave, wind and current motions to destroy these devices," said Dr. Jeffrey Falzarano, professor in the Department of Ocean Engineering. "We have developed much simpler analytical tools to judge the performance of these devices in a dynamic ocean environment without necessitating massive amounts of simulations or physical model tests that take a lot of time to run and are cost-prohibitive."The mathematical tools are described online in the journal Wave-energy devices function in two modes. In "normal mode," they convert the energy from tidal waves into electricity. Thus, this mode largely determines whether the design of the wave-energy device is economically efficient. However, in "survival" mode, or when incident waves cause large motions in the wave-energy devices, the performance of the wave-energy devices is largely determined by a system of moorings that anchor the devices to a location at the bottom of the body of water.Moorings can be of several types, including wharfs and anchor buoys, and can be arranged in different configurations. In addition, there are considerable variations in the shape of wave-energy devices, making the prediction of whether the device will capsize nontrivial."Ships come in a variety of shapes and sizes; tankers, for example, are very different from fishing vessels or other military ships. These different geometries affect the ship's motion in the water," said Falzarano. "Similarly, the shape of wave-energy devices can be quite diverse."For the analysis, Hao Wang, Falzarano' s graduate student, used a cylindrical wave-energy device. This generic shape allowed the researchers to simplify the problem of prediction and extended their analysis to other wave-energy converters of similar shape. He also considered three mooring configurations.Hao used two analytical methods, the Markov and Melnikov approaches, to predict the risks of turning over under random excitation. More specifically, using information from the wave-energy device's geometry, the configuration of the mooring system and tidal wave properties, the methods yield a graph containing an envelope-like region. Intuitively, if the waves are really big, like during a storm, and the floating vessel escapes this envelope, it will likely turnover.The researchers noted that although the analytical models were completely different, they yielded almost the same results, validating their merit and accuracy. They also said that their mathematical approach can be applied to assess the performance of other floating devices, such as floating wind turbines."The platform for a floating wind turbine is the same as the one for wave-energy devices, and so floating turbines can also pitchpole or turnover if the waves are very high," said Falzarano. "My group has been leaders in developing methods for predicting ship stability. We're now looking at applying those approaches to renewable, floating energy devices."Video: 
These unnatural additions to sea surface waters and the large quantity of cells and biomass carried by plastic debris has the potential to impact biodiversity, ecological functions and biogeochemical cycles within the ocean. Biofilm formation in the marine environment -- a collective of one or more types of microorganisms that can grow on many different surfaces -- is a complex process, involving many variables.While several studies have surveyed microbial diversity and quantified specific members of these biofilm habitats, a new study is the first to holistically quantify total cell inventories under in situ conditions. This study is fundamentally different from others due to the relatively non-biased visualization methods used to arrive at a quantitative number for biomass, which is the first estimate of its kind.Researchers from Florida Atlantic University's Harbor Branch Oceanographic Institute and Harriet L. Wilkes Honors College, in collaboration with Utrecht University, Netherlands, the University of Amsterdam, and The Royal Netherlands Institute for Sea Research (NIOZ), examined cell abundances, size, cellular carbon mass, and how photosynthetic cells differ on polymeric and glass substrates over time. They investigated nanoparticle generation from plastic such as polystyrene, which is known to disintegrate into nanoparticles in sunlight and ultraviolet radiation, and how this might disrupt microalgae.Results of the study, published in the "In the open ocean, nutrients are limiting. Just like we need to put fertilizer on a garden, microorganisms in the ocean are limited by nitrogen, iron or phosphorus depending upon where they are -- except in the open ocean, there is typically no fertilizer, so something has to die for another organism to live," said Tracy Mincer, Ph.D., lead author and an assistant professor of biology/bio-geochemistry at FAU's Harbor Branch and Wilkes Honors College. "With the advantage of a surface, which concentrates nutrients, organisms colonizing plastics in the ocean are taking up those limiting nutrients that normally would have been consumed or out-competed by free-living microbes. So essentially, these microbes on plastics are taking habitat space away and represent the beginning of a regime shift for these habitats."Using confocal laser scanning microscopy with sophisticated imaging software, researchers directly obtained data ranging from cell counts, size and the characterization of microbial morphotypes to complete three-dimensional constructs. They tested a range of chemically distinct substrates that included polypropylene, polystyrene, polyethylene and glass. Polypropylene is used by the automotive industry, for consumer goods such as packaging, industrial applications and the furniture market; polystyrene is used to make clear products like food packing or laboratory equipment; and polyethylene is the most widely used plastic in the world ranging from products such as clear food wrap to shopping bags to detergent bottles.Data from the confocal laser scanning microscopy showed that early biofilms displayed a high proportion of diatoms (unicellular eukaryotic microalgae that have cell walls made of glass). These diatoms could play a key role in the sinking of plastic debris. Unexpectedly, plastic substrates appeared to reduce the growth of photosynthetic cells after eight weeks compared to glass."The quantification of cell numbers and microbial biomass on plastic marine debris is crucial for understanding the implications of plastic marine debris on oceanic ecosystems," said Shiye Zhao, Ph.D., first author and a post-doctoral fellow at FAU's Harbor Branch. "Future efforts should focus on how this biomass fluctuates with season and latitude and its potential to perturb the flux of nutrients in the upper layers of the ocean."
"Thirty years ago, people noticed that these asteroid starfish larvae could clone themselves, and they wondered what the adult form was," said staff scientist Rachel Collin at the Smithsonian Tropical Research Institute (STRI). "They assumed that because the larvae were in the Caribbean the adults must also be from the Caribbean."Scientists monitor larvae because the larvae can be more sensitive to physical conditions than the adults and larval dispersal has a large influence on the distribution of adult fishes and invertebrates. Collin's team uses a technique called DNA barcoding to identify plankton. They determine the DNA sequence of an organism, then look for matches with a sequence from a known animal in a database."This mystery species was one of the most common in our samples from the Caribbean coast of Panama," Collin said. "We knew from people's studies that the DNA matched sequences from similar larvae across the Caribbean and it matched unidentified juvenile starfish caught in the Gulf of Mexico -- but no one had found a match to any known adult organism in the Caribbean. So we decided to see if the DNA matched anything in the global 'Barcode of Life' data base.""That's when we got a match with But why are the larvae common in the Caribbean if adult Valvaster starfish have never been found here? Are the adult starfish hidden inside Caribbean reefs, or are the larvae arriving from the other side of the world?"It's possible that the ability of the larvae to clone themselves is not just a clever way to stay forever young," Collin said. "There's a natural barrier that keeps organisms from the western Pacific and the Indian ocean from crossing the Atlantic to the Caribbean. After they make it around the tip of Africa, they are met by a cold current that presumably kills tropical species.""Just how cloning could help them get through the barrier is still not known, but it's intriguing that another sea star species from the Indo West Pacific that was collected for the first time in the Caribbean in the 1980s also has cloning larvae," Collin said.
Indeed, some countries, including the United States, Brazil and Australia, are back-tracking on existing laws and relaxing regulations and enforcement actions aimed at protecting nature, according to lead author Pamela McElwee, an associate professor in the Department of Human Ecology in the School of Environmental and Biological Sciences at Rutgers University-New Brunswick."Just last week at the United Nations, more than 60 heads of state spoke at a virtual summit and pledged their support to tackle the biodiversity crisis. But when we look at what countries are doing, either in their prior budget and policies or especially in their post-COVID planning and recovery packages, very few governments are putting their money where their mouths are," McElwee said. "We still see huge amounts of financial support for harmful practices, such as subsidizing overfishing or fossil fuel production or building infrastructure that will harm ecological integrity. Only a small number of countries are addressing the biodiversity crisis in the serious manner it deserves."The paper, by economists, anthropologists and environmental scientists at many institutions on three continents, is published in the journal Unless action is taken, around 1 million species face extinction, many within decades, and the global rate of species extinction will accelerate, according to the 2019 Global Assessment Report on Biodiversity and Ecosystem Services from the Intergovernmental Science-Policy Platform on Biodiversity and Ecosystem Services (IPBES). That report noted the extinction rate is "already at least tens to hundreds of times higher than it has averaged over the past 10 million years." The authors of this new paper were all contributors to the 2019 IPBES report.The new paper spells out the actions governments should be taking in their stimulus and recovery plans that would prioritize nature, provide immediate employment benefits and lead to longer-term transformations in the global economy. Examples include shifting from harmful fossil fuel subsidies to beneficial ones, including those that encourage environmentally friendly farming; carbon taxes that could support forest protection programs; and work programs that focus on ecological restoration and green infrastructure.While many scientists and politicians have promoted a COVID-19 recovery that is low carbon, how to include biodiversity and ecosystems in economic plans has received much less attention. Discussions of nature-related actions have largely focused on closing wildlife markets as a potential source of novel viruses, expanding protected natural areas or reducing tropical deforestation. While these can be important, they do not necessarily address the root causes of ecological disruptions, the authors say.A number of countries, including the United States and China, have allocated essentially zero stimulus funding to biodiversity or ecosystems. Only the European Union and member countries are making substantial financial investments in biodiversity for post-COVID planning. Other nations, including New Zealand, India and Pakistan, are proposing investments in nature-based jobs like ecological restoration, but at only modest levels."Governments are falling short of their stated promises and they need to do more -- immediately," McElwee said. "We will continue to monitor proposed recovery packages, stimulus measures and financial pledges for how they address the biodiversity crises going forward, particularly in light of the mega-summit on biodiversity to be held in China next May."
"These two groups of mice have been confused with one another for a century," says Julian Kerbis Peterhans, one of the paper's authors and a researcher at the Field Museum who's studied these rodents for over 30 years. "They've been so elusive for so long, they're some of the rarest animals in the world, so it's exciting to finally figure out their family tree.""It's underappreciated how little is known about the biodiversity of small mammals, especially in tropical parts of the world. We're not discovering a whole lot of new lions, tigers, and bears, but there's an incredible potential for discovery of new species of small mammals because they're tough to find," says Tom Giarla, the paper's lead author and an assistant professor of biology at Siena College in New York. "And they're sort of underappreciated animals -- they're really cool when you start to learn about their ecology. These are semi-aquatic mice, so they're not just your average, everyday rodents."There are two main kinds of mice that the researchers focused on: But since they spend their time by water, they're hard to catch. They prefer shallow streams so that they can use their whiskers to help them hunt, but they've also been found in swampy areas and even rivers that are 3-4 feet deep in places (they hang out by the shallow edges). "To cross one of the rivers where I caught a For this study, the researchers conducted the first evaluation of Giarla was also able to extract DNA from a piece of dried tissue on the skull of the 93-year-old specimen of Learning about the different species of mice in streams halfway around the world has broad implications for conservation science. "The new species we named are part of a global effort to understand the biodiversity of African rainforests and highlight the critical areas to be preserved," says Demos. "There are vast areas of the Congo Basin that have barely been explored in the last seventy years, places that are hard to access due to political instability. We're not even completely sure how these animals are distributed, there are big gaps."The findings could even help inform public health efforts down the line. "COVID is a zoonotic disease, and biodiversity research is essential to understanding zoonotic disease," says Giarla. "We need to understand what species are present in natural areas, especially natural areas being changed by humans." (It's worth noting, the mice in this paper aren't known to carry diseases that affect humans -- studying them and other animals can help scientists get a better baseline of which species live where, and that can help pinpoint zoonotic diseases in the future.)The researchers also note that their research was made possible by a large international network of scientists. "If you look at the author list, but we have people from all over the world," says Giarla. "We have colleagues in Africa and Europe and the United States. Museums in the Czech Republic, Germany, the US, South Africa, Eswatini. We had people all over the world helping us with this effort: field workers, geneticists, morphologists. Science is a really global effort."
Another view that can be captured by Suomi NPP satellite is a false-color image. The false-color image is collected by the VIIRS (Visible Infrared Imaging Radiometer Suite) instrument suite using corrected reflectance bands. Burned areas or fire-affected areas are characterized by deposits of charcoal and ash, removal of vegetation and/or the alteration of vegetation structure. When bare soil becomes exposed, the brightness in Band 1 may increase, but that may be offset by the presence of black carbon residue; the near infrared (Band 2) will become darker, and Band 7 becomes more reflective. When assigned to red/brown in the image, Band 7 will show burn scars as deep or bright reddish brown depending on the type of vegetation burned, the amount of residue, or the completeness of the burn. It is hard to see clearly due to the massive amounts of smoke covering the landscape.Inciweb reports the following weather concerns for this fires: "Hot and dry conditions persist. Smoke remains very thick in the lower valleys with visibility reduced under a mile. Temperatures will be 88-93 in the valleys and 75 to 80 in the higher elevations. The humidity will be 10-15% with 4-8 mph wind."NASA's satellite instruments are often the first to detect wildfires burning in remote regions, and the locations of new fires are sent directly to land managers worldwide within hours of the satellite overpass. Together, NASA instruments detect actively burning fires, track the transport of smoke from fires, provide information for fire management, and map the extent of changes to ecosystems, based on the extent and severity of burn scars. NASA has a fleet of Earth-observing instruments, many of which contribute to our understanding of fire in the Earth system. Satellites in orbit around the poles provide observations of the entire planet several times per day, whereas satellites in a geostationary orbit provide coarse-resolution imagery of fires, smoke and clouds every five to 15 minutes. For more information visit: NASA's Earth Observing System Data and Information System (EOSDIS) Worldview application provides the capability to interactively browse over 700 global, full-resolution satellite imagery layers and then download the underlying data. Many of the available imagery layers are updated within three hours of observation, essentially showing the entire Earth as it looks "right now." Actively burning fires, detected by thermal bands, are shown as red points. Image Courtesy: NASA Worldview, Earth Observing System Data and Information System (EOSDIS). Caption: Lynn Jenner with information from Inciweb.
"The Amazon is the world's most diverse rainforest, home to one in 10 known species on Earth," said Julia Tejada-Lara, who led the study as a graduate student at the Museum and Columbia University. "Closed-canopy rainforests have been proposed to occur in this area since at least the Eocene, some 50 million years ago, but we know very little about their extent and evolution through time."To reconstruct ancient ecosystems, including rainforests, researchers often use stable carbon isotope (?13C) analyses on extinct and living herbivores. Stable carbon isotopes, which form in specific proportions inside plants, are preserved in the body tissues of the animals that eat those plants. Samples from the animal's bones, teeth, toenails, or other biological material can help scientists determine the kinds of plants that were consumed.In the new study, Tejada and her colleagues analyzed specimens from the American Museum of Natural History and the Museum of Natural History in Lima representing 45 modern herbivores and 12 species of "secondary consumers" (meat-, insect-, and fish-eaters) that live in western Amazonia. The authors then compared their results with a landmark analysis of modern mammals in equatorial Africa, a generally accepted proxy used to identify past closed-canopy rainforests on all continents. The researchers also determined nitrogen isotope values from 35 Amazonian mammal species, finding greater than expected complexity in how nitrogen from macromolecules (carbohydrates, proteins, and fats [lipids]) is incorporated into body tissues in animals from different levels of the food chain."Up to this point, there had only been one other broad isotopic sampling -- and inferences of food sources -- of a tropical closed-canopy rainforest mammal community, and that was in central Africa," said co-author John Flynn, Frick Curator of Fossil Mammals in the Museum's Division of Paleontology. "So we knew that if we wanted to learn more about both modern and ancient Amazon ecosystems, we had to test whether we should expect the tropical forest conditions to be roughly the same in these two continents that separated more than 90 million years ago and have a 1,600-mile-wide ocean between them today."The comparison reveals that Amazonian and African closed-canopy rainforests have a very similar mean dietary carbon isotopic value, and it may be representative of mammalian herbivores in any closed-canopy rainforest. Beyond this newly discovered way of recognizing ancient rainforests, Amazonian mammals in this study lacked highly negative dietary values found in a few of the African animals. These negative values are often used outright to infer closed-canopy rainforests in fossil records."We have found that these negative isotopic values can no longer be used as an indispensable indicator of a rainforest," Tejada said. "And further, that many of the longtime assumptions about ecological niches, feeding habits, and isotopic signatures characterizing tropical communities likely need to be reassessed."
Their results, recently published in the journal "This faunal exchange can be seen as a natural experiment: two continents, each with its own kind of animals were connected by a narrow land bridge, allowing massive migrations in both directions," said Juan Carrillo, STRI fellow and lead author on the study at the National Museum of Natural History in Paris. "Our study shows how these migrations happened and that South American mammals had more extinctions. The effect of this exchange can be still seen today."Almost half of the living South American mammals today descend from North American immigrants. However, only 10% of the North American mammals are derived from South American ancestors, such as opossums, porcupines and armadillos. Some possible explanations for the increased extinctions of South American mammals during the interchange include habitat changes and increased predation and competition.The differences among predators on each continent could have played a role. South America had predators closely related to marsupials, a group that includes opossums, with large canines that resembled saber-toothed cats. When the North American predators or Carnivora, such as foxes, cats and bears, arrived with more specialized carnivorous teeth and larger brains, native South American mammals became more susceptible to predation. This could have contributed to higher extinction rates. By then, the South American predatory marsupials had also disappeared."We suspect that the emigration of so-called Carnivora to South America might have been one of the causes of the high extinction in South American mammals," said SÃ¸ren Faurby, senior lecturer of Gothenburg University in Sweden and co-author of the study. "Carnivora appear to be more efficient predators than marsupials, potentially due to more specialized carnivorous teeth or larger brains, and many of the native South American mammals might not have been able to survive the invasion of more efficient predators."This new study is a clear reminder that when there are major disturbances in the biodiversity status quo there can be unexpected outcomes, visible both in the fossil record and in the distribution of species millions of years later. Ultimately, these findings could provide insights into the long-term consequences of the movement of species seen today.Video: 
Dr Hugo Harrison from the ARC Centre of Excellence for Coral Reef Studies at James Cook University (Coral CoE at JCU) led a study on the effects of marine reserves, or no-take zones, on fish populations."The Great Barrier Reef Marine Park has established networks of no-take zones," Dr Harrison said. "A 'portfolio' of these protected areas can help connect reefs and ultimately provide more reliable quantities of fish across an ecosystem."Dr Harrison says no-take zones -- areas closed to fishing -- on their own act as valuable sources of fish for neighbouring reefs. These areas support more fish, which then produce even greater numbers of baby fish. But, just how many babies survive and where they end up varies greatly from year to year. These fluctuations can be volatile and uncertain."Our findings are comparable to investing your resources wisely," said Professor Michael Bode, a co-author on the study from the Queensland University of Technology. "If you put all your money into one type of stock and then the value of that entire industry crashes, then all of your investment will crash too.""By investing in a variety of stocks you can buffer or dampen market volatility and still maintain a valuable portfolio. Our study proves that marine protected areas are like financial stocks: if you invest in multiple smaller reserves instead of putting all your effort into one large reserve, you ensure a stable supply of fish to both recreational and commercial fishers."The authors tracked more than 1,500 baby fish using DNA 'fingerprinting' techniques. The baby fish were traced back to their parents inside a network of four reserves.The researchers found that each reserve was an important but variable source of baby fish. However, together, the network of reserves generated a reliable source of offspring to replenish exploited fish stocks in surrounding reefs.The study coincides with two significant international reports illustrating the stark decline of the natural world: the Living Planet Report 2020 and the Global Biodiversity Outlook 5."Governments all around the world failed to meet any of the UN Sustainable Development Goals on Biodiversity Conservation," Dr Harrison said. "To stem the loss of natural habitats, they had committed in 2010 to expand the world's nature reserves across ten percent of coastal and marine areas by 2020.""Though protected ocean areas have tripled in these past ten years, the targets remain well below the recommendation of at least 30 percent protection recommended by the International Union for Conservation of Nature (IUCN)."The IUCN also recently released guidelines on protecting connectivity and 'corridors' within ecosystems, which are essential for healthy natural habitats -- for conservation and for climate change adaptation.Prof Bode says maintaining corridors between protected areas is easy to picture in a terrestrial realm -- for example, in a forest setting where animals can move freely between areas."But it's a lot harder in the marine realm, where connectivity pathways between habitats are difficult to predict," Prof Bode said. "We can't maintain 'corridors' in coral reef seascapes, so we need other mechanisms to ensure connectivity through these 'portfolios', as we do on the Great Barrier Reef."Dr Harrison said there is an urgent need for further discussions on the value of marine reserve networks -- both locally and internationally."Our research is a timely reminder of the value of marine networks in protecting not only biodiversity but industries including tourism and the millions of people globally whose livelihoods depend on healthy ecosystems."
In a study published this month in Heterotrophic bacteria (i.e., those that cannot produce their own food, instead obtaining nutrition from other sources of organic carbon, such as plant or animal matter) are the main recyclers of dissolved organic matter (DOM) in the ocean. Hotspots of DOM that are made up of particles, such as marine snow, are important to the global carbon cycle."Some groups of heterotrophic bacteria take advantage of these hotspots," says one of the lead authors of the study Assistant Professor Yutaka Yawata. "We used bacteria from one of these groups to look at whether optimal foraging theory is applicable to microbes, because their influence on the global carbon cycle ultimately depends on bacteria's ability to find and obtain nutrients from particles. Borrowing from the field of behavioral ecology, we referred to this process as foraging."The researchers examined microbial foraging by studying the behavior of marine bacteria in seascapes of organic particles. They conducted experiments using single-cell tracking, where bacteria were video-recorded and the number of bacteria and the amount of time they spent on a surface was extracted and modelled."We found that foraging marine bacteria optimize nutrient uptake by rapidly switching between attached and planktonic lifestyles, and fine-tune the time spent on particles according to patch quality," explains Assistant Professor Yawata. "Bacteria stay longer on particles of higher quality, as predicted by patch use theory."Patch use theory, which is part of optimal foraging theory, predicts that organisms foraging in a mixed-resource environment balance the time spent on a patch that yields diminishing returns with the costs of leaving that patch to find a fresh one. Until this study, the applicability of optimal foraging theory to microorganisms has been largely unknown.Optimal foraging theory -- and specifically patch use theory -- provides a valuable framework for understanding microorganisms and their effects on ecosystems, such as quantifying and predicting the role of marine bacteria in the uptake and cycling of ocean nutrients.
Sharing their discoveries in a newly published article in the The Asian giant hornet could also find suitable habitat throughout the eastern seaboard and populous parts of Africa, Australia, Europe, and South America, if humans inadvertently transport it.The team's predictions underline the importance of Washington state's efforts to stop the large insects before they spread."We found many suitable climates in the U.S. and around the globe," said lead author Gengping Zhu, a postdoctoral scholar at WSU's Department of Entomology.Collaborating with Washington State Department of Agriculture scientist Chris Looney and WSU entomologists David Crowder and Javier Illan, Zhu examined more than 200 records from the hornet's native range in Japan, South Korea, and Taiwan, then used a set of ecological models incorporating climate data to predict likely global habitat across six continents."These predictions are scientific sleuthing," Illan said. "We're making an educated guess on how fast and far these insects can move, their rate of success in establishing a nest, and offering different scenarios, from least bad to worst. No one has done this before for this species."Native to forested parts of Asia, the Asian giant hornet, Vespa mandarinia, is a significant threat to Western honey bees, which have no natural defense. In late summer and fall, hornet colonies attack beehives, destroying entire bee colonies to feed their brood and produce new queens.Up to two inches long, the insect also deploys a potent sting, which is more dangerous than that of local bees and wasps.Asian giant hornets are most likely to thrive in places with warm summers, mild winters, and high rainfall. Extreme heat is lethal, so their most suitable habitats are in regions with a maximum temperature of 102 degrees Fahrenheit.Based on those factors, suitable habitat for the giant hornet exists along much of the U.S. west and east coasts, adjacent parts of Canada, much of Europe, northwestern and southeastern South America, central Africa, eastern Australia, and most parts of New Zealand.Much of the interior of the U.S. is inhospitable to the hornet due to extremes of heat, cold, and low rainfall. This includes the eastern parts of Washington state and British Columbia, as well as California's Central Valley, all of which have major fruit and nut crops that rely on honey bee pollination.Using data from a similar species, Vespa velutina, scientists predicted that without containment, Asian giant hornets could spread into southern Washington and Oregon, and north through British Columbia. Calculating that hornets could fly up to 68 miles per year, their worst-case scenario found that the insects could disperse throughout the western regions of Washington and Oregon in 20 years or less.However, scientists cautioned that these predictions are an educated guess."The information that we want -- how fast and far queens can fly, and when they fly -- is all unknown," Illan said. "A lot of basic biology is unknown. So, we're using a surrogate.""We know queens come out of their nest in the fall, mate, and fly -- somewhere," Looney said. But nobody knows how far they fly, or if they fly repeatedly. We don't know if they set up nests in the spring near where they hibernated, or if they start flying again. These are some of the things that make predicting natural dispersal a challenge."Nature alone cannot predict where the hornet may end up. Human activity plays a role in transporting invasive species around the globe. While colonies can only be started by mated queens, and a USDA analysis found that accidental transport by humans is unlikely, Looney said that human-assisted spread could be a concern."It's easy for some species to get moved accidentally from one side of the country to the other, even if there's a large swathe of unacceptable habitat in between," he said."Preventing the establishment and spread of Asian giant hornet in western North America is critical for protecting bees and beekeepers," Crowder said. "Our study can inform strategies to monitor and eradicate these invaders before they become established."
Published in "It turns out that the same ocean conditions that influence salmon returns, including the forage fish murrelets need to successfully nest, had a huge influence on the likelihood that murrelets will come inland to breed," said lead author Matt Betts, a researcher in the Oregon State College of Forestry and the director of the OSU-based Forest Biodiversity Research Network. "Given that these prey items tend to be in lower abundance when ocean temperatures are high, changing climate conditions could reduce prey availability as well as the tendency for murrelets to nest in the future."Marbled murrelets are closely related to puffins and murres, but unlike those birds, murrelets raise their young as much as 60 miles inland in mature forests. Disturbance in either the ocean or forest environment has the potential to impact murrelet populations."There aren't many species like it," said study co-author and project director Jim Rivers, also a faculty member in the College of Forestry. "There's no other bird that feeds in the ocean and commutes such long distances inland to nest sites. That's really unusual."The dove-sized bird spends most of its time in coastal waters eating krill, other invertebrates and forage fish such as herring, anchovies, smelt and capelin. Murrelets can only produce one offspring per year, if the nest is successful, and their young require forage fish for proper growth and development.Murrelets generally nest in solitude, although multiple nests sometimes occur within a small area. They typically lay their single egg high in a tree on a horizontal limb at least 4 inches in diameter, with Steller's jays, crows and ravens the main predators of murrelet nests."The end goal for these birds is to be very secretive and quiet so predators don't find their nests and they can produce young,' said Rivers.Along the West Coast, marbled murrelets are found regularly from Santa Cruz, California, north to the Aleutian Islands. Their populations have been declining by about 4% a year in Washington, Oregon and California, and the species is listed as threatened under the U.S. Endangered Species Act in those states."Early on in our work, we noticed strong fluctuations in the numbers of marbled murrelets coming inland to nest, so this study was about trying to get to the bottom of those highs and lows," Betts said. "We found the first evidence that ocean conditions combined with old-forest nesting habitat influence the murrelets' long-term occupancy dynamics. In particular, we learned ocean conditions are a key driver of those dynamics."The finding has potential key implications for forest policy in Oregon, where any state-owned site that goes two consecutive years without murrelet detection is classified as unoccupied and thus available for timber harvest."Our data show that below-average ocean conditions might last for more than two successive years," Rivers said. "That means there could be a scenario where sites on state lands that are suitable for breeding go unused for more than two years which, under current guidelines, would let them be considered available for harvest. Thus, murrelets might be missing from inland sites not because the forest is unsuitable for nesting, but because they have inadequate forage fish during the summer breeding season. That means it is critical that we consider factors that influence both marine food resources and terrestrial nesting habitat when considering how to recover murrelet populations."Betts was part of a research collaboration that published a 2019 paper in the Proceedings of the National Academy of Sciences that showed that old forest is still declining across the Pacific Northwest 25 years into the Northwest Forest Plan, a 100-year federal road map to protect older forests."This is now less due to the saw and more due to fire," he said. "That means that even with strong land conservation measures, climate could not only result in warmer ocean conditions but also greater fire frequency and extent, and therefore more old forest loss."Other Oregon State researchers contributing to the study were Kim Nelson and Dan Roby of the College of Agricultural Sciences and Jennifer Fisher of the Cooperative Institute for Marine Resources Studies. Scientists from Trent University in Ontario, Canada, the University of Rhode Island and the U.S. Forest Service also took part.The OSU College of Forestry and the USDA National Institute of Food and Agriculture provided funding.
"There were no data at all on how many people live in and around forests globally," says first author Peter Newton, an Assistant Professor in Environmental Studies at the University of Colorado Boulder. "The exercise was an initial step of trying to quantif
y the potential target population for projects that look at people's livelihoods in a forest environment."People who rely on forest resources for subsistence or income are commonly known as forest-dependent people. Although the number of forest-proximate people coincidently matches the 1.6 billion forest-dependent people from a widely cited estimation from the World Bank, living near the forest doesn't necessarily mean one relies on the forest for livelihood. Newton says that while "forest-dependent people" widely refers to people who derive some benefits from forests, the term "forest-proximate people" merely captures the spatial relationship between people and forests."Large numbers of people do live in and around forests, so that makes forests an important habitat and biome for thinking about sustainable development as well as about conservation," says Newton. "The programs, projects, and policies that affect forests also affect large numbers of people."To map out the spatial relationship between people and forests globally, Newton and his colleagues combined forest cover and human population density data for the year 2000 and 2012. They counted the number of people who lived within 5 km (3.1 miles) from the border of forests, which they defined as any area with more than 50 percent tree cover over 2 hectares (5 acres). But they excluded urban areas with a population above 1,500 people per square kilometer (0.4 square miles).The work provides a sketch to which other researchers and decision-makers could add on different layers of data, such as social, economic, or cultural details to paint a more complete picture. However, many of these datasets aren't available at a global level."What other researchers or we could do in the future is home in on a particular region where we did have data," says Newton. From local data, scientists could infer how many of those forest-proximate people were also forest dependent or living in poverty to help decision-makers implement spatial targeting and impact assessment.
In a new study published in Because the Arabian Peninsula is characterized by large, hyper-arid deserts inhospitable to early humans and the animals they relied on, Arabia has received considerably less attention than Africa or Eurasia, neighboring regions that are vital to understanding human prehistory. However, research over the last decade has shown that this was not always the case, and it is now well-understood that conditions in Arabia have fluctuated significantly over the past million years."At certain times in the past, the deserts that dominate the interior of the peninsula transformed into expansive grasslands with permanent freshwater lakes and rivers," explains Richard Clark-Wilson of Royal Holloway, one of the lead authors of the study. "It was during these periods of climatic upturn that human and animal populations dispersed into the interior, as shown by the archaeological and fossil record."The footprints described in the new study were discovered during a recent survey of the Nefud Desert in Saudi Arabia. At an ancient lake deposit dubbed 'Alathar' (meaning "the trace" in Arabic) by the team, hundreds of human and animal footprints were discovered embedded in the surface, having been exposed following the erosion of overlying sediments."We immediately realized the potential of these findings," says Mathew Stewart of MPI-CE, one of the study's lead authors. "Footprints are a unique form of fossil evidence in that they provide snapshots in time, typically representing a few hours or days, a resolution we tend not get from other records."Researchers were able to identify a number of animals from the footprints, including elephants, horses, and camels. The presence of elephants was particularly notable, as these large animals appear to have gone locally extinct in the Levant by around 400 thousand-years-ago."The presence of large animals such as elephants and hippos, together with open grasslands and large water resources, may have made northern Arabia a particularly attractive place to humans moving between Africa and Eurasia," says Michael Petraglia of MPI-SHH, who has been conducting research in the region for over a decade.The dense concentration of footprints and evidence from the lake sediments suggests that animals may have been congregating around the lake in response to dry conditions and diminishing water supplies. Humans, too, may have been utilizing the lake for water and the surrounding area for foraging."We know people visited the lake, but the lack of stone tools or evidence of the use of animal carcasses suggests that their visit to the lake was only brief," says Stewart. Human movements and landscape use patterns, therefore, may have been closely linked to the large animals they shared the area with.The age of the footprints is of particular interest. They date to a period known as the last interglacial, a time of relatively humid conditions across the region and an important moment in human prehistory. Environmental changes during the last interglacial would have allowed humans and animals to disperse across otherwise desert regions, which normally acted as major barriers to dispersal during the less humid periods. Fossil and archaeological records indicate that these conditions also facilitated human dispersal from Africa into the Levant."It is only after the last interglacial with the return of cooler conditions that we have definitive evidence for Neanderthals moving into the region," says Stewart. "The footprints, therefore, most likely represent humans, or Homo sapiens."These findings suggest that human movements beyond Africa during the last interglacial extended into northern Arabia, highlighting the importance of Arabia for the study of human prehistory.Researchers involved in this study work in close partnership with the Saudi Ministry of Culture. Additional partners include the Saudi Geological Survey, King Saud University, and other key institutions in the United Kingdom and Australia.
Orthione griffenis, a cough drop-sized crustacean native to Asia and Russia, has decimated mud shrimp populations in California and Washington over the past 30 years, causing the collapse of delicate mudflat ecosystems anchored by the shrimp. By the 2000s, it had reached as far as Vancouver Island. The discovery of O. griffenis at Calvert Island, described in a new study, represents a northward leap of more than 180 miles.Scientists found the parasite during a 2017 bioblitz, organized by the Hakai Institute and the Smithsonian Institution's Marine Global Earth Observatory, in which they intensely surveyed and documented marine life."I was on the lookout for things that seemed out of place," said study lead author Matt Whalen, a Hakai postdoctoral researcher at the University of British Columbia who studies coastal biodiversity. "But this particular parasite wasn't initially on my radar."Most scientists believed the parasites' expansion was exclusively mediated by human transport -- O. griffenisis thought to have first arrived in North America by traveling in ships' ballast water. Their appearance at Calvert Island, 150 miles from the nearest city of more than 5,000 people, shows "clearly, they can do it on their own," said study co-author Gustav Paulay, curator of invertebrate zoology at the Florida Museum of Natural History."This is such an astonishingly spectacular part of the planet," he said. "During the bioblitz, one of the things we talked about was that there were no invasive species at all. And then we found this thing."Whalen described the find as "a bit depressing.""We tended to associate this parasite with places that have a lot of marine traffic and aquaculture, like California and Oregon," he said in a statement. "Finding them on Calvert Island really suggests that there's very little preventing the spread because of the parasite's life cycle."The parasite is a bizarre crustacean called a bopyrid isopod. In the pre-adult part of its life, it hitches a ride on planktonic copepods -- an intermediate host that allows the isopods to travel to new and far-flung mudflats in search of shrimp blood. As adults, the parasites attach to the gills of another crustacean host, in this case a mud shrimp, Upogebia pugettensis, and proceed to sap the life from it. Infected mud shrimp are so hard done by that they lack the required energy to reproduce."They're essentially castrated," Paulay said.Mud shrimp may not be much to look at -- much like crayfish with stumpier claws -- but these homely crustaceans play an outsized role as environmental engineers in the mudflats of the Pacific Coast. They cycle nutrients when they filter food, pumping oxygenated water into an expansive network of tunnel dwellings, which provide housing for a suite of creatures, including gobies, worms, clams and other shrimp species. The shrimp's presence affects how the entire mudflat ecosystem functions -- or doesn't.When a parasite coevolves in the same place as its host, they often reach a sort of dÃ©tente, Paulay said. After all, the parasite needs a host to survive, and killing it off at once would not make a great long-term strategy. But when a parasite is introduced from elsewhere, that armistice may never arrive."The infection rates on Calvert Island were higher than I would've anticipated," Whalen said. "About one in four hosts were parasitized. That's a pretty good chunk of the population."For now, scientists are tracking the northward spread of the parasite. The parasite's prevalence on Calvert Island shows that it may only be a matter of time before it reaches the North Coast of British Columbia and moves onward to Alaska, the upper edge of the mud shrimp's range.For Paulay, the discovery of O. griffenis also underscores how marine bioblitzes can function as early warning systems for invasions."Every bioblitz we do, we find invasive species," he said. "If you catch them early enough, you have a chance to do something about it."
Led by Ferhat Karakas, a graduate student in mechanical engineering at the University of South Florida (USF), the study was co-authored by Jordan Wingate, a National Science Foundation (NSF) Research Experiences for Undergraduates (REU) intern at the Bermuda Institute of Ocean Sciences (BIOS); Leocadio Blanco-Bercial and Amy Maas, both associate scientists at BIOS; and David Murphy an assistant professor at USF.The study looked at the movements, or swimming kinematics, of nine species of warm water pelagic snails found in the waters off Bermuda: seven thecosome pteropods (which may have coiled, elongated, or globular shells), one gymnosome pteropod (which loses its juvenile shell during development), and one heteropod (which has a spiral shell). Pteropods, perhaps the most well-known among the pelagic snails, are often referred to as "sea butterflies," as their snail foot has evolved into a pair of wing-like appendages that appear to "flap" as they move through the water.Historically, study of these delicate organisms has been difficult, as they cannot be grown and maintained in a laboratory environment. However, the proximity of BIOS to the open ocean allowed living organisms to be collected and transported back to shore in under than one hour.Data collection began immediately upon return and most experiments were completed within one day of collection.Using a low magnification, high speed 3-D photography system, the research team was able to study the swimming behaviors of the snails, developing detailed models showing their swimming paths (trajectories) through the water column, swimming speeds, "flapping" rates of their appendages, and even the speeds at which they sank and how their shells were oriented as they did so."While different large-scale swimming patterns were observed, all species exhibited small-scale sawtooth-shaped swimming trajectories caused by reciprocal appendage flapping," Blanco Bercial said.The researchers then analyzed zooplankton samples collected from the surface to 3000 feet (1000 meters) with a MOCNESS net system (an array of long, tapered nets and sensors towed behind a research vessel) to determine the abundance and distribution of these organisms off Bermuda. When combined with molecular data and imaging using ZooScan, a device used to make digital images of zooplankton, the team was also able to relate swimming behaviors to night time and day time vertical distributions. Larger species sank down and swam up much faster and could be active at much greater depths, whereas the slower and smaller species were limited to shallower depths. This indicates that size does play a role in the vertical structure of habitat, as well as in predator-prey interactions."This project combined the expertise of engineers, molecular biologists, and ecologists, as well as a variety of different technologies, to look at the movement, ecology, and distribution of this beautiful group of organisms," Maas said. "This type of transdisciplinary collaboration doesn't happen very often and it allowed us to learn about an aspect of ocean science that has previously been understudied."Adding to the uniqueness of this investigation is the role of the study's second author, Jordan Wingate, who was an NSF REU intern at BIOS in 2018 while attending Georgia Military College. During the course of her three-month internship, Wingate worked with Maas on a project that became the basis for this paper, eventually presenting the results of their research at the 2020 Ocean Sciences Meeting in San Diego, California."I feel so accomplished to be a published author in a peer-reviewed scientific journal as an undergraduate student," said Wingate, who will graduate from the University of West Florida in the fall of 2021 with a bachelor's degree in marine biology. "I was very fortunate to be able to see this project through from start to finish and I'm grateful to Amy for her mentorship and guidance as I worked through the challenges of learning about pteropods, new computer programming languages, and the data analysis skills required to get this study published."
The world's food production depends directly on phosphorus. However, this plant nutrient is not unlimited, but comes from finite geological reserves. How soon these reserves might be exhausted is the subject of scholarly debate. Just as controversial is the question which states own the remaining reserves and the political dependencies this creates.An international research team led by Professor Christine Alewell has investigated which continents and regions worldwide are suffering the greatest loss of phosphorus. The researchers combined high-resolution spatially discrete global data on the phosphorus content of soils with local erosion rates. Based on this, they calculated how much phosphorus is lost through erosion in different countries.An important conclusion of the study is that more than 50% of global phosphorus loss in agriculture is attributable to soil erosion. "That erosion plays a role was already known. The extent of that role has never before been quantified with this level of spatial resolution," Alewell explains. Previously, experts reported losses primarily due to lack of recycling, food and feed waste, and general mismanagement of phosphorus resources.Erosion flushes mineral bound phosphorus out of agricultural soils into wetlands and water bodies, where the excess of nutrients (called eutrophication) harms the aquatic plant and animal communities. The researchers were able to validate their calculations using globally published measurement data on phosphorus content in rivers: the elevated phosphorus content in waters mirrors the calculated loss of phosphorus in the soil in the respective region.Mineral fertilizers can replace the lost phosphorus in the fields, but not all countries are equally able to use them. Although countries such as Switzerland can develop solutions thanks to organic fertilizers and potentially relatively closed phosphorus cycles (see box) in agriculture, Africa, Eastern Europe and South America register the greatest phosphorus losses -- with limited options for solving the problem. "It's paradoxical, especially as Africa possesses the largest geological phosphorus deposits," says Alewell. "But the mined phosphorus is exported and costs many times more for most farmers in African countries than, for example, European farmers." In Eastern Europe economic constraints are also the most crucial factor of phosphorus deficiency.South America could potentially mitigate the problem with efficient use of organic fertilizer and/or better recycling of plant residues. On the other hand, farmers in Africa do not have this option: Africa has too little green fodder and too little animal husbandry to replace mineral fertilizers with manure and slurry, says Alewell.It is still unclear when exactly phosphorus for global agriculture will run out. New large deposits were discovered a few years ago in Western Sahara and Morocco, although how accessible they are is questionable. In addition, China, Russia, and the US are increasingly expanding their influence in these regions, which suggest that they might also control this important resource for global future food production. Europe has practically no phosphorus deposits of its own."95% of our food is directly or indirectly produced as a result of plants growing in the soil. The creeping loss of the plant nutrient phosphorus should be of concern to all people and societies," says Alewell. If countries want to secure their independence from those states that possess the remaining large deposits, they must seek to minimize phosphorus losses in soils.A drastic reduction in soil erosion is a major and important step in the right direction. Land managers can reduce erosion by ensuring ground cover for as long as possible; for example, through mulching, green manure and intercropping, and through topography-adapted cultivation -- tilling fields transversely to the slope or terracing.
The complex and scientifically challenging research was completed aboard Schmidt Ocean Institute's research vessel Falkor, on its fourth expedition of the year, as part of the Institute's Australia campaign. Using a remotely operated underwater robot to view high-resolution video of the bottom of the ocean floor, some 1,820 meters deep, the science team examined deep sea bathymetry, wildlife, and ecosystems. The collaborative mission brought together scientists from Geoscience Australia, James Cook University, University of Sydney, Japan Agency for Marine-Earth Science and Technology (JAMSTEC), Queensland Museum Network, and Queensland University of Technology, to answer a range of questions about the geological evolution and biology of the deep sea canyons and reefs."This included the most comprehensive midwater robotic dive survey series to ever have been conducted in the South Pacific," said Dr. Brendan Brooke, the expedition's lead scientist from Geoscience Australia. "Research vessel Falkor has integrated a range of technologies that have allowed us to work across the full range of ocean depths in the Coral Sea and to provide data for multiple disciplines including geology, biology, and oceanography."During the expedition, researchers took the deepest samples ever collected of soft coral and scleractinian coral in the Coral Sea. They also collected the first sample of ancient bedrock beneath the Great Barrier Reef, estimated to be between 40 and 50 million years old. Scientists made the first recorded observation in Australia of the extremely rare fish Rhinopias agroliba , a colorful and well-camouflaged ambush predator in the scorpionfish family. The cruise also included the most comprehensive survey of midwater jellyfish in the South Pacific.In addition to the underwater dives, high-resolution mapping of the seafloor was conducted and covered 38,395 square kilometers, an area three times greater than Sydney. The maps include all the major coral atolls on the Queensland Plateau within the Coral Sea Marine Park and an 80-kilometer section of canyons off the northern Great Barrier Reef Marine Park."These maps, samples, and images are fascinating and provide a new understanding of the geological diversity and biological wealth of a region that is already world-renowned for its natural beauty," said Dr. Jyotika Virmani, executive director of Schmidt Ocean Institute. "The data will help marine park managers to protect these ecosystems that are so vital for our global biodiversity and human health. "Live streaming of the 18 underwater robotic dives via Schmidt Ocean's channel on YouTube and 112 hours of high definition underwater video during the month-long expedition, which ended August 30, allowed the science team to share their knowledge and excitement of the voyage's discoveries with the world. Through the livestreams, the scientists could interact directly with the public via chat and commentary."Schmidt Ocean Institute and the technology that it has brought to Australia is a huge enabler in better understanding our marine resources from a lens of diverse disciplines," said Dr. Scott Nichol, one of the lead expedition scientists from Geoscience Australia. "This work brings new understanding and will keep the scientists busy for years."
In a new proposal published in They call this proposed technology LAPO, or Live Streaming with Actual Proportionality of Objects. LAPO employs both information geometry -- the measures of an object's curvatures, angles and area -- and conformal mapping, which uses the measures of angles between the curves of an object and accounts for the distance between objects, to make images of people, places and things seem more real."This is about having a new kind of technology that uses advanced mathematical techniques to turn digitized data, captured live at a tourist site, into more realistic photos and videos with more of a feel for the location than you would get watching amovie or documentary," says corresponding author Rao. "When you go see the Statue of Liberty for instance, you stand on the bank of the Hudson River and look at it. When you watch a video of it, you can only see the object from one angle. When you measure and preserve multiple angles and digitize that in video form, you could visualize it from multiple angles. You would feel like you're there while you're sitting at home."Their proposed combination of techniques is novel, Rao says. "Information geometry has seen wide applications in physics and economics, but the angle preservation of the captured footage is never applied," he says.Rao and Krantz say the technology could help mediate some of the pandemic's impact on the tourism industry and offer other advantages.Those include its cost-effectiveness, because virtual tourism would be cheaper; health safety, because it can be done from the comfort of home; it saves time, eliminating travel times; it's accessibility -- tourism hotspots that are not routinely accessible to seniors or those with physical disabilities would be; it's safer and more secure, eliminating risks like becoming a victim of crime while traveling; and it requires no special equipment -- a standard home computer with a graphics card and internet access is all that's needed to enjoy a "virtual trip.""Virtual tourism (also) creates new employment opportunities for virtual tour guides, interpreters, drone pilots, videographers and photographers, as well as those building the new equipment for virtual tourism," the authors write."People would pay for these experiences like they pay airlines, hotels and tourist spots during regular travel," Rao says. "The payments could go to each individual involved in creating the experience or to a company that creates the entire trip, for example."Next steps include looking for investors and partners in the hospitality, tourism and technology industries, he says.If the pandemic continues for several more months, the World Travel and Tourism Council, the trade group representing major global travel companies, projects a global loss of 75 million jobs and $2.1 trillion in revenue.Rao is a professor of health economics and modeling in the MCG Department of Population Health Sciences.
One of the challenges of moving toward fully renewable energy is matching production to demand. Though the state has high existing solar energy capacity and the potential for even more, the supply of solar power peaks in the middle of the day and ends when the sun goes down. Consumer demand, on the other hand, peaks in the evening when people return from work around or after sunset.Because storage of solar energy on a large scale is not yet practical, other renewable sources are needed to meet the Golden State's environmental milestone of going fully renewable.The Cal Poly research team found that offshore winds are strongest when demand is greatest, making it an ideal candidate to fill the gap left by solar and on-shore wind energy production. The team was led by research scientist Yi-Hui Wang and included biology professors Ben Ruttenberg and Crow White and physics Professor Ryan Walter."The alignment between potential offshore wind power production and demand highlights the important role that offshore wind energy could play in meeting California's ambitious renewable energy goals," Wang said.Even more promising, offshore winds reach their peak during the hot summer months when state energy use is highest due to the use of air conditioning. Offshore wind energy offers several other advantages over land-based wind and solar energy, including stronger and more consistent winds and less impact on other land uses.The greatest wind speeds, which would produce the most energy, are found farther from the coast. Most existing offshore wind farms are installed close to shore in shallow water less than 160 feet deep. However, several floating wind farms in deeper water farther from shore are now in operation in Europe, with more in the planning stages."Floating offshore wind farms are now a proven technology and game-changer in many respects," Walter said. "These floating platforms make offshore wind farms a new reality in many locations, with a single turbine having the potential to power more than 10,000 homes."The Bureau of Ocean Energy Management, which funded the study, is considering the Central Coast as a location for California's first offshore wind farm and has proposed priority areas for leasing by energy companies. The Cal Poly study provides crucial information that, along with other studies on economic, cultural and environmental factors, will help guide the evaluation and planning of offshore wind energy."Looking at this wind data in relation to maps of fisheries, whale and seabird activity will help identify locations where offshore wind farms could add the most value and yet have the least impact on local economies and marine wildlife," White said.The Cal Poly team is working on the next steps, which include estimating the total amount of electricity wind farms in the area could produce and how these wind farms might affect the broader economy of San Luis Obispo County."Ultimately, we hope this information and our ongoing work will inform the conversation, helping the policymakers and citizens of California decide if, how and where to prioritize renewable offshore wind energy," Ruttenberg said.
In recent years, microdiamonds have received a great deal of attention because they have been discovered in metamorphic rocks around the world and it has become clear that they are formed in collisions between continents. It was thought that Japan would not produce such microdiamonds because it is not a continental collision zone, but an oceanic plate subduction zone. However, the first microdiamonds from metamorphic rocks in Japan were found in the Nishisonogi metamorphic rock formation in the west coast of Nagasaki Prefecture.The area where the microdiamonds were discovered is an approximately 100-million-year-old Cretaceous metamorphic rock formation. On the west coast of Saikai City in Nagasaki Prefecture, blocks of pelitic and basic schist are scattered amongst serpentinite that was created from mantle material. Such rocks are called a serpentinite mÃ©lange and indicate that they have risen from deep in the subduction zone. Researchers found microdiamonds here, in the serpentinite mÃ©lange. Their formation conditions have been estimated to be a temperature of about 450 Â°C and a pressure of about 2.8 GPa, which makes them the coldest diamonds ever formed. It has been thought that the Nishisonogi metamorphic rock was formed under a pressure of about 1 GPa, but it is now clear that they were ultrahigh-pressure metamorphic rocks that rose after subducting to 120 km -- a very unexpected discovery."The discovery of microdiamonds from Japan's first metamorphic rocks will rewrite Japan's geological history," said Professor Tadao Nishiyama, the leader of this study. "Until now, the Nagasaki metamorphic rocks were said to belong to a low-temperature, high-pressure-type metamorphic rock belt, the "Sanbagawa Belt," which crosses the Japanese mainland. It has become clear, however, that they are independently-formed ultrahigh-pressure metamorphic rocks. I expect that there will be many discussions about what kind of plate movement created this formation."
The Gulf of Mexico receives considerable levels of nutrients from the rivers that empty into it, especially the Mississippi River, which causes the Gulf's northern shelf waters to become overly enriched and more susceptible to algae growth. But scientists have remained unsure whether a significant portion of those nutrients ever leave the Gulf to potentially impact the chemistry of the North Atlantic Ocean."The Gulf of Mexico is an economically important body of water, as the surrounding areas rely on it for tourism, fisheries and oil production, and it also has significant ecological diversity," said Samantha Howe, a graduate student in the College of Arts and Sciences' Department of Earth, Ocean and Atmospheric Science, who led the research. "It is important to track the nutrient input from the Mississippi and Atchafalaya River System to the Gulf as those nutrients contribute to harmful algal blooms on the Northern Gulf Shelf."Researchers found no evidence that nitrate from the Mississippi-Atchafalaya River System is mixing across the Northern Gulf shelf into the open waters of the Gulf of Mexico. The findings are consistent with recent modeling work by fellow scientists that indicates 90 percent of Mississippi River nutrients are retained in the near-shore ecosystem, which implies that nutrients from the Mississippi River do not leave the Gulf."In order to assess and manage ecological challenges in the Gulf, it is critical to understand whether the nutrients are processed and retained nearshore or whether they are transported to the North Atlantic," Howe said. "This finding is valuable to know, as these ecosystems must harbor the nutrient burden."To conduct the study, the team collected and analyzed water samples taken during four different research cruises to the Gulf and the Florida Straits from 2011 to 2018.The research is the first ever to provide isotopic composition measurements of nitrate in the Gulf of Mexico, as well as a new isotopic profile from the Florida Straits. These new water column profiles were then compared with prior measurements from the North and South Atlantic and with the magnitude of nitrogen inputs to the Gulf.Howe, who earned her bachelor's degree in environmental science from FSU in Spring 2019, is now pursuing her master's in aquatic environmental science. She began the nutrient research as part of her honors undergraduate thesis while working in the research lab of study co-author, Associate Professor of Oceanography Angela Knapp."Samantha's thesis looked for distinct geochemical signatures of nitrate from the Mississippi River and whether this nitrate made it off the Northern Gulf of Mexico shelf into the deep waters of the Gulf that mix with the Loop Current and leave via the Florida Straits to enter the North Atlantic," Knapp said.Howe's collaborators on the study include co-authors Knapp and Carlos Miranda, a 2017 graduate of the FSU Department of Chemistry and Biochemistry and the FSU Department of Biological Science, and colleagues from the University of Southern Mississippi and the University of New Hampshire."This work has important implications for understanding the fate of nutrients from the Mississippi Atchafalaya River System and how to manage human inputs to coastal ecosystems," Knapp said.The research was funded by the National Science Foundation's Division of Ocean Sciences .
Published in a special edition of the journal The research, led by Dr Helen Wheeler of Anglia Ruskin University (ARU), involved participants from the Arctic regions of Norway, Sweden, Greenland, Russia, Canada, and the United States.Indigenous peoples inhabit 25% of the land surface and have strong links to their environment, meaning they can provide unique insights into natural systems. However, the greater resources available to scientists often creates a power imbalance when environmental decisions are made.The study's Indigenous participants identified numerous problems, including that Indigenous knowledge is often perceived as less valuable than scientific knowledge and added as anecdotes to scientific studies.They also felt that Indigenous knowledge was being forced into frameworks that did not match Indigenous people's understanding of the world and is often misinterpreted through scientific validation. One participant expressed the importance of Indigenous knowledge being reviewed by Indigenous knowledge holders, rather than by scientists.Another concern was that while funding for Arctic science was increasing, the same was not happening for research rooted in Indigenous knowledge or conducted by Indigenous peoples.Gunn-Britt Retter, Head of the Arctic and Environmental Unit of the Saami Council, said: "Although funding for Arctic science is increasing, we are not experiencing this same trend for Indigenous knowledge research."Sometimes Indigenous organisations feel pressured to agree to requests for collaboration with scientists so that we can have some influence in decision-making, even when these collaborations feel tokenistic and do not meet the needs of our communities. This is because there is a lack of funding for Indigenous-led research."Victoria Buschman, Inupiaq Inuit wildlife and conservation biologist at the University of Washington, said: "Much of the research community has not made adequate space for Indigenous knowledge and continues to undermine its potential for information decision-making. We must let go of the narrative that working with Indigenous knowledge is too challenging."The study concludes that values, laws, institutions, funding and mechanisms of support that create equitable power-relations between collaborators are necessary for successful relationships between scientists and Indigenous groups.Lead author Dr Helen Wheeler, Lecturer in Zoology at Anglia Ruskin University (ARU), said: "The aim of this study was to understand how to work better with Indigenous knowledge. For those who do research on Indigenous people's land, such as myself, I think this is an important question to ask."Our study suggests there are still misconceptions about Indigenous knowledge, particularly around the idea that it is limited in scope or needs verifying by science to be useful. Building capacity for research within Indigenous institutions is also a high priority, which will ensure Indigenous groups have greater power when it comes to informed decision-making."Indigenous knowledge is increasingly used in decision-making at many levels from developing international policy on biodiversity to local decisions about how to manage wildlife. However, as scientists and decision-makers use knowledge, they must do so in a way that reflects the needs of Indigenous knowledge holders. This should lead to better decisions and more equitable and productive partnerships."
Dr Kris Wyckhuys from UQ's School of Biological Sciences said biological control involved the careful release of an exotic natural enemy from a pest's native habitat."Scientists meticulously choose co-evolved beneficial insects that are the most effective and least likely to pose ecological upsets," Dr Wyckhuys said."We've reviewed how biological control introductions have effectively managed 43 insect pests in food, feed and fibre crops in the Asia-Pacific region over a century."The team found that biological control has helped regulate invasive pest threats in multiple key food crops such as banana, breadfruit and coconut."Our work shows these techniques are saving farmers in Asia around $20.1 billion to $26.8 billion (US$14.6-19.5 billion) per year," Dr Wyckhuys said."That's a phenomenal amount of money and benefit, particularly when compared to other innovations in the agricultural sector."A good point of comparison is the Green Revolution in Asia during the late 1960s, which tripled the output of local rice production but also saw a rise of chemical fertilisers, agrochemicals and newer methods of cultivation."A large part of the Green Revolution impacts can be ascribed to double-yielding rice varieties, which generated $4.8 billion (US$4.3 billion) per year in Asia."UQ's Associate Professor Michael Furlong said recognition of the success of biological control might lead to greater uptake and more resilient, prosperous farming globally."Biological control offers great opportunities for some of the world's poorest farmers," Dr Furlong said."It's promoted rural growth and prosperity even in marginal, poorly endowed, non-rice environments."A great example is the coconut scale (Aspidiotus destructor), which jeopardised the economic prosperity and food security of entire nations."This coconut scale posed a serious problem to crops like coconut, bananas and copra industries in Fiji at the start of the Twentieth Century."In 1928, lady beetles from Trinidad and millimetre-long parasitic wasps were introduced, and the results were almost immediate."Coconut scale ceased to be an economic issue on all of the main Fijian islands within nine months, and after 18 months, the scale was so rare it was difficult to find."These innovative approaches, with increasingly better science, are helping feed the world, safeguard on-farm biodiversity and increase farmers' quality of life."We're hoping this research provides lessons for future efforts to mitigate invasive species, restore ecological resilience, and sustainably increase the output of our global food system."
"We're seeing a shift from predominantly freshwater fishes to marine fishes in the Panama Canal (Lake Gatun) in a short period of time," said Mark Torchin, STRI marine ecologist. "The concern is that if fish invasions continue there is a good chance of some of those fishes moving into the other ocean, with unknown environmental consequences."Larger locks to allow transit of NeoPanamax vessels (NeoPanamax refers to ships too big to pass through the original 1914 locks) through the Panama Canal were finished in 2016. Expansion of the Suez Canal to include a new, 35-kilometer channel concluded in 2015."During the planning phases of both projects, researchers warned about the risks of expanding these two canals," said Gustavo Castellanos-Galindo, postdoctoral fellow at STRI and guest scientist at ZMT. "This report documents those changes in real time."Only four years after the Panama Canal expansion, long-term monitoring recorded the presence of 11 new marine fish species in Lake Gatun, which has served as a freshwater barrier to movement of marine fauna between Pacific and Atlantic Oceans since the canal opened in 1914. This takes the total number of marine fish species known from in the lake from 18 to 29. Marine fishes such as jacks, snooks, mojarras and ladyfish have entirely replaced freshwater fishes in some parts of the lake.Salinity in the lake increased, although the cause has not yet been determined. Possibilities include increased ship traffic and lock usage and the new locks' design, which incorporates recirculation of some lockage water."These marine fish invasions are an early warning sign of what could happen if no corrective measures are taken," Castellanos-Galindo said. "Along both coasts of Panama there are hundreds of fish species that could tolerate the conditions of an even slightly brackish canal. We don't know what the ecological and socioeconomic consequences of these fishes crossing the canal to either the Pacific or the Atlantic would be.""We can document the Panama Canal invasions because we have good, standardized and quantitative pre-expansion data," said D. Ross Robertson, STRI ichthyologist. "We need to get back out there to collect more data to find out exactly what is going on and to provide the science that will help policy makers mitigate the potential impact. This is a really good example of how the pandemic has interrupted field work with important implications for environmental decision making."Whereas the barrier to fish crossing from ocean to ocean in Panama is a freshwater lake, in the Suez waterway, the Bitter Lakes were originally saltier than the Mediterranean and Red Sea, which also limited species movement. Nonetheless, throughout the history of the Suez Canal, more than 400 non-native animal species, including more than 100 species of marine fishes from the Red Sea, have entered the Mediterranean. With canal expansion, increased water flow diluted the lakes and eight new fish species entered the Mediterranean during the past five years.Because fees for shipping through the canals account for roughly 10% of the gross domestic product in Panama and in Egypt, there is an economic incentive to continue to increase shipping traffic through the canals. The authors suggest creative, science-based solutions to limit environmental and socioeconomic damage. They propose that the UN Decade of Ocean Science for Sustainable Development (2021-2030) may provide the ideal opportunity for ensuring that the canals are included in international maritime policy to limit the environmental and economic impacts of invasive species. In addition, because policy changes can take a long time to implement, they also suggest that the shipping industry could proactively address this issue.The UN agency responsible for sustainable shipping, the International Maritime Organization, has implemented guidelines and obligations to reduce the spread of non-native species through ballast water -- but they do not apply specifically to the canals.In the case of the Suez Canal, it may be possible to use the hypersaline effluent from desalinization plants to make the Bitter Lakes saltier again, with the caveat that this alternative should be studied carefully before implementing. In both cases, sophisticated monitoring tools -- using DNA in water samples to generate lists of the species detected and using sound to detect invaders, may help to catch invaders early before they establish large populations. Technology may also be put to work to directly address invasion by means of acoustic and/or electric barriers to deter invaders.The authors hope that all of the stakeholders will recognize the importance of having the best scientific data in hand as they design new policy and mitigation measures.
But now, following a decade of research, a multinational study has refuted this assumption. Debora Iglesias-Rodriguez, professor and vice chair of UC Santa Barbara's Department of Ecology, Evolution, and Marine Biology, and her colleagues discovered that the seawater ratios of three key elements vary across the ocean, which means scientists will have to re-examine many of their hypotheses and models. The results appear in the Proceedings of the National Academy of Sciences.Calcium, magnesium and strontium (Ca, Mg and Sr) are important elements in ocean chemistry, involved in a number of biologic and geologic processes. For instance, a host of different animals and microbes use calcium to build their skeletons and shells. These elements enter the ocean via rivers and tectonic features, such as hydrothermal vents. They're taken up by organisms like coral and plankton, as well as by ocean sediment.The first approximation of modern seawater composition took place over 130 years ago. The scientists who conducted the study concluded that, despite minor variations from place to place, the ratios between the major ions in the waters of the open ocean are nearly constant.Researchers have generally accepted this idea from then on, and it made a lot of sense. Based on the slow turnover of these elements in the ocean -- on the order of millions of years -- scientists long thought the ratios of these ions would remain relatively stable over extended periods of time."The main message of this paper is that we have to revisit these ratios," said Iglesias-Rodriguez. "We cannot just continue to make the assumptions we have made in the past essentially based on the residency time of these elements."Back in 2010, Iglesias-Rodriguez was participating in a research expedition over the Porcupine Abyssal Plain, a region of North Atlantic seafloor west of Europe. She had invited a former student of hers, this paper's lead author Mario Lebrato, who was pursuing his doctorate at the time.Their study analyzed the chemical composition of water at various depths. Lebrato found that the Ca, Mg and Sr ratios from their samples deviated significantly from what they had expected. The finding was intriguing, but the data was from only one location.Over the next nine years, Lebrato put together a global survey of these element ratios. Scientists including Iglesias-Rodriguez collected over 1,100 water samples on 79 cruises ranging from the ocean's surface to 6,000 meters down. The data came from 14 ecosystems across 10 countries. And to maintain consistency, all the samples were processed by a single person in one lab.The project's results overturned the field's 130-year old assumption about seawater chemistry, revealing that the ratio of these ions varies considerably across the ocean.Scientists have long used these ratios to reconstruct past ocean conditions, like temperature. "The main implication is that the paleo-reconstructions we have been conducting have to be revisited," Iglesias-Rodriguez explained, "because environmental conditions have a substantial impact on these ratios, which have been overlooked."Oceanographers can no longer assume that data they have on past ocean chemistry represent the whole ocean. It has become clear they can extrapolate only regional conditions from this information.This revelation also has implications for modern marine science. Seawater ratios of Mg to Ca affect the composition of animal shells. For example, a higher magnesium content tends to make shells more vulnerable to dissolution, which is an ongoing issue as increasing carbon dioxide levels gradually make the ocean more acidic. "Biologically speaking, it is important to figure out these ratios with some degree of certainty," said Iglesias-Rodriguez.Iglesias-Rodriguez's latest project focuses on the application of rock dissolution as a method to fight ocean acidification. She's looking at lowering the acidity of seawater using pulverized stones like olivine and carbonate rock. This intervention will likely change the balance of ions in the water, which is something worth considering. As climate change continues unabated, this intervention could help keep acidity in check in small areas, like coral reefs.
The University of Cincinnati found that satellite imagery can identify nonnative and invasive Amur honeysuckle, an ornamental shrub introduced from Asia that has spread in forests across much of the United States.UC graduate Bridget Taylor, UC biology professor Denis Conover and UC geography professor Richard Beck used satellite imagery to find nonnative invasive Amur honeysuckle in several urban parks and cemeteries from space.Using one of the satellites in a series of Earth-observing missions jointly managed by NASA and the U.S. Geological Survey, the Landsat-8 satellite can measure the reflection of wavelength energy in the red and near-infrared bands. The ratio of the two wavelengths helps scientists identify foliage of different plants from orbit.UC found that the method was effective in detecting Amur honeysuckle, according to a study published in the journal Amur honeysuckle bushes grow in thick patches, often crowding out and outcompeting other plants in a forest's understory. It has an extended growing season, leafing out earlier and staying green far later in the year than many native trees and shrubs.UC used Landsat-8 images to examine five urban forests in Greater Cincinnati. The goal: to develop an inexpensive and efficient remote mapping approach for ecological restoration in urban forests. They used global-positioning satellites to corroborate their mapping observations on the ground. They found that their maps were 82% accurate."The fact that it was possible to use the satellite imagery in an urban setting was pretty unique," said Taylor, the study's lead author."Urban areas have a lot of noise in satellite imagery. So it's harder to identify specific details," she said.Taylor has participated in efforts to eradicate the nonnative Amur honeysuckle in places like Burnet Woods, the park adjacent to UC's Uptown campus."It's very bushy. Birds like to eat the berries and spread the seeds," she said. "It has a chance to green up and leaf out sooner than native plants, so native wildflowers often get killed off when they're growing under honeysuckle."The study shows that satellite images can provide an effective, inexpensive alternative to using drones or ground surveys to identify larger patches of the invasive bushes for ecological restoration, Taylor said.
For the study, the authors conducted almost 100 interviews with Indonesian smallholders, people from the village and decision-makers in the Jambi province of Sumatra. They then compared and supplemented their analyses of these results with scientific measurements of precipitation, river and groundwater levels, soil properties as well as land use mapping from the region. "Many studies on the relationship between land use changes and flooding are only based on analyses by individual disciplines and thus provide only fragmentary insights into the underlying processes," says lead author Jennifer Merten, Department of Human Geography at the University of GÃ¶ttingen. "It was therefore important for us to use the widest possible range of data from different disciplines and also to include observations from the local population."In their study, the scientists of the German-Indonesian Collaborative Research Centre EFForTS (Ecological and Socio-Economic Functions of Tropical Lowland Rainforest Transformation Systems) show that the current expansion of oil palm and rubber plantations has a significant impact on local water cycles. "The large-scale land-use change leads to a compaction of the soil, so that less rain is absorbed by the soil and the water quickly runs off at the surface," explains co-author Christian Stiegler, Bioclimatology Group at the University of GÃ¶ttingen. "In particular, the advancing destruction of floodplains plays an important role in this process." From the perspective of the village population, the construction of flood dams and drainage channels also contributes to a change in local patterns of flooding. As oil palm plantations in particular are increasingly cultivated in wetlands such as river floodplains or peatlands, larger plantation owners are trying to control flooding on their land by means of such constructions. "However, such dams often lead to increased flooding on neighbouring smallholder plantations," Merten reports following her experiences from the area. This means that the observed increase in flooding also leads to new social tensions and conflicts.In order to reduce the impact of land use change on the water cycle, soil protection and improved land use planning, especially in floodplains and wetlands, can play an important role. "Yet, it is just as important to regulate and control landscape interventions for flood protection and drainage more closely," says Merten. "Otherwise it might happen that the effects of increasing flooding will affect above all the poorest in society, because larger companies simply pass on the water."
According to new research, this type of adaptation has a long history. In a paper published Aug. 27 in the journal The creature, a member of the genus Lystrosaurus, was a distant relative of mammals. Antarctica during Lystrosaurus' time lay largely within the Antarctic Circle, like today, and experienced extended periods without sunlight each winter.The fossils are the oldest evidence of a hibernation-like state in a vertebrate animal, and indicates that torpor -- a general term for hibernation and similar states in which animals temporarily lower their metabolic rate to get through a tough season -- arose in vertebrates even before mammals and dinosaurs evolved."Animals that live at or near the poles have always had to cope with the more extreme environments present there," said lead author Megan Whitney, a postdoctoral researcher at Harvard University who conducted this study as a UW doctoral student in biology. "These preliminary findings indicate that entering into a hibernation-like state is not a relatively new type of adaptation. It is an ancient one."Lystrosaurus lived during a dynamic period of our planet's history, arising just before Earth's largest mass extinction at the end of the Permian Period -- which wiped out about 70% of vertebrate species on land -- and somehow surviving it. The stout, four-legged foragers lived another 5 million years into the subsequent Triassic Period and spread across swathes of Earth's then-single continent, Pangea, which included what is now Antarctica."The fact that Lystrosaurus survived the end-Permian mass extinction and had such a wide range in the early Triassic has made them a very well-studied group of animals for understanding survival and adaptation," said co-author Christian Sidor, a UW professor of biology and curator of vertebrate paleontology at the Burke Museum.Paleontologists today find Lystrosaurus fossils in India, China, Russia, parts of Africa and Antarctica. These squat, stubby, creatures -- most were roughly pig-sized, but some grew 6 to 8 feet long -- had no teeth but bore a pair of tusks in the upper jaw, which they likely employed to forage among ground vegetation and dig for roots and tubers, according to Whitney.Those tusks made Whitney and Sidor's study possible. Like elephants, Lystrosaurus tusks grew continuously throughout their lives. The cross-sections of fossilized tusks can harbor life-history information about metabolism, growth and stress or strain. Whitney and Sidor compared cross-sections of tusks from six Antarctic Lystrosaurus to cross-sections of four Lystrosaurus from South Africa.Back in the Triassic, the collection sites in Antarctica were at about 72 degrees south latitude -- well within the Antarctic Circle, at 66.3 degrees south. The collection sites in South Africa were more than 550 miles north during the Triassic at 58-61 degrees south latitude, far outside the Antarctic Circle.The tusks from the two regions showed similar growth patterns, with layers of dentine deposited in concentric circles like tree rings. But the Antarctic fossils harbored an additional feature that was rare or absent in tusks farther north: closely-spaced, thick rings, which likely indicate periods of less deposition due to prolonged stress, according to the researchers."The closest analog we can find to the 'stress marks' that we observed in Antarctic Lystrosaurus tusks are stress marks in teeth associated with hibernation in certain modern animals," said Whitney.The researchers cannot definitively conclude that Lystrosaurus underwent true hibernation -- which is a specific, weeks-long reduction in metabolism, body temperature and activity. The stress could have been caused by another hibernation-like form of torpor, such as a more short-term reduction in metabolism, according to Sidor.Lystrosaurus in Antarctica likely needed some form of hibernation-like adaptation to cope with life near the South Pole, said Whitney. Though Earth was much warmer during the Triassic than today -- and parts of Antarctica may have been forested -- plants and animals below the Antarctic Circle would still experience extreme annual variations in the amount of daylight, with the sun absent for long periods in winter.Many other ancient vertebrates at high latitudes may also have used torpor, including hibernation, to cope with the strains of winter, Whitney said. But many famous extinct animals, including the dinosaurs that evolved and spread after Lystrosaurus died out, don't have teeth that grow continuously."To see the specific signs of stress and strain brought on by hibernation, you need to look at something that can fossilize and was growing continuously during the animal's life," said Sidor. "Many animals don't have that, but luckily Lystrosaurus did."If analysis of additional Antarctic and South African Lystrosaurus fossils confirms this discovery, it may also settle another debate about these ancient, hearty animals."Cold-blooded animals often shut down their metabolism entirely during a tough season, but many endothermic or 'warm-blooded' animals that hibernate frequently reactivate their metabolism during the hibernation period," said Whitney. "What we observed in the Antarctic Lystrosaurus tusks fits a pattern of small metabolic 'reactivation events' during a period of stress, which is most similar to what we see in warm-blooded hibernators today."If so, this distant cousin of mammals isn't just an example of a hearty creature. It is also a reminder that many features of life today may have been around for hundreds of millions of years before humans evolved to observe them.The research was funded by the National Science Foundation.
Working with scientists from Australia's Flinders' University and privately-owned research firm Nova Blue Environment, biology doctoral student Bruno Carturan has been studying the ecosystems of the world's endangered reefs."Coral reefs are among the most diverse ecosystems on Earth and they support the livelihoods of more than 500 million people," says Carturan. "But coral reefs are also in peril. About 75 per cent of the world's coral reefs are threatened by habitat loss, climate change and other human-caused disturbances."Carturan, who studies resilience, biodiversity and complex systems under UBCO Professors Lael Parrott and Jason Pither, says nearly all the world's reefs will be dangerously affected by 2050 if no effective measures are taken.There is hope, however, as he has determined a way to examine the reefs and explore why some reef ecosystems appear to be more resilient than others. Uncovering why, he says, could help stem the losses."In other ecosystems, including forests and wetlands, experiments have shown that diversity is key to resilience," says Carturan. "With more species, comes a greater variety of form and function -- what ecologists call traits. And with this, there is a greater likelihood that some particular traits, or combination of traits, help the ecosystem better withstand and bounce back from disturbances."The importance of diversity for the health and stability of ecosystems has been extensively investigated by ecologists, he explains. While the consensus is that ecosystems with more diversity are more resilient and function better, the hypothesis has rarely been tested experimentally with corals.Using an experiment to recreate the conditions found in real coral reefs is challenging for several reasons -- one being that the required size, timeframe and number of different samples and replicates are just unmanageable.That's where computer simulation modelling comes in."Technically called an 'agent-based model', it can be thought of as a virtual experimental arena that enables us to manipulate species and different types of disturbances, and then examine their different influences on resilience in ways that are just not feasible in real reefs," explains Carturan.In his simulation arena, individual coral colonies and algae grow, compete with one another, reproduce and die. And they do all this in realistic ways. By using agent-based models -- with data collected by many researchers over decades -- scientists can manipulate the initial diversity of corals, including their number and identity, and see how the virtual reef communities respond to threats."This is crucial because these traits are the building blocks that give rise to ecosystem structure and function. For instance, corals come in a variety of forms -- from simple spheres to complex branching -- and this influences the variety of fish species these reefs host, and their susceptibility to disturbances such as cyclones and coral bleaching."By running simulations over and over again, the model can identify combinations that can provide the greatest resilience. This will help ecologists design reef management and restoration strategies using predictions from the model, says collaborating Flinders researcher Professor Corey Bradshaw."Sophisticated models like ours will be useful for coral-reef management around the world," Bradshaw adds. "For example, Australia's iconic Great Barrier Reef is in deep trouble from invasive species, climate change-driven mass bleaching and overfishing.""This high-resolution coral 'video game' allows us to peek into the future to make the best possible decisions and avoid catastrophes."The research, supported by grants from the Natural Sciences and Engineering Research Council of Canada and the Canada Foundation for Innovation, was published recently in 
"These microbes, which belong to the groups Patescibacteria and DPANN, are really special, really exciting examples of the early evolution of life," said Ramunas Stepanauskas, a senior research scientist at Bigelow Laboratory for Ocean Sciences and an author of the paper. "They may be remnants of ancient forms of life that had been hiding and thriving in the Earth's subsurface for billions of years."Stepanauskas led a research team that used advanced molecular techniques and bioinformatics to analyze thousands of microbial genomes and learn about their evolutionary history. Reading their genetic code revealed that these two groups of abundant microbes lack the capability to breathe in order to synthesize ATP, the common energy currency of life.The team found that these microbes, which live in a variety of environments in Earth's interior, appear to gain energy only through the process of fermentation. Many organisms are capable of fermentation, including humans when their muscles run out of oxygen during intense exercise -- but they use it only as a supplementary source of energy."Our findings indicate that Patescibacteria and DPANN are ancient forms of life that may have never learned how to breathe," Stepanauskas said. "These two major branches of the evolutionary tree of life constitute a large portion of the total microbial diversity on the planet -- and yet they lack some capabilities that are typically expected in every form of life."The researchers found that the most recent common ancestors of these two lineages lacked the ability to breathe, just as their modern descendants do. For the first two billion years of Earth's existence, there was no oxygen in the atmosphere. Today, oxygen is a key component of Earth's atmosphere and essential to the life it can support -- but just a few hundred feet underground, conditions have not changed, and this recent discovery suggests that some subsurface life hasn't, either.Scientists had previously speculated that because Patescibacteria and DPANN have very simple genetic features and metabolism, they must live symbiotically and depend upon host organisms to survive. In the new study, the research team found no evidence that Patescibacteria and DPANN are dominated by symbionts -- most of them seem to live as free cells and rely on the primitive pathway of fermentation to supply themselves with energy."Dependence on other organisms is a feature of life," said Jacob Beam, a former postdoctoral researcher at Bigelow Laboratory and the lead author of this study. "There are no absolutes in biology, and our research shows that microbes can vary along the spectrum of interdependencies."Scientists analyzed microbes from diverse environments around the globe, including a mud volcano at the bottom of the Mediterranean Sea, hydrothermal vents in the Pacific, and the world's deepest gold mines in South Africa. Bigelow Laboratory Bioinformatics Scientist Julie Brown, Research Scientist Nicole Poulton, former Postdoctoral Research Scientists Eric Becraft and Oliver Bezuidt, and Research Experience for Undergraduates intern Kayla Clark worked on this project, alongside with an international team of scientists who contributed to fieldwork, laboratory, and computational analyses.In addition to revealing the inner workings of Earth's subsurface and the evolution of life, these findings can provide a model system of what life on other planets may look like. Environments on Mars and other bodies in the solar system likely resemble Earth's subsurface, and Patescibacteria and DPANN represent examples of life that appear to require very little energy to survive, which scientists expect would be a requirement for life on other planets."This project would not have been possible without the collaboration of this diverse group of scientists collecting samples around the world and uniting their expertise," Beam said. "Through the collaboration of a global group of scientists working together, we know more about the inner workings of these microbes that form a major fraction of the total biodiversity on our planet."This work was funded by the National Science Foundation, the United States Department of Energy, the Simons Foundation, the Russian Science Foundation, and the National Aeronautics and Space Administration.
"More than 800 million people live at 1,500 meters above sea level or higher, with two-thirds of them in Sub-Saharan Africa, and Asia. These two regions host most of the world's stunted children so it is important to understand the role that altitude plays in growth" said IFPRI Senior Research Fellow and co-author of the study, Kalle Hirvonen."If children living at altitude are, on average, more stunted than their peers at sea level, then a more significant effort to address high altitude stunting is needed."The study, "Evaluation of Linear Growth at Higher Altitudes," co-authored by Hirvonen and Addis Ababa University Associate Professor Kaleab Baye, was published in the Children were classified as having lived in an ideal-home environment if they were born to highly educated mothers, had good health-service coverage and high living conditions. Global tracking of growth rates relies on the assumption that children living in such environments have the same growth potential, irrespective of genetic makeup or geographic location."The data clearly indicated that those residing in ideal-home environments grew at the same rate as the median child in the growth standard developed by the World Health Organization (WHO), but only until about 500 meters above sea level (masl). After 500 masl, average child height-for-age significantly deviated from the growth curve of the median child in the reference population," said Hirvonen. The research further shows that these estimated growth deficits are unlikely to be due to common risk factors such as poor diet and disease.The study suggests that the effects of altitude were most pronounced during the perinatal period i.e., the time leading up to, and immediately after, the birth. "Pregnancies at high-altitudes are characterized by chronic hypoxia, or an inadequate supply of oxygen, which is consistently associated with a higher risk of fetal growth restriction. Restricted growth in the womb is in turn a leading risk factor for linear growth faltering" said Hirvonen.There is some evidence to suggest that residing at high altitude over multiple generations may lead to some genetic adaption, but these findings did not hold for women with only a few generations of high-altitude ancestry. "Women of high-altitude ancestry were able to partially cope with the hypoxic conditions through increased uterine artery blood flow during pregnancy, but it may take more than a century before such adaptions are developed," said Baye.Hirvonen and Baye conclude that the WHO growth standards for children should not be adjusted because growth faltering at high altitudes is unlikely to be the result of physiological adaptations. Instead, they call for greater attention and health-care guidance for managing pregnancies in high-altitude settings."A first step is to unravel the complex relationship linking altitude, hypoxia and fetal growth to identify effective interventions. Failing to address altitude-mediated growth deficits urgently can fail a significant proportion of the world population from meeting the Sustainable Development Goals and World Health Assembly nutrition targets" said Baye.
But recent forest restoration research rarely acknowledges the social dimensions or environmental justice implications of such projects. A new study finds that nearly 300 million people in the tropics live on lands suitable for forest restoration, and about a billion people live within 5 miles of such lands. Many of these people live in poverty.Just and equitable implementation of restoration projects will require that communities be empowered to manage and use local forests, according to the authors of the study published in the journal "We argue that the success of global forest restoration critically depends on prioritizing local communities," said study lead author James Erbaugh of Dartmouth College, who earned a doctorate from the University of Michigan School for Environment and Sustainability."Empowering local communities to restore forests can provide human well-being benefits to millions of the most deprived and marginalized people, as well as environmental benefits for all."Study co-authors include SEAS professor Arun Agrawal, as well as other current and former graduate students and postdoctoral researchers at the U-M school.Their analysis examines the overlap between opportunities for tropical forest restoration, human populations, development and national policies for community forest ownership. The researchers focused on the opportunities in tropical countries because of the potential there for removing atmospheric carbon, promoting biodiversity conservation and contributing to the well-being of local residents.For the study, the researchers combined two datasets: one that classifies forest restoration opportunities using demographic, geographic and land-cover data, and another that uses estimates from a land-change model to predict carbon removal from forest restoration.They found that 294.5 million people live in recently tree-covered areas in the tropics that hold promise for forest restoration -- places the researchers call forest restoration opportunity areas. About 1 billion people live within 5 miles of land predicted to be suitable for forest restoration over the next 30 years if a moderate carbon-tax incentive of around $20 per ton of carbon dioxide is implemented.Brazil, the Democratic Republic of the Congo, India and Indonesia have the greatest number of people living in or near forest restoration opportunity areas with the greatest potential to remove heat-trapping carbon dioxide from the atmosphere and sequester it in forests, according to the study.Within low-income countries in the tropics, 12% of the population lives in forest restoration opportunity areas, a finding that highlights the potential for improving the livelihood and well-being of millions of people who are often underserved by standard investments in infrastructure and development, according to the authors.Nighttime satellite images showing the brightness and extent of artificial lighting on the Earth's surface can be used as a proxy for multiple development indicators. In the current study, areas in low-income nations with the least nighttime light radiance and the greatest carbon-removal potential indicated the places where forest restoration projects might best complement sustainable development agendas."There are many opportunities in central, eastern and southern Africa to restore forests and provide socioeconomic and infrastructure benefits to local people facing many multidimensional deprivations," said U-M's Agrawal, who is also editor-in-chief of the journal World Development."Forest landscape restoration that prioritizes local communities by affording them rights to manage and restore forests provides a promising option to align global agendas for climate mitigation, conservation, environmental justice and sustainable development."On the other hand, denying decision-making powers to affected locals could pose serious ethical problems, especially if some of those individuals are displaced by forest-restoration projects designed to help mitigate human-caused climate change and preserve biodiversity.Such exclusion would force some of the most multidimensionally poor people -- those who live in rural areas within low-income countries -- to move or give up their current livelihood for a global carbon and biodiversity debt to which they contributed little, according to the researchers.And while local communities should be empowered to manage forests for restoration, opportunities to expand community forest ownership must also be explored, they say..Most of the forest restoration opportunity areas analyzed in the study are in countries with preexisting legal frameworks for community forest ownership, which represents a stronger set of resource rights than community forest management.Continued efforts to expand community forest ownership are especially important in countries with a substantial proportion of people living in forest restoration opportunity areas, such as the Central African Republic, the Democratic Republic of the Congo, Thailand and the Lao People's Democratic Republic.Forest restoration projects in the tropics involve planting trees on land previously cleared for agriculture, timber harvesting or other purposes. Increasing support for such efforts is becoming available from both government agencies and nongovernmental organizations, Agrawal says.The authors of the Proponents of FLR say it contributes to human well-being through the use and sale of forest products, that it promotes increases in local food and water security, and that it respects diverse cultural values that local peoples hold for trees and forests."Our study highlights the critical need for close ties between researchers, decision makers and local communities to secure greater wellbeing for people and ecosystems," Agrawal said. "Those working on forests -- whether government agencies or researchers -- forget far too often the necessity of working with people, not against them."
The review, which looked at 81 studies carried out between 1980 and 2020, found that illegal hunting was causing worrying declines in the big mammal populations of protected areas across the globe, and particularly in poorer countries.In the four continents included in the study, 294 different mammal species were discovered to have been illegally hunted in the national parks created to protect them.The threat species face in poorer countries may be down to a boom in bushmeat trade and a lack of resources for conservation.In order to protect species, governments and policy makers need to focus on tackling human poverty, the researchers urge.Lead author of the study, Dr Alfan Rija, of Tanzania's Sokoine University of Agriculture who conducted the review while a PhD student at the University of York, said: "We have known for several years that illegal hunting reduces mammal populations, but our review reveals that this is happening even inside protected areas and particularly affects larger mammals (those with a body mass of over 100kg) in the poorest countries. In poorer countries such as my home of Tanzania, bushmeat is a valuable source of income and protein in some areas and there is also less resources available to invest in the security and policing of national parks."The threat from illegal hunting is particularly dangerous to large mammals because they have slow growth rates and so over-hunting is likely to cause population decline."Aside from concerns about the future of many of these species being in peril, the loss of mammals due to illegal hunting pressure has been related to substantial loss of important functional characteristics in an ecosystem. They support many ecological interactions -- such as seed dispersal and regeneration -- and their decline threatens wider biodiversity."The study found that in general across the globe, stricter protected areas showed lower rates of large mammal population decline. However, this was not the case in Asia, where stricter national parks had higher rates of illegal hunting and species decline.Senior author of the study, Dr Colin Beale from the Department of Biology at the University of York, said: "Our research adds to a growing number of studies that suggest Asia is currently a particular focus for the illegal trade of wildlife body parts. Despite strict laws, illegal hunters may be forced to enter protected areas where most sought-after species such as snow leopard, tiger, pangolin, orangutans and sun bears still remain."Improving the effectiveness of Asian protected areas will be important to strengthen biodiversity conservation across continental Asia, and is likely to need a range of measures including ensuing effective law enforcement as well as work with communities in and around valuable wildlife areas."The study was carried out in collaboration with the Department of Wildlife Management, Sokoine University of Agriculture, in Tanzania.
Hokkaido University scientists have identified an atypical hotspot of sub-glacier melting in East Antarctica. Their findings, published in the journal The 58th Japanese Antarctic Research Expedition had a very rare opportunity to conduct ship-based observations near the tip of East Antarctic Shirase Glacier when large areas of heavy sea ice broke up, giving them access to the frozen LÃ¼tzow-Holm Bay into which the glacier protrudes."Our data suggests that the ice directly beneath the Shirase Glacier Tongue is melting at a rate of 7-16 meters per year," says Assistant Professor Daisuke Hirano of Hokkaido University's Institute of Low Temperature Science. "This is equal to or perhaps even surpasses the melting rate underneath the Totten Ice Shelf, which was thought to be experiencing the highest melting rate in East Antarctica, at a rate of 10-11 meters per year."The Antarctic ice sheet, most of which is in East Antarctica, is Earth's largest freshwater reservoir. If it all melts, it could lead to a 60-meter rise in global sea levels. Current predictions estimate global sea levels will rise one meter by 2100 and more than 15 meters by 2500. Thus, it is very important for scientists to have a clear understanding of how Antarctic continental ice is melting, and to more accurately predict sea level fluctuations.Most studies of ocean-ice interaction have been conducted on the ice shelves in West Antarctica. Ice shelves in East Antarctica have received much less attention, because it has been thought that the water cavities underneath most of them are cold, protecting them from melting.During the research expedition, Daisuke Hirano and collaborators collected data on water temperature, salinity and oxygen levels from 31 points in the area between January and February 2017. They combined this information with data on the area's currents and wind, ice radar measurements, and computer modelling to understand ocean circulation underneath the Shirase Glacier Tongue at the glacier's inland base.The scientists' data suggests the melting is occurring as a result of deep, warm water flowing inwards towards the base of the Shirase Glacier Tongue. The warm water moves along a deep underwater ocean trough and then flows upwards along the tongue's base, warming and melting the ice. The warm waters carrying the melted ice then flow outwards, mixing with the glacial meltwater.The team found this melting occurs year-round, but is affected by easterly, alongshore winds that vary seasonally. When the winds diminish in the summer, the influx of the deep warm water increases, speeding up the melting rate."We plan to incorporate this and future data into our computer models, which will help us develop more accurate predictions of sea level fluctuations and climate change," says Daisuke Hirano.
The warning comes from a study of 14,189 fossil pollen samples taken from 358 locations across the continent. Researchers at the Georgia Institute of Technology used data from the samples to determine landscape resilience, including how long specific landscapes such as forests and grasslands existed -- a factor known as residence time -- and how well they rebounded following perturbations such as forest fires -- a factor termed recovery."Our work indicates that landscapes today are once again exhibiting low resilience, foreboding potential extinctions to come," wrote authors Yue Wang, Benjamin Shipley, Daniel Lauer, Roseann Pineau and Jenny McGuire. "Conservation strategies focused on improving both landscape and ecosystem resilience by increasing local connectivity and targeting regions with high richness and diverse landforms can mitigate these extinction risks."The research, supported by the National Science Foundation, is believed to be the first to quantify biome residence and recovery time over an extended period of time. The researchers studied 12 major plant biomes in North America over the past 20,000 years using pollen data from the Neotoma Paleoecology Database."We find that the retreat of North American glaciers destabilized ecosystems, causing large herbivores -- including mammoths, horses and camels -- to struggle for food supplies," said McGuire, an assistant professor in Georgia Tech's School of Biological Sciences and School of Earth and Atmospheric Sciences. "That destabilization combined with the arrival of humans in North America to land a one-two punch that resulted in the extinction of large terrestrial mammals on the continent."The researchers found that landscapes today are experiencing resilience lower than any seen since the end of the Pleistocene megafauna extinctions."Today, we see a similarly low landscape resilience, and we see a similar one-two punch: humans are expanding our footprint and climates are changing rapidly," said Wang, a postdoctoral researcher who led the study. "Though we know that strategies exist to mitigate some of these effects, our findings serve as a dire warning about the vulnerability of natural systems to extinction."By studying the mix of plants represented by pollen samples, the researchers found that over the past 20,000 years, forests persisted for longer than grassland habitats -- averaging 700 years versus about 360 years, though they also took much longer to re-establish after being perturbed -- averaging 360 years versus 260 years. "These findings were somewhat surprising," said McGuire. "We had expected biomes to persist much longer, perhaps for thousands of years rather than hundreds."The research also found that forests and grasslands transition quickly when temperatures are changing fast, and that they recover most rapidly if the ecosystem contains high plant biodiversity. Yet not all biomes recover; the study found that only 64% regain their original biome type through a process that can take up to three centuries. Arctic systems were least likely to recover, the study found.Landscape resilience, the ability of habitats to persist or quickly rebound in response to disturbances, have helped maintain terrestrial biodiversity during periods of climactic and environmental changes, the researchers noted."Identifying the tempo and mode of landscape transitions and the drivers of landscape resilience is critical to maintaining natural systems and preserving biodiversity given today's rapid climate and land use changes," the authors wrote. "However, resilient landscapes are difficult to recognize on short time scales, as perturbations are challenging to quantify and ecosystem transitions are rare."Contrary to prevailing ecological theory, the researchers found that pollen richness -- indicating diversity of species -- did not necessarily correlate with residence time. Ecological theory suggests that biodiversity increases ecosystem resilience by improving "functional redundancy," allowing a system to maintain stability even if a single or several species are lost. "But species richness does not necessarily reflect functional redundancy, and as a result may not be correlated with ecosystem stability," the researchers wrote.The study used pollen data from five forest types -- forest/tundra, conifer/hardwood, boreal forest, deciduous forest, and coastal forest, five shrub/herb biome types -- Arctic vegetation, desert, mountain vegetation, prairies, and Mediterranean vegetation, and two no?analog biome types -- spruce parkland and mixed parkland.The Neotoma Paleoecology Database contains fossil pollen and spores that are ubiquitous in lake and mire sediments. Collected through core sampling, the samples represent a wide diversity of plant taxa and cover an extended period of time.Though the effects of climate change and human environmental impacts don't bode well for the future of North American plant biomes, there are ways to address it, Wang said. "We know that strategies exist to mitigate some of these effects, such as prioritizing biodiverse regions that can rebound quickly and increasing the connectivity between natural habitats so that species can move in response to warming."
Coral reef environments are typically low in naturally occurring nutrients such as nitrogen and phosphorus compounds. But ocean currents passing by can bring in a concentration of nutrients from elsewhere. Similarly, nutrients from human-made fertilisers and stormwater runoff enter reefs from adjacent coastlines.Lead author Dr Thomas DeCarlo from the King Abdullah University of Science and Technology (KAUST) says corals are sensitive to high levels of nutrients."As the climate warms, mass coral bleaching could occur as often as annually within this century," Dr DeCarlo said. "In our study, we found that already heat-stressed corals exposed to excess nutrient levels were even more susceptible to bleaching."The study suggests ecosystem managers can reduce the impacts of coral bleaching by implementing strategies to reduce nutrient stress in areas subject to thermal stress.Co-author Professor John Pandolfi from the ARC Centre of Excellence for Coral Reef Studies (Coral CoE) at The University of Queensland says this and previous studies, including on the Great Barrier Reef, related coral bleaching to combinations of heat and nutrient stresses."Our results provide a roadmap for coral reef conservation efforts to be at their most effective," Prof Pandolfi said. "We suggest oceanographic processes should be included when deciding when and where to allocate resources or protection."Using the skeletal cores of long-living corals, the authors studied the past few decades worth of bleaching events in the Red Sea. They found the reefs historically suffered severe bleaching only when high sea surface temperatures were coupled with high nutrient levels.The Red Sea was chosen as a study site as it is one of the only marine environments where the effects of summertime nutrients and heat stress are independent of each other: only one area has a single major source of nutrients in the summer, when a water mass brings nutrients to the surface through a process called upwelling.Previous field tests on the role of nutrients in coral bleaching were otherwise difficult: nutrients and temperature often co-vary in the ocean, making it difficult to disentangle their effects. Nutrient loads are also difficult to measure in the same way sea surface temperatures are, via satellite."The fact that nutrients are more difficult to measure than temperature may be restricting our recognition of their importance," Dr DeCarlo said. "And we need greater longer-term monitoring efforts of nutrient levels on coral reefs.""Incorporating nutrient-supplying ocean currents into coral bleaching forecasts will enhance those predictions that are based on temperatures alone," Prof Pandolfi said."Our research suggests that projections of coral reef futures should move beyond solely temperature-based stress to incorporate the influence of ocean current systems on coral reef nutrient enrichment, and thus susceptibility to bleaching," Dr DeCarlo said.
The finding came from an international study led by the University of Alaska Fairbanks and Finnish Meteorological Institute. The study, published in the The moorings measured the heat released from the ocean interior to the upper ocean and sea ice during winter. In 2016-2018, the estimated heat flux was about 10 watts per square meter, which is enough to prevent 80-90 centimeters (almost 3 feet) of sea ice from forming each year. Previous heat flux measurements were about half of that much."In the past, when weighing the contribution of atmosphere and ocean to melting sea ice in the Eurasian Basin, the atmosphere led," said Igor Polyakov, an oceanographer at UAF's International Arctic Research Center and FMI. "Now for the first time, ocean leads. That's a big change."Typically, across much of the Arctic a thick layer of cold fresher water, known as a halocline, isolates the heat associated with the intruding Atlantic water from the sea surface and from sea ice.This new study shows that an abnormal influx of salty warm water from the Atlantic Ocean is weakening and thinning the halocline, allowing more mixing. According to the new study, warm water of Atlantic origin is now moving much closer to the surface."The normal position of the upper boundary of this water in this region was about 150 meters. Now this water is at 80 meters," explained Polyakov.A natural winter process increases this mixing. As sea water freezes, the salt is expelled from ice into the water. This brine-enriched water is heavier and sinks. In the absence of a strong halocline, the cold salty water mixes much more efficiently with the shallower, warm Atlantic water. This heat is then transferred upward to the bottom of sea ice, limiting the amount of ice that can form during winter."These new results show the growing and spreading influence of heat associated with Atlantic water entering the Arctic Ocean," added Tom Rippeth, a collaborator from Bangor University. "They also suggest a new feedback mechanism is contributing to accelerating sea ice loss."Polyakov and his team hypothesize that the ocean's ability to control winter ice growth creates feedback that speeds overall sea ice loss in the Arctic. In this feedback, both declining sea ice and the weakening halocline barrier cause the ocean's interior to release heat to the surface, resulting in further sea ice loss. The mechanism augments the well-known ice-albedo feedback -- which occurs when the atmosphere melts sea ice, causing open water, which in turn absorbs more heat, melting more sea ice.When these two feedback mechanisms combine, they accelerate sea ice decline. The ocean heat feedback limits sea ice growth in winter, while the ice-albedo feedback more easily melts the thinner ice in summer."As they start working together, the coupling between the atmosphere, ice and ocean becomes very strong, much stronger than it was before," said Polyakov. "Together they can maintain a very fast rate of ice melt in the Arctic."Polyakov and Rippeth collaborated on a second, associated study showing how this new coupling between the ocean, ice and atmosphere is responsible for stronger currents in the eastern Arctic Ocean.According to that research, between 2004-2018 the currents in the upper 164 feet of the ocean doubled in strength. Loss of sea ice, making surface waters more susceptible to the effects of wind, appears to be one of the factors contributing to the increase.The stronger currents create more turbulence, which increases the amount of mixing, known as shear, that occurs between surface waters and the deeper ocean. As described earlier, ocean mixing contributes to a feedback mechanism that further accelerates sea ice decline.Accelerated currents have practical implications in the Arctic. Ship captains need accurate maps of currents for navigation. Since currents move sea ice, oil and gas extraction activities also need information about currents.
However, not all birds are the same, and not all weather events have the same impact. How do different bird species respond to extreme weather events that occur for different amounts of time, ranging from weekly events like heat waves to seasonal events like drought? And how do traits unique to different species -- for example, how far they migrate or how commonly they occur -- predict their vulnerability to extreme weather?To answer these questions, ecologists would traditionally observe a small number of bird species at a few sites over a few years, and then draw general conclusions. However, Zuckerberg and UW-Madison postdoctoral researcher Jeremy Cohen, along with Daniel Fink of the Cornell Lab of Ornithology, had more ambitious goals: they looked at 109 species across eastern North America over a 15-year period, and integrated this information with fine-scale satellite temperature and precipitation data.In a study recently published in the journal The researchers used data from eBird, a global citizen-science initiative where bird enthusiasts submit checklists of bird sightings online. These checklists include which species were seen, how many, the location and time, and other observations.The researchers compiled more than 830,000 of these checklists and integrated each one with weather data summarized over the week, month and three months before the observation was recorded. They relied on advanced computing to manage this large amount of information."The study we did would not have been remotely possible without data science," says Cohen. The emerging field of data science involves the study, development or application of methods that reveal new insights from data.Zuckerberg points out that the combination of citizen science and data science makes research possible at a scale that was previously unimaginable for ecologists. However, citizen science has its limitations. Researchers have less control over the scientific process, and data quality can vary."Someone can go out for five minutes or two hours and submit eBird data. They can submit a checklist for 10 species or 40 species," says Zuckerberg. "We've adopted data science methods for working with large, unstructured data sets."After controlling for this noisy data, the researchers observed that some species are less sensitive to extreme weather, and populations are not equally exposed to its effects because some geographic areas are warming faster than others.When it comes to heat waves, Cohen notes, "long-distance migrants were not super affected by really hot periods. They winter in tropical environments and should be tolerant of heat."However, resident birds and short-distance migrants such as robins and red-winged blackbirds responded negatively to heat waves, with their numbers sometimes declining 10% to 30% over several weeks.As for drought, commonly occurring species like crows were more resilient than rare birds, particularly if the drought was severe and long-lasting."Rarer species have more specialized habitat and food requirements -- this is a general rule in ecology," says Cohen. "More common species usually have more options. If habitat quality declines due to drought, a generalist can go somewhere else."Cohen says this is the first large-scale study, spanning half a continent, to look at how birds respond immediately after weather events. Because of the scope of the project, conservationists can better understand how many different bird species are likely to be affected by climate change, and mitigate some of the negative effects."If birds are truly winged sentinels of climate change, the greater likelihood of drought, flooding and extreme temperature conditions like heat waves will have significant consequences," says Zuckerberg. "We need to think about how we help species adapt to climate extremes."The study was funded in part by the National Science Foundation (grants CCF-1522054, CNS-1059284 and DBI-1356308) and the UW-Madison Data Science Initiative.
In the new study, researchers modeled the effects of rising sea level along the entire California coastline. While results varied with local topography, the study indicates rising sea levels could push inland water tables higher, resulting in damage to infrastructure and increased severity of flooding."Increased roadway fatigue, reduced sewer and septic drainage, and the potential for mobilizing contaminants in soils currently above the water table will eventually be triggered farther inland as the water table rises with higher sea levels," researchers concluded.Kevin Befus, assistant professor of geosciences at the University of Arkansas, is the first author of the study, published in the journal Nature Climate Change.While many coastal areas are focused on overland flooding as a result of sea level rise, the threat of rising groundwater tables, known as "shoaling," is not as well known or understood. Shoaling occurs when rising seawater pushes inland. The denser marine water underlies shallow freshwater aquifers, pushing them upward. In some low-lying areas, shoaling could force groundwater water to the surface, increasing the likelihood of flood damage.Researchers identified key infrastructure at risk from shoaling, including the Port of Los Angeles and airports in Santa Barbara and San Francisco.But groundwater does not need to emerge to cause problems, the authors noted. Rising water tables, for instance from 6 feet below ground to 3 feet, could impact buried infrastructure such as wastewater pipes, electrical conduits and building foundations. Places like Miami and Hawaii have long grappled with this immediate connection between the ocean and their groundwater. But for most coastal communities in California, the connection is more subtle and has not yet become a part of their climate planning.
In a paper published today in Nature Communications, scientists at the University of California, Irvine, the University of Pennsylvania, William Paterson University of New Jersey and other international institutions explain how this major climate transformation led to a shift in human settlement patterns in Southeast Asia, which is now inhabited by more than 600 million people."In this study, we provide the first proof for a strong link between the end of the Green Sahara and Southeast Asian monsoon failure during the mid- to late Holocene period," said co-author Kathleen Johnson, UCI associate professor of Earth system science. "Our high-resolution and well-dated record suggests a strong connection between Northern Africa and mainland Southeast Asia during this time."To create a paleoclimate record for the study, Johnson and other researchers gathered stalagmite samples from caves in Northern Laos. In her UCI laboratory, they measured the geochemical properties of the oxygen and carbon isotopes, carbon-14, and trace metals found in the specimens. This helped them verify the occurrence of the drought and extrapolate its impacts on the region.Johnson said they combined data from the analysis of these stalagmite-derived proxies with a series of idealized climate model simulations -- conducted by co-author Francesco Pausata of the University of Quebec in Montreal -- in which Saharan vegetation and dust concentrations were altered in a way that permitted them to investigate the ocean-atmosphere feedbacks and teleconnections associated with such an abrupt shift in precipitation.The modeling experiments suggested that reduced plant growth in the Sahara led to increased airborne dust that acted to cool the Indian Ocean and shift the Walker circulation pattern eastward, causing it to behave in ways similar to modern-day El NiÃ±o events. This, ultimately, led to a large reduction in monsoon moisture across Southeast Asia that lasted more than 1,000 years, according to Johnson.Anthropologists and archaeologists have previously studied the effects of the demise of the Green Sahara, also known as the African humid period, on population centers closer to Western Asia and North Africa, noting the collapse of the Akkadian Empire of Mesopotamia, the de-urbanization of the Indus Civilization (near present-day Pakistan and India) and the spread of pastoralism along the Nile River.But the link to the origin of the Southeast Asia megadrought and lifestyle pattern shifts in the region had not been previously investigated, according to lead author Michael Griffiths, professor of environmental science at William Paterson University of New Jersey."Archaeologists and anthropologists have been studying this event for decades now, in terms of societal adaptations and upheavals, but its exact cause has eluded the scientific community," said Griffiths, who was a National Oceanic and Atmospheric Administration-supported postdoctoral scholar in Johnson's lab and has collaborated with her on this research topic for more than 10 years."Results from this work provide a novel and convincing explanation for the origin of the Southeast Asia megadrought and could help us better understand, to varying degrees, the observed societal shifts across many parts of the tropics and extra-tropics," he said.The researchers suggest that the centuries-long megadrought corresponds to the "missing millennia" in Southeast Asia between 4,000 and 6,000 years ago, a time characterized by a noticeable lack of archaeological evidence in interior Southeast Asia compared to earlier and later portions of the Holocene.They propose that the mid-Holocene megadrought may have been an impetus for mass population movements and the adoption of new, more resilient subsistence strategies -- and that it should now be considered as a possible driver for the inception of Neolithic farming in mainland Southeast Asia."This is outstanding evidence for the type of climate change that must have affected society, what plants were available, what animals were available," said co-author Joyce White, adjunct professor of anthropology at the University of Pennsylvania. "All of life had to adjust to this very different climate. From an archaeological point of view, this really is a game changer in how we try to understand or reconstruct the middle Holocene period."
In 2008, the Bern ice core specialists were able to show that the COThe fact that rapid COThe researchers compared the CO
The study, led by University of Melbourne PhD student Ellen Corrick and published today in the journal, "Some of the largest and most abrupt climate changes in Earth's geological recent past occurred during the Last Glacial Period, a cold interval that extended between 115,000 and 11,700 years ago," Ms Corrick said.Greenland ice cores recorded more than 25 abrupt warming episodes during this period. These so called 'Dansgaard-Oeschger events' were associated with increases in air temperature over Greenland of up to 16Â°Celsius, sometimes in a matter of a few decades.Researchers say the findings provide important information for testing numerical models used to predict future climate changes and demonstrate that profound climate changes can occur simultaneously, highlighting the unstable nature of the climate system.Co-author, University of Melbourne Associate Professor Russell Drysdale, said: "Demonstrating synchrony in the climate response across such a broad region marks a major advance in the study of Dansgaard-Oeschger events. It allows scientists to improve understanding of how the events are propagated globally via the ocean and atmosphere system."The research team, which involved scientists from Denmark, the UK, Germany, China, France and Switzerland, collated 63 individual climate records derived from stalagmites collected from caves across Europe, Asia and South America. The records represent over 20 years' worth of published research from scientific teams around the world.Stalagmites -- a type of cave mineral formation -- preserve information on regional temperature and rainfall as they grow. Crucially, they can be dated very precisely, allowing the timing of climate events to be compared between records from different regions.University of Melbourne Geochronologist Dr John Hellstrom, said that resolving the issue of timing has proved difficult because precisely dated records of past climate are required to determine exactly when the events took place."Such records are relatively rare, and it is only now that we have enough high-quality records to actually answer the question of synchrony," Dr Hellstrom said.According to co-author Professor Eric Wolff from the University of Cambridge, the findings resolve a long-standing dilemma within the paleoclimate community, who study ancient climates."They provide confirmation of a persistent but, until now, unsubstantiated assumption that climate changes between the tropics and the Arctic were synchronous."
In order to determine the ice loss, researchers from the Alfred Wegener Institute, Helmholtz Centre for Polar and Marine Research (AWI), the German Research Centre for Geosciences GFZ and international partners evaluated satellite data from the GRACE mission, and its successor mission, GRACE Follow-On (GRACE-FO). The satellites provided highly accurate measurements, which were used to create monthly maps of Earth's gravity. The redistribution of the masses, e.g. ice losses in the oceans, leads to temporal and spatial changes in Earth's gravitational forces. The researchers compared the satellite data with regional climate models that are specially designed to calculate the snowfall and the melting of the ice sheet."After a two-year 'breather', in 2019 the mass loss increased steeply and exceeded all annual losses since 1948, and probably for more than 100 years," says Ingo Sasgen, a glaciologist at the AWI in Bremerhaven and first author of the study. "There are increasingly frequent, stable high-pressure areas over the ice sheet, which promote the influx of warm air from the middle latitudes. We saw a similar pattern in the previous record year 2012."The mass balance for a given a year is calculated using the difference between the ice increase due to snowfall and ice loss due to melting and ice discharge at the edge of the ice sheet. "The snowfall in 2019 was below the long-term average, and that also contributed to the record figure," explains Marco Tedesco, a professor at Columbia University and co-author of the study. "By comparing satellite data with regional climate models, we were able to see precisely which processes were involved and to what extent, and which general weather conditions were dominant," he adds.The two satellite missions GRACE and GRACE-FO, which monitor the Earth's gravitational field, play a vital role in the continuous observations of the Greenland Ice Sheet. The measurements allow the mass changes in the ice sheet to be quantified. "The GRACE satellite mission, which ended in summer 2017, provided us with essential data on ice loss in the polar regions over a period of 15 years," explains Christoph Dahle from the GFZ, who is responsible for calculating the gravitational fields from the mission's raw data. "After a gap of about a year, in summer 2018 we were able to resume monitoring with the follow-on mission, GRACE-FO."In summer, the Arctic warms roughly one and a half times as quickly as the global average. Added to this are the various feedback effects that increase the ice loss. "2017 and 2018 were very cold years in Greenland, with high snowfall," says Sasgen. The GRACE/GRACE-FO data shows, however, that in these years the mass balance was negative due to the high discharge from the glacier into the ocean. "We see substantial variations from year to year. But the five years with the highest losses since 1948 were all in the last decade," reports Sasgen.
Sea level rise is occurring as Earth warms due to two main factors: melting of land-based ice such as glaciers and ice sheets, and the expansion of seawater as it warms -- termed thermal expansion. Previously unknown was whether the rate of thermal expansion, which accelerates with warming, will also affect the variability of sea level.In a study published this week in "Whereas it is well understood that the rate of global mean sea level rise will accelerate with future warming, in part due to the oceans expanding faster at higher temperatures, it was previously unexplored how this nonlinear thermal expansion property of seawater will affect future sea level variability," said Widlansky."Following thermodynamic laws, sea level variability increases in a warmer climate because the same temperature variations, for example related to the seasonal cycle, cause larger buoyancy and sea level fluctuations," added Fabian Schloesser, a researcher at the UH Sea Level Center who collaborated on the study.In places where changes due to ocean thermodynamics and other climate variability processes align, the team found the largest increases in future sea level variability.Coastal flooding occurs increasingly often due to a combination of slowly rising sea levels and ocean variability. The new findings therefore further emphasize the importance of sea level monitoring and forecasting."Forecasting can potentially provide alerts months in advance if sea levels are likely to cause tides to be more extreme than otherwise expected," said Widlansky.While the science team explores how to develop better forecast outlooks, the UH Sea Level Center is actively monitoring extremes through a global network of tide gauge observations, including in Honolulu, Hawai'i.
Bowlick says, "Our research is very applicable in the current remote learning era that we're working through, because it provides expertly driven insight into how to set up a virtual computing environment in different modes: with hardware and with software in the cloud. While tailored to those needing GIS support, it is also very applicable for other high-performance software needs.""By capturing the experiences of both setting up the system and of students using the system, we provide an important resource for others needing to make this investment of time, equipment and energy," he adds. Such technical practice is becoming required for GIS and other instruction, he points out.Writing in the He says, "UMass is just one of several programs nationally, but regionally it's very attractive, especially at the graduate level, because there are not that many in New England. Ours certainly started at the right time, too. With the turn toward using more computational skills and GIS practices, how to use different computer constructs and programming language are become more fundamental needs in education."Bowlick has directed a one-year M.S. geography degree program with an emphasis in GIS at UMass Amherst since 2017. He says there may be 10 or 15 students from every college on campus with different majors in the introductory course in a given semester. They need to gain fundamentals of spatial thinking, operating software and problem solving applicable to the diverse interests that students bring to the course.Generally, these applications involve how to think through spatial problems on such topics as political geography, for example, which might ask who is voting and where, or on gerrymandering and how to discover it. Others are creating COVID-19 virus maps and spatial data to show its prevalence for spatial epidemiology and health geography, while others are modeling ecosystems for fish and wildlife.Bowlick explains that geographic information science is "a bridging science" -- a suite of technologies, a way of thinking and a way to store spatial data including satellite systems for navigation. GIS handles imagery, computer mapping, spatial planning, modeling land cover over time, even helping businesses decide where to open their next location.GIS was first developed in the late 60s when the Canada Land Inventory needed ways to store, manage and analyze land resource maps over huge areas using new computer technology, Bowlick says. His two co-authors at Texas A&M, both experienced GIS instructors, are Dan Goldberg, an associate professor in geography, and Paul Stine, an IT system administrator for geography.The authors describe the setup, organization and execution of teaching an introductory WebGIS course while considering student experiences in such a course.The paper also defines an operational set of resource metrics needed to support the computing needs of students using virtual machines for server-based CyberGIS classes, as well as comparing costs and components needed to build and support an on-premise private cloud teaching environment for a WebGIS course in an on-premise private cloud teaching environment vs. a comparable cloud-based service provider.
To find an answer, the High Level Panel for a Sustainable Ocean Economy -- 14 world leaders working to facilitate a more resilient future for people and planet -- turned to an international consortium of experts whose breadth of knowledge encompasses economics, biology, ecology, nutrition, fisheries and mariculture."Basically the question we were trying to answer was: Does sustainably managing the ocean over the next 30 years mean we will produce more food, or less?" said Christopher Costello, a professor of environmental and resource economics at UC Santa Barbara's Bren School of Environmental Science & Management. Costello is the lead author of an Ocean Panel paper as well that is also new research published in the journal Given the growing demand for food and the constraints of expanding land-based food production, ocean-based foods -- nutrient-rich and a good source of protein -- are poised to be the next great stand against food insecurity for the estimated 9.8 billion people on the planet by 2050. But can we produce more from the ocean without collapsing its ecosystems?"I think many of us went into this thinking that to manage the ocean sustainably, we would have to extract less, which would mean less food from the sea," Costello said. What the researchers found, however, was the opposite."If done sustainably, you could actually increase food from the sea, and by an outsize proportion relative to expansion of land-based food," said Costello. "And it could be done in a way that's much more environmentally friendly for the climate, biodiversity and other ecosystem services than food production on land."In fact, sustainability is key to the successful increase in food production from the ocean. "By improving sustainability and equity through a range of actionable policy and business commitments, food from the sea has the potential to expand in the future, nourishing the growing human population," said Stefan Gelcich, an associate professor at the Pontificia Universidad CatÃ³lica de Chile and a co-author on the study."We've had a history of overexploiting many fisheries, but we're seeing governments starting to implement better fisheries management policies," Costello said. "And when you rebuild fisheries, you restore the health of the ocean and that allows you to have more food." The researchers estimate a roughly 16% increase in wild-caught seafood by 2050 if fisheries are sustainably managed. Conversely, failure to improve management could lead to significant reductions in seafood production from wild fisheries.Farmed seafood stands to see an even greater increase in food production if done in balance with nature; some places with unsustainable mariculture would have to be scaled back, possibly rehabilitated, and other areas encouraged to develop sustainable seafood farms. With innovations that reduce mariculture's dependency on fish-based feed and effective policies that can lower the barriers to initiating environmentally friendly mariculture operations, farmed fish and shellfish production can increase dramatically."More rapid alternative feed adoption and efficiency improvements in aquaculture will be key for scaling sustainable marine production," said Halley Froehlich, an assistant professor in UC Santa Barbara's Department of Ecology, Evolution, & Marine Biology and Environmental Studies and also a co-author on the study. While sustainable supply could increase by more than six-fold, when both supply and demand are considered, she added, the likely increase in mariculture is between 2 to 4 times, depending on future demand.There's no better time than the present to start sustainably planning and growing the system that could be feeding us in a generation, according to Costello, who pointed out that increases in population and wealth, along with the awareness that seafood is particularly nutritious, will drive future demand."Demand for meat tends to increase with wealth," said Costello, adding that the group also looked at the potential demand for seafood -- a rare and sometimes overlooked assessment -- and found that potential growth in supply could more than meet projected demand.Projections of population and income by 2050 suggest a future need for more than 500 million metric tons of edible meat per year for human consumption, a 38% increase from today's production. Supplying that demand with land-based meat production would be difficult due to less available space and environmental impacts; shifting to ocean production could ease that pressure while supplying meat that is sustainably sourced and overall healthier for people."As people's diets shift, as they get wealthier, as the population grows, as they start to realize that fish are more nutritious and healthier than land-based sources of meat, the demand grows," said Costello. "That raises prices and creates an economic incentive to generate food from the sea."
"Climate damages hit our businesses and jobs, not just polar bears and coral reefs," says Leonie Wenz from PIK, one of the two authors of the study. "Rising temperatures make us less productive which is relevant in particular for outdoor work in the construction industry or agriculture. They affect our harvests and they mean extra stress and thus costs for our infrastructure as for instance computer centres need to be cooled. By statistically evaluating climate and economic data from the past decades, we found that the aggregated economic damages from rising temperatures are even greater than previously estimated because we looked at the sub-national effects which provide a more comprehensive picture than national averages."Previous research suggested that a 1Â°C hotter year reduces economic output by about 1%, whereas the new analysis points to output losses of up to three times that much in warm regions. Using these numbers as a benchmark for computing future damages of further greenhouse gas emissions, the researchers find significant economic losses: 10% on a global average and more than 20% in the tropics by 2100. This is still a conservative assessment since the study did not take into account damages from, for example, extreme weather events and sea-level rise, which will also be substantial but are hard to pin down for single regions.The new insight was made possible by building a novel MCC-dataset of climate and economy for 1500 regions in 77 states around the world that, for some regions, dates back to the 1900s. Data coverage is best for industrialized countries, however, with economic information lacking in particular for large parts of Africa. While the calculations show a substantial impact on economic production, they do less so for permanent economic growth reductions, which might be a reason for hope once emissions are reduced. Importantly, the damages are distributed very unevenly across the world with tropical and already poor regions suffering most from continued warming whereas a few countries in the North might even profit.The findings have important implications for climate policy, and namely COBy way of comparison: the carbon price in European emissions trading currently fluctuates between 20 and 30 euros per tonne; the national carbon price in Germany rises from 25 euros next year to 55 euros in 2025. These current carbon prices thus reflect only a small part of the actual climate damage. According to the polluter-pays principle, they would need to be adjusted upwards significantly.
Salmon are critically important to both people and ecosystems in Alaska, supporting commercial and subsistence fisheries and transporting nutrients from the ocean to inland areas, fertilizing the ecosystems in and around the rivers where they spawn. Smaller salmon provide less food for people who depend on them, less value for commercial fishers, and less fertilizer for terrestrial ecosystems.For years, people in Alaska have been noticing that wild salmon were getting smaller, but the reasons have been unclear. In the new study, published August 19 in The results showed that the decreases in body size are primarily due to salmon returning to their spawning grounds at younger ages than they have in the past. Alaskan salmon can spend up to seven years at sea, although this varies by species. During this time they feed and grow to maturity, migrating great distances in the North Pacific Ocean before returning to fresh water to spawn."There are two ways they could be getting smaller -- they could be growing less and be the same age but smaller, or they could be younger -- and we saw a strong and consistent pattern that the salmon are returning to the rivers younger than they did historically," said corresponding author Eric Palkovacs, professor of ecology and evolutionary biology and associate director of the Fisheries Collaborative Program in the Institute of Marine Sciences at UC Santa Cruz.The researchers identified a range of factors that appear to be driving this shift, some acting across all regions and others affecting only certain species or populations."There's not a single smoking gun," said first author Krista Oke, a postdoctoral scientist initially at UC Santa Cruz and now at University of Alaska Fairbanks. "Small contributions from a lot of factors are adding up to drive these changes."Two factors -- climate change and competition with growing numbers of wild and hatchery salmon in the ocean -- have clearly contributed to size declines across all species and regions, Palkovacs said. In contrast, the effect of commercial fishing appears to be important only for some salmon populations. Similarly, the results were mixed for another proposed driver of size declines, the recovering populations of marine mammals that prey on salmon."We know that climate drives changes in ocean productivity, and we see a consistent signal of climate factors associated with decreasing salmon size," Palkovacs said. "Another consistent association is with the abundance of salmon in the ocean, especially pink salmon. Their abundance in the North Pacific is at historic highs due in part to hatchery production in Alaska and Asia, and they compete with other salmon for food."The observation that salmon are returning to freshwater streams at younger ages implies that the ocean is becoming a riskier place for them to be, he said. By staying in the ocean longer and growing larger, salmon can have greater success in spawning and lay more eggs, but each additional year increases the risk of not returning to reproduce at all."Natural selection has always pushed in both directions, but the balance between the two is changing, pushing harder against the older, larger salmon," Palkovacs said. "It seems that the ocean is becoming a riskier place to be."According to Oke, understanding exactly what is going on in the ocean to drive this shift is a difficult challenge that will require further study. "That's the next hard step I hope we can get to soon," she said. "It could be that they're having to spend more time feeding, which is putting them in risky places. Lots of things could be happening to increase the overall risk of mortality in the ocean, but we weren't able to pin that down."The consequences for people and ecosystems, however, are more clear. Smaller salmon means fewer meals per fish for subsistence fishers, lower profits for commercial fishers, fewer eggs laid to sustain salmon populations, and fewer nutrients to support the productivity and biodiversity of freshwater and riparian ecosystems."Smaller fish is a real problem for people who depend on salmon for their food and well being," Oke said. "For commercial fishers, smaller fish tend to fetch lower prices, and below a certain size they can't be made into high-value products and might have to be canned."On the ecosystem side, the nutrients delivered by salmon runs provide critical support for bears, insects, birds, trees, and juvenile salmon themselves. Palkovacs noted that an extensive body of research has tracked the movement of marine nitrogen from salmon into the terrestrial ecosystems around the streams where they spawn."Salmon go up into these small streams, and whether they are caught by predators or die after spawning, their nutrients are transferred into the forests and freshwater ecosystems," he said. "It's a classic salmon ecosystem service, and the amount of nutrients they deliver depends on their body size."The study had its origins in a working group organized by the National Center for Ecological Analysis and Synthesis (NCEAS) at UC Santa Barbara through its State of Alaska's Salmon and People project. With funding from the Gordon & Betty Moore Foundation, the researchers were able to work with the Alaska Department of Fish and Game to compile data the agency had been collecting for decades, but which was dispersed among different field offices in various smaller databases."At NCEAS, we had two data scientists who compiled all the data into one massive database on Alaskan salmon that is now publicly available," Palkovacs said. "It took a lot of time and energy, but that's what enabled us to do this comprehensive analysis."Oke added that getting the data in the first place was no small task either. "When you think about the fact that we used data from 12.5 million salmon, that's how many times someone from ADF&G measured a salmon. It's an exceptional amount of work to make a dataset like this possible," she said.In addition to Oke and Palkovacs, the coauthors of the paper include corresponding author Peter Westley at University of Alaska Fairbanks, as well as researchers at Alaska Pacific University in Anchorage, UC Davis, UC Berkeley, NCEAS, McGill University in Montreal, Washington Department of Fish and Wildlife, Virginia Polytechnic Institute, Alaska Department of Fish and Game, Simon Fraser University, and Tanana Chiefs Conference, Fairbanks.
Specifically, researchers found the target genes responsible for the atmospheric chemosynthesis phenomenon they discovered are abundant and widely distributed in the polar soils of the Antarctic, Arctic and Tibetan Plateau in the Hindu Kush-Himalayas.The new research was published in the journal The study's senior author Associate Professor Belinda Ferrari, of UNSW Science, said living on air was such a minimalistic way to survive that their findings lent further potential for microbial life to exist on other planets."This is what NASA's Mars 2020 Perseverance Rover is aiming to do -- to search for signs of ancient microbial life in core samples of Martian rock and soil," A/Prof Ferrari said."A future mission will take the samples back to Earth and NASA scientists will analyse the soil in a similar way we do, to try and see whether there are any indicators of life."A/Prof Ferrari said the researchers' findings meant that microbes which use trace gases as their energy and carbon source to grow -- unlike photosynthesis which uses light -- was not a process isolated to Antarctica."There are whole ecosystems probably relying on this novel microbial carbon fixation process where microbes use the energy obtained from breathing in atmospheric hydrogen gas to turn carbon dioxide from the atmosphere into carbon -- in order to grow," she said."We think this process occurs simultaneously alongside photosynthesis when conditions change, such as during the polar winter when there is no light, but we aim to confirm this hypothesis in the next stage of our research."So, while more work is needed to confirm this activity occurs globally, the fact that we detected the target genes in the soils of the three poles means this novel process likely occurs in cold deserts around the world, but has simply been overlooked until now."Researchers analysed 122 soil samples from 14 terrestrial cold desert sites across Antarctica (Windmill Islands and Vestfold Hills), the high Arctic and Tibetan Plateau, which they collected between 2005 and 2019.The study's lead author, UNSW PhD candidate Angelique Ray, said one of the big questions the team had when they finished their previous study was whether this new process of atmospheric chemosynthesis -- also known as carbon fixation or carbon sink -- was similarly occurring in other places around the world."So, this time we did a global study. We collected the top 10-centimetre layer of soil from various sites at the three poles, which is the depth where most of the organisms we study are found," she said."The ground at those locations is completely frozen for most of the year -- and there's not a lot of soil because it's mostly rock."The researchers extracted DNA from the soil samples and then sequenced the DNA to detect the target genes responsible for the process of carbon fixation.Ms Ray said the scientists also conducted environmental analyses of each location to gauge the conditions under which the microbes lived."By looking at the environmental parameters in the soil, that's how we knew there was low carbon, low moisture and other factors at play," she said."So, we correlated the target genes for the carbon fixation process against the different sites and found the locations which are drier and lower in nutrients -- carbon and nitrogen -- had a greater potential to support this process, which made sense."A/Prof Ferrari said the researchers' findings would change the way scientists thought about the limitations required for life to exist, as well as how microbiology was taught."By investigating places outside Antarctica, we can determine how significant the contribution of this new form of chemotrophy is to the global carbon budget," she said."Before we discovered this new carbon sink process, the two main known chemotrophic forms were photosynthesis and geothermal chemotrophy -- the latter is where bacteria harness inorganic compounds like hydrogen sulfide to fix carbon."But now we have found the genes involved in this process are abundant in cold deserts, although we are yet to study hot deserts, our finding probably indicates atmospheric chemosynthesis is contributing to the global carbon budget."A/Prof Ferrari said it was likely the bacteria which survived on nothing but air had become key players in the environments in which they lived."A lot of these ecosystems are quite dry and nutrient poor -- so, these locations are mostly dominated by bacteria," she said."Particularly at the original east Antarctic sites we studied, there is not much else there apart from some mosses and lichens (fungus)."Because these bacteria have adapted to survive and have the ability to use trace gases to live, their environment has selected them to become significant contributors to their ecosystems."A/Prof Ferrari said the researchers looked forward to making new discoveries in carbon fixation."As part of the next phase, we aim to isolate one of these novel bacteria in the laboratory -- to obtain a pure culture," she said."This is difficult because the bacteria are used to growing on very little and an agar plate is different to their natural environment."Hopefully then, we can fully understand the conditions these bacteria need to carry out this unique process of living on air."
A Rutgers-led team has discovered some surprising features in coral sperm and eggs (collectively called gametes), according to a study in the journal While coral eggs are large and sperm cells are tiny and far more numerous, the scientists showed for the first time that eggs and sperm appear to be surprisingly similar when it comes to the gene functions they express during the planktonic stage. Proteins encoded by genes, in a process called gene expression, play many critical roles and perform most of the work in cells.The scientists also identified two genes that may be involved in how coral sperm and eggs recognize each other in dynamic ocean waters, allowing fertilization."Much more attention needs to be paid to coral gametes because both egg and sperm are vulnerable to climate change and other insults," said senior author Debashish Bhattacharya, a distinguished professor in the Department of Biochemistry and Microbiology in the School of Environmental and Biological Sciences at Rutgers University-New Brunswick. "It goes without saying that without robust sperm and egg, the coral reproductive cycle will be significantly weakened. Therefore, we need to understand in more detail how natural selection has acted on coral gametes to ensure their survival, leading to successful fertilization."Coral reefs protect coastlines from erosion and storms; serve as habitat, nursery and spawning grounds for fish; and provide food for about 500 million people as well as their livelihoods, according to the National Oceanic and Atmospheric Administration. But corals are threatened by global climate change that warms the ocean and leads to coral bleaching, disease, sea-level rise and ocean acidification. Other threats include unsustainable fishing, land-based pollution, tropical storms, damage from vessels, marine debris and invasive species.By analyzing the genes of the Hawaiian stony coral "Our results pave the way for future genetic investigations, particularly in the context of climate change influences on the marine environment," Bhattacharya said.
Mangroves are hardy trees and shrubs that grow in the salty, wet, muddy soils of Earth's tropical and subtropical coastlines. They protect the coastlines from erosion and storm damage; store carbon within their roots, trunks, and in the soil; and provide habitats for commercially important marine species. The study showed that overall, mangrove habitat loss declined during the period. However, losses from natural causes like erosion and extreme weather declined more slowly than human causes such as farming and aquaculture. For conservation and resource managers trying to prevent loss or re-establish new habitats, this finding highlights the need for strategies that account for natural causes of loss.The global map will benefit researchers investigating the carbon cycle impacts of mangrove gain and loss, as well as help conservation organizations identify where to protect or restore these vital coastal habitats.In 2010, mangroves covered about 53,000 square miles of Earth's coastlines, straddling the line between salt water and muddy soil with their long, stilt-like root systems. The majority of these ecosystems are found in Southeast Asia, but they exist throughout the tropical and subtropical latitudes over the globe.These hardy trees and shrubs provide a "triple whammy" of environmental benefits, said Lola Fatoyinbo Agueh, an environmental scientist at NASA's Goddard Space Flight Center in Greenbelt, Maryland. Mangroves are uniquely efficient carbon sinks: locations where carbon is stored out of the atmosphere. They make up only 3 percent of Earth's forest cover, but if they were all cut down, they could contribute up to 10 percent of global carbon emissions. Adapted to withstand salty water, strong tides, low-oxygen soils and warm tropical temperatures, mangroves protect the coastlines from erosion and storm surges and provide a "nursery" for marine creatures."Mangroves provide shoreline protection from extreme storms and tidal waves," said Fatoyinbo. "Because they are amphibious trees, their root structure protects the inland areas from the coast, and they also protect the coast from the inland areas, because they're able to accumulate a lot of the soil that comes in from upstream or from the coast. They hold that sediment in their roots and essentially grow new land. If you have areas where you have increased erosion due to sea level rise, mangroves might counter that."Mangroves have been threatened by deforestation for decades, as agriculture and aquaculture, urban development and harvesting have caused the loss of more than a quarter of mangrove forests in the past 50 years. Forests in Southeast Asia have been especially hard-hit, as countries like Indonesia clear mangroves to make room for shrimp and rice farming.When planning conservation or restoration efforts for these crucial forests, experts need to know what the primary human and natural threats are for their area. Using high-resolution imagery from Landsat 5, 7 and 8, Fatoyinbo and her colleagues used machine learning algorithms to create a high-resolution map of mangrove losses between 2000 and 2016, with an important addition: They showed what drove those losses.The team found that nearly 1300 square miles of mangrove forests were lost during the study period, or about 2 percent of global mangrove area. Sixty-two percent of the lost area was due to human causes, mainly farming and aquaculture. The rest was due to natural causes, including erosion and extreme weather events.Over the period, both human and natural drivers of loss declined, the team said. But human impact declined more quickly."On the one hand, it's great," said lead author Liza Goldberg, a NASA Goddard intern and rising freshman at Stanford University. "It shows that conservation efforts are increasing in effectiveness on a local scale, and there's an increase in awareness of the importance of mangroves, economic damage from storms, and loss of life. But on the flip side, the decline in losses, especially in Southeast Asia, means that in many areas, there are simply no more mangroves to lose."While natural drivers of loss also decreased, they did so more slowly, the team said. This shift in the proportion of loss drivers poses challenges for conservation and resource managers."The main takeaway is that conservation and restoration efforts should continue to increase their focus on evaluating and mitigating natural threats," Goldberg said.Besides their role in stabilizing coastal ecosystems, mangroves are vital to Earth's carbon cycle -- the exchange of carbon between the land, ocean, atmosphere and living things. Their leaves fall to the soil and decompose very slowly, creating carbon-rich peat instead of releasing it back into the atmosphere. When these trees and shrubs are cut down or destroyed by storms or floods, that carbon instead escapes into the atmosphere, where it contributes to climate change as a greenhouse gas."The type of carbon emissions you'll see from mangroves depend on what type of conversion is happening," said Fatoyinbo. "If you're doing clear-cutting and digging up the soil where most of the carbon is stored to put in a shrimp pond, that will have a very different rate of emission from, let's say, a tropical storm that comes in and damages standing trees, but where you might have regrowth happening afterwards."The team is collaborating with nonprofit and other organizations to put their data to work, helping with carbon emissions estimation, conservation planning and other initiatives to protect these ecosystems for future generations.Goldberg began working with Fatoyinbo and David Lagomasino when she was just 14, starting with basic lab tasks and advancing quickly to writing her own analysis codes for mangrove data. She recently completed her senior year of high school at Atholton High School in Maryland and will begin undergraduate studies at Stanford University this fall."Working with Liza has been really amazing. She's very inspiring," said Fatoyinbo. "We had a lot of discussion with her and large international organizations that are interested in mangroves, and when we asked what would help them better implement their policies and procedures, we kept hearing about needing better change maps and better understanding what the drivers of change are. Liza took that and ran with it."Goldberg plans to continue partnering with Fatoyinbo's team during her undergraduate studies."It's been an honor to work with Lola and her team for the last couple of years," Goldberg said. "It's rare to find an environment where people are so supportive regardless of your age and level of expertise, and it's been invaluable for my own research as I go into college. This environment is unique to NASA and to Goddard."
Specifically, she looked at annual average temperatures to see if they would exceed the pre-industrial seasonal maximum temperature (PSMT), or if they already had. In other words, she wanted to see how much hotter future To do this, she created individual range maps for each of the 426 species and subspecies of primates. She then estimated temperature increases as a direct result of the amount of COAccording to her calculations, a 2 degree Celsius increase in global average temperatures above pre-industrial levels -- the ceiling affirmed by the Paris Agreement -- would lead to more than a quarter of all species ranges' experiencing temperatures higher than those of pre-industrial times. For eight per cent of species, their entire current range would be significantly hotter than in the pre-industrial past."That's where my assumption really gets its power," she explains. "The maximum pre-industrial temperature under which these primates could function could have been a very brief period of time, for instance, the hottest week of the summer. But with this model, it becomes the average annual temperature."While two-thirds of primates still live in habitats with average temperatures below their PSMT, one-third are living in ranges that have experienced higher temperatures. That can spell serious trouble, especially if their ranges are particularly small."When it gets really hot, the primates need to rest in shade more. That means they can't forage for food or socialize and play as much as they should," she says. "Their food supply could also be at risk, and seasonal changes in temperature can even affect their reproductive cycles."She notes that nine species, several of them endangered and two critically so, are currently living in habitats that are entirely above their threshold temperature.Her work has clearly impressed her supervisors. Turner says she is "a superb young researcher exploring scientific questions in animal behaviour while making her research relevant to conservation and sustainability. This study models potential climate change impacts on our closest animal relatives, and Brogan is continuing to bring together primates and sustainability issues in her current PhD research."Stewart is well aware that the struggle to mitigate the effects of climate change is not the work of a single individual, but rather a collaborative effort that requires sharing knowledge among researchers. She hopes the 426 maps she created for this paper will be of use to future colleagues."If someone is looking for specific data, I could send them my maps where I isolate different species in different areas," she says. "It would be ideal if this research actually contributed to conservation efforts."
Significantly, this figure is only for three of the most common types of plastic litter in a limited size range. Yet, it is comparable in magnitude to estimates of all plastic waste that has entered the Atlantic Ocean over the past 65 years: 17 million tonnes. This suggests that the supply of plastic to the ocean have been substantially underestimated.The lead author of the paper, Dr Katsiaryna Pabortsava from the National Oceanography Centre (NOC), said "Previously, we couldn't balance the mass of floating plastic we observed with the mass we thought had entered the ocean since 1950. This is because earlier studies hadn't been measuring the concentrations of 'invisible' microplastic particles beneath the ocean surface. Our research is the first to have done this across the entire Atlantic, from the UK to the Falklands."Co-author, Professor Richard Lampitt, also from the NOC, added "if we assume that the concentration of microplastics we measured at around 200 metres deep is representative of that in the water mass to the seafloor below with an average depth of about 3000 metres, then the Atlantic Ocean might hold about 200 million tonnes of plastic litter in this limited polymer type and size category. This is much more than is thought to have been supplied. ""In order to determine the dangers of plastic contamination to the environment and to humans we need good estimates of the amount and characteristics of this material, how it enters the ocean, how it degrades and then how toxic it is at these concentrations. This paper demonstrates that scientists have had a totally inadequate understanding of even the simplest of these factors, how much is there, and it would seem our estimates of how much is dumped into the ocean has been massively underestimated."Pabortsava and Lampitt collected their seawater samples during the 26th Atlantic Meridional Transect expedition in September to November 2016. They filtered large volumes of seawater at three selected depths in the top 200 metres and detected and identified plastic contaminants using state-of-the-art spectroscopic imaging technique. Their study focussed on polyethylene, polypropylene and polystyrene, which are commercially most prominent and also most littered plastic types.This study builds on the NOC's cutting-edge research into marine plastic contamination, which aims to better understand the magnitude and persistence of exposure to plastics and the potential harms it can cause. This work was supported by the EU H2020 AtlantOS programme and the NOC. The AMT programme was supported by the UK Natural Environment Research Council's National Capability, Climate Linked Atlantic Sector Science (CLASS) programme.
The tropics wrap around Earth's middle like a warm, wet belt. This part of the globe gets the most direct sunlight throughout the year and is characterized by high average temperatures and heavy rainfall. In contrast to the tropics' lush interior, however, this region's edges are hot and parched.Scientists have noticed for the past 15 years that these arid bands are expanding toward the poles into regions like the Mediterranean, southern Australia and southern California. Interestingly, these dry areas have expanded more in the Southern Hemisphere than the Northern Hemisphere and researchers have struggled to pinpoint exactly what is driving the trend.A new study in AGU's ,Tropical expansion could have profound economic and social implications: the process could shift storm paths and cause more severe wildfires and droughts in places like California and Australia that are already water-stressed.The new findings provide the clearest evidence yet that tropical expansion is in fact primarily driven by climate change, according to the study authors. While natural long-term climate fluctuations contribute to the observed trends, these variations alone cannot explain the extent to which expansion has already occurred.This means, the authors argue, that climate change might have already significantly contributed to tropical expansion, especially in the ocean-dominated Southern Hemisphere."We demonstrate that the enhanced subtropical ocean warming is independent from the natural climate oscillations," said Hu Yang, a climate scientist at the Alfred Wegner Institute in Bremerhaven, Germany and lead author of the new study. "This is a result of global warming."A 2006 paper published in the journal Science announced a troubling finding: in some parts of the world, the tropics were expanding. Researchers have attempted to figure out the culprit ever since that paper was published. Scientists estimate from satellite observations that this widening is happening at a rate of 0.25 to 0.5 degrees latitude per decade. But without pinpointing a root cause, they cannot accurately model how quickly the expansion will occur in the future or what regions it will impact.Some researchers have suggested greenhouse gas emissions, ozone depletion and aerosols in the atmosphere are driving the expansion. But climate models using these variables to explain the expansion consistently underestimate the speed of the shift and do not account for why expansion is happening in some regions but not others. This has led some researchers to theorize that tropical expansion can simply be explained by natural oscillations in Earth's climate. But natural variation does not quite fit the patterns scientists have already observed.Yang and colleagues began to take notice of tropical expansion in 2015, when analyzing ocean currents that carry warm water toward the poles. This got them thinking: what if tropical expansion was driven not by changes in the atmosphere, but changes in the ocean?Because the ocean and atmosphere are highly connected systems, it is often difficult to tell which is driving the other, Yang said. In the new study, Yang and his colleagues analyzed water temperatures in the major ocean gyres, large circular ocean currents that carry warm water toward the poles and cold water toward the equator. They used satellite observations of sea surface temperature between 1982, the year observations began, and 2018, and compared these observations to data on the expanding tropics that stretches back to 1979.They found excess heat building up in the subtropical oceans since global warming began in the mid-1800s has driven tropical edges and ocean gyres toward the poles. When the researchers compared movement of the ocean gyres to tropical expansion, they found the two phenomena matched: tropical expansion was happening in places where the ocean gyres were moving poleward."I actually am really impressed with this paper," said Kristopher Karnauskas, associate professor in the Department of Atmospheric and Oceanic Sciences at the University of Colorado Boulder who was not connected to the new study. "There really aren't a lot of papers out there that really investigate the role of the ocean in the tropical expansion problem."
And over the past several decades, it has appeared that cold-climate forests at high latitudes have become even more effective carbon sinks as rising temperatures and higher COBut a new study led by University of Michigan researchers gives a clearer picture of what's happening in different regions, and it has cast additional uncertainty on whether those ecosystems will continue to absorb carbon as they become hotter and drier in the decades ahead.Published in The study is the first to quantify how carbon emitted from specific surface regions during the annual carbon flux affects the seasonal cycle of COKnowing this seasonal flux gives researchers a picture of how productive different forest regions are and how much carbon they remove from the atmosphere.The varied carbon flux across different forests of similar latitudes suggests that, while some forests, like those in Siberia, are continuing to increase their carbon uptake, others, like those in North America, may not. They may even absorb less as the climate changes."This research shows that we need to be thinking differently about how we understand the carbon cycle," said study co-author Gretchen Keppel-Aleks, U-M assistant professor of climate and space sciences and engineering. "We can't just lump ecosystems together by their latitude. We need to be thinking about individual species and specific seasonal cycles of temperature and precipitation."Researchers know that the swings in annual seasonal carbon flux have increased substantially in the past several decades. In the Northern Hemisphere, the intensity of the flux has gone up 30-50% since the 1960s, suggesting widespread ecological change. But because previous studies have focused on planetwide or hemisphere average fluxes, it has been unclear exactly what's driving the increase.There's been a simple narrative that warmer temperatures have been universally fueling plant photosynthesis across the high latitudes, said Brendan Rogers of Woodwell Climate Research Center (formerly Woods Hole Research Center)."While that's true on the whole, we found starkly divergent responses across regions," Rogers said. "Siberia has been greening, strengthening its carbon sink and driving increases in seasonal CO"Going forward, we need to make sure our carbon budgets and models are fully incorporating what's happening in Alaska and Canada, as these patterns are largely not captured in models and the region may soon transition from a carbon sink to a source."To produce their findings, the team began with actual measurements of atmospheric COThey then worked backwards, using a computer model to calculate the regional surface emissions that would result in atmospheric carbon levels that matched the actual observations."We used these realistic surface fluxes and released them to the atmosphere in our model, and what's unique is that we tagged individual regions differently," Keppel-Aleks said. "We could watch red CONOAA doesn't measure fluxes but instead measures carbon dioxide in the atmosphere and has been tracking the increase in the seasonal cycle since 1976 at sites like the Barrow Observatory in Alaska."These observations and the magnitude of the change we have measured are unparalleled compared with the many other sites across the globe where we track COThe research also corroborates earlier data that shows significant greening in Siberian forests alongside much less greening at similar latitudes in North America."It's really significant that, using completely independent atmospheric data, we're corroborating the browning and greening trends in the remote sensing data and showing that Siberian ecosystems do in fact seem to be growing more productive in the summer," Keppel-Aleks said."It's another unambiguous sign that humans are causing changes in the Earth's ecosystems, and it shows that we need to develop a better understanding of those ecosystems if we want to predict what's in store for the planet."
Mesoscale convective systems (MCSs) are 'megastorms' that affect large parts of the world, including Africa, Australia, Asia and the Americas, causing human and livestock deaths plus major damage to infrastructure. They can potentially:In Sahelian Africa, these extreme storms have tripled in frequency since the 1980s due to global warming.Until now, it was thought that the path of these complex weather systems was largely unpredictable.However, a new study by the UK Centre for Ecology & Hydrology (UKCEH) has found that land surface conditions frequently affect the direction and intensity of megastorms after they have formed.The research is now helping scientists to develop online tools to better forecast the path and strength of an approaching storm, which will inform alert systems for communities across Africa, providing them with up to six hours' warning. This includes Senegal, where UKCEH is working with the national meteorological service, ANACIM, to see how useful very short-term forecasts are for local emergency responses.The new study, published in the journal The researchers looked at satellite data on the activity of thousands of storms, plus land temperatures, in the Sahel for the period 2006 to 2010.Lead author Dr Cornelia Klein of UKCEH explains: "It is well known that heat provides thunderstorms with great energy, but it was commonly thought that once they are moving, they were not affected by the state of the ground over which they travelled."However, we found that drier soils increased the intensity of an MCS mid-storm, affecting the amount of rainfall they release and also where they travel. Conversely, we found storms were often weakened over moister soils.""Our finding means that, for the first time, we can predict, from satellite-observed surface conditions, how these extremely large West African storms may behave when, for example, they approach a city. A more effective alert system will enable local people to take action to protect themselves as well as their homes, livestock and possessions, plus plan emergency responses."Flash flooding frequently occurs during the storm season in the Sahel, peaking between June and September, and can have a serious impact, with water entering homes and people losing property and a safe, dry space to live. Flooding can also cause sewage overflow from inadequate drainage systems, posing a health risk to humans and animals.The study's authors say the results have important implications for 'nowcasting' (forecasting for several hours ahead) of severe weather not just in the Sahel, but potentially other MCS hotspot regions of the world.Professor Chris Taylor of UKCEH, co-author of the new paper, adds: "The pattern of these megastorms is supposed to be difficult to forecast but we found a surprising level of predictability. Very dry soils influenced around half of storms in late afternoon or early evening, when they are at their peak."Further research and advances in satellite technology will increase our certainties about their movement. In decades to come, scientists will look back at this latest study as a gamechanger in the reliable forecasting of these devastating storms."The research is part of the UKCEH-led AMMA-2050 project, which is carrying out multidisciplinary climate research to support improved forecasting, in order to enable better decision making by town planners, farmers and communities. Comprising partners from Europe and West Africa, it is funded by DFID and NERC.A DFID spokesperson said:"Highly destructive megastorms are becoming much more common because of climate change. They can devastate entire communities and it is the world's poorest people who are most at risk."UK aid is supporting ground-breaking research, led by British experts, to better anticipate storms so vulnerable African communities can better prepare for their impact, protecting themselves and their families, and making their economies more resilient to climate shocks."Thousands of people were displaced in northern Burkina Faso in mid-June 2020 after shelters were damaged there. Ouagadougou, the country's capital, has been regularly hit by flash flooding in recent years. In 2009, a downpour of 263mm over several hours forced 150,000 residents to leave their homes and eight people were killed. Within a few weeks in mid-2016, heavy rain and strong winds caused flash floods, leaving 15 dead and severely affecting healthcare facilities.
Earth's magnetic field acts like a protective shield around the planet, repelling and trapping charged particles from the Sun. But over South America and the southern Atlantic Ocean, an unusually weak spot in the field -- called the South Atlantic Anomaly, or SAA -- allows these particles to dip closer to the surface than normal. Particle radiation in this region can knock out onboard computers and interfere with the data collection of satellites that pass through it -- a key reason why NASA scientists want to track and study the anomaly.The South Atlantic Anomaly is also of interest to NASA's Earth scientists who monitor the changes in magnetic field strength there, both for how such changes affect Earth's atmosphere and as an indicator of what's happening to Earth's magnetic fields, deep inside the globe.Currently, the SAA creates no visible impacts on daily life on the surface. However, recent observations and forecasts show that the region is expanding westward and continuing to weaken in intensity. It is also splitting -- recent data shows the anomaly's valley, or region of minimum field strength, has split into two lobes, creating additional challenges for satellite missions.A host of NASA scientists in geomagnetic, geophysics, and heliophysics research groups observe and model the SAA, to monitor and predict future changes -- and help prepare for future challenges to satellites and humans in space.The South Atlantic Anomaly arises from two features of Earth's core: The tilt of its magnetic axis, and the flow of molten metals within its outer core.Earth is a bit like a bar magnet, with north and south poles that represent opposing magnetic polarities and invisible magnetic field lines encircling the planet between them. But unlike a bar magnet, the core magnetic field is not perfectly aligned through the globe, nor is it perfectly stable. That's because the field originates from Earth's outer core: molten, iron-rich and in vigorous motion 1800 miles below the surface. These churning metals act like a massive generator, called the geodynamo, creating electric currents that produce the magnetic field.As the core motion changes over time, due to complex geodynamic conditions within the core and at the boundary with the solid mantle up above, the magnetic field fluctuates in space and time too. These dynamical processes in the core ripple outward to the magnetic field surrounding the planet, generating the SAA and other features in the near-Earth environment -- including the tilt and drift of the magnetic poles, which are moving over time. These evolutions in the field, which happen on a similar time scale to the convection of metals in the outer core, provide scientists with new clues to help them unravel the core dynamics that drive the geodynamo."The magnetic field is actually a superposition of fields from many current sources," said Terry Sabaka, a geophysicist at NASA's Goddard Space Flight Center in Greenbelt, Maryland. Regions outside of the solid Earth also contribute to the observed magnetic field. However, he said, the bulk of the field comes from the core.The forces in the core and the tilt of the magnetic axis together produce the anomaly, the area of weaker magnetism -- allowing charged particles trapped in Earth's magnetic field to dip closer to the surface.The Sun expels a constant outflow of particles and magnetic fields known as the solar wind and vast clouds of hot plasma and radiation called coronal mass ejections. When this solar material streams across space and strikes Earth's magnetosphere, the space occupied by Earth's magnetic field, it can become trapped and held in two donut-shaped belts around the planet called the Van Allen Belts. The belts restrain the particles to travel along Earth's magnetic field lines, continually bouncing back and forth from pole to pole. The innermost belt begins about 400 miles from the surface of Earth, which keeps its particle radiation a healthy distance from Earth and its orbiting satellites.However, when a particularly strong storm of particles from the Sun reaches Earth, the Van Allen belts can become highly energized and the magnetic field can be deformed, allowing the charged particles to penetrate the atmosphere."The observed SAA can be also interpreted as a consequence of weakening dominance of the dipole field in the region," said Weijia Kuang, a geophysicist and mathematician in Goddard's Geodesy and Geophysics Laboratory. "More specifically, a localized field with reversed polarity grows strongly in the SAA region, thus making the field intensity very weak, weaker than that of the surrounding regions."Although the South Atlantic Anomaly arises from processes inside Earth, it has effects that reach far beyond Earth's surface. The region can be hazardous for low-Earth orbit satellites that travel through it. If a satellite is hit by a high-energy proton, it can short-circuit and cause an event called single event upset or SEU. This can cause the satellite's function to glitch temporarily or can cause permanent damage if a key component is hit. In order to avoid losing instruments or an entire satellite, operators commonly shut down non-essential components as they pass through the SAA. Indeed, NASA's Ionospheric Connection Explorer regularly travels through the region and so the mission keeps constant tabs on the SAA's position.The International Space Station, which is in low-Earth orbit, also passes through the SAA. It is well protected, and astronauts are safe from harm while inside. However, the ISS has other passengers affected by the higher radiation levels: Instruments like the Global Ecosystem Dynamics Investigation mission, or GEDI, collect data from various positions on the outside of the ISS. The SAA causes "blips" on GEDI's detectors and resets the instrument's power boards about once a month, said Bryan Blair, the mission's deputy principal investigator and instrument scientist, and a lidar instrument scientist at Goddard."These events cause no harm to GEDI," Blair said. "The detector blips are rare compared to the number of laser shots -- about one blip in a million shots -- and the reset line event causes a couple of hours of lost data, but it only happens every month or so."In addition to measuring the SAA's magnetic field strength, NASA scientists have also studied the particle radiation in the region with the Solar, Anomalous, and Magnetospheric Particle Explorer, or SAMPEX -- the first of NASA's Small Explorer missions, launched in 1992 and providing observations until 2012. One study, led by NASA heliophysicist Ashley Greeley as part of her doctoral thesis, used two decades of data from SAMPEX to show that the SAA is slowly but steadily drifting in a northwesterly direction. The results helped confirm models created from geomagnetic measurements and showed how the SAA's location changes as the geomagnetic field evolves."These particles are intimately associated with the magnetic field, which guides their motions," said Shri Kanekal, a researcher in the Heliospheric Physics Laboratory at NASA Goddard. "Therefore, any knowledge of particles gives you information on the geomagnetic field as well."Greeley's results, published in the journal Space Weather, were also able to provide a clear picture of the type and amount of particle radiation satellites receive when passing through the SAA, which emphasized the need for continuing monitoring in the region.The information Greeley and her collaborators garnered from SAMPEX's in-situ measurements has also been useful for satellite design. Engineers for the Low-Earth Orbit, or LEO, satellite used the results to design systems that would prevent a latch-up event from causing failure or loss of the spacecraft.In order to understand how the SAA is changing and to prepare for future threats to satellites and instruments, Sabaka, Kuang and their colleagues use observations and physics to contribute to global models of Earth's magnetic field.The team assesses the current state of the magnetic field using data from the European Space Agency's Swarm constellation, previous missions from agencies around the world, and ground measurements. Sabaka's team teases apart the observational data to separate out its source before passing it on to Kuang's team. They combine the sorted data from Sabaka's team with their core dynamics model to forecast geomagnetic secular variation (rapid changes in the magnetic field) into the future.The geodynamo models are unique in their ability to use core physics to create near-future forecasts, said Andrew Tangborn, a mathematician in Goddard's Planetary Geodynamics Laboratory."This is similar to how weather forecasts are produced, but we are working with much longer time scales," he said. "This is the fundamental difference between what we do at Goddard and most other research groups modeling changes in Earth's magnetic field."One such application that Sabaka and Kuang have contributed to is the International Geomagnetic Reference Field, or IGRF. Used for a variety of research from the core to the boundaries of the atmosphere, the IGRF is a collection of candidate models made by worldwide research teams that describe Earth's magnetic field and track how it changes in time."Even though the SAA is slow-moving, it is going through some change in morphology, so it's also important that we keep observing it by having continued missions," Sabaka said. "Because that's what helps us make models and predictions."The changing SAA provides researchers new opportunities to understand Earth's core, and how its dynamics influence other aspects of the Earth system, said Kuang. By tracking this slowly evolving "dent" in the magnetic field, researchers can better understand the way our planet is changing and help prepare for a safer future for satellites.
"This is a completely new way of studying life in the ocean," said study first author Deepak Krishnamurthy, a mechanical engineering PhD student at Stanford.The innovation could provide a new window into the secret life of ocean organisms and ecosystems, said study senior author Manu Prakash, associate professor of bioengineering at Stanford. "It opens scientific possibilities we had only dreamed of until now."On Earth, half of all the conversion of carbon to organic compounds occurs in the ocean, with plankton doing most of that work. The tiny creatures' outsized role in this process, known as carbon fixation, and other important planetary cycles has been hard to study in the ocean's vertically stratified landscape which involves vast depth and time scales.Conventional approaches to sampling plankton are focused on large populations of the microorganisms and have typically lacked the resolution to measure behaviors and processes of individual plankton over ecological scales. As a result, we know very little about microscale biological and molecular processes in the ocean, such as how plankton sense and regulate their depth or even how they can remain suspended in the water column despite having no appendages that aid in mobility."I could attach a tag to a whale and see where it goes, but as things get smaller and smaller it becomes extremely difficult to know and understand their native behavior," Prakash said. "How do we get closer to the native behavior of a microscopic object, and give it the freedom that it deserves because the ocean is so large a space and extremely vertically oriented?"To bridge the gap, Prakash and researchers in his lab developed a plastic contaminant based on what they call a "hydrodynamic treadmill." The idea involves a simple yet elegant insight: a circular geometry provides an infinite water column ring that can be used to simulate ocean depths. Organisms injected into this fluid-filled circular chamber move about freely as the device tracks them and rotates to accommodate their motion. A camera feeds full-resolution color images of the plankton and other microscopic marine critters into a computer for closed-loop feedback control. The device can also recreate depth characteristics in the ocean, such as light intensity, creating what the researchers call a "virtual reality environment" for single cells.The team has deployed the instrument for field testing at Stanford's Hopkins Marine Station in Monterey, in Puerto Rico and also on a research vessel off the coast of Hawaii. The innovative microscope has already revealed various microorganisms' behaviors previously unknown to science. For example, it exposed in minute detail how larvae of marine creatures from the Californian coast, such as the bat star, sea cucumber and Pacific sand dollar employ various methods to move through the sea, ranging from a steady hover to frequent changes in ciliary beat and swimming motion or blinks. This could allow scientists to better understand dispersal properties of these unique organisms in the open ocean. The device has also revealed the vertical swimming behaviors of single-celled organisms such as marine dinoflagellates, which could allow scientists to link these behaviors to ecological phenomena such as algal blooms.In Puerto Rico, Krishnamurthy and Prakash were shocked to observe a diatom, a microorganism with no swimming appendages, repeatedly change its own density to drop and rise in the water -- a puzzling behavior that still remains a mystery."It's as if someone told you a stone could float and then sink and then float again," Krishnamurthy said.Prakash credit the device's success to the interdisciplinary nature of his lab's team, which includes electrical, mechanical and optical engineers, as well as computer scientists, physicists, cell biologists, ecologists and biochemists. The team is working to extend the microscope's capabilities further by virtually mapping all aspects of the physical parameters that an organism experiences as it dives into depths of the ocean, including environmental and chemical cues and hydrostatic pressure."To truly understand biological processes at play in the ocean at smallest length scales, we are excited to both bring a piece of the ocean to the lab, and simultaneously bring a little piece of the lab to the ocean," said Prakash.Prakash is also a senior fellow at the Stanford Woods Institute for the Environment; a member of Bio-X, the Maternal & Child Health Research Institute and the Wu Tsai Neurosciences Institute; a faculty fellow at the Howard Hughes Medical Institute; and an investigator at the Chan Zuckerberg Biohub.Study co-authors include Hongquan Li, a graduate student in electrical engineering; FranÃ§ois Benoit du Rey, and Pierre Cambournac, former summer interns in the Prakash lab from Ãcole Polytechnique; Ethan Li, a graduate student in bioengineering and Adam Larson, a postdoctoral research fellow in bioengineering.Portions of the technology described here are part of a pending U.S patent.Funding provided by a Bio-X Bowes and SIGF fellowships, the National Science Foundation, the Gordon and Betty Moore Foundation, the HHMI Faculty Fellows Program.
The estimates, which scientists warn are "conservative" given the powerful effects of changes in weather systems and possible ways of accelerating ice loss, are broadly consistent with recent predictions reported by the Intergovernmental Panel on Climate Change.Professor Edward Hanna of the University of Lincoln, UK, led an international team involving Belgian, Danish, Swiss and American glaciologists and climatologists in the new study that quantifies the response of the Greenland Ice Sheet to climate change. Their findings are published in the The Greenland Ice Sheet is a giant reservoir of ice that contains enough water to ultimately raise global sea-level by seven metres.The researchers provide an updated analysis of Greenland surface air temperature data for the last three decades through to 2019, focusing mainly on coastal weather stations but also analysing records from relatively long-running sites on the interior plateau of the ice sheet. They found that Greenland coastal regions warmed significantly by about 4.4 degrees Celsius (degC) in winter and 1.7 degC in summer from 1991 to 2019. Their work, combining Greenland temperature data with computer model output of ice-sheet mass balance for 1972 to 2018, shows that each 1degC of summer warming corresponds to some 91 billion tonnes per year of surface mass loss and 116 billion tonnes per year of total mass loss from the ice sheet.The research team then used some of the latest available global and regional climate modelling tools to estimate that, under sustained strong global warming (a "business as usual" scenario), Greenland is likely to warm 4.0 to 6.6 degC by the year 2100. These recent and projected future Greenland warmings are considerably greater than global temperature changes for equivalent time periods, reflecting a high sensitivity of the polar regions to climate change.The scientists then used the relation they derived between recent changes in Greenland summer temperature and surface mass balance to calculate a 10 to 12.5 centimetres increase in global sea-level rise by 2100 arising from increased Greenland ice melt and surface mass loss.Prof. Hanna's team also explored the relation between Greenland air temperature changes and a phenomenon called atmospheric high pressure blocking which involves a greater than normal mass of air sometimes positioned over Greenland. This relation is generally present but has strengthened in spring and summer in recent decades. The authors show Greenland blocking played a crucial role in the near-record Greenland melt in the summer of 2019 (narrowly surpassed by the all-time record in 2012), and point out that possible future changes in blocking need to be better considered in computer-model projections of climate change.Prof. Hanna, Professor of Climate Science and Meteorology in Lincoln's School of Geography and Lincoln Centre for Water and Planetary Health, said "The Greenland Ice Sheet is one of the most sensitive and reliable measures of global climate change. Here we have used relatively simple statistical analysis of data and model output from the last 30 years as a sense-check on prediction of future ice-sheet surface mass change. Our work, which represents in part a major updated analysis of Greenland climate records, is highly interdisciplinary since it cross-cuts between climate science and glaciology, and so will help improve interpretation of recent ice-sheet changes."
Thanks to research published today in "We can see from the trace fossils -- tracks, trails, borings, and burrows animals left behind -- that this particular environment of the ocean floor, the offshore, served as a 'crucible' for life," said USask paleobiologist Luis Buatois, lead author of the article. "Over the next millions of years, life expanded from this area outwards into deeper waters and inwards into shallower waters."The research is the culmination of over 20 years of work from Buatois and the team which examined hundreds of rock formations in locations across every continent."Until now, these two events -- the Cambrian Explosion and the Great Ordovician Biodiversification Event -- have been understood mostly through the study of body fossils -- the shells, carapaces and the bones of ancient sea creatures," said Buatois. "Now we can confidently say that these events are also reflected in the trace fossil record which reveals the work of those soft-bodied creatures whose fleshy tissues rot very quickly and so are only very rarely preserved."For the first time, the team has shown evidence of animals actively "engineering" their ecosystem -- through the construction of abundant and diverse burrows on the sea floor of the world's oceans in this ancient time."Never underestimate what animals are capable of doing," said USask paleobiologist Gabriela MÃ¡ngano, co-author of the paper. "They can modify their physical and chemical environment, excluding other animals or allowing them to flourish by creating new resources. And they were definitely doing all these things in these ancient seas."The trace fossil-producing animals' engineering efforts may have laid the foundation for greater diversity in marine life. The researchers identified a 20-million-year time lag during the Cambrian Explosion (the time when most of the major groups of animals first appear in the fossil record) between diversification in trace fossils and in animal body fossils, suggesting the later animals exploited changes which enabled them to diversify even more.The research also helps resolve a big question from the geochemical record, which indicated much of the ancient ocean was depleted of oxygen and unsuitable for life. Like oceans today, the Cambrian ocean had certain areas that were full of life, while others lacked the necessary conditions to support it."The fact that trace fossil distribution shows that there were spots where life flourished adjacent to others devoid of animal activity all through the early Cambrian period is a strong argument in favor of the idea that zones with enough oxygen to sustain a diversity of animals co-existed with oxygen-depleted waters in deeper areas," said MÃ¡ngano. "It's a situation similar to what happens in modern oceans with oxygen minimum zones in the outer part of the continental shelf and the upper part of the continental slope, but oxygenated ones in shallower water."The research could provide new insights from an evolutionary perspective into the importance of extensive rock formations of a similar vintage found in Canada and elsewhere, and help society to prepare for coming challenges."Understanding changes that took place early in the history of our planet may help us to face present challenges in modern oceans, particularly with respect to oxygen changes," said Buatois.Other members of the team are: USask PhD student Kai Zhou, University of Portsmouth researcher Nic Minter, Senckenberg am Meer institute (Hamburg) researcher Max Wisshak, College of Wooster (Ohio) paleontologist Mark Wilson, and statistician Ricardo Olea of the United States Geological Survey.The research was funded by grants from Canada's Natural Sciences and Engineering Research Council awarded to Buatois and MÃ¡ngano.
Researchers from the Department of Earth and Environmental Sciences, including Emily Judd '20 Ph.D., Thonis Family Assistant Professor Tripti Bhattacharya and Professor Linda Ivany, have published a study titled, "A dynamical framework for interpreting ancient sea surface temperatures," in the journal "Geophysical Research Letters," to help account for the offset between location-biased paleoclimate data and the 'true' average temperature at a given latitude through Earth's history. Their work was funded by the National Science Foundation.According to Judd, accurate temperature estimates of ancient oceans are vital because they are the best tool for reconstructing global climate conditions in the past, including metrics like mean global temperature and the latitudinal temperature gradient. While climate models provide scenarios of what the world could look like in the future, paleoclimate studies (study of past climates) provide insight into what the world did look like in the past. Seeing how well the models we use to predict the future can simulate the past tells us how confident we can be in their results. It is therefore of utmost importance to have thorough, well-sampled data from the ancient past."By understanding how latitudinal temperature gradients have changed over the course of Earth's history and under a variety of different climate regimes, we can start to better anticipate what will happen in the future," says Judd.To determine ancient temperatures, geologists study proxies, which are chemical or biological traces that record temperatures from sedimentary deposits preserved on the sea floor or continents. Due to the recycling of ancient seafloor into the Earth's mantle, there is an 'expiration date' on the availability of seafloor data. Most ancient temperature proxies therefore come from sediments that accumulated on continental margins or in shallow inland seas where records can persist for much longer.Judd, Bhattacharya and Ivany use temperature data from modern oceans to reveal consistent, predictable patterns where the ocean surface is warmer or cooler, or more or less seasonal, than otherwise expected at that latitude."The biggest offsets happen to be in the two settings that are most represented in the geologic past," says Ivany. "Knowing how those regions are biased in comparison to the global mean allows researchers to better interpret the proxy data coming from the ancient Earth."Data from shallow, semi-restricted seas (e.g., the Mediterranean and Baltic Seas) show that sea surface temperatures are warmer than in the open ocean. As a result, a key finding of their paper theorizes that estimates of global mean temperature from the Paleozoic Era (~540-250 million years ago), a time when the majority of data come from shallow seas, are unrealistically hot.Even in the more recent geologic past, the overwhelming majority of sea surface temperature estimates come from coastal settings, which they demonstrate are also systematically biased in comparison to open ocean temperatures.In order to have a more accurate record of average ocean temperature at a given latitude, Bhattacharya says researchers must account for the incomplete nature of paleotemperature data. "Our work highlights the need for the scientific community to focus sampling efforts on under-sampled environments," says Bhattacharya. "New sampling efforts are essential to make sure we are equally sampling unique environmental settings for different intervals of Earth's history."According to Judd, the paleoclimate community has made major advances toward understanding ancient climates in the past few decades. New, faster, and cheaper analytical techniques, as well as a surge in expeditions that recover ocean sediment cores, have led to massive compilations of ancient sea surface temperature estimates. Despite these advancements, there are still significant disagreements between temperature estimates from different locations within the same time interval and/or between temperature estimates and climate model results."Our study provides a framework within which to reconcile these discrepancies," says Judd. "We highlight where, when and why temperature estimates from the same latitudes may differ from one another and compare different climate models' abilities to reconstruct these patterns. Our work therefore lays the groundwork to more holistically and robustly reconstruct global climate through Earth's history."
The finding, published today, Aug. 13, in the journal "We've been looking at these remote sensing observations to study how ice discharge and accumulation have varied," said Michalea King, lead author of the study and a researcher at The Ohio State University's Byrd Polar and Climate Research Center. "And what we've found is that the ice that's discharging into the ocean is far surpassing the snow that's accumulating on the surface of the ice sheet."King and other researchers analyzed monthly satellite data from more than 200 large glaciers draining into the ocean around Greenland. Their observations show how much ice breaks off into icebergs or melts from the glaciers into the ocean. They also show the amount of snowfall each year -- the way these glaciers get replenished.The researchers found that, throughout the 1980s and 90s, snow gained through accumulation and ice melted or calved from glaciers were mostly in balance, keeping the ice sheet intact. Through those decades, the researchers found, the ice sheets generally lost about 450 gigatons (about 450 billion tons) of ice each year from flowing outlet glaciers, which was replaced with snowfall."We are measuring the pulse of the ice sheet -- how much ice glaciers drain at the edges of the ice sheet -- which increases in the summer. And what we see is that it was relatively steady until a big increase in ice discharging to the ocean during a short five- to six-year period," King said.The researchers' analysis found that the baseline of that pulse -- the amount of ice being lost each year -- started increasing steadily around 2000, so that the glaciers were losing about 500 gigatons each year. Snowfall did not increase at the same time, and over the last decade, the rate of ice loss from glaciers has stayed about the same -- meaning the ice sheet has been losing ice more rapidly than it's being replenished."Glaciers have been sensitive to seasonal melt for as long as we've been able to observe it, with spikes in ice discharge in the summer," she said. "But starting in 2000, you start superimposing that seasonal melt on a higher baseline -- so you're going to get even more losses."Before 2000, the ice sheet would have about the same chance to gain or lose mass each year. In the current climate, the ice sheet will gain mass in only one out of every 100 years.King said that large glaciers across Greenland have retreated about 3 kilometers on average since 1985 -- "that's a lot of distance," she said. The glaciers have shrunk back enough that many of them are sitting in deeper water, meaning more ice is in contact with water. Warm ocean water melts glacier ice, and also makes it difficult for the glaciers to grow back to their previous positions.That means that even if humans were somehow miraculously able to stop climate change in its tracks, ice lost from glaciers draining ice to the ocean would likely still exceed ice gained from snow accumulation, and the ice sheet would continue to shrink for some time."Glacier retreat has knocked the dynamics of the whole ice sheet into a constant state of loss," said Ian Howat, a co-author on the paper, professor of earth sciences and distinguished university scholar at Ohio State. "Even if the climate were to stay the same or even get a little colder, the ice sheet would still be losing mass."Shrinking glaciers in Greenland are a problem for the entire planet. The ice that melts or breaks off from Greenland's ice sheets ends up in the Atlantic Ocean -- and, eventually, all of the world's oceans. Ice from Greenland is a leading contributor to sea level rise -- last year, enough ice melted or broke off from the Greenland ice sheet to cause the oceans to rise by 2.2 millimeters in just two months.The new findings are bleak, but King said there are silver linings."It's always a positive thing to learn more about glacier environments, because we can only improve our predictions for how rapidly things will change in the future," she said. "And that can only help us with adaptation and mitigation strategies. The more we know, the better we can prepare."This work was supported by grants from NASA. Other Ohio State researchers who worked on this study are Salvatore Candela, Myoung Noh and Adelaide Negrete.
Epidemiologists use disease atlases to identify disease prevalence and mortality rates and QUT researchers say data could be expanded by including factors such as remoteness to investigate health inequalities.QUT PhD student Farzana Jahan is the lead author of a study, published in the The study, which drew upon the Australian Cancer Atlas, considered cancers from geographical regions including major cities, inner regional, outer regional and remote areas.Cancers having higher incidence in remote areas were head and neck, liver, lung, esophageal for males and females and cervical and uterine cancers for females.While in major cities, cancers more likely to have greater incidence include brain, myeloma, non-Hodgkin lymphoma, pancreatic, stomach, thyroid cancer for both sexes, kidney cancer for males, leukemia, and ovarian cancer for females.Some cancers more likely to occur in regional areas included bowel, melanoma for both males and females, kidney cancer for females, leukemia, and prostate cancer for males.Ms Jahan said the research was an attempt to create a method by which any available disease maps or summary disease measures can be further modelled to "unmask new insights about health and medical issues" without having to go back to the individual health records."Our research provides a method for further analysing information that goes beyond the scope of disease summaries," Ms Jahan said.Dr Susanna Cramb, a biostatistician and epidemiologist based at QUT's Faculty of Health and who co-authored the study, said disease atlases are helpful for showing patterns but rarely adjusted for anything beyond age and population size."People might be interested in considering whether for instance the distance to the nearest radiotherapy facility affects survival, or the proportion of workers with high sun exposure is associated with melanoma incidence," Dr Cramb said."Comparing socioeconomic associations with certain cancer types and with other countries worldwide is another potential area to investigate."This study unlocks data from sources like the Cancer Atlas to explore and refine research hypotheses."
Periodically, a river will change its course to the sea, forming a new path through a process called river avulsion. River avulsions are a natural part of a river's life and are responsible for building new land and nourishing wetland ecosystems with water, nutrients, and sediment. However, river avulsions are also catastrophic natural hazards. They were responsible for some of the deadliest floods in human history, including the 1887 Yellow River floods and the 1931 China floods, which together claimed an estimated six million lives. On some rivers, like the Mississippi, engineers have built bypass channels and levees to counter the dangers of river avulsion."A river avulsion is a catastrophic flood that is also crucial for sustaining coastal land," says Austin Chadwick, lead author of a paper about the new model that was published by Sea level has been rising overall since the start of the 20th century, and at an accelerating pace. In 2014, the Intergovernmental Panel on Climate Change (IPCC) projected that sea level could creep up as much as three feet by the end of this century. Earth scientists have had an ongoing debate about how this could affect river avulsions on deltas, the fertile landscapes created where a river meets an ocean or lake -- a critical question, given that deltaic landscapes host roughly 10 percent of the human population."Avulsions are the earthquakes of rivers," Lamb says. "They are sudden and sometimes catastrophic natural events that occur with statistical regularity, shifting the direction of major rivers. We are trying to understand where and when the next avulsions will occur." Lamb, Chadwick, and Ganti combined theory, numerical modeling, and field observations to explain how often river avulsions will occur, and how their frequency would respond to a changing climate.They found that the occurrence of future avulsions depends mainly on two factors: the rate of sea-level rise, and the amount of silt and sand carried by a river.On most deltas, including the Mississippi River delta, sea-level rise is expected to cause more frequent catastrophic river avulsions. This is because, as sea level rises, rivers respond by depositing more of their sediment into the channel, which raises the riverbed relative to the neighboring land, making the river unstable. Eventually, a levee breach will force the river to find a shorter and steeper path to the sea. More frequent avulsions could flood coastal communities like New Orleans, Louisiana, that are already vulnerable to inundation by sea-level rise.Sea-level rise could affect not only when, but also where, future river avulsions occur. "If sea level rises faster than rivers can deposit sediment, then the zone of deposition and avulsion will shift upstream, introducing new avulsion hazards to upstream communities," Chadwick says. In such a scenario, existing river-management infrastructure (dams and levees) could be rendered obsolete, and costly avulsion-mitigation efforts would need to shift upstream.Chadwick, Lamb, and Ganti hope that this work could help guide river management on densely populated deltas, offering them a framework for calculating what to expect over the coming decades.
The implications of their results, published today in The results imply widespread ocean warming and sea level rise, compared to the past, including increased warming near the Eastern edges of ocean basins leading to more sea level rise along the Western coastlines of continents in the North Atlantic and Pacific Oceans.Co-author, Laure Zanna, Visiting Professor in Climate Physics at Oxford University and Professor in the Center of Atmosphere Ocean Science at NYU Courant, said: 'In the future, the imprint of rising atmospheric temperatures on ocean warming will likely dominate that of changes in ocean circulation. Initially, we might think that as the climate warms more, changes in ocean currents and their impact on ocean warming patterns will become larger. However, we show that that this is not the case in several regions of the ocean.'A new method, developed by scientists at Oxford University, uses climate models to suggest that ocean warming patterns will increasingly be influenced by simple uptake of atmospheric warming -- making them easier to predict. This is in contrast to now and the past when circulation changes were key factors in shaping ocean warming patterns.Changes in ocean warming due to the simple uptake of atmospheric warming are easier to model and so the scientists hope that where previous models have struggled, they might become more accurate for future projections.Lead author, Dr Ben Bronselaer, who began conducting this research while a PhD student at Oxford University, said: 'I think it is an encouraging possibility that climate models, which struggle to simulate past ocean warming, might be better at predicting future warming patterns. Better prediction of warming patterns implies better prediction of regional sea level rise, which will help to mitigate climate impacts such as flooding on individual communities. Of course, we do need to understand predictions of ocean circulation better to solidify this result.'During our research, we found a surprising relationship between ocean heat and carbon storage which appears to be unique. While there is a connection between these two quantities that is not yet fully understood, we think we have made significant progress towards uncovering it.'The These results highlight a deep and fundamental connection between ocean and carbon uptake, which has implications for atmospheric heat and carbon. While ocean carbon and heat are separate systems, this study shows that they are deeply interconnected, via the capacity of the ocean to absorb these quantities. These results help explain why atmospheric warming depends linearly on cumulative carbon emissions.Prof Laure Zanna said: 'We find that the ocean's capacity to absorb heat and carbon are coupled, and constrained by the ocean state. This implies that the present ocean state will regulate surface warming whether CO2 emissions continue to rise or decline.'The rates of ocean warming over the past 60 years have been significantly altered by changes in ocean circulation, particularly in the North Atlantic and parts of the Pacific Ocean, where we can identify cooling over some decades. However, in the future changes in ocean currents appear to play a smaller role on patterns of ocean warming, and the oceans will transport the excess anthropogenic heat in the ocean in a rather passive manner in these regions.'The modelling in this study relied on a set of creative simulations done by colleagues at The Geophysical Fluid Dynamics Laboratory (GFDL), and other published work. Using these simulations, the scientists were able to draw hypotheses on how the patterns of heat and carbon are related and how they differ.Building on this research, the scientists will now attempt to understand how the storage of heat and carbon in the ocean will affect the decline of atmospheric temperature and CO2 levels if carbon emissions start going down.They will also use the component of ocean warming that is driven by circulation changes to better understand ocean circulation changes, which are difficult to measure directly, and their impact on regional sea level in the Tropics.
The University of Queensland's Dr Elisa Bayraktarov led the team that investigated 12 coral reef restoration case studies in five countries."Coral reefs worldwide are degrading due to climate change, overfishing, pollution, coastal development, coral bleaching and diseases," Dr Bayraktarov said."Coral reef restoration -- or rebuilding what we have lost -- may become critical, especially for coral species that are threatened with extinction."Much of this work is led by environmental non-Government organisations (ENGOs), tourism operators, community groups, national resource management groups and governments who rarely publish their great depth of knowledge."So we decided to bridge the gap between academia, ENGOs and other groups that restore coral reefs."The researchers analysed the motivations and techniques used for each project, providing estimates on total annual project cost per unit area of reef restored, project duration and the spatial extent of interventions.The team found the most successful projects had high coral survival rates or an increase in coral cover, but that they also offered socioeconomic benefits for their surrounding communities."Projects that train local fishermen or recreational divers to participate in restoration, or engage with dive operators or hotels to support the maintenance of the coral nurseries, were much more effective and long-lived," Dr Bayraktarov said."We also found that coral reef restoration efforts in Latin American countries and territories were cheaper than previously thought -- with the median cost of a project around US$93,000 (~AUD$130,000) to restore one hectare of coral reef.A one-year-old coral"The projects also had run for much longer than assumed, with some active for up to 17 years."And best of all, an analysis of all the studied projects revealed a high likelihood of overall project success of 70 per cent."Co-author Dr Phanor Montoya-Maya, director and founder of the Colombian-based organisation Corales de Paz, said he was excited about the project's collaborative nature."Twenty-five Latin-American coral reef restoration scientists and practitioners from 17 institutions in five countries worked on this research," he said."We wanted to showcase the efforts of Spanish-speaking countries that depend on their local coral reefs to the global coral reef restoration community."And to share the diversity of objectives, techniques, tools used, and methods to measure success in Latin America to encourage others to carry out similar work."We're providing critical project information -- such as total annual project cost per unit area of reef restored, spatial extent of restored site and duration -- on how to best save our degraded reefs.
The study, published in July in "There are two East African rainy seasons with different sensitivities to greenhouse gases," said Kerry Cook, a professor in the Jackson School of Geosciences' Department of Geological Sciences. "Our paper shows that the short rains will continue to increase -- in fact, flooding and locust infestations are already occurring -- and that there is no drying trend for the long rains."Both the transportation of water vapor by atmospheric circulation and the distribution of rain are sensitive to differences between ocean and land temperatures. These differences occur because oceans warm and cool more slowly than the land due to differences in heat capacity.When the short rains develop, typically with a peak in November, the southern hemisphere circulation is in a summer pattern, with high pressure over the ocean and low pressure over land in the subtropics, setting up a circulation pattern that funnels more moisture over East Africa. It is this rainy season that is more sensitive to greenhouse-gas induced climate change.The region's long rains, on the other hand, appear to be less sensitive to greenhouse gas forcing. This season occurs from March through May, peaking near the northern hemisphere's spring equinox, when continental low pressures are centered over the equator.The newly published simulations have a 30 kilometer resolution that resolves the complex East African topography, and more accurately represent currently observed rainfall amounts and seasonality than coarser resolution global models. Simulations of rainfall through 2050 are consistent with currently observed rainfall amounts and seasonality. These results show that the pattern of the long rains is not changing. But the short rains are increasing: rainfall in November over East Africa will increase by about one-third by 2050 and double by 2100."This research will allow people to plan ahead in East Africa," said Cook. "But future work will need to see how additional rainfall will be delivered because, if it is as intense as in the current observations and continues to impact agriculture, developing infrastructure will be important."
Gaining a better understanding of these volcanically active areas is important, as the chemistry at seafloor vents impacts ocean chemistry more generally. In addition, the seafloor's unique environment supports biological and non-biological processes that offer clues as to how life on Earth first began, how it is sustained over time?and the potential for life on other planetary bodies.According to geochemist Jill McDermott, a professor in the Department of Earth and Environmental Science at Lehigh University, past studies of the chemistry of hydrothermal vent fluids have revealed reductions in certain gas species, such as molecular hydrogen. These depletions were thought to be caused by microbiological communities living in the shallow seafloor, collectively called the subseafloor biosphere.However, results of a new study by McDermott and colleagues contradict that assumption. The researchers analyzed gas-tight hydrothermal fluid samples from the world's deepest known vent field, the Piccard hydrothermal field at the Mid-Cayman Rise, which is at a depth of 4970 meters, or about 16,000 feet below sea level. They observed chemical shifts in their samples, including a large loss of molecular hydrogen, that could only be the result of abiotic (non-biological) and thermogenic (thermal breakdown) processes, because the fluid temperatures were beyond the limits that support life?understood to be 122 degrees Celsius, or around 250 degrees Fahrenheit, or lower.The results were published online today in an article "Abiotic redox reactions in hydrothermal mixing zones: decreased energy availability for the subsurface biosphere" in the "Our study finds that these shifts in chemistry are driven by non-biological processes that remove energy before microbial communities gain access to it," says McDermott. "This could have critical implications for constraining the extent to which global geochemical cycles can sustain a deep biosphere, and for the global hydrogen budget."She adds "This also means the subsurface biosphere is likely receiving less energy than anyone had realized previously. The degree to which non-biological hydrogen consumption in the oceanic crust may reduce the impact of life inhabiting the seafloor is a great target for future studies."Using chemical analysis of dissolved gases, inorganic compounds, and organic compounds, the team found that the low-temperature fluid samples originated from mixing between seawater and the nearby Beebe Vents black smokers, so named because the fluid expelled from the vents resembles black smoke from a chimney. In these mixed fluid samples, many chemical species are either high or low in abundance, according to McDermott. The sample with the largest shifts in the amount of gas had a seafloor temperature of 149 degrees Celsius, or 300 degrees Fahrenheit, a temperature that is too hot to host life. Thus, they concluded, the process responsible for the geochemical changes could not directly involve life.The non-biological reactions they identified as responsible for these chemical shifts include sulfate reduction and the thermal degradation of biomass, and are supported by mass balance considerations, stable isotope measurements, and chemical energetics calculations.The samples were collected during two research expeditions using two remotely operated vehicles, Jason II and Nereus, both designed for deep-water exploration and to conduct a diverse range of scientific investigations in the world's oceans."This was a really exciting field program that provided a rare opportunity for us to explore the complex interplay between the chemistry of a natural environment and the life that it supports," said Seewald. "We are now in a much better position to estimate the amount of microbial life that may exist beneath the seafloor."Discovered in 2010, the Piccard Hydrothermal Field is located just south of Grand Cayman in the Caribbean. The fluid samples the researchers examined vented at 44 to 149 degrees Celsius (111 to 300 degrees Fahrenheit), providing a rare opportunity for the team to study the transition between life-supporting and non-life-supporting environments."The cool (hot) thing about this study is that we were able to find a set of vents that spanned from where it was too hot for life, to where it was just right," says German. "That particularly cute set of circumstances opened up the possibility to gain new insights into what life might (and might not) be able to do, down beneath the seafloor."Shifts in hydrothermal vent fluid temperature and chemical composition are known to serve as an important control on microbial community structure and function in the oceanic crust throughout the world's oceans."This relationship exists because hydrothermal fluids provide energy for specific microbial metabolic reactions," says McDermott. "However, the reverse question of whether vent fluid chemistry is modified by life itself, or instead by non-living processes, is an important one that is rarely addressed."The team's discovery may serve to open up a new path of exploration toward assessing whether non-biological processes serve as important controls on energy availability, in addition to microbial processes.
Led by UC San Diego political science researcher Kathryn Baragwanath, the study uses an innovative method to combine satellite data of vegetation coverage in the Amazon rainforest, between 1982 and 2016, with Brazilian government records of indigenous property rights. The study found significantly reduced deforestation rates in territories that are owned fully and collectively by local tribes -- when compared to territories that are owned only partially by the tribes or not at all. The average effect was a 66% reduction in deforestation.The Amazon accounts for half of the Earth's remaining tropical forest, is an important source of the biodiversity on our planet and plays a major role in climate and water cycles around the world. Yet the Amazon basin is losing trees at an alarming rate, with particularly high levels in recent years, due to a combination of massive forest fires and illegal activities.Who owns the Amazon, meanwhile, is hotly contested, with numerous actors vying for the privilege. Some private entities go ahead with illegal mining or logging, for example, to demonstrate "productive use of land" and thereby gain title to that land. At present, about 2 million hectares of indigenous land are still awaiting official designation as tribal territories.Also debated is whether collective property rights are effective in curbing deforestation. These rights are granted to indigenous peoples in Brazil through a complex and lengthy constitutional process, and are distinct from the private property rights most of us are more familiar with.UC San Diego's Baragwanath and co-author Ella Bayi, now at Columbia University, say "yes, collective property rights are effective" -- if you focus your analysis on the final stage of the titling process in Brazil (which can take up to 25 years to complete), or the point at which tribes gain full property rights.Full property rights give indigenous groups official territorial recognition, enabling them not only to demarcate their territories but also to access the support of monitoring and enforcement agencies, the researcher say."Our research shows that full property rights have significant implications for indigenous people's capacity to curb deforestation within their territories," said Baragwanath. "Not only do indigenous territories serve a human rights role, but they are a cost-effective way for governments to preserve their forested areas and attain climate goals. This is important since many indigenous territories have yet to receive their full property rights and it points to where policymakers and NGOs concerned about the situation in Brazil should now focus their efforts."
And, it wasn't alone!The research, published in the Ranging in up to 33 feet in length From previous studies of cranial remains and bite marks on dinosaur fossil bones, paleontologists have long speculated that the massive beasts preyed on dinosaurs.Now this new study"There are multiple examples of bite marks made by In spite of the genus's name, which means "terror crocodile," they were actually more closely related to alligators. Based on its enormous skull, it looked like neither an alligator nor a crocodile. Its snout was long and broad, but inflated at the front around the nose in a way not seen in any other crocodylian, living or extinct. The reason for its enlarged nose is unknown."It was a strange animal," says co-author Professor Christopher Brochu a palaeontologist, from the University of Iowa. "It shows that crocodylians are not 'living fossils' that haven't changed since the age of dinosaurs. They've evolved just as dynamically as any other group.""It had two large holes are present at the tip of the snout in front of the nose," Dr Cossette says."These holes are unique to 
In the study, the United Nations Development Programme (UNDP), the National Aeronautics and Space Administration (NASA), Wildlife Conservation Society and scientists from eight leading research institutions -- including professor Scott Goetz, research professor Patrick Jantz and research associate Pat Burns of Northern Arizona University' School of Informatics, Computing, and Cyber Systems -- identified significant omissions in international forest conservation strategies. Current global targets focus solely on forest extent and fail to acknowledge the importance of forest intactness, or structural condition, creating a critical gap in action to safeguard ecosystems essential for human and planetary well-being.New targets that recognize forest quality are urgently needed to safeguard the Earth's precious humid tropical forests. Of the 1.9 million hectares of humid tropical forests globally, the study advocated for new protections in 41 percent of these areas, active restoration in 7 percent and reduction of human pressure in 19 percent to promote coordinated strategies to sustain forests of high ecological value."By serving as a convener to bring together the world's best scientists with governments, UNDP plays a critical role in ensuring that cutting-edge research is relevant for the development of key international agreements and implementation at the national level," commented Haoliang Xu, UN Assistant Secretary-General and UNDP Director of Bureau for Policy and Programme Support.Collaborating with UNDP Country Offices and key stakeholders in Brazil, Colombia, Costa Rica, the Democratic Republic of the Congo, Ecuador, Indonesia, Peru, and Viet Nam, researchers mapped the location of high-quality forests using recently developed high-resolution maps of forest structure and human pressure across the global humid tropics.The paper reveals that the Earth's humid tropical forests, only half of which have high ecological integrity, are largely limited to the Amazon and Congo Basins. The vast majority of these forests have no formal protection and, given recent rates of loss, are at significant risk.With the rapid disappearance of these 'best of the last' forests at stake, the paper provides a policy-driven framework for their conservation and restoration, recommending locations to maintain protections, add new protections, restore forest structure, and mitigate human pressure.The coming year is a so-called 'super year' for biodiversity, in which the world will agree on a new deal for nature that will shape global action for the next 30 years. Countries will also have a final chance to revise their contributions to reduce carbon emissions before the Paris Climate Agreement goes into effect. Both these milestones will impact efforts to advance the nature-based Sustainable Development Goals of the 2030 Agenda."The work reported in this paper is the result of a long process assessing the condition of the world's tropical forests," said Goetz, a co-author of the paper. "The breakthrough here was being able to use spaceborne satellite data to provide the first robust estimates of the structural condition of forests in three dimensions, not just forest canopy cover.""Advances in earth observation instruments and methodologies developed by NASA and partner institutions, coupled with the use of incredibly powerful computing systems like NAU's Monsoon and Google Earth Engine, enabled a near-global mapping of tropical forest quality. We synthesized the best available earth observation datasets to map the changing condition of the Earth's tropical forests, finding that only 6.5 percent of the highest quality tropical forests are formally protected. We hope that the conservation strategies proposed as part of this international effort will be a step towards conserving high quality forests and restoring those that have been degraded," said Burns."Every year, research reveals new ways that old, structurally complex forests contribute to biodiversity, carbon storage, water resources, and many other ecosystem services. That we can now map such forests in great detail is an important step forward in efforts to conserve them," said Jantz.
High temperatures in the Arctic during the last interglacial -- the warm period around 127,000 years ago -- have puzzled scientists for decades. Now the UK Met Office's Hadley Centre climate model has enabled an international team of researchers to compare Arctic sea ice conditions during the last interglacial with present day. Their findings are important for improving predictions of future sea ice change.During spring and early summer, shallow pools of water form on the surface of Arctic sea-ice. These 'melt ponds' are important for how much sunlight is absorbed by the ice and how much is reflected back into space. The new Hadley Centre model is the UK's most advanced physical representation of the Earth's climate and a critical tool for climate research and incorporates sea-ice and melt ponds.Using the model to look at Arctic sea ice during the last interglacial, the team concludes that the impact of intense springtime sunshine created many melt ponds, which played a crucial role in sea-ice melt. A simulation of the future using the same model indicates that the Arctic may become sea ice-free by 2035.Joint lead author Dr Maria Vittoria Guarino, Earth System Modeller at British Antarctic Survey (BAS), says:"High temperatures in the Arctic have puzzled scientists for decades. Unravelling this mystery was technically and scientifically challenging. For the first time, we can begin to see how the Arctic became sea ice-free during the last interglacial. The advances made in climate modelling means that we can create a more accurate simulation of the Earth's past climate, which, in turn gives us greater confidence in model predictions for the future."Dr Louise Sime, the group head of the Palaeoclimate group and joint lead author at BAS, says:"We know the Arctic is undergoing significant changes as our planet warms. By understanding what happened during Earth's last warm period we are in a better position to understand what will happen in the future. The prospect of loss of sea-ice by 2035 should really be focussing all our minds on achieving a low-carbon world as soon as humanly feasible."Dr David Schroeder and Prof Danny Feltham from the University of Reading, who developed and co-led the implementation of the melt pond scheme in the climate model, say:"This shows just how important sea-ice processes like melt ponds are in the Arctic, and why it is crucial that they are incorporated into climate models."The work is funded by NERC, grant number NE/P013279/1 and is part of the TiPES project (
The study, which generated future projections of climate impacts on fish in a rapidly warming sea region, suggests changes in the availability and catchability of commercially important Atlantic fish species including Atlantic cod, Dover sole, monkfish and lemon sole. This could have implications for fisheries management, and future fish diets of the British public.The Celtic Sea, English Channel and southern North Sea have experienced significant warming over the past 40 years and further increases in sea temperatures are expected over the coming decades. Projecting future changes can help prepare the fishing industry and management systems for resulting ecological, social and economic effects.The study involved researchers from the University of Exeter, the University of Bristol, the Centre for Environment, Fisheries and Aquaculture Science (Cefas) and the Met Office Hadley Centre. They used computer models to look at how fish abundances may alter by 2090 under a range of future climates. This provided opportunities to not only understand future trends, but how these trends might differ depending on the amount of warming in these seas.Main findings from the study include:Importantly, the results indicate implications not only for the wider ecosystem (e.g. predator prey dynamics or community composition) but that the fishing industry and management systems will likely have to adjust their operations to address these changes. British consumers may need to also adapt their diets into the future to eat species that could benefit under future warming, such as the warm-water species red mullet, Dover sole, john dory and squid.Lead author Dr Katherine Maltby, who undertook the research while at Cefas, said: "Our results show that climate change will continue to affect fish stocks within this sea region into the future, presenting both potential risks but some opportunities that fishers will likely have to adapt to. Consumers can help fishers take advantage of these fishing opportunities by seeking out other fish species to eat and enjoy."Co-author Louise Rutterford, from University of Exeter, said: "We know from working with fishers that warmer water species are appearing in catches more. Bringing together their 'on-the-ground' experiences with studies like ours will help inform future management decisions that enable sustainable exploitation while supporting fishers' adaptation."
The deep sea, ocean depths below 650 feet (200 metres), constitutes more than 90% of the biosphere, harbors the most remote and extreme ecosystems on the planet, and supports biodiversity and ecosystem services of global importance. Interest in deep-seabed mining for copper, cobalt, zinc, manganese and other valuable metals has grown substantially in the last decade and mining activities are anticipated to begin soon."As a team of deep-sea ecologists, we became alarmed by the misconceptions present in the scientific literature that discuss the potential impacts of seabed mining," said Smith. "We found underestimates of mining footprints and a poor understanding of the sensitivity and biodiversity of deep-sea ecosystems, and their potential to recover from mining impacts. All the authors felt it was imperative to dispel misconceptions and highlight what is known and unknown about deep seabed mining impacts."In addition to the impacts of mining on ecosystems in the water above extraction activities, as detailed in another UH-led study published last month, Smith and co-authors emphasize deep-seabed mining impacts on the seafloor, where habitats and communities will be permanently destroyed by mining."The bottom line is that many deep-sea ecosystems will be very sensitive to seafloor mining, are likely to be impacted over much larger scales than predicted by mining interests, and that local and regional biodiversity losses are likely, with the potential for species extinctions," said Smith.The scope of mining impacts from full scale mining, however, will not be well understood until a full-scale mining operation is conducted for years. The geographic scale and ecosystem sensitivities to mining disturbance occurring continuously for decades cannot be simulated or effectively studied at a smaller scale, according to the authors."All the simulations conducted so far do not come close to duplicating the spatial scale, intensity and duration of full-scale mining," said Smith. "Further, the computer models use ecosystem sensitivities derived from shallow-water communities that experience orders of magnitude higher levels turbidity and sediment burial (mining-type perturbations) under natural conditions than the deep-sea communities targeted for mining."Much of the planned deep-seabed mining will be focused in the Pacific Ocean, near Hawai'i, and also near Pacific Island nations. Hawai'i and Pacific Island nations are likely to particularly suffer from any negative environmental impacts, but may benefit economically from deep-seabed mining, creating a need to understand the trade-offs of such mining."Polymetallic-nodule mining (as currently planned) may ultimately impact 500,000 square kilometers of deep seafloor in the Pacific, an area the size of Spain, yielding perhaps the largest environmental footprint of a single extractive activity by humans," said Smith. "Addressing the misconceptions and knowledge gaps related to deep-sea mining is the first step towards effective management of deep-seabed mining."The researchers aim to work closely with regulators and society to help manage deep-seabed mining and emphasize the need to proceed slowly with seabed mining until impacts are fully appreciated.
Instead, they found that Earth's dynamic atmosphere is a wild card that plays a much bigger role than sea surface temperatures, yet defies predictability, in the wet and dry cycles that whipsaw the western states. The study, published Monday in The findings are significant for water management, agriculture, urban planning and natural resources protection. Recent droughts have claimed many lives and caused damaging crop losses, making drought forecasting a high priority. Meanwhile, the West faces rapid population growth at the same time that forecasts show dry times ahead due to global climate change."The main finding is not terribly hopeful for short-term drought prediction," said Julien Emile-Geay, a study author and associate professor of Earth sciences at the USC Dornsife College of Letters, Arts and Sciences. "We found that, historically speaking, year-to-year droughts in the western United States were less predictable than previous studies have claimed."New study examines 1,000 years of droughts in the West and beyondEmile-Geay and postdoctoral scholar Michael Erb, who is lead author from USC and now at Northern Arizona University, joined with other scientists at the University of Washington and Columbia University to produce the study.The researchers set out to answer the question: What determines droughts in the West?They examined North American droughts and global conditions spanning more than 1,000 years. Megadroughts, which lasted decades, and dry spells predate the Industrial Revolution, American expansion on the continent or European colonialism. For example, a megadrought in the late 13th century likely contributed to the dispersal of the Anasazi people.The prevailing explanation is that the El NiÃ±o-Southern Oscillation plays a key role in these drought episodes. The oscillation is a two-sided coin based on water conditions in the eastern equatorial Pacific Ocean. El NiÃ±o conditions occur when sea temperatures in the region are warmer than normal and are associated with wet years in the American Southwest; La NiÃ±a conditions occur when water is cooler than normal and are associated with dry years in the Southwest.But the scientists found that rule of thumb didn't jibe well with all drought cycles of the past. While it's true there's a correlation between La NiÃ±a and drought, these ocean water conditions accounted for only about 13% of the variability, the study says."La NiÃ±a proved to not be the only game in town," Emile-Geay said. "La NiÃ±a is part of the game, but not the biggest part."A notable example of this phenomenon occurred in 2015-16, an El NiÃ±o year when Southern California did not receive the increased precipitation that was predicted. Instead, the relief came unexpectedly the following year, a La NiÃ±a year that should have been drier than normal.What other variables can lead to drought?The scientists also examined other drought influencers, including water temperatures in the Atlantic Ocean and volcanic activity. While those phenomena can influence drought conditions, they are too weak or episodic to explain many droughts.Instead, the study says droughts can originate in the atmosphere. The air around Earth is highly dynamic and influenced by more variables than the ocean alone."The atmosphere creates a lot of variations in moisture supply on its own, and it can cook up droughts all by itself, without being told what to do by the ocean," Emile-Geay said.But while the past is key to the future, it does not hold all the keys. In the future, research says carbon emissions will continue to trap heat and warm the surface, and the West will experience increasingly dry conditions as a result."Our study suggests that the atmosphere will continue to add a strongly unpredictable element to moisture conditions in the southwestern United States, on top of drying induced by global warming," Emile-Geay said. "That is, the Southwest is headed for a drier future overall but with the atmosphere adding a wildcard that may, at times, make things better or worse for the people and ecosystems that depend on that water."The study integrates numerous sources of information spanning centuries to support the findings. The dataset, called the Last Millennium Reanalysis, aggregates climate models, modern temperature measurements and nearly 3,000 climate proxies, such as tree rings, corals, and ice cores. The reanalysis was developed by scientists at USC, the University of Washington and the University of Colorado, with the support of the National Oceanic and Atmospheric Administration. According to the NOAA, the reanalysis aimed to "transform the ways in which the climate community investigates low-frequency climate."
"In the ocean, almost everything is connected," said Christopher Piecuch, an assistant scientist in the Physical Oceanography Department at the Woods Hole Oceanographic Institution (WHOI) and author of the study. "We can use those connections to look at things in the past or far from shore, giving us a more complete view of the ocean and how it changes across space and time."Piecuch, who specializes in coastal and regional sea level change, used a connection between coastal sea level and the strength of near-shore currents to trace the evolution of the Florida Current, which forms the beginning of the Gulf Stream. The Gulf Stream flows north along the Southeast Atlantic Coast of the United States and eventually east into the North Atlantic Ocean, carrying heat, salt, momentum, and other properties that influence Earth's climate. Because nearly continuous records of sea level stretch back more than a century along Florida's Atlantic Coast and in some parts of the Caribbean, he was able to use mathematical models and simple physics to extend the reach of direct measurements of the Gulf Stream to conclude that it has weakened steadily and is weaker now than at any other point in the past 110 years.One of the biggest uncertainties in climate models is the behavior of ocean currents either leading to or responding to changes in Earth's climate. Of these, one of the most important is the Atlantic Meridional Overturning Circulation, or AMOC, which is a large system or "conveyor belt" of ocean currents in the Atlantic that includes the Gulf Stream and that helps regulate global climate. Piecuch's analysis agrees with relationships seen in models between the deeper branches of the AMOC and the Gulf Stream, and it corroborates studies suggesting that the deeper branches of AMOC have slowed in recent years. His method also offers the potential to monitor ocean currents like the Gulf Stream from the coast, complementing existing but difficult-to-maintain moored instruments and expensive research cruises."If we can monitor something over the horizon by making measurements from shore, then that's a win for science and potentially for society," said Piecuch.
Tungsten is an essential component of high-performance steels but global production is strongly influenced by China and western countries are keen to develop alternative sources.The work, published in the leading journal The research applies machine learning to multiple existing datasets to examine the geological factors that have resulted in known tungsten deposits in SW England.These findings are then applied across the wider region to predict areas where tungsten mineralisation is more likely and might have previously been overlooked. The same methodology could be applied to help in the exploration for other metals around the world.Dr Yeomans, a Postdoctoral Research Fellow at the Camborne School of Mines, based at the University of Exeter's Penryn Campus in Cornwall said: "We're really pleased with the methodology developed and the results of this study."SW England is already the focus of UK mineral exploration for tungsten but we wanted to demonstrate that new machine learning approaches may provide additional insights and highlight areas that might otherwise be overlooked."SW England hosts the fourth biggest tungsten deposit in the world (Hemerdon, near Plympton), that resulted in the UK being the sixth biggest global tungsten producer in 2017; the mine is currently being re-developed by Tungsten West Limited.The Redmoor tin-tungsten project, being developed by Cornwall Resources Limited, has also been identified as being a potentially globally significant mineral deposit.The new study suggests that there may be a wider potential for tungsten deposits and has attracted praise from those currently involved in the development of tungsten resources in SW England.James McFarlane, from Tungsten West, said: "Tungsten has only been of economic interest in the last 100 years or so, during which exploration efforts for this critical metal have generally been short-lived."As such is very encouraging to see work that aims to holistically combine the available data to develop a tungsten prospectivity model in an area that has world-class potential."Brett Grist, from Cornwall Resources added: "Our own work has shown that applying modern techniques can reveal world-class deposits in this historic and globally-significant mining district."Dr Yeomans' assertion, that the likelihood of new discoveries of tungsten mineralisation may be enhanced by a high-resolution gravity survey, is something in which we see great potential."Indeed, such a programme could stimulate the new discovery of economically significant deposits of a suite of critical metals, here in the southwest of the UK, for years to come."
Japan neighbors this ocean area, known for rich marine resources including salmon and trout. The area, located at the termination of the global ocean circulation called the ocean conveyor belt, has one of the largest biological carbon dioxide draw-downs of the world's oceans.The study, led by Hokkaido University, the University of Tokyo and Nagasaki University, showed that water rich in nitrate, phosphate and silicate -- essential chemicals for producing phytoplankton -- is pooled in the intermediate water (from several hundred meters to a thousand meters deep) in the western subarctic area, especially in the Bering Sea basin. Nutrients are uplifted from the deep ocean through the intermediate water to the surface, and then return to the intermediate nutrient pool as sinking particles through the biological production and microbial degradation of organic substances.The intermediate water mixes with dissolved iron that originates in the Okhotsk Sea and is uplifted to the surface -- pivotal processes linking the intermediate water and the surface and that maintain high surface biological productivity. This finding defies the conventional view that nutrients are simply uplifted from the deep ocean to the surface.The study relied on ocean data obtained by a research vessel that surveyed the marginal seas (the Okhotsk Sea and the Bering Sea) where, the group believed, large-scale mixture of seawater occurs due to the interaction of tidal currents with the rough topography. This voyage was made in collaboration with a Russian research team because many of the areas surveyed fall inside Russia's exclusive economic zone. The obtained data was then combined with data collected by Japanese research vessels.Analysis of the data showed that nitrate and phosphate re-produced through microbial degradation of organic substances accumulate in high concentrations in intermediate water in the entire subpolar Pacific region.The researchers also found that the vertical mixing magnitude near the Kuril Islands and the Aleutian Islands is far stronger than that in the surrounding open seas. This study demonstrated that large-scale vertical mixing in the marginal seas breaks the density stratification to mix ocean water, transporting nutrients from the intermediate water to the surface."Our findings should help deepen understanding about the circulation of carbon and nutrients in the ocean and ecological changes caused by climate change," says Associate Professor Jun Nishioka of Hokkaido University, who led the study.
Research led by the University of Leeds, in collaboration with the National Institute of Water and Atmospheric Research (NIWA) in New Zealand, mapped Southern Alps ice loss from the end of the Little Ice Age -- roughly 400 years ago -- to 2019.The study found that the rate of ice loss has doubled since glaciers were at their Little Ice Age peak extent. Relative to recent decades, the Southern Alps lost up to 77% of their total Little Ice Age glacier volume.Climate change has had a significant impact on ice loss around the world. Not only do local communities depend on glaciers as sources of fresh water, hydropower and irrigation, but mountain glacier and ice cap melt presently accounts for 25% of global sea-level rise.Rapid changes observed today for mountain glaciers need to be put into a longer-term context to understand global sea-level contributions, regional climate-glacier systems and local landscape evolution.The study, published in the journal The team reconstructed glacier volumes using historical records of glacier outlines, as well as examinations of moraines and trimlines, which are accumulations of glacial debris and clear lines on the side of a valley formed by a glacier, respectively. Moraines and trimlines can indicate former ice margin extent and ice thickness changes through time.By comparing changes in the glacier surface reconstructed during the Little Ice Age peak and the glacier surface in more recent digital elevation models, the study found that ice loss has increased two-fold since the Little Ice Age with a rapid increase in ice volume loss in the last 40 years.Up to 17% of the volume that was present at the Little Ice Age was lost between 1978 and 2019 alone. In 2019, only 12% of ice mass remained in what was formerly the low altitude part of the Little Ice Age glacier region -- also called the ablation zone -- and much of the what used to be ice-covered in the Little Ice Age ablation zone is now completely ice free.Study lead author Dr Jonathan Carrivick, from the School of Geography, said: "These findings quantify a trend in New Zealand's ice loss. The acceleration in the rate of ice mass loss may only get worse as not only climate but also other local effects become more pronounced, such as more debris accumulating on glaciers surfaces and lakes at the bottom of glaciers swell, exacerbating melt."Our results suggest that the Southern Alps has probably already passed the time of 'peak water' or the tipping point of glacier melt supply. Looking forwards, planning must be made for mitigating the decreased runoff to glacier-fed rivers because that affects local water availability, landscape stability and aquatic ecosystems."Co-author Dr Andrew Lorrey is a Principal Scientist based at NIWA who was involved with the study. He says "The long-term ice volume decline, rising snowlines, and rapid disintegration of glaciers across the Southern Alps we have observed is alarming. Photographic evidence that has been regularly collected since the late 1970s show the situation has dramatically worsened since 2010."Our findings provide a conservative baseline for rates of Southern Alps ice volume change since pre-industrial times. They agree with palaeoclimate reconstructions, early historic evidence and instrumental records that show our ice is shrinking from a warming climate."
"We've watched over the past nine-plus years as the levels of radioactive cesium have declined in seawater and in marine life in the Pacific," said Ken Buesseler, a marine chemist at the Woods Hole Oceanographic Institution and author of the new paper. "But there are quite a few radioactive contaminants still in those tanks that we need to think about, some of which that were not seen in large amounts in 2011, but most importantly, they don't all act the same in the ocean."Since 2011, Buesseler has been studying the spread of radiation from Fukushima into and across the Pacific. In June of that year, he mobilized a team of scientists to conduct the first international research cruise to study the early pathways that cesium-134 and -137, two radioactive isotopes of cesium produced in reactors, were taking as they entered the powerful Kuroshio Current off the coast of Japan. He has also built a network of citizen scientists in the U.S. and Canada who have helped monitor the arrival and movement of radioactive material on the Pacific coast of North America.Now, he is more concerned about the more than 1,000 tanks on the grounds of the power plant filling with ground water and cooling water that have become contaminated through contact with the reactors and their containment buildings. Sophisticated cleaning processes have been able to remove many radioactive isotopes and efforts to divert groundwater flows around the reactors have greatly reduced the amount of contaminated water being collected to less than 200 metric tons per day, but some estimates see the tanks being filled in the near future, leading some Japanese officials to suggest treated water should be released into the ocean to free up space for more wastewater.One of the radioactive isotopes that remains at the highest levels in the treated water and would be released is tritium, an isotope of hydrogen is almost impossible to remove, as it becomes part of the water molecule itself. However, tritium has a relatively short half-life, which measures the rate of decay of an isotope; is not absorbed as easily by marine life or seafloor sediments, and produces beta particles, which is not as damaging to living tissue as other forms of radiation. Isotopes that remain in the treated wastewater include carbon-14, cobalt-60, and strontium-90. These and the other isotopes that remain, which were only revealed in 2018, all take much longer to decay and have much greater affinities for seafloor sediments and marine organisms like fish, which means they could be potentially hazardous to humans and the environment for much longer and in more complex ways than tritium."The current focus on tritium in the wastewater holding tanks ignores the presence other radioactive isotopes in the wastewater," said Buesseler. "It's a hard problem, but it's solvable. The first step is to clean up those additional radioactive contaminants that remain in the tanks, and then make plans based on what remains. Any option that involves ocean releases would need independent groups keeping track of all of the potential contaminants in seawater, the seafloor, and marine life. The health of the ocean -- and the livelihoods of countless people -- rely on this being done right."
The worm While the worm might form a big threat to aquaculture farming, it is also likely that aquaculture itself acted as the primary vector of introduction. NIOZ researcher and co-author David Thieltges: 'A large part of the invasive species in the marine ecosystem arrive with the import of commercial species and the transfer of farmed specimens between aquaculture sites.' The worm's favourite host, the Pacific oyster, is traded and cultured globally. By moving the oyster, the worm, though not -intended, becomes an international traveller as well. The researchers, including Thieltges and AWI-scientist Andreas Waser, found the first Once introduced, the further spread of invasive species can continue either via dispersal of larval stages or human-aided secondary vectors such as fouling on ship hulls. This may explain that the worm was also found during sampling at the Mokbaai on Texel, an island without oyster farms. Thieltges underlines, that it is unlikely that the worms found near Texel came from Sylt. 'That they made their way from Sylt to Texel, along almost 500 kilometres of coastline, seems rather unlikely. We think there might be a different origin.'An option would be that larval stages of the worms found in the Dutch Wadden Sea came from Zeeland where there is commercial oyster aquaculture. However, the team still needs to investigate whether the worm is already present in Zeeland as well.' Thieltges: 'Sampling at other places in the Netherlands and in Europe together with genetic research is now needed to establish the origin and distribution of the worm. We don't know its exact origins yet, but we know that it's here and that it is very likely to keep extending its range.'
Carbonyl sulfide (OCS) is the most stable and abundant sulfur-containing gas in the atmosphere. It is derived from both natural and anthropogenic sources and is of key interest to scientists investigating how much carbon dioxide (COUnderstanding the precise OCS budget (the balance of source and sink) is an ongoing challenge. The most critical point of uncertainty related to the OCS budget is its missing source. Lack of observational evidence has so far led to debate about whether the missing OCS source is oceanic or anthropogenic emission.In a new study published in "It's very exciting that we were able to separate anthropogenic and oceanic signals for OCS sources based on sulfur isotope ratios," says Shohei Hattori, an assistant professor at Tokyo Tech and lead author of the study. "These measurements required at least 200 liters of air for each sample measurement. We overcame this challenge by developing a new sampling system, and eventually succeeded in measuring sulfur isotope ratios of the atmospheric OCS."The team found a north-south latitudinal gradient in the "The higher relevance of anthropogenic OCS at mid-to-low latitudes has implications for understanding climate change and stratospheric chemistry in both past and future contexts," says co-author Kazuki Kamezaki.Given that the historical estimation of how much CO"Our sulfur isotopic approach for measuring atmospheric OCS is an important step, but more observations, together with analysis using a chemical transport model, will enable detailed quantitative conclusions," Hattori says.
Seafood is the most highly traded food commodity globally, with tropical zone marine fisheries contributing more than 50 per cent of the global fish catch, an average of $USD 96 billion annually. Available scientific evidence consistently shows that tropical marine habitats, fish stocks and fisheries are most vulnerable to oceanic changes associated with climate change. However, the scientific review highlights that telecoupling, or linkages between distant human-natural systems, could generate cascades of climate change impacts from the tropics that propagate to other 'extra-' tropical natural systems and human communities globally."Telecoupling interactions between two or more linked areas over distance between tropical fisheries and elsewhere include distant-water fishing, the international seafood supply chain, transboundary fisheries resources and their governance would allow benefits derived from tropical fisheries to transfer to the people in the extratropical regions," said Vicky Lam, lead author and research associate in the UBC's Institute for the Oceans and Fisheries. "Although these linkages could enable the flow of benefits, including food, livelihoods and government revenue, from tropical fisheries to extratropical locations, their dependence on tropical fisheries also exposes them to the negative consequences of climate change in tropical regions. The effects of climate change on tropical fisheries also affect the profitability and employment opportunities of fish-processing industries in extratropical regions.""Pacific Island countries and territories, for example, are expected to see a redistribution of skipjack and yellowfin tuna -- their two most exported fish species -- that could see decreased catches of between 10 and 40 per cent by 2050 in many countries such as Palau and the Solomon Islands, while catches are expected to increase by 15 to 20 per cent in Kiribati and the Cook Islands. This will have a tremendous effect on the economies of these small island developing states," said Rashid Sumaila, co-author and professor at UBC's Institute for the Oceans and Fisheries and School of Public Policy and Global Affairs. "There are similar projections in African nations, where climate-related changes are expected to decrease the value of landed catch by approximately 20 per cent by 2050, as well as reduce fisheries-related jobs by 50 per cent."To reduce the effect of climate change on the benefits derived from tropical fisheries, both locally and in extra-tropical regions, the root causes of climate-driven problems in tropical fisheries need to be recognized and rectified. Effective and practical adaptation and mitigation solutions with stakeholder commitment and involvement, as well as supporting policies, are therefore necessary in the tropics."We already see that there are close linkages between the tropical regions and the extra-tropical nations through trade and distant-water fishing" said William Cheung, co-author and professor at UBC's Institute for the Oceans and Fisheries. "Solving climate change impacts in the tropics will benefit the whole world; this provides an additional argument for non-tropical countries to support climate mitigation and adaptation in tropical countries."
Fluting is a distinct technological tradition invented by early human cultures that spread across the Americas. Fluted point technology is very well known in North America, evidenced by finds across the continent dating from 13,000 to 10,000 years ago. As lead author Dr. RÃ©my Crassard of the CNRS notes, "Until the early 2000s, these fluted points were unknown elsewhere on the planet. When the first isolated examples of these objects were recognized in Yemen, and more recently in Oman, we recognized that there could be huge implications."The sites of Manayzah and Ad-Dahariz yielded dozens of fluted points. The Arabian examples date to the Neolithic period, about 8,000 to 7,000 years ago, at least two thousand years later than the American examples. As Professor Petraglia of the Max Planck explains, "Given their age and the fact that the fluted points from America and Arabia are separated by thousands of kilometers, there is no possible cultural connection between them. This is then a clear and excellent example of cultural convergence, or independent invention in human history."The new PLOS ONE article carefully examines the fluted points found in south Arabia. Detailed technological analysis, backed up by stone tool experiments and replication by an expert modern flintknapper, illustrate the similarities between the American and Arabian fluting procedures.In addition to the similarities, the authors of the new study also investigated the contrasts between the technologies of the two regions. Technological differences were apparent in the nature and location of the flute. The authors emphasize that the 'fluting method' was likely a mental conceptualization of stone tool manufacture, more than just a technical way to produce a projectile and hafting zone. Whereas the apparent function of fluting in the Americas is to facilitate hafting, or attaching the point to a shaft, most of the Arabian fluted points do not have hafting as a functional final aim. The fluting concept and the method itself are the same in both American and Arabia, yet the final aim of fluting appears to be different.Arabian and American fluted point technologies were highly specialized stone tool production methods. The PLOS ONE study of Arabian fluting technology demonstrates that similar innovations and inventions were developed under different circumstances and that such highly-skilled and convergent production methods can have different anthropological implications. As discussed in the article, Professor McCorriston argues that "fluting in Arabia was used as a display of skill, rather than serving a purely functional purpose such as hafting, as is more widely accepted in the Americas."In Arabian prehistory, southern Arabia experienced developments of local origin, with multiple examples of inventions and innovations not culturally transmitted by outside traditions. The fluting method is then a hallmark of this indigenous development in the south Arabian Neolithic.
To measure that temporary dislocation of ocean surface temperatures, which can in turn drive ecological changes, NOAA scientists have now introduced a new metric called "thermal displacement." A research paper describing the changes and the means of measuring them was published in the journal Research scientist Michael Jacox of NOAA Fisheries' Southwest Fisheries Science Center called it a powerful new way of looking at marine heatwaves."When the environment changes, many species move," Jacox said. "This research helps us understand and measure the degree of change they may be responding to."Scientists have typically characterized marine heatwaves based on how much they increase sea surface temperatures, and for how long. Such local warming particularly affects stationary organisms such as corals. In contrast, thermal displacement measures how far mobile species must move to track ocean surface temperatures.The extent of thermal displacement caused by marine heatwaves may not necessarily correspond to their intensity.Thermal displacement depends on the sea surface temperature gradient, the rate at which temperature changes across the ocean. If a heatwave warms an area of ocean, fish, turtles, whales, and other species may have to travel great distances if the temperature gradient is weak, but not if the gradient is strong."It may give us an idea how the ecosystem may change in the future," said Michael Alexander, research meteorologist at NOAA's Physical Sciences Laboratory and a coauthor of the new research. The changes may have implications for coastal communities if commercial fish species shift. Fishermen would have to travel hundreds of miles farther to reach them, he said.Changing Temperatures Highlight Management QuestionsFor example, a 2012 marine heatwave in the northwest Atlantic pushed commercial species such as squid and flounder hundreds of miles northward. At the same time it contributed to a lobster boom that led to record landings and a collapse in price."Given the complex political geography of the United States' Eastern Seaboard, this event highlighted management questions introduced by marine heatwave-driven shifts across state and national lines," the scientists wrote."While these management issues are often discussed in the context of climate change, they are upon us now," the scientists wrote. "Modern day marine heatwaves can induce thermal displacements comparable to those from century-scale warming trends, and while these temperature shifts do not solely dictate species distributions, they do convey the scale of potential habitat disruption."A 2014-2015 Pacific marine heatwave known as "the Blob," shifted surface temperatures more than 700 kilometers, or more than 400 miles, along the West Coast of the United States and in the Gulf of Alaska. That moved the prey of California sea lions farther from their rookeries in the Channel Islands off Southern California. This left hundreds of starving sea lion pups to strand on beaches.Across the world's oceans, the average long-term temperature shift associated with ocean warming has been estimated at just over 20 kilometers, about 13 miles, per decade. By comparison, marine heatwaves have displaced temperatures an average of approximately 200 kilometers, roughly 120 miles, in a matter of months. In effect, marine heatwaves are shifting ocean temperatures at similar scales to what is anticipated with climate change -- but in much shorter time frames.The research was supported by funding from the NOAA Climate Program Office's Coastal and Ocean Climate Applications program and Modeling, Analysis, Predictions, and Projections program and the NOAA Fisheries Office of Science and Technology.
Plants and animals sometimes partner up in symbiotic relationships that benefit both, such as corals that provide a protective environment for algae that live inside them, and receive oxygen and nutrients from the algae in return. Originally, scientists believed that the salamander eggs and algae may be helping one another by exchanging sugar molecules -- but a series of laboratory experiments showed molecular biologist John Burns and his colleagues Solange Duhamel at the University of Arizona and Ryan Kerney at Gettysburg College that this was not the case. Burns is the newest senior research scientist at Bigelow Laboratory for Ocean Sciences, and much of his research explores how unusual situations in cell biology can inform understanding of the way larger systems function."Direct associations between algae and vertebrate animals are rare, and so one of the big questions has always been why this symbiosis exists in the first place," Burns said. "Learning about the chemical dialog between the algae and salamander eggs is essential for understanding their relationship, and implications for other symbioses."Algae and other plants remove carbon dioxide from their surroundings for use in key biochemical processes, such as synthesizing essential molecules. Animals must assimilate, or "fix," carbon to excrete as the waste product urea. Animals also fix small amounts of carbon for use in other biochemical pathways -- including, the researchers discovered, spotted salamander embryos.Burns believes that this ability could provide a "shortcut" that makes biochemical processes in the embryos more efficient. All animals must synthesize and process dozens of molecules in order to conduct the processes necessary for life, like the conversion of food into energy and waste products. Carbon is one of the essential ingredients in these processes, and being able to quickly incorporate an additional carbon atom could confer a handy evolutionary advantage."Research today often doesn't account for the fact that animals can fix small amounts of carbon," Burns said. "Understanding that plants and animals can actually compete for carbon is one key to understanding what really happens in these symbiotic relationships."Though algae and plants require light to fix carbon, the salamander eggs do not. Burns believes that the processes taking place in the eggs may be similar to those happening in some ocean microbes, and that they could serve as a useful parallel for an often-overlooked type of carbon fixation.Previous research has shown that carbon fixation continues in the ocean even during the dark of night. It also happens in the deep ocean, beyond the reach of the sun -- but it has never been clear how much of an impact these processes have on a global scale."Learning more about these chemical dialogs could teach us about the players in dark carbon fixation, and help us begin understanding how big an effect this has on the global ocean," Burns said. "This research into the minute world inside a salamander egg can prompt us to ask new questions about the effects of competition for inorganic carbon, particularly during symbioses, on entire food webs."
The Northumbria University study, which has been published in As glaciers shrink, their surrounding mountain slopes become exposed and eroded rock debris slides down and accumulates on glacier surfaces. This debris forms a protective layer that can be many metres thick, reducing the rate at which the ice below melts. Although the effects of this protective cover are known, it has never been carefully mapped until now, and so has not been included in global glacier models.As well as revealing where rock debris is located on Earth's glaciers, the researchers also found and corrected key errors within the Randolph Glacier Inventory -- a global inventory of glacier outlines on which hundreds of studies are based.Using Landsat imagery, the research team from Northumbria University's Department of Geography and Environmental Sciences and the Swiss Federal Research Institute WSL spent three years painstakingly examining and manually verifying more than 923,000 square kilometres of glacier worldwide.The exercise allowed them to analyse the debris cover on a global-, regional-, as well as individual glacier-scale and created the world's first baseline dataset of glaciers in their current state.They found more than 29,000 square kilometres of the world's mountain glacier area is covered in rock debris -- an area equivalent to almost 500 Manhattan Islands.Lead researcher Sam Herreid undertook the study for his PhD at Northumbria University and is now believed to be the only person who has examined every glacier on Earth, manually correcting the Randolph Glacier Inventory and bringing a level of consistency that has never before been present in a global glacier dataset.He explained: "The structure of the debris cover of each glacier is unique and sensitive to climate, but until now, global glacier models have omitted debris cover from their forecasts of how glaciers respond to a changing climate."We now know that debris cover is present on almost half of Earth's glaciers, with 7.3% of the world's total mountain glacier area being debris covered."When we consider that much of this debris cover is located at the terminus, or toe, of a glacier where melt would usually be at its highest, this percentage becomes particularly important with respect to predicting future water resources and sea level rise."The study also uncovered errors within the Randolph Glacier Inventory, finding an error rate of 3.3%. One of their findings revealed that 10,000 square kilometres of mapped glacier area was not actually glacier, but rather bedrock or vegetated ground that was either incorrectly mapped previously or glacier area that has since melted away.This, combined with the melt reduction from debris insulating the ice below, means that all past global glacier models based on the Inventory are likely to have overestimated the true volume of glacier melt, run off and subsequent contribution to global sea level rise.They described the 10.6% of glacier area that requires an updated approach to estimating melt as "an alarmingly high number" and said that their work provides a key dataset for revising, and likely lowering, the glacier contribution to sea level rise.The team also devised a way to analyse how the world's debris-covered glaciers will evolve over the coming centuries.By comparing the many states of glaciers present on Earth today, from those considered to be 'young' and icy in Greenland, to 'old' and rock covered in the Himalaya, they were able to piece together a conceptual timeline which they believe outlines how a glacier might evolve in the future.Their timeline reveals that many glaciers are at the older end of the spectrum and can therefore be considered to be on the decline.Co-author Francesca Pellicciotti of the Swiss Federal Research Institute WSL and an Associate Professor at Northumbria University, explained: "The upper levels of the glaciers are constantly accumulating snow and will always be debris free, so we looked only at the lower levels of glaciers which is where rock debris can accumulate."Ice melts and flows away as water, but the rocks do not, and accumulate at the surface. Changes in the rate of mountain erosion as well as glacier changes in a warming climate will affect the size and shape of the rock layer at the surface of a glacier at any one time."Although we can't say exactly what year a glacier will evolve to a certain state, say, a state where it is almost entirely covered in rocks, we were able to place each glacier on a conceptual timeline and learn roughly how far along this line each glacier is to becoming almost entirely covered in rocks.She added: "We found that the bulk of glaciers that have a debris cover today are beyond a peak debris cover formation state and are trending closer to the "old" Himalayan glaciers that might not be around for much longer."From a climate change perspective this is one more indication of the toll a warming climate is having on Earth's glaciers. However, we now have a benchmark measurement of debris cover for all of Earth's glaciers and new tools to monitor and predict the rate of changes couple to a warming climate."
The international journal This study involved the Universities of Bologna and Padua and its coordinators are Francesco Sauro and Riccardo Pozzobon. Francesco Sauro is a speleologist and head of the ESA programmes CAVES and PANGAEA, he is also a professor at the Department of Biological, Geological, and Environmental Sciences at the University of Bologna. Riccardo Pozzobon is a planetary geologist at the Department of Geosciences of the University of Padua."We can find lava tubes on planet Earth, but also on the subsurface of the Moon and Mars according to the high-resolution pictures of lava tubes' skylights taken by interplanetary probes. Evidence of lava tubes was often inferred by observing linear cavities and sinuous collapse chains where the galleries cracked," explains Francesco Sauro. "These collapse chains represent ideal gateways or windows for subsurface exploration. The morphological surface expression of lava tubes on Mars and the Moon is similar to their terrestrial counterpart. Speleologists thoroughly studied lava tubes on Earth in Hawaii, Canary Islands, Australia and Iceland.""We measured the size and gathered the morphology of lunar and Martian collapse chains (collapsed lava tubes), using digital terrain models (DTMs), which we obtained through satellite stereoscopic images and laser altimetry taken by interplanetary probes," reminds Riccardo Pozzobon. "We then compared these data to topographic studies about similar collapse chains on the Earth's surface and to laser scans of the inside of lava tubes in Lanzarote and the Galapagos. These data allowed to establish a restriction to the relationship between collapse chains and subsurface cavities that are still intact."Researchers found that Martian and lunar tubes are respectively 100 and 1,000 times wider than those on Earth, which typically have a diameter of 10 to 30 meters. Lower gravity and its effect on volcanism explain these outstanding dimensions (with total volumes exceeding 1 billion of cubic meters on the Moon).Riccardo Pozzobon adds: "Tubes as wide as these can be longer than 40 kilometres, making the Moon an extraordinary target for subsurface exploration and potential settlement in the wide protected and stable environments of lava tubes. The latter are so big they can contain Padua's entire city centre.""What is most important is that, despite the impressive dimension of the lunar tubes, they remain well within the roof stability threshold because of a lower gravitational attraction," explains Matteo Massironi, who is professor of Structural and Planetary Geology at the Department of Geosciences of the University of Padua. "This means that the majority of lava tubes underneath the maria smooth plains are intact. The collapse chains we observed might have been caused by asteroids piercing the tube walls. This is what the collapse chains in Marius Hills seem to suggest. From the latter, we can get access to these huge underground cavities."Francesco Sauro concludes: "Lava tubes could provide stable shields from cosmic and solar radiation and micrometeorite impacts which are often happening on the surfaces of planetary bodies. Moreover, they have great potential for providing an environment in which temperatures do not vary from day- to night-time. Space agencies are now interested in planetary caves and lava tubes, as they represent a first step towards future explorations of the lunar surface (see also NASA's project Artemis) and towards finding life (past or present) in Mars subsurface."Researchers also point out how this study opens up to a completely new perspective in planetary exploration, which is increasingly focusing on the subsurface of Mars and the Moon."In autumn 2019, ESA called up universities and industries with a campaign seeking ideas for developing technologies for lunar caves exploration. They are specifically looking for systems that would land on the lunar surface to operate missions exploring lunar tubes," clarifies Unibo professor Jo De Waele, who is one of the authors of the study and a speleologist. "Since 2012, in collaboration with some European universities including Bologna and Padua, ESA has been carrying out two training programmes for astronauts focusing on the exploration of underground systems (CAVES) and planetary geology (PANGAEA). These programmes include lava tubes on the island of Lanzarote. So far, 36 astronauts from five space agencies have received training in cave hiking; moreover, six astronauts and four mission and operation specialists have received geological field training."The title of this study is "Lava tubes on Earth, Moon and Mars: A review on their size and morphology revealed by comparative planetology" and it was published in the journal 
The Southern Ocean is one of the most important pillars of the Earth's climate system. Its Antarctic Circumpolar Current, the most powerful current on the planet, links the Pacific, Atlantic and Indian Oceans, and has effectively isolated the Antarctic continent and its ice masses from the rest of the world for over 30 million years. Then and now, ocean currents can only flow where the water is sufficiently deep and there are no obstacles like land bridges, islands, underwater ridges and plateaus blocking their way. Accordingly, anyone seeking to understand the climate history and glacial history of the Antarctic needs to know exactly what the depth and surface structures of the Southern Ocean's floor looked like in the distant past.Researchers around the globe can now find this information in new, high-resolution grid maps of the ocean floor and data-modelling approaches prepared by a team of international experts led by geoscientists from the AWI, which cover nine pivotal intervals in the climate history of the Antarctic. "In the course of the Earth's history, the geography of the Southern Ocean has constantly changed, as continental plates collided or drifted apart, ridges and seamounts formed, ice masses shoved deposited sediments across the continental shelves like bulldozers, and meltwater transported sediment from land to sea," says AWI geophysicist and co-author Dr Karsten Gohl. Each process changed the ocean's depth and, in some cases, the currents. The new grid maps clearly show how the surface structure of the ocean floor evolved over 34 million years -- at a resolution of ca. 5 x 5 kilometres per pixel, making them 15 times more precise than previous models.In order to reconstruct the past water depths, the experts gathered geoscientific field data from 40 years of Antarctic research, which they then combined in a computer model of the Southern Ocean's seafloor. The basis consisted of seismic profiles gathered during over 150 geoscientific expeditions and which, when put end-to-end, cover half a million kilometres. In seismic reflection, sound waves are emitted, penetrating the seafloor to a depth of several kilometres. The reflected signal is used to produce an image of the stratified sediment layers below the surface -- a bit like cutting a piece of cake, which reveals the individual layers. The experts then compared the identified layers with sediment cores from the corresponding regions, which allowed them to determine the ages of most layers. In a final step, they used a computer model to 'turn back time' and calculate which sediment deposits were already present in the Southern Ocean at specific intervals, and to what depths in the seafloor they extended in the respective epochs.They applied this approach to nine key intervals in the Antarctic's climate history, including e.g. the warm phase of the early Pliocene, five million years ago, which is widely considered to be a potential template for our future climate. Back then the world was 2 to 3 degrees Celsius warmer on average than today, partly because the carbon dioxide concentration in the atmosphere was as high as 450 ppm (parts per million). The IPCC (IPCC Special Report on the Ocean and Cryosphere in a Changing Climate, 2019) has cited this concentration as the best-case scenario for the year 2100; in June 2019 the level was 415 ppm. Back then, the Antarctic ice shelves now floating on the ocean had most likely completely collapsed. "Based on the sediment deposits we can tell, for example, that in extremely warm epochs like the Pliocene, the large ice sheets in East Antarctica reacted in a very similar way to what we're currently seeing in ice sheets in West Antarctica," reports Dr Katharina Hochmuth, the study's first author and a former AWI geophysicist, who is now conducting research at the University of Leicester, UK.Accordingly, the new maps provide data on important climatic conditions that researchers around the world need in order to accurately simulate the development of ice masses in their ice-sheet and climate models, and to produce more reliable forecasts. Researchers can also download the corresponding datasets from the AWI's Earth system database PANGAEA.In addition to researchers from the AWI, experts from the following institutions took part in the study: (1) All Russia Scientific Research Institute for Geology and Mineral Resources of the Ocean, St. Petersburg, Russia; (2) St. Petersburg State University, Russia; (3) University of Tasmania, Australia; (4) GNS Science, Lower Hutt, New Zealand; and (5) the National Institute of Oceanography and Applied Geophysics, Italy.The grid maps depict the geography of the Southern Ocean in the following key intervals in the climate history and glacial history of the Antarctic:(2) 27 million years ago -- the early Oligocene;(3) 24 million years ago -- transition from the Oligocene to the Miocene;(4) 21 million years ago -- the early Miocene;(5) 14 million years ago -- the mid-Miocene, Miocene Climatic Optimum (mean global temperature ca. 4 degrees Celsius warmer than today; high carbon dioxide concentration in the atmosphere);(6) 10.5 million years ago -- the late Miocene, major continental-scale glaciation;(7) 5 million years ago -- the early Pliocene (mean global temperature ca. 2 -- 3 degrees Celsius warmer than today; high carbon dioxide concentration in the atmosphere);(8) 2.65 million years ago -- transition from the Pliocene to the Pleistocene;(9) 0.65 million years ago -- the Pleistocene.The data on sediment cores was gathered in geoscientific research projects conducted in connection with the Deep Sea Drilling Project (DSDP), Ocean Drilling Program (ODP), Integrated Ocean Drilling Program, and International Ocean Discovery Program (IODP).
To reach this conclusion, lead author Anna Grau Galofre, former PhD student in the department of earth, ocean and atmospheric sciences, developed and used new techniques to examine thousands of Martian valleys. She and her co-authors also compared the Martian valleys to the subglacial channels in the Canadian Arctic Archipelago and uncovered striking similarities."For the last 40 years, since Mars's valleys were first discovered, the assumption was that rivers once flowed on Mars, eroding and originating all of these valleys," says Grau Galofre. "But there are hundreds of valleys on Mars, and they look very different from each other. If you look at Earth from a satellite you see a lot of valleys: some of them made by rivers, some made by glaciers, some made by other processes, and each type has a distinctive shape. Mars is similar, in that valleys look very different from each other, suggesting that many processes were at play to carve them."The similarity between many Martian valleys and the subglacial channels on Devon Island in the Canadian Arctic motivated the authors to conduct their comparative study. "Devon Island is one of the best analogues we have for Mars here on Earth -- it is a cold, dry, polar desert, and the glaciation is largely cold-based," says co-author Gordon Osinski, professor in Western University's department of earth sciences and Institute for Earth and Space Exploration.In total, the researchers analyzed more than 10,000 Martian valleys, using a novel algorithm to infer their underlying erosion processes. "These results are the first evidence for extensive subglacial erosion driven by channelized meltwater drainage beneath an ancient ice sheet on Mars," says co-author Mark Jellinek, professor in UBC's department of earth, ocean and atmospheric sciences. "The findings demonstrate that only a fraction of valley networks match patterns typical of surface water erosion, which is in marked contrast to the conventional view. Using the geomorphology of Mars' surface to rigorously reconstruct the character and evolution of the planet in a statistically meaningful way is, frankly, revolutionary."Grau Galofre's theory also helps explain how the valleys would have formed 3.8 billion years ago on a planet that is further away from the sun than Earth, during a time when the sun was less intense. "Climate modelling predicts that Mars' ancient climate was much cooler during the time of valley network formation," says Grau Galofre, currently a SESE Exploration Post-doctoral Fellow at Arizona State University. "We tried to put everything together and bring up a hypothesis that hadn't really been considered: that channels and valleys networks can form under ice sheets, as part of the drainage system that forms naturally under an ice sheet when there's water accumulated at the base."These environments would also support better survival conditions for possible ancient life on Mars. A sheet of ice would lend more protection and stability of underlying water, as well as providing shelter from solar radiation in the absence of a magnetic field -- something Mars once had, but which disappeared billions of years ago.While Grau Galofre's research was focused on Mars, the analytical tools she developed for this work can be applied to uncover more about the early history of our own planet. Jellinek says he intends to use these new algorithms to analyze and explore erosion features left over from very early Earth history."Currently we can reconstruct rigorously the history of global glaciation on Earth going back about a million to five million years," says Jellinek. "Anna's work will enable us to explore the advance and retreat of ice sheets back to at least 35 million years ago -- to the beginnings of Antarctica, or earlier -- back in time well before the age of our oldest ice cores. These are very elegant analytical tools."
Michael Waters, director of The Center for The Study of the First Americans and Distinguished Professor at Texas A&M University, and colleagues from Baylor University and the University of Houston have had their work published in Some researchers believed the event -- which cooled the Earth by about 3 degrees Centigrade, a huge amount -- was caused by an extraterrestrial impact with the Earth, such as a meteor collision.But Waters and the team found that the evidence left in layers of sediment in Hall's Cave were almost certainly the result of volcanic eruptions.Waters said that Hall's Cave, located in the Texas hill country, has a sediment record extending over 20,000 years and he first began researching the cave in 2017."It is an exceptional record that offers a unique opportunity for interdisciplinary cooperation to investigate a number of important research questions," he said."One big question was, did an extraterrestrial impact occur near the end of the last ice age, about 13,000 years ago as the ice sheets covering Canada were melting, and cause an abrupt cooling that thrust the northern hemisphere back into the ice age for an extra 1,200 years?"Waters and the team found that within the cave are layers of sediment, first identified by Thomas Stafford (Stafford Research Laboratories, Colorado), that dated to the time of the proposed impact that could answer the question and perhaps even identify the trigger that started the ancient cold snap.The event also likely helped cause the extinction of large mammals such as mammoth, horse and camel that once roamed North America."This work shows that the geochemical signature associated with the cooling event is not unique but occurred four times between 9,000 and 15,000 years ago," said Alan Brandon, professor of geosciences at University of Houston and head of the research team."Thus, the trigger for this cooling event didn't come from space. Prior geochemical evidence for a large meteor exploding in the atmosphere instead reflects a period of major volcanic eruptions."I was skeptical," Brandon said. "We took every avenue we could to come up with an alternative explanation, or even avoid, this conclusion. A volcanic eruption had been considered one possible explanation but was generally dismissed because there was no associated geochemical fingerprint."After a volcano erupts, the global spread of aerosols reflects incoming solar radiation away from Earth and may lead to global cooling post eruption for one to five years, depending on the size and timescales of the eruption, the team said."The Younger Dryas, which occurred about 13,000 years ago, disrupted distinct warming at the end of the last ice age," said co-author Steven Forman, professor of geosciences at Baylor.The Earth's climate may have been at a tipping point at the end of Younger Dryas, possibly from the ice sheet discharge into the North Atlantic Ocean, enhanced snow cover and powerful volcanic eruptions that may have in combination led to intense Northern Hemisphere cooling, Forman said."This period of rapid cooling coincides with the extinction of a number of species, including camels and horses, and the appearance of the Clovis archaeological tradition," said Waters.Brandon and fellow University of Houston scientist Nan Sun completed the isotopic analysis of sediments collected from Hall's Cave. They found that elements such as iridium, ruthenium, platinum, palladium and rhenium were not present in the correct proportions, meaning that a meteor or asteroid could not have caused the event."The isotope analysis and the relative proportion of the elements matched those that were found in previous volcanic gases," said Sun, lead author of the report.Volcanic eruptions cause their most severe cooling near the source, usually in the year of the eruption, with substantially less cooling in the years after the eruption, the team said.The Younger Dryas cooling lasted about 1,200 years, "so a sole volcanic eruptive cause is an important initiating factor, but other Earth system changes, such as cooling of the oceans and more snow cover were needed to sustain this colder period, "Forman said.Waters added that the bottom line is that "the chemical anomalies found in sediments dating to the beginning of the Younger Dryas are the result of volcanism and not an extraterrestrial impact."
The most relevant quantity for assessing the impacts of sea-level change on these communities is the relative sea-level rise -- the elevation change between the Earth's surface height and sea surface height. For an observer standing on the coastland, relative sea-level rise is the net change in the sea level, which also includes the rise and fall of the land beneath observer's feet.Now, using precise measurements from state-of-the-art satellite-based interferometric synthetic aperture radar (InSAR) that can detect the land surface rise and fall with millimeter accuracy, an Arizona State University research team has, for the first time, tracked the entire California coast's vertical land motion.They've identified local hotspots of the sinking coast, in the cities of San Diego, Los Angeles, Santa Cruz and San Francisco, with a combined population of 4 to 8 million people exposed to rapid land subsidence, who will be at a higher flooding risk during the decades ahead of projected sea-level rise."We have ushered in a new era of coastal mapping at greater than 1,000 fold higher detail and resolution than ever before," said Manoochehr Shirzaei, who is the principal investigator of the NASA-funded project. "The unprecedented detail and submillimeter accuracy resolved in our vertical land motion dataset can transform the understanding of natural and anthropogenic changes in relative sea-level and associated hazards."The results were published in this week's issue of The research team included graduate student and lead author Em Blackwell, and faculty Manoochehr Shirzaei, Chandrakanta Ojha and Susanna Werth, all from the ASU School of Earth and Space Exploration (Werth has a dual appointment in the School of Geography and Urban Planning).Em Blackwell had a keen interest in geology, and as Blackwell began graduate school, the applications of InSAR drew them to pursue this project. InSAR uses radar to measure the change in distance between the satellite and ground surface, producing highly accurate deformation maps of the Earth's surface at 10s m resolution over 100s km spatial extent.Land subsidence can occur due to natural and anthropogenic processes or a combination of them. The natural processes comprise tectonics, glacial isostatic adjustment, sediment loading, and soil compaction. The anthropogenic causes include groundwater extraction and oil and gas production.As of 2005, approximately 40 million people were exposed to a 1 in 100-year coastal flooding hazard, and by 2070 this number will grow more than threefold. The value of property exposed to flooding will increase to about 9% of the projected global Gross Domestic Product, with the U.S., Japan, and the Netherlands being the countries with the most exposure. These exposure estimates often rely only on projections of global average sea level rise and do not account for vertical land motion.The study measured the entire 1350-kilometer long coast of California from 2007-2018, compiling 1000s of satellite images over time, used for making a vertical land motion map with 35-million-pixel at ~80 m resolution, comprising a wide range of coastal uplift and subsidence rates. Coastal communities' policymakers and the general public can freely download the data (link in supplemental data).The four metropolitan areas majorly affected in these areas included San Francisco, Monterey Bay, Los Angeles, and San Diego."The vast majority of the San Francisco Bay perimeter is undergoing subsidence with rates reaching 5.9 mm/year," said Blackwell. "Notably, the San Francisco International Airport is subsiding with rates faster than 2.0 mm/year. The Monterey Bay Area, including the city of Santa Cruz, is rapidly sinking without any zones of uplift. Rates of subsidence for this area reach 8.7 mm/year. The Los Angeles area shows subsidence along small coastal zones, but most of the subsidence is occurring inland."Areas of land uplift included north of the San Francisco Bay Area (3 to 5 mm/year) and Central California (same rate).Going forward in the decades ahead, the coastal population is expected to grow to over 1 billion people by 2050, due to coastward migration. The future flood risk that these communities will face is mainly controlled by the rate of relative sea-level rise, namely, the combination of sea-level rise and vertical land motion. It is vital to include land subsidence into regional projections that are used to identify areas of potential flooding for the urbanized coast.Beyond the study, the ASU research team is hopeful that others in the scientific community can build on their results to measure and identify coastal hazards more broadly in the U.S. and around the world.
Ship-based observations with the German research vessel METEOR in September 2015 provided first measurements of a strong turbulent mixing event below the sea surface, where mixing was up to a factor of 100 higher than previously observed at this location. "When we noticed the greatly enhanced turbulence in the water column during data processing, we at first suspected a malfunction of our sensors," says Dr. Marcus Dengler, co-author of the study. "But when we also noticed strong currents at the ocean surface, we became curious." Precisely such events can explain the lower temperatures at the ocean surface."We were able to isolate the process behind this strong mixing event, which lasted only for a few days," explains Dr. Hummels. "It is a so-called inertial wave, which is a very short but intense flow event," Hummels continues. Inertial waves are horizontal wave phenomena in which the current at the surface rotates clockwise with time, whereas the movement rapidly decays with increasing depth. The different velocities at the surface and in the layer below cause instabilities and ultimately mixing between the warm water in the surface layer and the colder water below. Such inertial waves can be caused by brief variations in the near-surface winds. Up to now, generally only weak currents have been observed in this region and the rather steady trade winds at this time of year did not suggest particularly strong mixing events. However, wind variations are crucial to trigger these waves in the upper ocean. The winds do not have to be particularly strong, but ideally should rotate the same way the ocean currents do. Since such wind fluctuations are relatively rare and only last a few days, it has not yet been possible to measure such a strong wave phenomenon with the associated strong mixing in this region.After the discovery of this event during the METEOR cruise in September 2015, the Kiel scientists wanted to know more about the frequency and the actual impact of such events. "Through model-based data analysis, we were able to give a context to the in-situ observations," explains co-author Dr. Willi Rath from the Research Unit Ocean Dynamics at GEOMAR. "Together, we have scanned 20 years of global wind observations looking for similar events triggered by wind fluctuations and described their occurrence in the region and during the course of the year," Dr. Rath adds. This has supported the hypothesis that the temporal and spatial distribution of such events can indeed explain the gap in the heat balance of the upper ocean.The strong turbulent mixing caused by the inertial waves at the base of the surface layer is also crucial for biology: For example, the cold water that is mixed into the surface layer during such an event also brings nutrients from deeper layers into the upper ocean penetrated by sunlight. "This also explains the hitherto largely unexplained occurrence of chlorophyll blooms in this region, which could now also be attributed to the seasonally increased occurrence of these inertial waves," explains Dr. Florian SchÃ¼tte, also co-author of the study.The ship measurements in the tropical Atlantic were carried out in close cooperation with the international PIRATA program. For more than 20 years, the PIRATA surface buoys have been providing valuable data for studies of ocean-atmosphere interaction, which were also used for this study. "Indeed, the intensive mixing measurements resulted from a failure in the hydraulic system of the METEOR, which made other measurements impossible at that time," says Prof. Dr. Peter Brandt, chief scientist of the expedition. Despite buoys and series of ship expeditions to this region, new phenomena are still being discovered -- sometimes by chance -- which decisively advance our understanding of the tropical climate.
"Traditional satellite remote sensing approaches can collect a wide range of information about the upper ocean, but satellites typically can't 'see' deeper than the top five or 10 meters of the sea," said Barney Balch, a senior research scientist at Bigelow Laboratory for Ocean Sciences and an author of the paper. "Harnessing a tool that lets us look so much deeper into the ocean is like having a new set of eyes."Lidar uses light emitted by lasers to gain information about particles in seawater, much as animals like bats and dolphins use sound to echolocate targets. By sending out pulses of light and timing how long it takes the beams to hit something and bounce back, lidar senses reflective particles like algae in the water.Lead study author Brian Collister used a shipboard lidar system to detect algae and learn about conditions deeper in the ocean than satellites can measure. The research team on this 2018 cruise was composed of scientists from Old Dominion University and Bigelow Laboratory for Ocean Sciences."The lidar approach has the potential to fill some important gaps in our ability to measure ocean biology from space," said Collister, a PhD student at Old Dominion University. "This technique will shed new light on the distribution of biology in the upper oceans, and allow us to better understand their role in Earth's climate."In the Gulf of Maine, the team used lidar to detect and measure particles of the mineral calcium carbonate, gathering information about a bloom of coccolithophores. These algae surround themselves with calcium carbonate plates, which are white in color and highly reflective. The plates scatter light in a unique way, fundamentally changing how the light waves are oriented -- and creating an identifiable signature that the lidar system can recognize.Balch's research team has studied the Gulf of Maine for over two decades through the Gulf of Maine North Atlantic Time Series. Their experience in finding and identifying algae in this ecosystem provided key background information for testing the lidar system in what turned out to be the largest coccolithophore bloom observed in the region in 30 years."This cruise allowed us an ideal opportunity to try the lidar system out with the ability to sample the water and know exactly what species were in it," Balch said. "Lidar has been used in the ocean for decades, but few, if any, studies have been done inside a confirmed coccolithophore bloom, which profoundly changes how light behaves in the environment."Coccolithophores thrive around the global ocean and exert a huge level of control on the biogeochemical cycles that shape the planet. Studying them is key to understanding global ocean dynamics, but field research is always costly. The team established that using lidar could potentially allow researchers to remotely estimate coccolithophore populations without stopping the ship to collect water samples -- increasing their ability to collect valuable data, thus also conserving precious ship-time funds.The research team also tested this approach in ocean environments that included the clear depths of the Sargasso Sea and the turbid waters off the coast of New York City. They found it to be effective across these diverse environments. Lidar systems can probe the ocean up to three times deeper than passive satellite remote sensing techniques that rely on the sun. Further research may establish approaches that allow lidar measurements to be taken by satellites, as well."It's a huge deal that we are learning to reliably identify particles in the ocean from a lidar system positioned above the water," said Richard Zimmerman, a study author and professor at Old Dominion University. "This is a significant advance, and it could revolutionize our ability to characterize and model marine ecosystems."This work was supported by the National Aeronautics and Space Administration, the National Science Foundation, and the Virginia SpaceGrant Consortium.
A study carried out at the University of Barcelona and the Southern Centre for Scientific Research (CADIC-CONICET, Argentina), analysed the potential implications in the distribution of the Argentinian hake (The study, published in the journal Researchers focused on the Atlantic coast of Isla Grande in Tierra del Fuego, in the extreme south of Argentina, where the hake is a key species for industrial fisheries. They collected samples from two archaeological sites dating from the Middle Holocene, that is, between 6,000 and 500 years ago, a period when temperatures would be analogous to those we are heading to in the future -according to climate models. "Remains from fish that lived in the warmest periods of the Holocene are specially interesting since they offer a plausible view of the future in the context of global warming. At the moment, the average annual temperature of the sea surface in Tierra del Fuego is about 7ÂºC, but during the Middle Holocene it reached 11 and 12ÂºC. Therefore, data on the biology of the hake during this period can provide information on the distribution of this species in a near future," note the authors.The presence of remains from other models of hake in the archaeological site RÃ­o Chico 1, in the north of Tierra del Fuego (Argentina), show the existence of a large population of hake in the northern east of Tierra del Fuego during the Middle Holocene. Since then, this population disappeared due to the cooling temperatures and their habitat was unknown.In order to discover the habitat of these fish, the first step in the study was to identify the remains through the mitochondrial DNA analysis and make a reconstruction of the size of old models. Then, researchers used the technique of carbon and nitrogen stable isotope analysis to study changes in the trophic position and the use of the habitat over time. This technique enables researchers to get information on the food intake, and the environment of the species that lived in a recent past, since the information is registered in the bone isotopic signal.Results show that Argentinian hake that lived in the Atlantic coast of Tierra del Fuego during the Middle Holocene had a broader isotopic niche and fed in more coastal habitats compared to those in current times. "This information, combined with strong winds and currents of the region, together with the lack of sailing technology during the Middle Holocene suggest that groups of aboriginal hunter-fisher-gatherers were likely to fish in the shore," note the authors. If the environmental conditions of a warmer world coincide with what prevails in the Middle Holocene, the Argentinian hake could be more abundant in the continental Argentinian platform of Tierra del Fuego. "From a fishing perspective, this situation suggests a potential increase of resources in shallow waters regarding Tierra del Fuego with important changes in the fishing industry in this region," highlights LluÃ­s Cardona.According to the researchers, this methodology can be used with other species and in other areas of the planet. "In the future, we would like to know the changes that have taken place in the distribution and ecological niche of the hake and the cod in European waters," concludes the researcher.
A new study published by GEOMAR scientists today in the During expeditions with RV POSEIDON in 2017 and 2019, the researchers were able to detect gas leakage at 28 of 43 directly investigated wells. 'The propensity for such leaks increases the closer the boreholes are located with respect to shallow gas pockets, which are normally uninteresting for commercial use. Apparently, however, the disturbance of the overburden sediment by drilling process causes the gas to rise along the borehole,' explains Dr. Matthias Haeckel from GEOMAR, who lead the study.In addition, the team used available seismic data of the industry from the British sector of the North Sea to make further statements about the boreholes in the area. 'We cover 20,000 square kilometres of seafloor in our study, which is approximately the size of Wales. This area contains 1,792 wells of which we have information. We evaluated a number of factors, such as location, distance to shallow gas pockets, and age, based on our direct measurements and weighted how these factors promote methane gas leakage from old wells. The most important factor was indeed the distance of the wells from the gas pockets,' explains Dr. BÃ¶ttner.The positions of the boreholes and the location and extent of the gas pockets indicate that this area of the North Sea alone has the potential to emit 900 to 3700 tonnes of methane every year. 'However, more than 15,000 boreholes have been drilled in the entire North Sea,' adds Dr Haeckel.In seawater, methane is usually consumed by microbes. This can lead to local seawater acidification. In the North Sea, about half of the boreholes are at such shallow water depths that part of the emitted methane can escape into the atmosphere. Methane is the second most important greenhouse gas after carbon dioxide.The authors of the study encourage the industry to publish their data and recommend more independent emission measurements from abandoned wells in order to develop stricter guidelines and legally binding regulations for abandonment procedures.'The sources and sinks of methane, the second most important greenhouse gas after carbon dioxide, are still subject to large uncertainties. This also applies to emissions from the fossil energy sector. In order to better understand the reasons for the continuously increasing methane concentrations in the atmosphere and to be able to take mitigation measures, it is important to have a reliable numbers of the individual anthropogenic contributions,' summarizes Dr. Haeckel.
The paper, published July 27, 2020 in "We hear a lot about changes in the Arctic with respect to temperature, how ecosystems and animals are going to be affected," said Rory Laiho, co-author and PhD student in atmospheric and oceanic sciences. "But this particular study gives an added perspective on what's happening physically to the ocean itself, which then can have important implications for ocean circulation and climate."Since the 1990s, the Arctic Ocean has seen a 10% increase in its freshwater. That's 2,400 cubic miles (10,000 cubic kilometers), the same amount it would take to cover the entire U.S. with 3 feet of water.The salinity in the ocean isn't the same everywhere, and the Arctic Ocean's surface waters are already some of the freshest in the world due to large amounts of river runoff.This freshwater is what makes sea ice possible: it keeps cold water at the surface, instead of allowing this denser liquid to sink below less dense, warm water. In this way, the Arctic Ocean is much different than other oceans. But as more freshwater exits the Arctic, this same stabilizing mechanism could disrupt the ocean currents in the North Atlantic that moderate winter temperatures in Europe.Such disruptions have happened before, during the "great salinity anomalies" of the 1970s and 80s. But these were temporary events. If too much cold freshwater from the Arctic continuously flows into the North Atlantic, the ocean turnover could be disrupted more permanently.Ironically, this would mitigate the impacts of global warming during winter in northern Europe for a while. But disrupting the ocean currents could have negative effects for climate long-term and on the North Atlantic's ecosystems.The main mission of the research for Alexandra Jahn, lead author of the new study and assistant professor in the Department of Atmospheric and Oceanic Sciences and the Institute of Arctic and Alpine Research, and her graduate student, Laiho, was to differentiate between natural variability cycles in Arctic freshwater amounts and climate change's impact. They examined the results from an ensemble of models run from 1920 to 2100."When we look at all the simulations together, we can see if they all do the same thing. If so, then that's due to a forced response," said Jahn. "If those changes are big enough so they could not occur without increasing greenhouse gases in the model simulations, that's what we call the emergence of a clear climate change signal. And here we see such clear climate change signals for the Arctic freshwater during the current decade."Their results showed that Nares Strait, which runs between Greenland and Canada and is the most northern gateway between the Arctic and more southern oceans -- will be the first place to see a freshwater export increase attributable to climate change in the next decade. Other straits farther south and east, including Davis and Fram straits, will be next to show this signal.The researchers also ran the models through different emissions scenarios to see if these changes will be affected by humans' emissions choices in the next few decades. They looked at the "business as usual" (over 4 degrees Celsius warming by the end of the century) scenario and what would happen if humans limited warming to 2 degrees Celsius, the upper end of IPCC (Intergovernmental Panel on Climate Change) targets for this century.They found that the change in freshwater in the Arctic Ocean and the amounts moving through the northern straits were unaffected since they will be subject to an increase in freshwater before the 2040s -- and the decisions made globally in the next few decades will not influence them, as these climatic changes are already in motion. But in the second half of this century, the two scenarios diverged, and increases in freshwater amounts were seen in more places in the high-warming scenario than in the low-warming scenario."What this work is showing us is that we're probably already experiencing the first of these changes, we just can't tell from the direct observations yet," Jahn said.All water from the Arctic Ocean eventually ends up in the North Atlantic. But timing is everything. Being able to predict the timing of the emergence of climate change signals will allow scientists to monitor upcoming changes in real time, and better understand how changes in the Arctic Ocean can impact climate worldwide."It fills a gap in our current understanding, and helps us ask new questions about what physically is happening in the Arctic," said Jahn.
"This new ocean current and the path it takes toward the Faroe Bank Channel are exciting findings," said LÃ©on Chafik, the lead author of the paper published in "The two discoveries reported here, in one of the best studied areas of the world ocean, is a stark reminder that we still have much to learn about the Nordic Seas," said co-author Thomas Rossby, emeritus professor at the URI Graduate School of Oceanography. "This is crucial given the absolutely fundamental role they play in the major glacial-interglacial climate swings."Previous studies dealing with this deep flow have long assumed that these cold waters, which flow along the northern slope of the Faroes, turn directly into the Faroe-Shetland Channel (the region the water flows through before reaching the Faroe Bank Channel). Instead, Chafik and the paper's co-authors show that there exists another path into the Faroe-Shetland Channel. They show that water can take a longer path all the way to the continental margin outside Norway before turning south heading toward this major waterfall. "Revealing this newly identified path from available observations was not a straightforward process and took us a good deal of time to piece together" said Chafik.The researchers also found this new path depends on prevailing wind conditions. "It seems that the atmospheric circulation plays a major role in orchestrating the identified flow regimes," added Chafik.The study further reveals that much of the water that will end up in the Faroe Bank Channel is not in fact transported along the western side of the Faroe-Shetland Channel (the region the water flows through before reaching the Faroe Bank Channel), as previously thought. Instead, most of this water comes from the eastern side of the Faroe-Shetland Channel where it is transported by a jet-like and deep-reaching ocean current. "This was a curious but very exciting finding, especially since we are aware that a very similar flow structure exists in the Denmark Strait. We are pleased that we were able to identify this new ocean current both in observations and a high-resolution ocean general circulation model," said Chafik."Because this newly discovered flow path and ocean current play an important part in the ocean circulation at higher latitudes, its discovery adds to our limited understanding of the overturning circulation in the Atlantic Ocean," said Chafik. "This discovery would not have been possible without many institutional efforts over the years."
The same perturbations of the Earth's magnetic field that lit up the sky for Lojewski's camera were also captured by seismometers on the ground, a team of researchers reports in the journal By comparing data collected by all-sky cameras, magnetometers, and seismometers during three aurora events in 2019, University of Alaska Fairbanks seismologist Carl Tape and colleagues show that it's possible to match the striking display of lights with seismic signals, to observe the same phenomenon in different ways.Researchers have known for a while that seismometers are sensitive to magnetic fluctuations -- and have worked hard to find ways to shield their instruments against magnetic influence or to remove these unwanted signals from their seismic data. But the aurora study offers an example of how seismometers could be paired with other instruments to study these fluctuations."It can be hard to be definitive that these seismometer recordings are originating from the same influence as what's going on 120 kilometers up in the sky," Tape said. "It helps to have a simultaneous view of the sky, to given you more confidence about what you're seeing from the signals at ground level."The aurora borealis, or northern lights, occurs when solar winds -- plasma ejected from the Sun's surface -- meet the protective magnetic field that surrounds the Earth. The collision of particles produces colorful lights in the sky and creates fluctuations in the magnetic field that are sometimes called solar or space "storms." Magnetometers deployed on the Earth's surface are the primary instrument used to detect these fluctuations, which can significantly impact electrical grids, GPS systems and other crucial infrastructure. The aurora is commonly visible in wintertime in high-latitude regions such as Alaska.The seismometers in the study are part of the USArray Transportable Array, a network of temporary seismometers placed across North America as part of the EarthScope project. The array in Alaska and western Canada was completed in the fall of 2017. The aurora paper is one of several included in an upcoming SRL focus section about EarthScope in Alaska and Canada.These temporary seismic stations are not shielded from magnetic fields, unlike more permanent stations that are often cloaked in mu-metal, a nickel-iron alloy that directs magnetic fields around the instrument's sensors. As a result, "I was blown away by how well you can record magnetic storms across the array," said U.S. Geological Survey seismologist Adam Ringler, a co-author on the SRL paper.Last month, Ringler and his colleagues published a paper demonstrating how the array's 200-plus seismometers in Alaska can be used to record space weather, potentially augmenting the 13 magnetometers in operation in the state.Along with the all-sky camera data, seismic array data can help make sense of the strong variations in the magnetic field that occur in a magnetic east-west direction, adding a second dimension to typical north-south directional studies of the aurora and other magnetic storms, Tape and colleagues suggest.The researchers noted in their paper that the link between the aurora borealis and magnetic perturbations was first discovered in Sweden in 1741, and that a seismometer in Germany detected an atmosphere-generated magnetic event for the first time during a strong solar storm in 1994."People have been making these connections for 250 years," Tape said. "This shows that we can still make discoveries, in this case with seismometers, to understand the aurora."
At the peak of its melting season, in July 2018, the Arctic was losing sea ice at a rate of 105,500 square kilometers per day -- an area bigger than Iceland or the state of Kentucky. "On the ground, I am sure it would have looked like an excellent summer month in the Arctic, in general, but over the past four decades, September sea-ice loss has accelerated to a rate of 12.8% per decade and 82,300 square kilometers per year," says co-author Avinash Kumar, a senior scientist at the National Centre for Polar and Ocean Research (NCPOR) in India.The researchers followed the warm water currents of the Atlantic north to the Arctic Ocean and tracked the ice as it subsequently retreated through the Chukchi, East Siberian, Laptev, Kara, and Barents seas. Thanks to higher temporal resolution and greater satellite coverage than had previously been available, they could also measure the ice's decline through variables such as its thickness, concentration, and volume in addition to its extent throughout the Arctic. This dramatic loss of sea ice culminated at the end of the boreal summer, when in September, the ice had been reduced to a mere third of its winter extent.Then, the team compared the decline to the previous four decades of data. "In the summer of 2018, the loss of sea ice was three times higher than the reported loss at the beginning of the satellite era," says Kumar. "Our study shows that both the minimum sea-ice extent and the warmest September records occurred in the last twelve years.""Every year, news pops up of a new record of high temperature or fastest loss of sea ice in the Arctic region, but in the global system, each portion of the planet receiving climate feedback will lead to changes in the other parts as well," Kumar says. "If the sea-ice decline continues at this pace, it can have a catastrophic impact by raising air temperatures and slowing down global ocean circulation." These global impacts are partly why he became interested in trying to decipher the mysteries of the polar regions as a doctoral student studying the coastal zone in India. Now, he works at NCPOR, whose scientific programs, he says, are "truly trans-hemispheric, cutting across from north to south."The researchers also turned their attention to the atmosphere, where they were able to gain insight into the processes that contribute to the loss of Arctic sea ice. They found not only that September of 2018 was the third warmest on record, but that there was a temperature difference within the Arctic itself: the temperature of the air above the Arctic Ocean (~3.5Â°C) was slightly higher than that of the Arctic land (~2.8Â°C).Their findings provide further evidence that ocean warming around the globe has influenced the natural cycle of the wind and pressure patterns in the Arctic. El NiÃ±os, or warm phases in long-term temperature cycles stemming from tropical regions, have long been known to drive extreme weather events around the world and are occurring with greater frequency as the world warms. El NiÃ±o cycles in the equatorial Pacific Ocean can carry warm air and water from tropical circulations to the Arctic, spurring the sea ice to melt. As the ice retreats, it cascades the Arctic into a positive feedback loop known as Arctic amplification, whereby the reduced ice extent gives way to darker ocean waters that absorb more of the sun's radiation. As it retains more heat, temperatures rise and more ice melts, causing the Arctic region to heat up faster -- about four times so -- than the rest of the world."If the decline of sea ice continues to accelerate at a rate of 13% per decade in September, the Arctic is likely to be free of ice within the next three decades," Kumar says. And just as sea-ice retreat is largely the result of anthropogenic pressures from across the globe, its impacts will be felt worldwide: this work adds to the mounting body of evidence that changes in the Arctic sea ice could be detrimental to weather patterns spanning the globe. He says, "The changes taking place in the Arctic can lead to other changes in lower latitudes, such as extreme weather conditions. The world should be watching tropical countries like India, with our research center saddled close to the beaches of Goa, and trying to understand -- even in a small way -- more about climate change and the polar regions."This work was supported by the National Centre for Polar and Ocean Research, Goa, the Ministry of Earth Science, New Delhi, and the University Grants Commission, New Delhi.
After studies indicated that two PFAS -- PFOA and PFOS -- can cause cancer, a compromised immune response and other health problems in lab animals, the two compounds were voluntarily phased out by industry. However, these legacy compounds are still widely detected in the environment. Intended as a safer replacement for PFOA, HFPO-DA (sold under the trade name GenX) is now thought to pose similar health and persistence concerns. Hanna Joerss and colleagues wanted to investigate the long-range, oceanic transport of legacy and replacement PFAS to the Arctic Ocean -- a remote body of water connected to the Atlantic Ocean by the Fram Strait, which is located between Svalbard and Greenland.Aboard an icebreaker research ship, the team collected water samples along two Fram Strait currents entering and exiting the Arctic Ocean and along a path from Europe's North Sea to the Arctic Ocean. Using mass spectrometry, the researchers detected 11 PFAS in the ocean water, including PFOA, HFPO-DA and other long- and short-chain PFAS. This was the first time that HFPO-DA had been detected in seawater from a remote region, indicating that the compound can be transported long distances. Higher levels of PFAS were detected in the water exiting the Arctic Ocean compared with the water entering the Arctic from the North Atlantic. The PFAS composition in the outgoing water suggested that more of these compounds arose from atmospheric sources than from ocean circulation.
The study, published in the "Scientists and Indigenous communities working together are needed to understand our rapidly changing world," said lead author Pamela McElwee, an associate professor in the Department of Human Ecology in the School of Environmental and Biological Sciences at Rutgers University-New Brunswick. "Many Indigenous peoples have unique abilities to notice ecosystems altering before their eyes by using local indicators, like the color of fat in hunted prey or changes in types of species found together. Scientists wouldn't be able to perform these kinds of observations over the long run for many reasons, including costs and the remoteness of some areas. So Indigenous knowledge is absolutely essential for understanding the cumulative impacts of biodiversity loss and ecosystem degradation."Indigenous and local knowledge is the practical information that people use to manage resources and pass on between generations. Such knowledge benefits conservation initiatives and economies that depend on natural resources in vast areas of the world.The study follows the Global Assessment Report on Biodiversity and Ecosystem Services released last year by the Intergovernmental Science-Policy Platform on Biodiversity and Ecosystem Services. That report was the first global ecological assessment to use Indigenous and local knowledge as a source of evidence.The new study, by researchers at many institutions who were part of the global assessment, provides background on how the report tapped into Indigenous knowledge systems and lessons learned. Working with these local sources of information in ecological research and in management requires a deliberate approach from the start, additional resources and engagement with stakeholders reflecting diverse worldviews, McElwee said."Partnering with Indigenous peoples can help scientists and researchers understand how natural and cultural systems affect each other, identify trends through diverse indicators and improve sustainable development goals and policies for all," she said.
"In this paper we show that supporting Indigenous peoples' rights is in the interest of the conservation agenda," explains Dr. Ãlvaro FernÃ¡ndez-Llamazares, the first author of the study, from the University of Helsinki. "The future of a substantial proportion of the Amazon's biodiversity depends largely on coordinated action to support and strengthen Indigenous peoples' rights across the entire region."The authors argue that the convergence of the agendas and priorities of both wilderness-centred conservationists and Indigenous peoples is more important than ever, as some of the government in the region have started to trample over commitments towards globally agreed goals on both the environment and Indigenous peoples' rights."There is no doubt that the Amazon is at a crossroads in its social-ecological history," adds Dr. FernÃ¡ndez-Llamazares. "Rollbacks on environmental protections and Indigenous Peoples rights across the entire region are opening up vast natural areas to new external pressures."All these macroeconomic and political forces are being felt in both wilderness areas and Indigenous Peoples territories. However, disputes on whether conserving wilderness should come at the expense of Indigenous peoples rights undermine potential for collaborative conservation.The study underscored the substantial role of Indigenous territories in buffering against deforestation through advanced geospatial analyses based on available satellite data. These lands account for less than 15% of all the forest loss occurring within the Amazon's last wilderness frontiers. This is largely evidenced throughout the southern rim of the Amazon, where Indigenous territories represent the only islands of biological and cultural diversity in the larger landscape."The concept of wilderness has a contentious history across much of the Global South, as it is based on the assumption that humans have inherently negative impacts on nature," highlights Prof. Eduardo S. Brondizio, a researcher from Indiana University Bloomington and senior author of the study."Yet, the Amazon is a classic example of how long-term interactions between Indigenous peoples and forests can be linked to positive environmental outcomes. We have known for decades that a significant portion of the region's supposedly pristine forests are in fact cultural forests,"he notes. "Indigenous peoples, and also other traditional communities, show that it is possible to successfully combine forest conservation, management and agroforestry systems."In view of this, the authors call for a more socially inclusive notion of wilderness in order to align the agendas and priorities of both wilderness-focused conservationists and Indigenous peoples against a new wave of frontier expansion.
The research team behind the new study, from the Japan Agency for Marine-Earth Science and Technology (JAMSTEC), the URI Graduate School of Oceanography, the National Institute of Advanced Industrial Science and Technology, the Kochi University and Marine Works Japan, gathered the ancient sediment samples ten years ago during an expedition to the South Pacific Gyre, the part of the ocean with the lowest productivity and fewest nutrients available to fuel the marine food web."Our main question was whether life could exist in such a nutrient-limited environment or if this was a lifeless zone," said the paper's lead author Yuki Morono, senior scientist at JAMSTEC. "And we wanted to know how long the microbes could sustain their life in a near-absence of food."On the seafloor, there are layers of sediment consisting of marine snow (organic debris continually sourced from the sea surface), dust, and particles carried by the wind and ocean currents. Small life forms such as microbes become trapped in this sediment.Aboard the research drillship With fine-tuned laboratory procedures, the scientists, led by Morono, incubated the samples to coax their microbes to grow. The results demonstrated that rather than being fossilized remains of life, the microbes in the sediment had survived, and were capable of growing and dividing."We knew that there was life in deep sediment near the continents where there's a lot of buried organic matter," said URI Graduate School of Oceanography professor and co-author of the study Steven D'Hondt. "But what we found was that life extends in the deep ocean from the seafloor all the way to the underlying rocky basement."Morono was initially taken aback by the results. "At first I was skeptical, but we found that up to 99.1% of the microbes in sediment deposited 101.5 million years ago were still alive and were ready to eat," he said.With the newly developed ability to grow, manipulate and characterize ancient microorganisms, the research team is looking forward to applying a similar approach to other questions about the geological past. According to Morono, life for microbes in the subseafloor is very slow compared to life above it, and so the evolutionary speed of these microbes will be slower. "We want to understand how or if these ancient microbes evolved," he said. "This study shows that the subseafloor is an excellent location to explore the limits of life on Earth."Before looking ahead to future research, D'Hondt took time to reflect on Morono's achievement. "What's most exciting about this study is that it shows that there are no limits to life in the old sediment of the world's ocean," said D'Hondt. "In the oldest sediment we've drilled, with the least amount of food, there are still living organisms, and they can wake up, grow and multiply."
Climate models currently include the global warming effect of greenhouse gases as well as the cooling effects of atmospheric aerosols. The tiny particles that make up these aerosols are produced by human-made sources such as emissions from cars and industry, as well as natural sources such as phytoplankton and sea spray.They can directly influence the flow of sunlight and heat within the Earth's atmosphere as well as interact with clouds. One of the ways that they do this is by bolstering clouds' ability to reflect sunlight back into space by increasing their droplet concentration. This in turn cools the planet. The amount of sunlight that is reflected to space is referred to Earth's albedo.However, there has been extremely limited understanding of how aerosol concentration has changed between early-industrial times and the present day. This lack of information restricts the ability of climate models to accurately estimate the long-term effects of aerosols on global temperatures -and how much of an effect they could have in the future.Now, an international study led by the Universities of Leeds and Washington has recognised that remote, pristine parts of the Southern Hemisphere provide a window into what the early-industrial atmosphere looked like.The team used satellite measurements of cloud droplet concentration in the atmosphere over the Northern Hemisphere -- heavily polluted with today's industrial aerosols -- and over the relatively pristine Southern Ocean.They used these measurements to quantify the possible changes due to industrial aerosols in Earth's albedo since 1850.The results, published today in the journal Co-lead author, Daniel McCoy, Research Fellow in the School of Earth and Environment at Leeds, said: "Limitations in our ability to measure aerosols in the early-industrial atmosphere have made it hard to reduce uncertainties in how much warming there will be in the 21st century."Ice cores provide carbon dioxide concentrations from millennia in the past, but aerosols don't hang around in the same way. One way that we can try to look back in time is to examine a part of the atmosphere that we haven't polluted yet."These remote areas allow us a glimpse into our past and this helps us understand the climate record and improve our predictions of what will happen in the future."Co-lead author, Isabel McCoy, from the Atmospheric Sciences Department at Washington, said: "One of the biggest surprises for us was how high the concentration of cloud droplets is in Southern Ocean clouds. The way that the cloud droplet concentration increases in summertime tells us that ocean biology is playing an important role in setting cloud brightness in unpolluted oceans now and in the past."We see high cloud droplet concentrations in satellite and aircraft observations, but not in climate models. This suggests that there are gaps in the model representation of aerosol-cloud interactions and aerosol production mechanisms in pristine environments."As we continue to observe pristine environments through satellite, aircraft, and ground platforms, we can improve the representation of the complex mechanisms controlling cloud brightness in climate models and increase the accuracy of our climate projections."Co-author Leighton Regayre, a Research Fellow also from the School of Earth and Environment at Leeds, said: "The science supporting our climate models is improving all the time. These models are tackling some of the most pressing and complex environmental questions of the modern era and climate scientists have always been up front about the fact that uncertainties exist."We are only going to reach the answers we need to combat global warming by regularly interrogating the science. Our team used millions of variants of a model to explore all the potential uncertainties, the equivalent of having a clinical trial with millions of participants."We hope our findings, along with studies on the detailed process of aerosol production and aerosol-cloud interactions in pristine environments that our work has motivated, will help guide the development of the next generation of climate models."
In a recent study, researchers from The University of Texas at Austin show that another natural record -- sediments packed together at basin margins -- offers scientists a powerful tool for understanding the forces that shaped our planet over millions of years, with implications on present day understandingThe study was published in the journal "We are trying to find a way to distinguish the tectonics and the climate signals," said lead author Jinyu Zhang, a research associate at UT's Bureau of Economic Geology. "By using this numerical model we suddenly have this power to simulate the world under different tectonics and climate."ZoltÃ¡n Sylvester and Jacob Covault, both research scientists at the bureau, co-authored the paper.Geoscientists have long looked to sedimentary basins for clues about Earth's past climate. That's because sediment supply is closely linked to environmental factors, such as rainfall or snowfall, that influence sediment creation through erosion and sediment transport across a landscape and into a basin. Tectonic factors also influence sediment creation, with increasing uplift associated with more sediment and decreasing uplift with less.However, despite knowledge of sediment supply being linked with climate and tectonics, the researchers said little is known about how changes in these phenomena directly influence how sediment is deposited along basin margins over long time scales.This study changes that, with Zhang using the open-source computer program pyBadlands to create a "source-to-sink" 3D model that tracks how changes in precipitation, tectonic uplift and sea level influence sediment erosion and deposition. The model uses topography inspired by the Himalaya Mountains and Indus River Delta to track the sediment as it makes its way from the mountains, through a river system, and settles into a basin margin over millions of years."This is one of the first [models] to put the landscape evolution part with the stratigraphic response, depositional response, and do it in 3D," Covault said. "Jinyu has made a really great step in putting this all together."The researchers ran 14 different scenarios -- each with a different climatic, tectonic, and sea level settings -- over a simulated time period of 30 million years to investigate changes in landscape topography and sediment deposition.The different scenarios created distinct patterns in sediment deposition, which allowed the researchers to draw general conclusions about how tectonic and climatic factors affect basin margin growth. For example, changes in uplift take millions of years to affect change in the basin margin sediments, but once those changes are in effect, they set a new baseline for behavior. In contrast, changes in precipitation cause much more abrupt change, followed by a return to the depositional behavior observed before the climate shift.The scenarios showed that sea level could potentially complicate the delivery of the signal of tectonic change into the basin. For example, an increase in sea level flooded coastal regions and interfered with sediment reaching a basin margin. But when this scenario was paired with increased precipitation, the sediment supply was large enough to make it to the basin margin.Gary Hampson, a professor at Imperial College London who was not part of the study, said that the model provides important guidelines for geoscientists looking to reconstruct Earth's past."The results increase the confidence with which geoscientists can interpret tectonic and climatic histories in the geologic archives of basin margins," he said.Zhang spent the past two years learning the programming language Python so he could use the pyBadlands software, which was developed by the University of Sydney's Tristan Salles.Sylvester, who leverages similar tools to study erosion and sedimentation in river systems, said that the computing tools available to geoscientists are making long-standing yet fundamental questions in geosciences more accessible than ever."It's an exciting time," he said. "It's increasingly easier to investigate the stratigraphic record in a quantitative way."
"So far, measurement instruments have been so expensive that society's mapping of greenhouse gas emissions has had to rely on rough models. It's extremely important that we can make lots of proper measurements locally, so we can test whether measures for reducing emissions actually work. We hope that our simple and cost-efficient logger can contribute to more such measurements" says David Bastviken, professor at Environmental Change, and author of an article in A current limitation when it comes to determining the greenhouse gas fluxes has been the lack of reliable low-cost measurement methods that can be widely available in society. In 2015, David Bastviken and colleagues described and published a logger for carbon dioxide, which is now used for various types of environmental measurements. However for methane, more complicated and expensive measurement equipment has so far been required. In the current article in Methane, CH4, is one of the most important long-lived greenhouse gases which contributes greatly to global warming. Since the 1750s, its relative increase in the atmosphere has been greater than for other greenhouse gases. There are many different sources and examples including incomplete combustion, handling of natural gas and biogas, and microbial production in agriculture, wetlands and lakes. However the large number of sources that can vary greatly in ways not fully understood makes it difficult to quantify fluxes and to propose best practices for flux mitigation. In addition, the discovery that lakes, rivers and flooded forests are large sources of methane, made by David Bastviken and his colleagues as recently as 2011 and later, shows that major methane sources are still being discovered."We have now built and tested a simple logger based on the open-source Arduino hardware. The parts are available in many electronics stores; they can be ordered online and cost about 200 euro. We have also developed more precise ways to calibrate the methane sensor, to enable the measurement of greenhouse gas fluxes at a very low cost," says David Bastviken.The researchers hope that the logger will make it easier for all interested, and in e.g. education and environmental monitoring, to monitor greenhouse gas emissions."We also propose simplified but satisfactory ways to calibrate the sensors that don't require continuous access to advanced research laboratories. This can make measurements easier, for instance in developing countries," says David Bastviken.
"Our 44-year study shows that the amount of living coral has not changed in the ETP," said James W. Porter, the paper's senior author. "Live coral cover has gone up and down in response to El NiÃ±o-induced bleaching, but unlike reefs elsewhere in the Caribbean and Indo Pacific, reefs in the ETP almost always bounce back," he said.The study was conducted by an international team of researchers from across the region led by Dr. Mauricio Romero-Torres of the Pontificia Universidad Javeriana and Unidad Nacional para la GestiÃ³n del Riesgo de Desastres (the National Unit for Disaster Risk Management or UNGRD) in BogotÃ¡, Colombia. The group examined coral cover data for the area, which stretches from Baja California to the Galapagos Islands, from 1970-2014. During that time there were several El NiÃ±o events -- periods when the equatorial Pacific Ocean reaches unusually high temperatures. Excessive heat can kill the symbiotic algae that inhabit the corals, leading to widespread coral bleaching and death.The researchers found that while losses of coral cover followed the worst of those episodes, in many cases ETP reefs recovered within 10-15 years."So much of my career has been spent documenting coral reef decline that to discover a large area of the tropics where coral reefs are holding their own is very gratifying," said Porter, professor emeritus in the University of Georgia Odum School of Ecology.They hypothesized that several key factors allowed the ETP reefs to bounce back.First, corals in this area are mostly pocilloporids, a type of coral that reproduces at high rates. They also contain species of symbiotic algae that are particularly tolerant to extreme temperatures.Patterns of weather and geography in the ETP may also play a role. Areas having heavier cloud cover or upwelling of cooler waters may survive locally and be able to reseed more severely affected reefs elsewhere.Another important factor may be "ecological memory," meaning that ETP corals may have become conditioned to heat stress over the years, through mechanisms such as genetic adaptation and epigenetic inheritance, whereby parents pass on these survival traits to their offspring."The key to survival for future reefs may not be an immunity to stress, but rather an ability to recover and regrow after stress," said Porter. "ETP reefs show us what this might look like."Porter said that the study is also important as an example of the need for maintaining long-term original data, which was crucial to the research."As soon as Dr. Romero contacted me, I consulted my original dive logs, made when I was a Smithsonian Pre-Doctoral Fellow in Panama in 1970," said Porter. "I realized immediately that my hand-written field notes contained everything needed to anchor this study with the oldest data (1970) used in this long-term survey. Particularly in a changing world, we need to archive and store original data carefully," he said. "Knowing what the world looked like in the past may be the best way to set restoration goals in the future.""This research teaches the relevance of doing science with FAIR standards (findable, accessible, interoperable and reusable) so that other researchers in the region can continue the work and estimate the effects of the next El NiÃ±o phenomenon on the ETP," said Romero.
"Lightning influences the ability of forests to store biomass, and therefore carbon, because it tends to strike the largest trees," said Evan Gora, a post-doctoral fellow at STRI who recently finished his doctorate at the University of Louisville. "And lightning strikes may also be very important in savanna ecosystems."Because lightning is so challenging to study, it has been overlooked as a change-agent in tropical forests where researchers focus their energy on more obvious disturbances like drought, fire, and high winds.In a previous study, the first to examine the effects of lightning on a tropical forest landscape, the same team found that lightning probably kills half of the biggest trees in a Panamanian forest. Tropical ecologist Steve Yanoviak, study coauthor and professor at the University of Louisville who was studying ants in the tropical forest canopy -- and often thought about the role of lightning while climbing trees, invited lightning researchers Jeffrey Burchfield and Phillip Bitzer from the University of Alabama at Huntsville to set up lightning detectors at STRI's Barro Colorado Island Research Station."We found that a lightning strike damages a total of 23.6 trees and kills 5.5 of these trees within a year, on average," Yanoviak said.Now the team is asking how lightning affects tropical ecosystems everywhere. Gora led the effort to map lightning strike counts based on images from the Earth Networks Global Lightning Network (ENGLN) onto a map of tropical ecosystems created using land-cover categories from the International Geosphere-Biosphere Program and the Moderate Resolution Spectroradiometer (MODIS) Land Cover Climate Modeling Grid.Based on satellite data about strike locations and on-the-ground effects around 92 lightning strikes, including many from the previous study, Gora and his colleagues estimated that lightning damages approximately 832 million tropical trees each year. Roughly a quarter of the trees probably die from their injuries.Gora and colleagues then asked whether there was a connection between the number of lightning strikes and the type of ecosystem, its biomass and climate variables like rainfall and temperature. They found that lightning strikes were more frequent in forests, savannas and urban areas than in grasslands, shrublands and croplands.Forests that experience more lightning strikes each year have fewer large trees per hectare, perhaps because the large individual trees in these forests stand out more, higher rates of woody biomass turnover (more tree biomass dies each year) and less total aboveground biomass.But more burning questions remain. No one knows why some trees survive lightning strikes while others die, although it is likely that trees have evolved ways of coping with such a common threat.And, as climate change accelerates, polluted, hot air over cities may also increase the number of lightning strikes there. What will the effects be on vegetation in urban areas?"This is the best evidence to date that lightning is a major disturbance influencing tropical forest dynamics and structure," said STRI staff scientist and study co-author Helene Muller-Landau, "We suspect that our study vastly underestimates the total effect of lightning. Lightning strikes may play a major role in forest biomass/carbon cycling not only in tropical forests but also in other tropical ecosystems."
A methane seep is a location where methane gas escapes from an underground reservoir and into the ocean. Methane seeps have been found throughout the world's oceans, but the one discovered in the Ross Sea was the first active seep found in Antarctica, said Andrew Thurber, a marine ecologist at Oregon State University."Methane is the second-most effective gas at warming our atmosphere and the Antarctic has vast reservoirs that are likely to open up as ice sheets retreat due to climate change," Thurber said. "This is a significant discovery that can help fill a large hole in our understanding of the methane cycle."The researchers' findings were published today in the journal Methane is a greenhouse gas that is 25 times more powerful than carbon dioxide at warming the planet. Most methane in the ocean water and sediment is kept out of the atmosphere by microbes that consume it.Thurber and his colleagues discovered that the microbes around the Antarctic seep are fundamentally different that those found elsewhere in the world's oceans. This helps researchers better understand methane cycles and the factors that determine whether methane will reach the atmosphere and contribute to further warming, Thurber said.The Ross Sea seep was discovered in an area that scientists have studied for more than 60 years, but the seep was not active until 2011, said Thurber, an assistant professor in Oregon State's College of Earth, Ocean, and Atmospheric Sciences and the College of Science's Department of Microbiology.An expansive microbial mat, about 70 meters long by a meter across, formed on the sea floor about 10 meters below the frozen ocean surface. These mats, which are produced by bacteria that exist in a symbiotic relationship with methane consumers, are a telltale indication of the presence of a seep, said Thurber."The microbial mat is the road sign that there's a methane seep here," Thurber said. "We don't know what caused these seeps to turn on. We needed some dumb luck to find an active one, and we got it."Thurber happened to be in Antarctica in 2012 when another researcher told him about a "microbial waterfall" and thought it was something he should look at. Thurber was able to confirm the seep's presence, collect samples and analyze the seep and its environment. When he returned to the site in 2016 to conduct further study, he also discovered a second seep nearby.Antarctica is believed to contain as much as 25 percent of Earth's marine methane. Having an active seep to study gives researchers new understanding of the methane cycle and how that process might differ in Antarctica compared to other places on the planet, Thurber said.For example, researchers have found that the most common type of microbe that consumes methane took five years to show up at the seep site and even then those microbes were not consuming all of the methane, Thurber said. That means some methane is being released and is likely working its way into the atmosphere.Studying the site over a five-year time span allowed researchers to see how microbes respond to the formation of a seep, said Seabrook, who earned her doctorate at OSU and is now a post-doctoral scholar at the National Institute of Water and Atmospheric Research in Wellington, New Zealand."What was really interesting and exciting was that the microbial community did not develop as we would have predicted based on other methane seeps we have studied around the globe," she said.Researchers had assumed that microbes should respond really quickly to changes in the environment, but that wasn't reflected in what OSU's team saw in Antarctica, Thurber said."To add to the mystery of the Antarctic seeps, the microbes we found were the ones we least expected to see at this location," he said. There may be a succession pattern for microbes, with certain groups arriving first and those that are most effective at eating methane arriving later."We've never had the opportunity to study a seep as its forming or one in Antarctica, because of this discovery we can now uncover whether seeps just function differently in Antarctica or whether it may take years for the microbial communities to become adapted," Thurber said."Animals in Antarctica are very different than elsewhere in the world as the continent has been separated from the rest of the globe for more than 30 million years -- a long time for evolution to act," he said. "That has resulted in a remarkable diversity of fauna that we only find there. That may also contribute to the differences in microbes there."It is important to understand how methane seeps behave in this environment so researchers can begin factoring those differences into climate change models, Thurber said. He hopes to return to the site to monitor its evolution and conduct further research.
Tropical cyclones in the Atlantic (hurricanes) are a substantial threat for the lives and property of the local population in the Caribbean and neighboring regions, such as the south-east of the USA. The storms' increasing force, described in Chapter 15 of the report by the Intergovernmental Panel on Climate Change (IPCC Report), raises the probability of ecological and social catastrophes, as the occurrence of such cyclones over the past 20 years, which caused devastating damage, has shown. The climate models used to date, which could help to estimate the danger better, are, however, based on data that are lacking in spatial and temporal depth. Instrumental climate data, such as regular measurement of sea surface temperatures and reliable chronicling of hurricanes, date back only to the 19th century, at most.In the framework of a research project (Gi 222/31) funded by the German Research Foundation, the Biosedimentology Working Group at the Department of Geosciences of the Faculty of Geosciences and Geography (Professor Eberhard Gischler) of Goethe University has now been able to build up and analyze a sedimentary "storm archive" that covers almost the entire Common Era (2,000 years) with annual resolution. The archive comprises fine-grained annual layers of sediments from the 125-meter-deep bottom of the Blue Hole, a flooded karst sinkhole on the Lighthouse Reef Atoll off the coast of Belize (Central America). There, 2.5 mm of lime mud, composed of shell debris from organisms in the reef lagoon along with changing amounts of organic matter, collect year after year. Coarser layers up to several centimeters thick that constitute tempestites (storm sediments) are intercalated in these fine-grained sediments. They mostly consist of shell debris from reef organisms living on the edge of the atoll. The almost 9-metre-long drill core from the bottom of the Blue Hole, which was recovered with the help of an electrical vibracorer, spans the last 1,885 years with a total of 157 storm layers.In the framework of extensive studies conducted by doctoral researcher Dominik Schmitt and collaboration between the Biosedimentology Working Group and colleagues at the University of Bern (Switzerland), it has become apparent that both short-term and long-term climate phenomena, such as the El NiÃ±o Southern Oscillation (ENSO), the North Atlantic Oscillation (NAO) and the Atlantic Multidecadal Oscillation (AMO), have influenced storm activity over the last 2,000 years and are mirrored in the new climate archive. The beginning of the Medieval Warm Period (approx. AD 900-1100) constitutes an important transition period when the activity of tropical cyclones changed substantially, presumably in conjunction with the shift of the Intertropical Convergence Zone (the low-pressure zone where northern and southern trade winds converge) towards the south: From AD 100-900, storm activity in the region tended to be more stable and weaker, while since AD 900 up until today it has been more variable and more vigorous. Interestingly, this change in the increase of cyclone frequency goes hand in hand with the occurrence of a few, very thick, coarse-grained storm layers and coincides with the final demise of the classical Mayan culture in Central America. It is possible that the increased impact of hurricanes on the Central American mainland, combined with extensive flooding of cultivated land in the Mayan lowlands and rainfall-induced erosion in the backlands of the Mayan Mountains of Belize -- apart from the recurring periods of drought already known -- was another environmental factor that influenced the end of the Maya's high culture.
UNLV climate scientist Matthew Lachniet and colleagues have compiled a detailed, 13,000-year climate history from stalagmite specimens in Leviathan Cave, located in the southern Great Basin, which provides clues for the mitigation of climate change today.These ancient climate records show that Nevada was even hotter and drier in the past than it is today, and that one 4,000-year period in particular may represent a true, "worst-case" scenario picture for the Southwest and the Colorado River Basin -- and the millions of people who rely on its water supply.At that time, the long-term hot and dry climate of the region was linked to warm Arctic seas and a lack of sea ice, as well as warming in the western tropical Pacific Ocean, the cave record shows.This parallels today and the near future, as the release of human carbon emissions into the atmosphere will warm the Arctic and possibly the western tropical Pacific, and is expected to result in long-term arid conditions for Nevada and the broader Colorado River Basin.If the arid conditions become permanent, then the water supply in the Colorado River Basin is expected to decrease, which researchers say would imperil critical water resources for millions of people who live in the Southwest U.S."The last few decades have seen increasingly severe 'hot droughts' in the Colorado River Basin, when high temperatures coincide with less rainfall, and which have startled climate scientists and water policy managers," Lachniet said. "But these dry intervals don't usually last more than a few decades. In contrast, our new data show that Nevada climate can experience an extended interval of aridity for thousands of years, not just a few decades."The recent Southwestern U.S. drought that began in 2001, which has resulted in historic low reservoir levels in Lake Mead, is one indicator of the gravity of the problem. The Colorado River and Rio Grande basins are critical human support systems as their headwaters in the Rocky Mountains supply snow-fed water for myriad economic uses and support 56 million residents throughout the region."'Business as usual' scenarios for anthropogenic warming carry the risk of tipping the Southwest into an extended state of aridification," researchers wrote.The paper, published in the journal Stalagmites -- like those located in Leviathan Cave -- are common cave formations that act as ancient rain gauges to record historic climate data. Stalagmites grow upward at rates of inches every few hundred years as mineral-rich waters seep through the ground above and drop from the tips of stalactites on cave ceilings.These deposits more accurately represent a long-term shift toward a more arid climate as they hold data that extends deeper into the past.A former analysis of one tree ring record, for example, pointed to a 10-year drought in the Medieval era as being a "worst case" predictor of a future, comparable drought, as compared to the more persistent and sustained 4,000-year period of aridity presented in Lachniet's new study.Regionally, paleoclimate records from other sources like lakes, landforms, pollen, and others, also support the conclusion of warmth and aridity during the same 4,000-year period.Researchers also found that the Leviathan Cave region, where the stalagmite specimen was collected, is representative of climate conditions in most of the Mojave Desert and the southern Great Basin, and that the data has implications for the broader desert region.Lachniet and colleagues say that their study can be a resource for policymakers today in adopting measures to reduce greenhouse gas emissions which will in turn "minimize oceanic and Arctic warming.""There already is evidence that droughts in the Southwest are partly caused by humans because of the higher temperatures and more evaporation in surface waters like Lake Mead," Lachniet said. "The new fossil-fuel climate might end up making these droughts permanent."
'Predictions of climate variations are possible for certain regions on Earth', says Dr. Annika Reintges, scientist at GEOMAR and lead author of the study, that is now published in Are such predictions possible? What are the requirements and which kind of information can be provided by such predictions? These questions were addressed by a research team of GEOMAR and of the Leibniz Institute for Baltic Research WarnemÃ¼nde. 'Indeed, long-term predictions are possible. This is enabled by the slow, over several years, varying oceanic processes', explains Dr. Reintges. The difficulty is that ocean observations -- that are necessary to start the model computation -- must be as accurate as possible. 'However, ocean observations, in particular below the surface, are limited in quantity and quality' says Reintges.'For the predictions in our study, we did not use any ocean observations. Instead, we create oceanic start values, by prescribing only observed variations in the wind at the sea surface. After some time, this brings the ocean of the model into a state that is sufficiently realistic to start successful predictions for even more than 7 years into the future', explains the author of the study.The research team suggests the following mechanism to explain this fact: The winds cause a change in the ocean circulation. By this, a certain region in the North Atlantic accumulates an anomalous amount of heat. This heat is then transported towards Northeast over a time of several years. This finally results in a warming of the sea surface in the eastern North Atlantic, in response to the winds many years before.'Previous studies have shown that the sea surface temperature of the North Atlantic can influence the European climate. Therefore, such predictions of the North Atlantic surface temperature, covering several years are of great importance also for decision makers in politics, economy, society, and also for the public', Reintges concludes.
Crustaceans dominate the food webs of many costal habitats in our oceans. In addition, as 'stowaways' on board of vessels used in global shipping, many crab species have spread far beyond their natural homes. The Asian shore crab Hemigrapsus sanguineus is a good example of these invasive species: in just a few decades this species, native to the Pacific, has spread to many corners of the globe. By the 1980s, it had made its way to the Atlantic coast of North America, and by the 1990s, had gained a foothold in the coastal waters of Europe. In both North America and Northern Europe, this species is spreading farther and farther north, toward the rapidly warming polar waters. In the ecosystems they invade, these crabs can soon reach such high numbers that native species like the European shore crab Carcinus maenas are impacted or displaced. Furthermore, they exert considerable predation pressure in their new homes, often decimating e.g. marine invertebrates like mussels or young shore crabs, and taking these food sources away from other species in the process. This can produce lasting changes to the invaded ecosystems.But how is climate change influencing the spread of invasive marine species? Invasive species are often characterised by a high tolerance for fluctuations in environmental factors like temperature and salinity, thus being more adapted to the effects of climate change in the oceans. The team of researchers, including members from the Alfred Wegener Institute, Bangor University (Wales, UK) and the University of Greifswald, especially focused on the early developmental stages of the Asian shore crab, and examined its microscopically small larvae, which grow as they float in the water column. Since it has been confirmed that the larvae of many marine organisms are more sensitive to environmental fluctuations than their adult counterparts, these larvae often represent a 'bottleneck' in the establishment of new populations.In addition, the study sought to develop models for predicting the speed at which the Asian shore crab could spread northwards, taking climate warming into account. The project's main question: Are findings regarding seasonal influences on larval development helpful for such forecasts? In the study, the team began by measuring the larvae's developmental parameters, e.g. the survival rate and time needed for development at different water temperatures. For this purpose, at the AWI's facilities on Helgoland they studied the duration of their young developmental stages in the lab; and they investigated the occurrence of crab larvae in the field. With the aid of a mechanistic model, the authors were then able to determine the timeframe during the mating season in which the water temperature needs to be above a certain threshold in order for the larvae to successfully develop into juvenile crabs. This modelling indicates considerable potential for the Asian shore crab to spread farther north, along the coasts of Northern England and Norway.According to AWI biologist Dr Gabriela Torres and Dr Luis GimÃ©nez, a fellow biologist at the AWI and first author: "Our study confirms that, when it comes to predicting the climate-related spread of marine fauna, we need to especially focus on the early stages of development, as they are critical for the settlement on new habitats and the establishment of new permanent populations." Prof Steffen Harzsch from the University of Greifswald's Zoological Institute and Museum adds: "The Research Training Group RESPONSE offers us an outstanding platform for scientifically investigating various aspects of climate change, through interdisciplinary collaborations that reach far beyond Greifswald."
The study, published July 22 in Ice flows slowly through the basins from the interior of the continent out to the floating ice shelves at the margins. Ice loss causes the grounding line -- the point at which the ice loses contact with the ground and starts floating -- to shift inland, explained first author Terrence Blackburn, assistant professor of Earth and planetary sciences at UC Santa Cruz."Our data shows that the grounding line in the Wilkes Basin retreated 700 kilometers [435 miles] inland during one of the last really warm interglacials, when global temperatures were 1 to 2 degrees Celsius warmer than now," Blackburn said. "That probably contributed 3 to 4 meters to global sea level rise, with Greenland and West Antarctica together contributing another 10 meters."In other words, a period of global warming comparable to what is expected under current scenarios for humanmade greenhouse gas emissions resulted in an increase in sea level of around 13 meters (43 feet). Of course, this wouldn't happen all at once -- it takes time for that much ice to melt."We've opened the freezer door, but that block of ice is still cold and it's not going anywhere in the short term," Blackburn said. "To understand what will happen over longer time scales, we need to see what happened under comparable conditions in the past."The problem with studying the interglacial periods during the Pleistocene is that they all ended in another ice age when the ice sheet advanced again and covered up the evidence. For the new study, Blackburn and his colleagues used a novel technique based on isotope measurements in mineral deposits that record past changes in subglacial fluids.Uranium-234 (U-234) is an isotope of uranium that accumulates very slowly in water that is in contact with rocks due to the high-energy decay of uranium-238. This happens everywhere, but in most places hydrological processes carry water away from sources of enrichment, and the U-234 gets diluted in large bodies of water. In Antarctica, however, water is trapped at the base of the ice sheet and moves very slowly as long as the ice is stable, allowing U-234 to build up to very high levels over long periods of time.Blackburn explained that the ice sheet acts like an insulating blanket, so that heat from Earth's interior causes melting at the base. But temperatures are colder where the ice is thinner at the margins of the ice sheet, causing subglacial water to refreeze."Water flowing beneath the ice starts refreezing at the edges, which concentrates all the dissolved minerals until it becomes supersaturated and the minerals precipitate out to form deposits of opal or calcite," he said. "Those deposits trap uranium-234, so we can date the deposits and measure their composition, and we can track that through time to get a deep history of the composition of water under the ice sheet."What that history suggests is that the U-234 in subglacial water in the Wilkes Basin was flushed out during the interglacial period 400,000 years ago as the ice melted and the grounding line retreated. That reset the U-234 concentration to low background levels, and accumulation then restarted when the ice advanced again.Blackburn noted that present-day evidence for the accumulation of U-234 in subglacial fluids can be found in the McMurdo Dry Valleys, the only place where Antarctic glaciers terminate on land. There, highly concentrated brines emerge from the glaciers in places such as Blood Falls, where the blood-red color comes from high iron concentrations in the brine."The isotopic compositions of those brines are comparable to the precipitates that we've dated from a range of locations, and they all share the characteristic U-234 enrichment," Blackburn said. "The brines are what's left when the subglacial fluids get all the way to the edge of the ice sheet."He said the new study was inspired by a 2016 paper in which researchers studying deep-sea corals reported evidence of a major change in ocean chemistry, including a spike in U-234, coinciding with the end of the last ice age, when the vast Laurentide Ice Sheet that covered much of North America melted."They speculated that it accumulates under the ice sheets and pointed to some possible sites in Antarctica where that might be happening," Blackburn said. "I happened to be in one of those places at the time."So was his colleague, glaciologist Slawek Tulaczyk, a professor of Earth and planetary sciences at UC Santa Cruz. They discussed the paper and began planning this study, which eventually involved several UCSC faculty and students. The team collected some samples of mineral deposits themselves, but some of the most important samples used in the study were collected in the 1980s and archived at the Byrd Polar Rock Repository at Ohio State University.
For more than 40 years, the estimated likely range of the eventual global temperature response to a doubling of atmospheric carbon dioxide compared to preindustrial levels has stubbornly remained at 1.5Â°C -- 4.5Â°C.This new research, revealed in a 165 page, peer-reviewed journal article commissioned by the World Climate Research Programme (WCRP) written over four years, finds that the true climate sensitivity is unlikely to be in the lowest part of the 1.5-4.5Â°C range. The analysis indicates that if atmospheric carbon dioxide levels double from their pre-industrial levels and are maintained, the world would probably experience eventual warming from 2.3 -- 4.5Â°C. The researchers found there would be less than 5% chance of staying below 2Â°C and a 6-18% chance of exceeding 4.5Â°C.With the Earth's temperature already at around 1.2Â°C above preindustrial levels, if greenhouse gas emissions trajectories continue unabated the world can expect to see a doubling of carbon dioxide in the next 60-80 years."Narrowing the range of climate sensitivity has been a major challenge since the seminal US National Research Council paper came up with a 1.5 -- 4.5Â°C range in 1979 (Charney et al). That same range was still quoted in the most recent IPCC report," said lead author Prof Steven Sherwood, a University of New South Wales chief investigator with the ARC Centre of Excellence for Climate Extremes.The research was only made possible by bringing together an international team of researchers from a wide range of climate disciplines. Using temperature records since the industrial revolution, paleoclimate records to estimate prehistoric temperatures, satellite observations and detailed models that examine the physics of interactions within the climate system the team were able to combine more independent lines of evidence than any previous study to get their results.These lines of evidence were then combined in a statistically rigorous way allowing the team to find where the results overlapped. This allowed them to converge on the best estimate of climate sensitivity. The team found that, with new developments, the various lines of evidence corroborated one another leading to more confidence in the result. The 2.3-4.5Â°C range accounts cautiously for alternative views or assumptions and "unknown unknowns," with a more straightforward calculation yielding an even narrower 2.6-3.9Â°C likely range."This paper brings together what we know about climate sensitivity from measurements of atmospheric processes, the historical warming, and warm and cold climates of the past. Statistically combined, these estimates make it improbable that climate sensitivity is at the low end of the IPCC range and confirm the upper range. This adds to the credibility of climate model simulations of future climate," said co-author Gabi Hegerl from the University of Edinburgh."An important part of the process was to ensure that the lines of evidence were more or less independent," said Prof Sherwood. "You can think of it as the mathematical version of trying to determine if a rumour you hear separately from two people could have sprung from the same source; or if one of two eyewitnesses to a crime has been influenced by hearing the story of the other one."The researchers then went another step further and identified the conditions that would be required for the climate sensitivity to lie outside this most likely range.The researchers show that low climate sensitivities previously thought to be plausible, around 1.5-2C, could only occur if there were multiple unexpected and unconnected errors in the data analysis (for example unexpected cloud behaviour and patterns of long-term ocean warming), underlying their judgment that these low values are now extremely unlikely.A different set of circumstances make it unlikely that global temperatures would rise more than 4.5Â°C for a doubling of carbon dioxide from pre-industrial times, although these higher temperature responses are still more likely than very low sensitivities.Even with this qualification, the three-year long research process initiated by the WCRP with double-checking at every step, a detailed examination of the physical processes and an understanding of the conditions required for the estimate has finally consolidated an advance on the 40-year-problem."These results are a testament to the importance of cross-disciplinary research along with slow, careful science and perfectly highlight how international co-operation can unpick our most vexing problems," said co-author Prof Eelco Rohling from the Australian National University."If international policymakers can find the same focus and spirit of co-operation as these researchers then it will give us hope that we can forestall the worst of global warming."
Professor Colin Simpfendorfer from James Cook University in Australia was one of the scientists who took part in the study, published today in "This doesn't mean there are never any sharks on these reefs, but what it does mean is that they are 'functionally extinct' -- they are not playing their normal role in the ecosystem," said Professor Simpfendorfer.He said almost no sharks were detected on any of the 69 reefs of six nations: the Dominican Republic, the French West Indies, Kenya, Vietnam, the Windward Dutch Antilles and Qatar."In these countries, only three sharks were observed during more than 800 survey hours," said Professor Simpfendorfer.Dr Demian Chapman, Global FinPrint co-lead and Associate Professor in the Department of Biological Sciences and Institute of Environment at Florida International University, said it's clear the central problem is the intersection between high human population densities, destructive fishing practices, and poor governance."We found that robust shark populations can exist alongside people when those people have the will, the means, and a plan to take conservation action," said Dr Chapman.Professor Simpfendorfer said it was encouraging that Australia was among the best nations at protecting shark populations and ensuring they played their proper role in the environment."We're up there along with such nations as the Federated States of Micronesia, French Polynesia and the US. These nations reflect key attributes that were found to be associated with higher populations of sharks: being generally well-governed, and either banning all shark fishing or having strong, science-based management limiting how many sharks can be caught," he said.Jody Allen, co-founder and chair of the Paul G. Allen Family Foundation which backs the Global FinPrint project, said the results exposed a tragic loss of sharks from many of the world's reefs, but also gave some hope."The data collected from the first-ever worldwide survey of sharks on coral reefs can guide meaningful, long-term conservation plans for protecting the reef sharks that remain," she said.For more information and a new global interactive data-visualized map of the Global FinPrint survey results, visit Global FinPrint is an initiative of the Paul G. Allen Family Foundation and led by Florida International University, supported by a global coalition of partner organizations spanning researchers, funders and conservation groups. The project represents the single largest and most comprehensive data-collection and analysis program of the world's populations of reef-associated sharks and rays ever compiled.
University of Exeter scientists studied four species of demersal (seabed-dwelling) shark.Of the 46 sharks examined, 67% contained microplastics and other human-made fibres.A total of 379 particles were found and -- though the impact on the sharks' health is unknown -- the researchers say it highlights the "pervasive nature of plastic pollution.""Our study presents the first evidence of microplastics and anthropogenic fibre contaminants in a range of native UK demersal shark species," said lead author Kristian Parton, of the Centre for Ecology and Conservation at Exeter's Penryn Campus in Cornwall.Commenting on the possible sources of the particles, he added: "We were surprised to find not only microplastics but also particles such as synthetic cellulose, which is most commonly found in textiles (including disposable hygiene items like facemasks) and clothing."When clothes are washed, or items are discarded as litter, tiny fibres are released and these often flow into water sources and out to sea."Once in the sea, microfibres can either float or sink to the bottom, which is where these sharks live."The fibres could then be ingested via the sharks' food, which is mostly crustaceans, or directly through the sediment on the seabed."In terms of the other types of microplastics we found, many of these may have come from fishing lines or nets."The research team, which included scientists from Greenpeace Research Laboratories, examined the stomachs and digestive tracts of four species: small-spotted catshark, starry smooth-hound, spiny dogfish and bull huss.These species can be found at varying depths from 5-900m, but usually live and feed near the sea floor.Though the study is based on a modest sample size, the findings suggest larger sharks contained more particles. No differences were found based on sex or species.The study was conducted in Cornwall, UK, using sharks caught as "bycatch" (by accident) in a demersal hake fishery, fishing in and around the North-East Atlantic and Celtic Sea.Study co-author Professor Tamara Galloway, of Exeter's Global Systems Institute, said: "We were not expecting to find microfibres from textiles in so many of our native shark species."Our study highlights how important it is to think before we throw things away."Dr Laura Foster, Head of Clean Seas at the Marine Conservation Society, added: "The new research from into these iconic shark species around the UK shows high levels of microplastic ingestion, with 95% of the contaminants found being fibrous."
In the first study of its kind, researchers at the University of British Columbia, the GEOMAR Helmholtz Centre for Ocean Research Kiel and the University of Western Australia assessed the biomass -- the weight of a given population in the water -- of more than 1,300 fish and invertebrate populations. They discovered global declines, some severe, of many popularly consumed species.Of the populations analyzed, 82 per cent were found to be below levels that can produce maximum sustainable yields, due to being caught at rates exceeding what can be regrown. Of these, 87 populations were found to be in the "very bad" category, with biomass levels at less than 20 per cent of what is needed to maximize sustainable fishery catches. This also means that fishers are catching less and less fish and invertebrates over time, even if they fish longer and harder."This is the first-ever global study of long-term trends in the population biomass of exploited marine fish and invertebrates for all coastal areas on the planet," said Maria "Deng" Palomares, lead author of the study and manager of the To reach their findings, the researchers applied computer-intensive stock assessment methods known as CMSY and BSMY to the comprehensive catch data by marine ecosystem reconstructed by the The greatest declines in stocks were found in the southern temperate and polar Indian Ocean and the southern polar Atlantic Ocean, where populations shrunk by well over 50 per cent since 1950.While much of the globe showed declining trends in fish and invertebrates, the analysis found a few exceptions. One of these was the Northern Pacific Ocean where population biomass increased by 800 per cent in its polar and subpolar zones, and by about 150 per cent in its temperate zone.Despite these pockets of improvement, the overall picture remains a cause for concern, according to co-author Daniel Pauly, principal investigator at "Despite the exceptions, our findings support previous suggestions of systematic and widespread overfishing of the coastal and continental shelf waters in much of the world over the last 60-plus years," said Pauly. "Thus, pathways for improvements in effective fisheries management are needed, and such measures should be driven not only by clearly set total allowable annual catch limits, but also by well-enforced and sizeable no-take marine protected areas to allow stocks to rebuild."
Climate change has consequences for agriculture worldwide, with clear differences between regions. Expectations are that sufficient food will remain available in the Northern hemisphere, but in regions such as Sub-Saharan Africa or South Asia, falling crop yields may lead to higher food prices and a sharp rise in hunger. Further liberalisation of world trade can relieve these regional differences: "If regions like Europe and Latin America, for example, where wheat and corn thrive, increase their production and export food to regions under heavy pressure from global warming, food shortages can be reduced," says doctoral researcher Charlotte Janssens. "It sounds quite obvious, but there are many barriers that complicate this free trade."Import tariffs are a major barrier to international trade in food. They increase the cost of importing basic food crops like wheat, corn or rice. Around a fifth of the worldwide production of these grains is traded internationally. That makes good trade agreements very important in the battle against hunger. Professor Miet Maertens explains: "In the early 21st century, we saw a major liberalisation of the international market. This caused the average import tariffs on agricultural products in Europe, Sub-Saharan Africa and South Asia to drop by a third. Our research shows that this liberalisation makes global food provision less vulnerable to climate change. We also see that further reduction and phasing-out of tariffs can intensify this positive effect."Besides, there are also other barriers. In some countries, the logistical aspect is a sticking point. Roads are sometimes poor or ports are not equipped for loading and unloading large container ships. Countless complicated trade procedures can drive up the effective cost of trade. "A global food strategy must go hand in hand with improvements to trade infrastructure," argues Charlotte Janssens.The international research team, consisting of scientists from KU Leuven, IIASA and RTI International, among others, are making their recommendations based on 60 scenarios. They took into account different forms of trade policy, along with climate change varying from a 2 to 4-degree warming of the Earth. 2050 was set as the horizon for each scenario. "Under the current barriers to trade, the worst-case climate scenario of a 4-degree warming will lead to an extra 55 million people enduring hunger compared to the situation without climate change. If vulnerable regions cannot increase their food imports, this effect will even rise to 73 million," argues Janssens. Where barriers to trade are eliminated, 'only' 20 million people will endure food shortages due to climate change. In the more mild climate scenarios, an intensive liberalisation of trade may even prevent more people from enduring hunger owing to climate change.Yet a liberalisation of international trade may also involve potential dangers. "If South Asian countries would increase rice exports without making more imports of other products possible, they could be faced with increased food shortage within their own borders," warns Charlotte Janssens. "A well thought-out liberalisation is needed in order to be able to relieve food shortages properly.""Sadly enough, we see that in times of crisis, countries are inclined to adopt a protectionist stance. Since the start of the current corona crisis, around ten countries are closing their borders for the export of important food crops," says Janssens. "In the context of climate change, it is highly important that they avoid such protectionist behaviour and instead continue to maintain and utilise the international trade framework."
The South Atlantic Anomaly is an area characterized by a significant reduction in the strength of Earth's magnetic field compared with areas at similar geographic latitudes. Here, protection from harmful radiation from space is reduced. The most significant signs of this are technical malfunctions aboard satellites and spacecraft.In a study published in the The geomagnetic records from the rocks covering 34 different volcanic eruptions that took place between eight and 11 million years ago revealed that at these occurrences the direction of the magnetic field for St Helena often pointed far from the North pole, just like it does today.The Earth's magnetic field, or the geomagnetic field, not only gives us the ability of navigating with a compass, but also protects our atmosphere from charged particles coming from the sun, called solar wind. However, it is not completely stable in strength and direction, both over time and space, and it has the ability to completely flip or reverse itself with substantial implications.The South Atlantic Anomaly is a topic of debate between scientists in this field. Besides the fact that it causes damages to space technology, it also raises the question of where it comes from and whether it represents the start of the total weakening of the field and a possible upcoming pole reversal.Lead author of the paper, University of Liverpool PhD student Yael Engbers, said: "Our study provides the first long term analysis of the magnetic field in this region dating back millions of years. It reveals that the anomaly in the magnetic field in the South Atlantic is not a one-off, similar anomalies existed eight to 11 million years ago."This is the first time that the irregular behaviour of the geomagnetic field in the South Atlantic region has been shown on such a long timescale. It suggests that the South Atlantic Anomaly is a recurring feature and probably not a sign of an impending reversal."It also supports earlier studies that hint towards a link between the South Atlantic Anomaly and anomalous seismic features in the lowermost mantle and the outer core. This brings us closer to linking behaviour of the geomagnetic field directly to features of the Earth's interior"
Humans depend on farming for their very survival but this activity takes up more than one third of the world's landmass and endangers 62% of all threatened species globally. However, agricultural landscapes can support, rather than damage, biodiversity, but only through a global transition to agroecological production. An international team of over 360 scientists from 42 countries, led by the University of GÃ¶ttingen and Westlake University in China, argue that agroecological principles should be integrated in the post-2020 Global Biodiversity Framework, which aims to reduce threats to biodiversity and will be decided at the 15th Convention of the Parties (COP15) meeting in China. Their Correspondence article was published in Reversing the trend in species decline is essential for the benefit of both people and the planet, but it will require coordinated actions and sustainable agriculture. Intensive farming relying on excessive pesticides and fertiliser has negative effects on biodiversity. The authors argue that farming landscapes can provide habitats for biodiversity, promote connectivity between protected areas and increase species' ability to respond to environmental threats. The authors' research agenda includes enhancing global research networks, expanding technical innovation and improving communication. The authors emphasise the importance of working with and supporting farmers, indigenous people and local communities. Diversification in crops together with new varieties and combinations, for instance, can sustain yields. In addition, these actions can support biodiversity and ecosystems whilst providing more nutritious and healthy food for all.This year is crucial for biodiversity, not just because time is running out to conserve insects and other wildlife, but also because the 15th Convention of the Parties (COP15) will meet in China for the UN Biodiversity Conference, now in 2021 due to COVID-19. At COP15, the post-2020 Global Biodiversity Framework will be agreed which has targets to reduce threats to biodiversity. The authors have elaborated how agroecological principles can help meet each of these targets.Dr Thomas Cherico Wanger from Westlake University China and University of GÃ¶ttingen and first author of the correspondence reports, "The importance of agroecology to change agriculture and protect biodiversity has been recognized by many top level organizations, in the scientific community, and by practitioners, which is also reflected in the number and affiliations of signatories of our Correspondence. Following our positive discussions with representatives of the COP15, I hope that this correspondence can help to stimulate discussions in the policy arena and make a real impact on agricultural production systems."Professor Teja Tscharntke, co-author and Head of the Agroecology Research Group at the University of GÃ¶ttingen, adds: "Agroecology has the potential to change the way we 'do agriculture'. We hope that our comprehensive research agenda will help to chart the path to sustainable, diversified agriculture and biodiversity conservation in the future."
"These results provide the first definitive support that increases in sediment deposited to oceans from river erosion coincide with dramatic changes in glacial cycles," says Utah State University geoscientist Tammy Rittenour. "Our ability to date former river deposits was the game-changing factor in allowing us to pursue this hypothesis."Rittenour and colleagues from the U.S. Geological Survey, the University of Vermont and Purdue University published findings in the July 20, 2020, issue of "Oxygen isotope values in marine sediment show worldwide fluctuations between cold and warm climates that abruptly intensified during the early Pleistocene period," says Rittenour, professor in USU's Department of Geosciences. "Rates of river sediment accumulation also jumped during this time."Since rivers do the work of erosion and sediment transport over most of the Earth's surface, scientists have long suggested patterns of global precipitation mimic climate fluctuations."If that's the case, enhanced river discharge resulting from intensified global precipitation would increase rates of river erosion," she says.To test this idea, the team took advantage of the landscape history preserved in the study site's prominent river terraces -- ancient river floodplains -- perched up to hundreds of meters above the modern Fortymile River, a Yukon River tributary that flows from northwestern Canada to Alaska."This 'Rosetta-stone' location, with exposed terraces, provided a long-sought window from which to obtain data," says Rittenour, a Geological Society of America Fellow. "We geochronologists often repeat the adage, 'No Dates, No Rates,' meaning we can't calculate rates of erosion without age control. Using relatively new dating techniques, we were able, for the first time, to establish ages for river deposits that span these key time periods of global climate change."Co-authors Lee Corbett and Paul Bierman of UVM and Marc Caffee of Purdue provided age control on the site's older terraces, using cosmogenic nuclide burial dating methods that use differing decay rates of unique radiogenic isotopes of beryllium and aluminum produced by sediment exposure to cosmic radiation.Rittenour, director of USU's Luminescence Laboratory, used optically stimulated luminescence dating of younger river sediments."OSL dating provides an age estimate of the last time the sediment was exposed to light," she says.Corroborating the team's new results, Bering Sea sediment records show concurrent increases in accumulation of sediment eroded from the Fortymile River."It's exciting to apply new tools to test foundational ideas that have been only previously speculated," Rittenour says. "These results represent an important step toward understanding the influence of climate in shaping landscapes inhabited by people, and provide clues regarding future landscape response to human activity."
Permafrost is permanently frozen ground which stores as much carbon as there is in all plants on Earth and in the atmosphere together. The surface of the permafrost thaws in summer, allowing plant and soil life to thrive. When microorganisms breathe, they emit greenhouse gases. Scientists have previously anticipated that rapidly rising temperatures will drive the emission of 50-100 billion ton permafrost carbon by 2100. On top of that, plant roots feed sugar to the microorganisms in the soil, which the microbes can use to break down more soil organic matter -- the priming effect -- resulting in even higher greenhouse gas emissions."We have known about the priming effect since the 1950's, but we did not know whether or not this small-scale ecological interaction had a significant impact on the global carbon cycle," says Research Scientist Frida Keuper, affiliated with the French National Research Institute for Agriculture, Food and Environment, INRAE, and with UmeÃ¥ University, Sweden.The team of researchers combined maps of plant activity and data on soil carbon content from the Northern Circumpolar Soil Carbon Database with an extensive literature survey on priming and plant root properties, to estimate the priming effect in permafrost ecosystems and its influence on greenhouse gas emissions.They show that the priming effect increases soil microbial respiration by 12 percent, which causes the additional loss of 40 billion ton carbon by 2100 compared to current predictions for permafrost. This equals almost a quarter of the remaining 'carbon budget' for human activities to limit global warming to max 1.5Â°C."These new findings demonstrate how important it is to consider small-scale ecological interactions, such as the priming effect, in global greenhouse gas emission modelling," says Birgit Wild, Assistant Professor at Stockholm University.
Satellite imagery is already used in Kenya to monitor the state of pastures and determine the health of the vegetation using a metric known as the Vegetation Condition Index. These are conveyed to the decision makers in arid and semi-arid regions of Kenya through drought early warning systems.However, these systems, operated by the National Drought Management Authority (NDMA), only allows organisations and communities to intervene when the impacts of a drought have already occurred. By that point, such extreme weather would already have had a devastating effect on the livelihood of local people.Instead, a team of researchers from the University of Sussex and the NDMA have developed a new system called Astrocast.Part-funded by the Science and Technology Facilities Council, the project allows humanitarian agencies and drought risk managers to be proactive when it comes to dealing with the impacts of extreme weather by forecasting changes before they occur.In a research paper published in Dr Pedram Rowhani, Senior Lecturer in Geography and co-founder of Astrocast, said: "In many cases, the first signs of a drought can be seen on natural vegetation, which can be monitored from space."Our approach measures past and present Vegetation Condition Index (VCI), an indicator that is based on satellite imagery and often used to identify drought conditions, to understand trends and the general behaviour of the VCI over time, to predict what may happen in the future."Joint first author on the paper and Lecturer in Machine Learning and Data Science, Dr Adam Barrett said: "After conversations in corridors with Dr Rowhani about AstroCast, I saw an opportunity to apply methodology I'd been developing in theoretical neuroscience to a project with potential for real humanitarian impact."With Sussex actively encouraging interdisciplinary working, we decided to combine skillsets. It's been eye-opening to see how our techniques can be applied to a real-world problem and improve lives."There has been a growing demand within the humanitarian sector to develop systems that focus on advance warnings and encourage a more proactive approach to disasters.The Kenyan NDMA already provides monthly drought bulletins for every county, which state detected changes in the vegetation and are used to make decisions about whether to declare a drought alert.But with Astrocast forecasts, these bulletins could also include a prediction of what the VCI is likely to be in a few weeks' time, giving farmers and pastoralist valuable time to prepare.Seb Oliver, Professor of Astrophysics and co-founder of Astrocast, said: "A large part of my astrophysics research requires processing data from astronomical space telescopes, like the Herschel Space Observatory. Earth observation satellites are not that different."We often use cutting-edge statistics and machine-learning approaches to interpret our astronomical data. In this case we've used machine-learning approaches, and we've been able to forecast the state of the vegetation up to ten weeks ahead with very good confidence."We imagine that our reports might be used to define a new warning flag allowing county leaders to make decisions earlier and so prepare better. But this information could also be used by humanitarian organisations like the Kenya Red Cross as well as other organisations like the Kenya Met Department."Earlier preparation is well known to be much more effective than reactive response."
How widespread this activity is across the continent has never been quantified. We know Antarctica has no cities, agriculture or industry. But we have never had a good idea of where humans have been, how much of the continent remains untouched or largely unimpacted, and to what extent these largely unimpacted areas serve to protect biodiversity.A team of researchers led by Monash University, including Dr Bernard Coetzee from the Global Change Institute at the University of the Witwatersrand, Johannesburg (Wits University), has changed all of that. Using a data set of 2.7 million human activity records, the team showed just how extensive human use of Antarctica has been over the last 200 years. The research was published in the journal With the exception of some large areas mostly in the central parts of the continent, humans have set foot almost everywhere.Although many of these visited areas have only been negligibly affected by people, biodiversity is not as well represented within them as it should be."We mapped 2.7 million human activity records from 1819 to 2018 across the Antarctic continent to assess the extent of wilderness areas remaining and its overlap with the continent's biodiversity," says Coetzee, a conservation scientist at Wits University. Based in Skukuza in the Kruger National Park in South Africa, Coetzee helped conceptualise the study and collated a spatial database from multiple sources to map the extent of human activity in Antarctica."In a region often thought of as remote, we showed that in fact human activity has been extensive, especially in ice-free and coastal areas where most of its biodiversity is found. This means that "wilderness" areas do not capture many of the continent's important biodiversity sites, but that an opportunity exists to conserve the last of the wild."The study found that only 16% of the continent's Important Bird Areas, areas identified internationally as critical for bird conservation, are located within negligibly impacted areas, and little of the total negligibly impacted area is represented in Antarctica's Specially Protected Area network.High human impact areas, for example some areas where people build research stations or visit for tourism, often overlap with areas important for biodiversity.Lead author, Rachel Leihy, a PhD student in the Monash School of Biological Sciences, points out that "While the situation does not look promising initially, the outcomes show that much opportunity exists to take swift action to declare new protected areas for the conservation of both wilderness and biodiversity.""Informatics approaches using large data sets are providing new quantitative insights into questions that have long proven thorny for environmental policymakers," says Steven Chown, the corresponding author based at Monash University."This work offers innovative ways to help the Antarctic Treaty Parties take forward measures to secure Antarctica's Wilderness."The transdisciplinary team delivering this work includes researchers from Australia, the Netherlands, New Zealand, and South Africa.
"All four whale species were present in waters from the southeast U.S. to Greenland, with humpbacks also present in the Caribbean Sea," said Genevieve Davis, a senior acoustician at the Northeast Fisheries Science Center in Woods Hole, Massachusetts and lead author of the study. "These four species were detected throughout all the regions in the winter, suggesting that baleen whales are widely distributed during these months. Humpback, sei, fin, and blue whales also showed significant changes in where they were detected between the two time periods considered in this study: before and after 2010."A large group of federal, state and academic researchers from the United States and Canada conducted the study, published in Data collected from 2004 to 2014 on 281 bottom-mounted passive acoustic recorders totaled 35,033 days of recording. These passive acoustic recorders were deployed between the tiny island of Saba in the Caribbean Sea to the Davis Strait off western Greenland. Recorders were located on the continental shelf or along the shelf edge, with six recording units in off-shelf waters.All available passive acoustic recordings from more than 100 research projects throughout the western North Atlantic Ocean were combined to create the decade-long dataset. The time series was split between 2004 to 2010 and 2011 to 2014. That split was based on the timing of shifts in climate in the Gulf of Maine and distribution changes by numerous species in the western North Atlantic Ocean.This is also the same time period used in a similar analysis of North Atlantic right whales that was published in 2017, and used for comparison with this study.Results show that fin, blue, and sei whales were more frequently detected in the northern latitudes after 2010 but less on the Scotian Shelf area. This matches documented shifts in prey availability in that region."The Gulf of Maine, an important feeding ground for many baleen whale species, is warming faster than most places in the world, resulting in changes in distribution not only of marine mammals and fish but also for their prey," said Davis, who was also the lead author of the 2017 North Atlantic right whale study. "These changes in distribution for five of the six baleen whale species mirrors known shifts in distribution for other species attributed to climate and the impacts of ocean warming."Researchers have not yet studied if or how minke whale distribution has shifted. Minkes are the sixth baleen whale species found in the western North Atlantic Ocean.Researchers caution that while recorders provided widespread coverage, there were gaps. Also, these data can confirm where and when a species is present, but not how many individuals are present. There are differences in vocal behavior, seasonal changes, and vocalizations thought to be made by males only. The data provide a comprehensive overview of the minimum distribution in space and time of each species and add information to the current understanding of these species.While humpback whales are found in all regions, researchers were a bit surprised at the length of time they are present in all areas. Fin, blue, and sei whales increased the time that they spent in northern latitudes after 2010, perhaps following prey. All but sei whales had a decreased acoustic presence on the Scotian Shelf after 2010.Sei whales, one of the least-studied baleen whales, were detected with the other whale species from Florida to eastern Greenland. Sei whales are found year-round in Southern New England and the New York Bight. These are also important regions for other baleen whale species, including North Atlantic right whales that target the same prey as sei whales."This study is the first comprehensive analysis of sei whale distribution throughout the western North Atlantic Ocean, including their movements and important habitat," Davis said. "The southern limit of their range remains unknown, and their migratory movements in the western North Atlantic are still not well understood but we have filled in a number of information gaps."Fin whales were detected nearly year-round from Virginia to eastern Greenland. They are commonly found year-round in the Gulf of Maine and in Canadian waters off Nova Scotia. Acoustic records revealed their year-round presence in Massachusetts Bay and the New York Bight. New England waters provide feeding grounds, but mating and calving grounds are unknown. Their distribution year-round suggests that, like other baleen whales, not all fin whales migrate.Blue whales are seen and heard year-round in and around the Gulf of St. Lawrence, where their population is well-studied. Considered a more northern whale, they have occasionally been sighted in the Gulf of Maine. Acoustic detections revealed blue whales are present as far south as North Carolina.Blue whales tend to use deeper waters, making their seasonal movements difficult to study. Satellite tag studies, however, indicate they move from the Gulf of St. Lawrence to North Carolina, including on and off the continental shelf. They also move into deeper waters around the New England Seamounts -- a chain of underwater extinct volcanoes that extends from Georges Bank southeast for about 700 miles. Researchers found the shelf break and canyons to be important habitat areas for blue whales."A decade of acoustic observations have shown important changes over the range of baleen whales and identified new habitats that will require further protection from human-induced threats like fixed fishing gear, shipping, and noise pollution," said Davis.
In February 2017, Fisheries and Oceans Canada designated this region -- including Hecate Strait and Queen Charlotte Sound -- a marine protected area in order to preserve the delicate, glass reefs. But to effectively manage conservation efforts, scientists must develop a better understanding of the lifeforms that are already there."One of the most important reasons for studying the diversity of sea sponges in our oceans is for conservation management," explained Lauren Law, who conducted this research as part of her graduate studies with Sally Leys, professor in the University of Alberta's Department of Biological Sciences. "Many studies in the protected area have focused on describing the crustaceans and fish living in the reefs, but non-reef forming sponges remain overlooked."Now, the UAlberta research team has published a study on the discovery of a new sponge that is abundant in the region, making up nearly 20 per cent of the live sponges in the reefs off the coast of British Columbia. The new species -- called Desmacella hyalina -- was discovered using an underwater robot that travelled along the ocean floor, surveying reefs and collecting samples."Our findings show Desmacella comprise a surprisingly large amount of live sponge cover in the reefs and can have potential major influence on reef function, recruitment, and overall ecosystem health," said Law, who is now a biologist with Fisheries and Oceans Canada Pacific Region. "While we have discovered a new species, we have yet to determine its relationship with glass sponges in the area."The researchers recommend further investigation to better understand the role of Desmacella in the ecosystem, as well as more ecological assessment of glass sponge habitat focused on surveying non-reef forming sponges."Properly knowing the components of an environment and the linkages between them -- here this new species Desmacella hyalina and the reef sponges it lives on -- is a major step forward in understanding the ecosystem services and function of the sponge reefs," added Leys. "This is the information we need for concrete management strategies."
Using satellite data on the size and extent of the snow pack on the Tibetan plateau and in Siberia, the team created better climate model simulations that predict variation in monsoon rainfall the following season. The new research was published online in "We are focusing on the time scale beyond the 14 days of weather forecasting to a farther, seasonal outlook," said Peirong Lin, currently a postdoc at Princeton University who helped lead this research project while a graduate student at UT Jackson School of Geosciences. "This is a very important time scale because water resource managers need to know the forecast months prior to the monsoon onset for decisions about resources and agriculture."Monsoon winds and the rain that comes with them are propelled by the temperature difference between land and ocean. Current climate forecasting relies on computer models that use general circulation models, soil moisture and other factors. The new model uses complementary satellite data to improve these forecasts by revisiting a historically recognized link between snow pack characteristics and monsoon strength over the Asian monsoon region, especially on the Indian subcontinent."For Indian monsoons, it was empirically known almost 140 years ago that rainfall in the summer was connected to snowpack in the Himalaya," said Zong-Liang Yang, professor in the Jackson School's Department of Geological Sciences. "But with our new model, we now have a deeper understanding of the interconnected processes, and we are able to quantify such connection that predicts monsoon season strength from snow pack."The new research uses both the breadth and depth of winter snows to more accurately simulate monsoons. The information constraining the new models comes from two satellites: the Moderate Resolution Imaging Spectroradiometer (MODIS) that provides data about snow cover, and the Gravity Recovery and Climate Experiment (GRACE) with gravitational information that determines the depth of snow. Combined, the observations make the modeled snow conditions more realistic and demonstrate that heavy snow pack -- with slower heating of landmass in comparison to the ocean -- leads to weaker monsoons. Conversely, milder winter snows lead to stronger monsoons.The research also finds that snow in Tibet and Siberia have different roles in moderating monsoon rainfall. The snow on the Tibetan plateau is relatively thin compared to Siberia's. Detailed analysis in the research paper shows that the Tibetan snow pack improves a few weeks of forecasting. It is the Siberian snow that melts later in the summer, thereby having a longer impact on the climate system, that influences predictions with greater lead time and further into peak monsoon season.There are caveats to this research. Monsoons impact a far wider region of the world, but the team's simulations showed the most pronounced forecasts were obtained only in the Indian subcontinent, and they were not as effective over East Asia."The forecast is mostly improved over the Indian subcontinent likely because Indian monsoon is more sensitive to snow changes on land," said Lin. "The East Asian monsoon may be more complex."Still, the team hopes that the new strategy developed by their research will be used to improve seasonal forecasts beyond the Indian subcontinent, with future research that expands the current simulations."The work that we accomplished at the Jackson School is leading the field, but it will take time before these ideas are implemented in operational modeling systems in operational centers," said Yang. "But our goal is to decrease the research-to-operation gap and find ways to use many of the underutilized satellites that can inform long-term weather prediction."Additional authors of this research include Jiangfeng Wei, currently affiliated with Nanjing University of Information Science and Technology in China; Robert E Dickinson of the Jackson School of Geosciences; Yongfei Zhang, currently affiliated with Program in Atmospheric and Oceanic Sciences at Princeton University; and Long Zhao, currently affiliated with Southwest University in Chongqing, China. All research by all authors was done while affiliated with the Jackson School of Geosciences.
"By satellite tracking turtles travelling to small, isolated oceanic islands, we show that turtles do not arrive at their targets with pinpoint accuracy," says Graeme Hays of Australia's Deakin University. "While their navigation is not perfect, we showed that turtles can make course corrections in the open ocean when they are heading off-route. These findings support the suggestion, from previous laboratory work, that turtles use a crude true navigation system in the open ocean, possibly using the earth's geomagnetic field."Despite much study of sea turtle navigation, many details were lacking. Hays' team realized that was in part because most sea turtles return to spots along the mainland coast, which are also the easiest places to find.For the new study, his team had attached satellite tags to nesting green turtles (Chelonia mydas) out of an interest in learning about the extent of the turtles' movements and to identify key areas for conservation. In the process, they realized that, by serendipity, many of the tracked turtles travelled to foraging sites on isolated islands or submerged banks. It allowed them to explore in more detail how turtles make their way to such small and harder-to-find islands.In total, the researchers recorded the tracks of 33 green sea turtles migrating across the open ocean from their nesting beaches on the island of Diego Garcia (Indian Ocean) to their foraging grounds across the western Indian Ocean, many of which were isolated island targets. Using individual-based models that incorporated ocean currents, they then compared actual migration tracks against candidate navigational models to show that 28 of the 33 turtles didn't re-orient themselves daily or at fine-scales.As a result, the turtles sometimes travelled well out of their way -- several hundred kilometers off the direct routes to their goal -- before correcting their direction, often in the open ocean. Frequently, they report, turtles did not reach their small island destinations with pinpoint accuracy. Instead, they often overshot and or spent time searching for the target in the final stages of migration."We were surprised that turtles had such difficulties in finding their way to small targets," Hays says. "Often they swam well off course and sometimes they spent many weeks searching for isolated islands."We were also surprised at the distance that some turtles migrated. Six tracked turtles travelled more than 4,000 kilometers to the east African coast, from Mozambique in the south, to as far north as Somalia. So, these turtles complete round-trip migrations of more than 8,000 kilometers to and from their nesting beaches in the Chagos Archipelago."The findings lend support to the notion that migrating sea turtles use a true navigation system in the open ocean. They also provide some of the best evidence to date that migrating sea turtles have an ability to re-orient themselves in deep waters in the open ocean, the researchers say. This implies that they have and rely on a map sense. But the results also show that their map lacks fine details, allowing them to operate only at a crude level.As a result of this imperfect navigation system, the turtles reach their destination only imperfectly. In the process, the turtles spend extra energy and time searching for small islands.The findings also have implications for the turtles' conservation, Hays says. Turtles travel broadly across the open ocean once nesting season has finished. As a result, he says, "conservation measures need to apply across these spatial scales and across many countries."The researchers say that they hope the next generation of tag technology will allow them to directly measure the compass heading of migrating turtles as well as their location. "Then we can directly assess how ocean currents carry turtles off-course and gain further insight into the mechanisms that allow turtles to complete such prodigious feats of navigation," Hays says.
Rising summer temperatures are also resulting in higher rates of dehydration among wet-skinned amphibians as they attempt to keep themselves cool.Researchers from SFU and the University of California-Santa Cruz predict that by the 2080s, habitats previously thought to be safe for amphibians will either be too hot or too dehydrating for them to inhabit. Even the edges of wetlands may be too hot for up to 74 percent of the summer and that sunny, dry spots will be too dehydrating for up to 95 percent of the summer.The study was published yesterday in the journal Researchers studied the environmental conditions in shaded and damp nooks and crannies at the edges of wetlands in the mountains of the Pacific Northwest. They sought to predict how suitable those environments will be for amphibians in the future.These findings are significant because most previous research on the effects of climate change on amphibians has focused solely on temperature, ignoring an equally important physiological process for amphibians -- evaporative water loss.By incorporating rates of water loss, the researchers found that previous studies may have dramatically underestimated the already dire predictions of climate change impacts on amphibians.Instead of subjecting live amphibians to invasive measurements, the researchers estimated water loss rates and internal body temperatures using model frogs made of agar (seaweed extract) that closely mimic the water loss and temperatures of live amphibians.These model frogs were placed in four habitats that encompass the behavior of many different amphibian species -- shaded locations on land and in shallow wetlands, and sun exposed locations on land and in shallow wetlands.The data was related to key environmental conditions, including air temperature, precipitation, and relative humidity, and then linked to forecasts of future climate change.The study also found that amphibians face a difficult trade-off: animals in cool shaded places on dry land face harmful rates of dehydration, and those in shallow water face harmful high temperatures."Such trade-offs will only get more challenging with future climate change, with no single habitat being safe at all times," says Gavia Lertzman-Lepofsky, the study's lead author.This also means that to remain within their environmental limits, frogs and salamanders will have to move between habitats much more often, using up energy for movement rather than for finding food.Unfortunately, the larger landscape surrounding amphibians is also changing. As individuals become more dependent on finding damp and shaded spots to escape the heat, there will also be less water available in the landscape as small ponds and wetlands dry up over the long, dry summers.This puts increasing pressure on populations and provides a sobering view of how amphibians will survive in a hotter, drier world.
There's one thing about these drifting critters that has puzzled ecologists for decades -- the diversity among ocean plankton is much higher than expected. Generally, in any given ocean sample, there are many rare species of plankton and a small number of abundant species. Researchers from the Okinawa Institute of Science and Technology Graduate University (OIST) have published a paper in "For years, scientists have been asking why there are so many species in the ocean," said Professor Simone Pigolotti, who leads OIST's Biological Complexity Unit. Professor Pigolotti explained that plankton can be transported across very large distances by currents, so they don't seem to be limited by dispersal. This would suggest that niche preference is the factor that determines species diversity -- in other words, a single species will outcompete all other species if the environment suits them best, leading to communities with only a few, highly abundant species."Our research explored the theory that ocean currents promote species diversity, not because they help plankton to disperse, but because they can actually limit dispersal by creating barriers," said Professor Pigolotti. "In contrast, when we looked at samples from lakes, where there are little or no currents, we found more abundant species, but fewer species altogether."At first glance, this might seem counter-intuitive. But while currents may carry plankton from one area to another, they also prevent the plankton from crossing to the other side of the current. Thus, these currents reduce competition and force each species of plankton to coexist with other species, albeit in small numbers.For over a century, ecologists have measured diversity by counting the number of species, such as birds or insects, in an area. This allowed them to find the proportions of abundant species versus rare species. Today, the task is streamlined through both quantitative modelling that can predict species distributions and metagenomics -- instead of just counting species, researchers can efficiently collect all the DNA in a sample."Simply counting the amount of species in a sample is very time consuming," said Professor Tom Bourguignon, who leads OIST's Evolutionary Genomics Unit. "With advancements in sequencing technologies, we can run just one test and have several thousand DNA sequences that represents a good estimation of planktonic diversity."For this study, the researchers were particularly interested in protists -- microscopic, usually single-celled, planktonic organisms. The group created a mathematical model that considered the role of oceanic currents in determining the genealogy of protists through simulations. They couldn't just simulate a protist community at the DNA level because there would be a huge number of individuals. So, instead, they simulated the individuals in a given sample from the ocean.To find out how closely related the individuals were, and whether they were of the same species, the researchers then looked back in time. "We created a trajectory that went back one hundred years," said Professor Pigolotti. "If two individuals came from a common ancestor in the timescale of our simulation, then we classed them as the same species."What they were specifically measuring was the number of species, and the number of individuals per species. The model was simulated with and without ocean currents. As the researchers had hypothesized, it showed that the presence of ocean currents caused a sharp increase in the number of protist species, but a decline in the number of individuals per species.To confirm the results of this model, the researchers then analyzed datasets from two studies of aquatic protists. The first dataset was of oceanic protists' DNA sequences and the second, freshwater protists' DNA sequences. They found that, on average, oceanic samples contained more rare species and less abundant species and, overall, had a larger number of species. This agreed with the model's predictions."Our results support the theory that ocean currents positively impact the diversity of rare aquatic protists by creating these barriers," said Professor Pigolotti. "The project was very interdisciplinary. By combining theoretical physics, marine science, and metagenomics, we've shed new light on a classic problem in ecology, which is of relevance for marine biodiversity."
Using sophisticated satellite telemetry, a study is the first to provide unique insights into how tiger sharks move and use habitats in the Gulf of Mexico across life-stages. Data from the study, just published in For the study, Matt Ajemian, Ph.D., lead author and an assistant research professor at Florida Atlantic University's Harbor Branch Oceanographic Institute, and a team of scientists examined size and sex-related movement and distribution patterns of tiger sharks in the Gulf of Mexico. They fitted 56 tiger sharks with Smart Position and temperature transmitting tags between 2010 -- following the Deepwater Horizon Oil Spill -- and 2018 -- spanning shelf waters from south Texas to south Florida and examined seasonal and spatial distribution patterns across the Gulf of Mexico. The tags transmitted whenever the fin-mounted tags broke the sea surface, with orbiting satellites estimating shark positions based on these transmissions. Ajemian also analyzed overlap of core habitats among individuals relative to large benthic features including oil and gas platforms, natural banks, and bathymetric breaks."While all life stages of tiger sharks are known to occur in the Gulf of Mexico, detailed habitat use has never been quantified," said Ajemian. "This is rather striking as this marine system faces numerous humanmade stressors, complex tri-national management, and indications of size reductions in recreational landings for large sharks."Results showed significant ontogenetic and seasonal differences in distribution patterns as well as across-shelf (i.e., regional) and sex-linked variability in movement rates. Prior studies into tiger shark horizontal movements in the western North Atlantic Ocean have been restricted primarily to males or females separately, in disparate locations. By simultaneously tracking many males and females of varying life stages within the same region, the researchers observed sex and size-specific differences in distribution and movement rates, as well as associations with large-scale habitat features. For example, researchers found evidence of tiger shark core regions encompassing the National Oceanographic and Atmospheric Administration designated Habitat Areas of Particular Concern during cooler months, particularly by females. These are specifically bottom features of the Gulf that rise up from the edges of the continental shelf, and include places like the Flower Garden Banks National Marine Sanctuary. Additionally, shark core regions intersected with 2,504 oil and gas platforms, where previous researchers have observed them along the bottom.The scientists note that future research may benefit from combining alternative tracking tools, such as acoustic telemetry and genetic approaches, which can facilitate long-term assessment of tiger shark movement dynamics and help identify the role of the core habitats identified in this study."This research is just a first glimpse into how these iconic predators use the Gulf of Mexico's large marine ecosystem," said Ajemian.
The process quantifies the changing statistics of temperature evolution before global warming in the early 20th century and recent heat wave events to serve as the early warning signals for potential catastrophic changes. In addition, the study illustrates the contrast between urban and rural early warning signals for extreme heat waves.Tracking the pre-event signatures, or tipping points, of the increasing frequency and intensity of heat extremes will support the development of countermeasures to restore climate system resilience."Many studies have identified such changes in climate systems, like the sudden end of glacial period," said Chenghao Wang, a former ASU Research Scientist now at the Department of Earth System Science at Stanford University. "These qualitative changes usually have early-warning signals several thousand years before them.""We detected similar signals in events much shorter than previous studies," said Chenghao Wang. "We found early-warning signals also exist before global warming and heat waves on the time scale of years and days."In addition to global historical temperature data, the team tracks current temperature variances from airport weather stations. If it's abnormally hot, compared to 30 years of record, for at least three consecutive days, it's considered a heat wave."This method isn't just applicable for predicting extreme weather events in the next few days or weeks, said Zhihua Wang, an ASU environmental and water research engineering associate professor. "It observes human-induced variabilities and will support prediction over the next decades or even century." Zhihua Wang also serves as co-director of climate systems research at ASU's National Center of Excellence on Smart Materials for Urban Climate and Energy.The emergence of early-warning signals before heat waves provides new insights into the underlying mechanisms (e.g., possible feedback via land-atmosphere interactions). In particular, given the increasing frequency and intensity of heat extremes, the results will facilitate the design of countermeasures to reserve the tipping and restore the resilience of climate systems.According to Zhihua Wang, this method creates a "completely new frontier" for evaluating how things like global energy consumption and, conversely, the introduction of urban green infrastructure, are affecting climate change. "We're not replacing existing evaluation tools," he said. "The data is already there. It's enabling us to gauge what actions are having an impact."Based on the study results, researchers surmise that urban greening, or the use of public landscaping and forestry projects, along with adequate irrigation, may promote reverse tipping.In addition to Chenghao Wang and Zhihua Wang, the team included rising high school junior Linda Sun from Horace Greely High School in Chappaqua, NY.
Knowledge of underground water storage is of existential importance for agriculture as well as for the drinking water supply in many regions. These reservoirs are replenished by precipitation and seeping water, which in turn feeds rivers and lakes and allows rivers to flow in dry seasons. Measurements, however, are difficult because it is difficult to look into the earth, so one has to rely on either point values only -- via boreholes and wells -- or on calculations from precipitation and runoff data.Since 2002 there has been another method of measuring groundwater changes: Via the GRACE satellite missions (from 2002 to 2017) and GRACE-Follow On (since 2018), the change in the amount of water in and on the earth can be determined on the basis of its gravity field signal. But this method also has its pitfalls. First, the mass changes measured by the GRACE-FO satellites say nothing about the depth in which the mass is located: Do lakes empty at the surface? Is the level of rivers falling? Or does water drain from deeper layers? Secondly, the GRACE-FO satellites provide data for comparatively large areas of several tens of thousands of square kilometres. It is currently not possible to resolve the gravity field data more precisely.In a new study, Amanda H. Schmidt from Oberlin College, Ohio, together with researchers from the German Research Centre for Geosciences, is showing how different methods can be cleverly combined to obtain reliable groundwater data even for small river basins. They have examined monsoon rainfall data and seasonal water storage in almost 250 river basins in Asia. The size of the individual areas varies from one thousand to one million square kilometres. The study covers almost all of Asia.The water balance on our planet is characterized by three main variables: precipitation, surface runoff and evaporation. The difference of these goes into or flows out of various reservoirs, e.g. the groundwater. Time series of measuring stations on rivers (hydrographs) after persistent precipitation show typical falling curves (so-called recession curves), which reflect the emptying of water reservoirs. Groundwater fluctuations can be estimated from these curves. Another method is the comparison of precipitation and runoff values by the time delay of the runoff; the temporary intermediate storage results in a so-called P-Q hysteresis. P stands for precipitation and Q for runoff. The area or size of the hysteresis loop can be used as a measure for the intermediate storage.The study in 
Their research, published in the international journal Honorary Associate Professor Mark Diesendorf, in collaboration with Prof Tommy Wiedmann of UNSW Engineering, analysed dozens of studies on renewable electricity systems in regions where wind and/or solar could provide most of the electricity generation in future, such as Australia and the United States.The Clean Energy Australia report states that renewable energy's contribution to Australia's total electricity generation is already at 24 per cent.Lead author A/Prof Diesendorf is a renewable energy researcher with expertise in electricity generation, while co-author Prof Tommy Wiedmann is a sustainability scientist.A/Prof Diesendorf said their findings were controversial in light of some fossil fuel and nuclear power supporters, as well as some economists, rejecting a transition to large-scale electricity renewables."These critics claim the world's economy would suffer because they argue renewables require too much lifecycle energy to build, to the point of diverting all that energy away from other uses," he said."Our paper shows that there is no credible scientific evidence to support such claims, many of which are founded upon a study published in 2014 that used data up to 30 years old."There were still research papers coming out in 2018 using the old data and that prompted me to examine the errors made by those perpetuating the misconception."A/Prof Diesendorf said critics' reliance on outdated figures was "ridiculous" for both solar and wind technology."It was very early days back then and those technologies have changed so dramatically just in the past 10 years, let alone the past three decades," he said."This evolution is reflected in their cost reductions: wind by about 30 per cent and solar by 85 to 90 per cent in the past decade. These cost reductions reflect increasing EROIs."A/Prof Diesendorf said fears about macro-economic damage from a transition to renewable energy had been exaggerated."Not only did these claims rely on outdated data, but they also failed to consider the energy efficiency advantages of transitioning away from fuel combustion and they also overestimated storage requirements," he said."I was unsurprised by our results, because I have been following the literature for several years and doubted the quality of the studies that supported the previous beliefs about low EROIs for wind and solar."A/Prof Diesendorf said the study focused on wind and solar renewables which could provide the vast majority of electricity, and indeed almost all energy, for many parts of the world in future."Wind and solar are the cheapest of all existing electricity generation technologies and are also widely available geographically," he said."We critically examined the case for large-scale electricity supply-demand systems in regions with high solar and/or high wind resources that could drive the transition to 100 per cent renewable electricity, either within these regions or where power could be economically transmitted to these regions."In these regions -- including Australia, the United States, Middle East, North Africa, China, parts of South America and northern Europe -- variable renewable energy (VRE) such as wind and/or solar can provide the major proportion of annual electricity generation."For storage, we considered hydroelectricity, including pumped hydro, batteries charged with excess wind and/or solar power, and concentrated solar thermal (CST) with thermal storage, which is a solar energy technology that uses sunlight to generate heat."Co-author Prof Wiedmann said the researchers used Net Energy Analysis as their conceptual framework within which to identify the strengths and weaknesses of past studies in determining the EROI of renewable energy technologies and systems."We used the established Net Energy Analysis method because it's highly relevant to the issue of EROI: it aims to calculate all energy inputs into making a technology in order to understand the full impact," Prof Wiedmann said."From mining the raw materials and minerals processing, to building and operating the technology, and then deconstructing it at the end of its life. So, it's a lifecycle assessment of all energy which humans use to make a technology."A/Prof Diesendorf said their findings revealed that a transition from fossil fuels to renewable energy was worthwhile, contradicting the assumptions and results of many previous studies on the EROIs of wind and solar."We found that the EROIs of wind and solar technologies are generally high and increasing; typically, solar at a good site could generate the lifecycle primary energy required to build itself in one to two years of operation, while large-scale wind does it in three to six months," he said."The impact of storage on EROI depends on the quantities and types of storage adopted and their operational strategies. In the regions we considered, the quantity of storage required to maintain generation reliability is relatively small."We also discovered that taking into account the low energy conversion efficiency of fossil-fuelled electricity greatly increases the relative EROIs of wind and solar."Finally, we found the macro-economic impact of a rapid transition to renewable electricity would at worst be temporary and would be unlikely to be major."A/Prof Diesendorf said he hoped the study's results would give renewed confidence to businesses and governments considering or already making a transition to more sustainable electricity technologies and systems."This could be supported by government policy, which is indeed the case in some parts of Australia -- including the ACT, Victoria and South Australia -- where there's strong support for the transition," he said."A number of mining companies in Australia are also going renewable, such as a steel producer which has a power purchase agreement with a solar farm to save money, while a zinc refinery built its own solar farm to supply cheaper electricity."A/Prof Diesendorf said the Australian Government, however, could help with more policies to smooth the transition to renewable energy."In Australia the transition is happening because renewable energy is much cheaper than fossil fuels, but there are many roadblocks and potholes in the way," he said."For example, wind and solar farms have inadequate transmission lines to feed power into cities and major industries, and we need more support for storage to better balance the variability of wind and solar."So, I hope our research will help bolster support to continuing with the transition, because we have discredited the claim that the EROIs of electricity renewables are so low that a transition could displace investment in other sectors."
Between 2000 and 2017, levels of the potent greenhouse gas barreled up toward pathways that climate models suggest will lead to 3-4 degrees Celsius of warming before the end of this century. This is a dangerous temperature threshold at which scientists warn that natural disasters, including wildfires, droughts and floods, and social disruptions such as famines and mass migrations become almost commonplace. The findings are outlined in two papers published July 14 in In 2017, the last year when complete global methane data are available, Earth's atmosphere absorbed nearly 600 million tons of the colorless, odorless gas that is 28 times more powerful than carbon dioxide at trapping heat over a 100-year span. More than half of all methane emissions now come from human activities. Annual methane emissions are up 9 percent, or 50 million tons per year, from the early 2000s, when methane concentrations in the atmosphere were relatively stable.In terms of warming potential, adding this much extra methane to the atmosphere since 2000 is akin to putting 350 million more cars on the world's roads or doubling the total emissions of Germany or France. "We still haven't turned the corner on methane," said Jackson, a professor of Earth system science in Stanford's School of Earth, Energy & Environmental Sciences (Stanford Earth).Globally, fossil fuel sources and cows are twin engines powering methane's upward climb. "Emissions from cattle and other ruminants are almost as large as those from the fossil fuel industry for methane," Jackson said. "People joke about burping cows without realizing how big the source really is."Throughout the study period, agriculture accounted for roughly two-thirds of all methane emissions related to human activities; fossil fuels contributed most of the remaining third. However, those two sources have contributed in roughly equal measure to the increases seen since the early 2000s.Methane emissions from agriculture rose to 227 million tons of methane in 2017, up nearly 11 percent from the 2000-2006 average. Methane from fossil fuel production and use reached 108 million tons in 2017, up nearly 15 percent from the earlier period.Amid the coronavirus pandemic, carbon emissions plummeted as manufacturing and transportation ground to a halt. "There's no chance that methane emissions dropped as much as carbon dioxide emissions because of the virus," Jackson said. "We're still heating our homes and buildings, and agriculture keeps growing."Methane emissions rose most sharply in Africa and the Middle East; China; and South Asia and Oceania, which includes Australia and many Pacific islands. Each of these three regions increased emissions by an estimated 10 to 15 million tons per year during the study period. The United States followed close behind, increasing methane emissions by 4.5 million tons, mostly due to more natural gas drilling, distribution and consumption."Natural gas use is rising quickly here in the U.S. and globally," Jackson said. "It's offsetting coal in the electricity sector and reducing carbon dioxide emissions, but increasing methane emissions in that sector." The U.S. and Canada are also producing more natural gas. "As a result, we're emitting more methane from oil and gas wells and leaky pipelines," said Jackson, who is also a senior fellow at Stanford's Woods Institute for the Environment and Precourt Institute for Energy.Europe stands out as the only region where methane emissions have decreased over the last two decades, in part by tamping down emissions from chemical manufacturing and growing food more efficiently. "Policies and better management have reduced emissions from landfills, manure and other sources here in Europe. People are also eating less beef and more poultry and fish," said Marielle Saunois of the UniversitÃ© de Versailles Saint-Quentin in France, lead author of the paper in Tropical and temperate regions have seen the biggest jump in methane emissions. Boreal and polar systems have played a lesser role. Despite fears that melting in the Arctic may unlock a burst of methane from thawing permafrost, the researchers found no evidence for increasing methane emissions in the Arctic -- at least through 2017.Human driven emissions are in many ways easier to pin down than those from natural sources. "We have a surprisingly difficult time identifying where methane is emitted in the tropics and elsewhere because of daily to seasonal changes in how waterlogged soils are," said Jackson, who also leads a group at Stanford working to map wetlands and waterlogged soils worldwide using satellites, flux towers and other tools.According to Jackson and colleagues, curbing methane emissions will require reducing fossil fuel use and controlling fugitive emissions such as leaks from pipelines and wells, as well as changes to the way we feed cattle, grow rice and eat. "We'll need to eat less meat and reduce emissions associated with cattle and rice farming," Jackson said, "and replace oil and natural gas in our cars and homes."Feed supplements such as algae may help to reduce methane burps from cows, and rice farming can transition away from permanent waterlogging that maximizes methane production in low-oxygen environments. Aircraft, drones and satellites show promise for monitoring methane from oil and gas wells. Jackson said, "I'm optimistic that, in the next five years, we'll make real progress in that area."Rob Jackson is Stanford's Michelle and Kevin Douglas Provostial Professor. Co-authors of the paper in The research received support from the Gordon and Betty Moore Foundation, Stanford University, the Australian Government's National Environmental Science Programme's Earth Systems and Climate Change Hub (JGC) and Future Earth.
New evidence from International Ocean Discovery Program (IODP) Expedition 364 of trace fossils of burrowing organisms that lived in the seafloor of the Chicxulub Crater beginning a few years after the impact shows just how quick the recovery of the seafloor ecosystem was, with the establishment of a well-developed tiered community withinÂ  approximately 700,000 years after the event.In April and May 2016, a team of international scientists drilled into the Chicxulub impact crater. This joint expedition, organized by the International Ocean Discovery Program (IODP) and International Continental Scientific Drilling Program (ICDP) recovered an extended syn- and post-impact set of rock cores, allowing study of the effects of the impact on life and its recovery after the mass extinction event. The end Cretaceous (K-Pg) event has been profusely studied and its effect on biota are relatively well-known. However, the effect of these changes on the macrobenthic community, the community of organisms living on and in the seafloor that do not leave body fossils, is poorly known.The investigators concluded that the diversity and abundance of trace fossils responded primarily to variations in the flux of organic matter (i.e., food) sinking to the seafloor during the early Paleocene. Local and regional-scale effects of the K-Pg impact included earthquakes of magnitude 10-11, causing continental and marine landslides, tsunamis hundreds of meters in height that swept more than 300 km onshore, shock waves and air blasts, and the ignition of wildfires. Global phenomena included acid rain, injection of aerosols, dust, and soot into the atmosphere, brief intense cooling followed by slight warming, and destruction of the stratospheric ozone layer, followed by a longer-term greenhouse effect.Mass extinction events have punctuated the past 500 million years of Earth's history, and studying them helps geoscientists understand how organisms respond to stress in their environment and how ecosystems recover from the loss of biodiversity. Although the K-Pg mass extinction was caused by an asteroid impact, previous ones were caused by slower processes, like massive volcanism, which caused ocean acidification and deoxygenation and had environmental effects that lasted millions of years.By comparing the K-Pg record to earlier events like the end Permian mass extinction (the so-called "Great Dying" when 90% of life on Earth went extinct), geoscientists can determine how different environmental changes affect life. There are similar overall patterns of recovery after both events with distinct phases of stabilization and diversification, but with very different time frames. The initial recovery after the K-Pg, even at ground zero of the impact, lasted just a few years; this same phase lasted tens of thousands of years after the end Permian mass extinction. The overall recovery of seafloor burrowing organisms after the K-Pg took ~700,000 years, but it took several million years after the end Permian.
Radiocarbon dating of shell middens -- remnants of meals eaten long ago -- capture a record of Aboriginal occupation that extends to around 29,000 years, confirming the location as one of the oldest sites along the 2500km river to become the oldest River Murray Indigenous site in South Australia.In the first comprehensive survey of the region, one of the oldest Indigenous sites along Australia's longest river system has been discovered. The results, published in "These results include the first pre-Last Glacial Maximum ages returned on the River Murray in South Australia and extend the known Aboriginal occupation of the Riverland by approximately 22,000 years," says Flinders University archaeologist and PhD candidate Craig Westell.More than 30 additional radiocarbon dates were collected in the region, spanning the period from 15,000 years ago to the recent present. Together, the results relate Aboriginal people to an ever-changing river landscape, and provide deeper insights into how they responded to these challenges.The period represented by the radiocarbon results brackets the Last Glacial Maximum (commonly known as the last Ice Age) when climatic conditions were colder and drier and when the arid zone extended over much of the Murray-Darling Basin. The river and lake systems of the basin were under stress during this time.In the Riverland, dunes were advancing into the Murray floodplains, river flows were unpredictable, and salt was accumulating in the valley.The ecological impacts witnessed during one of the worst droughts on record, the so-called Millennium Drought (from late 1996 extending to mid-2010), provides an idea of the challenges Aboriginal people may have faced along the river during the Last Glacial Maximum, and other periods of climate stress, researchers conclude."These studies show how our ancestors have lived over many thousands of years in the Riverland region and how they managed to survive during times of hardship and plenty," says RMMAC spokesperson Fiona Giles."This new research, published in Australian Archaeology, fills in a significant geographic gap in our understanding of the Aboriginal occupation chronologies for the Murray-Darling Basin," adds co-author Associate Professor Amy Roberts.The dating, which was undertaken at the Australian Nuclear Science and Technology Organisation (ANSTO) and Waikato University, forms part of a much larger and ongoing research program led by Associate Professor Amy Roberts which is undertaking a broad-ranging investigation of past and contemporary Aboriginal connections to the Riverland region.
The study, published in The clearing of grass by crabs has dramatically altered the flow of creeks that run through the marshes, the study found, and is altering the dynamics between predator and prey species in the marshes. In fact, the researchers say that Sesarma, which had previously been a minor player in southeastern salt marshes, can now be considered a keystone species, meaning it plays a dominant role in shaping the ecosystem."What we've found is an example of how sea level rise can activate a keystone species that's now dramatically remodeling these salt marshes," said Mark Bertness, a professor emeritus of ecology and evolutionary biology at Brown University and a coauthor of the research. "That's a big deal because sea level rise is a pervasive global phenomenon, and this is a largely unexpected consequence. We need to start thinking about how global climate change could activate new keystone species in other ecosystems."Research on Sesarma crabs and their impact on salt marshes has a long history in Bertness's lab at Brown. In 2011, Bertness and his students discovered that Sesarma, voracious grazers of cordgrass roots and leaves, were behind sudden die-offs of marshes on Cape Cod. In that case, overfishing had suddenly pulled predator species like striped bass out of the water, giving the crabs free reign to decimate the marshes. One of the undergraduate co-authors on that earlier research was Christini Angelini, now an associate professor at the University of Florida and a senior author on this new paper.Sesarma were known to inhabit southern marshes in Florida and the Carolinas, but their populations hadn't boomed like those further north. One potential reason for that was differing soil substrates. While working several years ago as an undergraduate researcher in Bertness' lab, Sinead Crotty, now project director at Yale's Carbon Containment Lab, showed that ground hardness played a big role in where Sesarma are able to establish themselves. Her findings indicated that Sesarma had a much easier time building burrows and feeding on grass roots in the peaty New England soil compared to harder soil substrates often found in southern marshes.But as sea levels continue to rise due to climate change, Crotty, Angelini and Bertness wondered if softening soils might be giving Sesarma more of a foothold in the South. Looking at aerial photos from nine locations across South Carolina and Florida, they found that the number of marsh creeks with evidence of Sesarma grazing increased by up to 240% from the late 1990s to the late 2010s. Meanwhile, surveys of sea level rise show that the ground in these areas is tidally submerged up to an hour longer per day now compared to the late 1990s."You've got the sea level rising, which softens the substrate that these crabs usually can't burrow in," Bertness said. "Now that it's softer you've got an ideal habitat to support these huge communal Sesarma burrows."This new Sesarma activity is reshaping marshes, the researchers found. Elimination of grasses has increased the rate at which creeks form in the marshes, and increases the drainage density of marsh creeks by up to 35%.Sesarma activity is also influencing interactions between predators and prey in the creeks. Clearing of grasses provides predators increased access to shellfish and other prey species. The research found that populations of mussels were dramatically lower in Sesarma-grazed creeks compared to creeks that weren't grazed."As they drown, southeastern U.S. marshes are fracturing from grasslands to patches of marsh, with depleted populations of mussels, snails and other invertebrates," Angelini said. "These dynamics reveal how quickly marshes may disappear with accelerating sea level rise and how long they will remain foraging grounds for commercially, recreationally and ecologically important species."The fact that Sesarma is now altering the geomorphology of the marshes, as well as the ecological interactions between other species, is evidence that it now qualifies as a keystone species in southern marshes. This is the first example, the researchers say, of activation of new keystone species as the result of anthropogenic climate change."This is going to be something for the textbooks," Bertness said. "This is an underappreciated way in which climate change alters ecosystems."The research was supported by the National Science Foundation (1652628, 1546638, 1315138).
Scientists are working to understand how environmental changes alter river dynamics. A new study in the Deltas counteract sea level rise by building up sediment, which mostly occurs near a river channel itself. Every once in a while, the river will switch course through an avulsion and begin building up the delta somewhere else. "So avulsions are the way that the river spreads its sediment out over the whole landscape," said first author Austin Chadwick, a postdoctoral scholar at University of Minnesota."The questions we're asking are how often do rivers naturally change their course," he continued, "and how is that going to change with climate change and human interference."Unfortunately, there has previously been no consensus on how rivers responded to climactic shift. Some scientists thought avulsion rates would increase as sea level rises, while others predicted they'd decrease. "There simply was no unifying theory to explain how river avulsion frequency is dependent on sea level," Ganti said.To straighten out the situation, Ganti, Chadwick and their coauthor Michael Lamb of Caltech, combined observations from the geologic and historical records with a mathematical model of river dynamics. By focusing on this specific issue, they aimed to finally get definitive answers and useful predictions.Large rivers tend to flatten out and decelerate as they approach the ocean. After a certain point, the downstream conditions of the sea level begin to influence the river's behavior in what scientists call backwater hydrodynamics. "This is a dynamic zone where deposition and erosion occurs in coastal rivers," Ganti explained.In a previous paper, the team had shown that avulsions occur within this backwater region, which can extend quite far inland. For instance, the backwater zone of the Mississippi River reaches 500 kilometers from the coast. Deeper, flatter rivers like the Mississippi, which have larger backwater regions, therefore have larger deltas.The researchers goal with this study was to apply their newfound understanding of the impact of backwater hydrodynamics to learn about the frequency of avulsions themselves.Using the model, and comparing their results to field data, the team discovered that there are three ways that deltas can respond to sea level rise, which depend on the balance between the rate of sea-level change and the sediment supplied by the river.The first: when a river has a lot of sediment and sea-level rise is relatively slow. According to the model, these rivers are resilient to sea-level rise, and their avulsion rates remain stable. China's Yellow River is one example.The second case occurs when a river has less sediment or the sea level rises more quickly. In this scenario, avulsions become more frequent. The rising ocean promotes sedimentation, and once a channel fills to a certain depth, the river will jump its course.And representing the extreme, in which sea level rise outpaces a river's ability to deposit sediment, is the third case. As the ocean infiltrates the delta, the river will reach its maximum avulsion rate, and the whole system will begin migrating inland. Scientists hadn't known about this case before, and the discovery of the three regimes together explains the previous inconsistencies in the scientific literature.The researchers inputted observations and data into their model to see whether various river deltas would behave differently under predicted climate conditions. "The answer is yes, for most of them," Chadwick said. "Many rivers will experience more frequent avulsions and some rivers will also have avulsions farther inland."River avulsions have huge societal implications, with the potential to cause economic and civil unrest. Archaeologists believe that a course change of the Indus River in western India directly contributed to the decline of the Bronze Age Harappan civilization. More recently, avulsions led to the 1877 Yellow River flood and 1931 China floods, two of the deadliest natural disasters in modern history.An avulsion could have dire consequences for rivers like the Mississippi, where a system called the Old River Control Structure has prevented the river from jumping course since 1963. If the backwater region migrated inland, the river could change course upstream from the facility and bypass it altogether. Millions of gallons of water per minute would course through previously dry land, while the downstream portion of the channel would go completely dry.The authors have made their model available and accessible to anyone who might want to use it. They were even able to reduce several formulas into a single equation by implementing a few basic assumptions about river conditions and dynamics."Groups like the Army Corps of Engineers and the Department of the Interior can use this tool to apply to any delta," said Chadwick. "And hopefully it will help inform our decisions in these places as we cope with climate change."
The American crocodile is widespread across the American continent (from South Florida to Venezuela, across the Greater Antilles, and from Mexico to Ecuador). Successful due to its ability to thrive within brackish and saltwater environments. Efforts to conserve the crocodile species have existed since 1975 when their status was set to vulnerable on the IUCN (International Union for Conservation of Nature) red list. However, although conservation efforts have been put in place, the American crocodile faces further threats including habitat degradation due to coastal development.Replenishing these populations requires understanding of population structures through genetic analysis, which can elaborate on the evolution of the species' distribution. Gaining more understanding on how a species has come to be distributed so widely and how populations can differentiate genetically, can inform regions how best to manage their populations.The study reflected a regional collaborative effort, where DNA sampling occurred across seven countries including Venezuela, Jamaica and Cuba. There has been ongoing discussion on how these regional populations of C.acutus are similar. However, the study's results found that populations in Northern, Central and Southern America's and Great Antilles differed genetically. There were similarities found between Costa Rica and Jamaican populations. In Venezuela, they identified three new haplotypes, which are closely related genes that help scientists identify an origin of distribution.Researchers believe that the mating with different species could have contributed to this distribution, also known as hybridisation. Crocodiles hybridise easily, contributing to their ability to survive since the prehistoric era. Additionally, in Florida genetic analysis showed there had been a case of unintentional translocation, where the species had been moved from a different location over time. This had been flagged by previous research, where crocodiles with haplotypes from Central and South America had been transported to Florida, most likely for the pet trade, and later escaped or released into the wild by owners.By identifying these differences between regional populations of C. acutus, conservation efforts can establish population clusters which consider the populations as independent management units that may have different needs and focuses.Natalia Rossi, Country Manager of the Cuba Program at the Wildlife Conservation Society and the study's co-author explains some of the challenges around taking samples from large crocodiles: "Our study involved several research teams across multiple sites and countries and often in difficult field conditions. For four years between May to July the team would record, mark and sample crocodile hatchings, and juvenile and adult crocodiles in Cuba's Birama Swamp, one of the study sites. It was not unusual for us to have to spend hours in the mangrove lakes waiting for one to appear, and when a crocodile was spotted the whole team would have to enter the water to help net it. While both exciting and rewarding work, it is also dangerous as the crocodiles are powerful and it involves lots of team co-ordination and trust to secure the crocodile to enable us to take samples."The study was ambitious and could not have been achieved without its global collaboration and efforts from its long list of authors. In particular, the late John Thorbjarnarson and Rafael Crespo, who dedicated their lives to this research.
The University of Alaska Fairbanks and Finnish Meteorological Institute led the international effort, which included researchers from six countries. The first of several related papers was published this month in Climate change is most pronounced in the Arctic. The Arctic Ocean, which covers less than 3% of the Earth's surface, appears to be quite sensitive to abnormal conditions in lower-latitude oceans."With this in mind, the goal of our research was to illustrate the part of Arctic climate change driven by anomalous [different from the norm] influxes of oceanic water from the Atlantic Ocean and the Pacific Ocean, a process which we refer to as borealization," said lead author Igor Polyakov, an oceanographer at UAF's International Arctic Research Center and FMI.Although the Arctic is often viewed as a single system that is impacted by climate change uniformly, the research stressed that the Arctic's Amerasian Basin (influenced by Pacific waters) and its Eurasian Basin (influenced by Atlantic waters) tend to differ in their responses to climate change.Since the first temperature and salinity measurements taken in the late 1800s, scientists have known that cold and relatively fresh water, which is lighter than salty water, floats at the surface of the Arctic Ocean. This fresh layer blocks the warmth of the deeper water from melting sea ice.In the Eurasian Basin, that is changing. Abnormal influx of warm, salty Atlantic water destabilizes the water column, making it more susceptible to mixing. The cool, fresh protective upper ocean layer is weakening and the ice is becoming vulnerable to heat from deeper in the ocean. As mixing and sea ice decay continues, the process accelerates. The ocean becomes more biologically productive as deeper, nutrient-rich water reaches the surface.By contrast, increased influx of warm, relatively fresh Pacific water and local processes like sea ice melt and accumulation of river water make the separation between the surface and deep layers more pronounced on the Amerasian side of the Arctic. As the pool of fresh water grows, it limits mixing and the movement of nutrients to the surface, potentially making the region less biologically productive.The study also explores how these physical changes impact other components of the Arctic system, including chemical composition and biological communities.Retreating sea ice allows more light to penetrate into the ocean. Changes in circulation patterns and water column structure control availability of nutrients. In some regions, organisms at the base of the food web are becoming more productive. Many marine organisms from sub-Arctic latitudes are moving north, in some cases replacing the local Arctic species."In many respects, the Arctic Ocean now looks like a new ocean," said Polyakov.These differences change our ability to predict weather, currents and the behavior of sea ice. There are major implications for Arctic residents, fisheries, tourism and navigation.This study focused on rather large-scale changes in the Arctic Ocean, and its findings do not necessarily represent conditions in nearshore waters where people live and hunt.The study stressed the importance of future scientific monitoring to understand how this new realm affects links between the ocean, ice and atmosphere.Co-authors of the paper include Matthew Alkire, Bodil Bluhm, Kristina Brown, Eddy Carmack, Melissa Chierici, Seth Danielson, Ingrid Ellingsen, Elizaveta Ershova, Katarina GÃ¥rdfeldt, Randi Ingvaldsen, Andrey V. Pnyushkov, Dag Slagstad and Paul Wassmann.
One promising solution is "coral gardening" or outplanting, a method where coral fragments grown in a nursery are transplanted onto degraded reefs. Successful outplanting raises coral biomass and helps to restore reef function. Each year, thousands of corals are outplanted using this method.While effective, the technique is both time-consuming and expensive; the cost of reef restoration can reach $400,000 per hectare and success isn't always guaranteed. If the newly settled corals are exposed to stressors such as algae outbreaks, unfavorable water chemistry, and/or temperature fluctuations, they can quickly deteriorate and die. With temperature being one of the most fundamental factors determining coral health and survival, understanding its role in outplanting survival is crucial to restoration success.In a study published today in "Coral reefs experience a global, annual maximum sea surface temperature of about 29.4 degrees Celsius. Our study reveals that increasing the maximum temperature a site experiences by one degree higher reduces the chance of coral outplant survival to below 50%. We highlight the importance of considering temperatures a site has previously experienced to optimize outplant outcomes," said Shawna Foo, lead author and postdoctoral researcher at GDCS.The study was based on an analysis of hundreds of coral outplanting projects worldwide between 1987 and 2018. The team assessed data on coral survival rates, outplant locations and dates, along with sea surface temperature data extracted from satellites to determine the effects of temperature on outplant survival. They also considered whether temperatures from the year prior to coral outplanting showed similar patterns. The results of their analysis help to determine if a restoration site is appropriate or not."Although sobering for reef conservationists and managers, our findings provide a critical compass as to where reef restoration efforts can have their greatest impact in the future. Reef restoration is just now turning from a cottage industry to a global enterprise, and this needs to happen in concert with the changing global geography of ocean temperature," said Greg Asner, co-author of the study and director of GDCS.The study was supported by the John D. and Catherine T. MacArthur Foundation.
Currently 30 exploration licenses cover about 580,000 square miles of the seafloor on the high seas and some countries are exploring exploitation in their own water as well. Most research assessing the impacts of mining and environmental baseline survey work has focused on the seafloor.However, large amounts of mud and dissolved chemicals are released during mining and large equipment produces extraordinary noise -- all of which travel high and wide. Unfortunately, there has been almost no study of the potential effects of mining beyond the habitat immediately adjacent to extraction activities."This is a call to all stakeholders and managers," said Jeffrey Drazen, lead author of the article and professor of oceanography at UH Manoa. "Mining is poised to move forward yet we lack scientific evidence to understand and manage the impacts on deep pelagic ecosystems, which constitute most of the biosphere. More research is needed very quickly."The deep midwaters of the world's ocean represent more than 90% of the biosphere, contain 100 times more fish than the annual global catch, connect surface and seafloor ecosystems, and play key roles in climate regulation and nutrient cycles. These ecosystem services, as well as untold biodiversity, could be negatively affected by mining.This recent paper, published in the "The current study shows that mining and its environmental impacts may not be confined to the seafloor thousands of feet below the surface but could threaten the waters above the seafloor, too," said Drazen. "Harm to midwater ecosystems could affect fisheries, release metals into food webs that could then enter our seafood supply, alter carbon sequestration to the deep ocean, and reduce biodiversity which is key to the healthy function of our surrounding oceans."In accordance with UN Convention on the Law of the Sea (UNCLOS), the International Seabed Authority (ISA) is required to ensure the effective protection of the marine environment, including deep midwater ecosystems, from harmful effects arising from mining-related activities. In order to minimize environmental harm, mining impacts on the midwater column must be considered in research plans and development of regulations before mining begins."We are urging researchers and governing bodies to expand midwater research efforts, and adopt precautionary management measures now in order to avoid harm to deep midwater ecosystems from seabed mining," said Drazen.
The research appears July 10 in The study centers on net primary production (NPP), a measure of how quickly plants and algae convert sunlight and carbon dioxide into sugars that other creatures can eat. "The rates are really important in terms of how much food there is for the rest of the ecosystem," Arrigo said. "It's also important because this is one of the main ways that COArrigo and colleagues found that NPP in the Arctic increased 57 percent between 1998 and 2018. That's an unprecedented jump in productivity for an entire ocean basin. More surprising is the discovery that while NPP increases were initially linked to retreating sea ice, productivity continued to climb even after melting slowed down around 2009. "The increase in NPP over the past decade is due almost exclusively to a recent increase in phytoplankton biomass," Arrigo said.Put another way, these microscopic algae were once metabolizing more carbon across the Arctic simply because they were gaining more open water over longer growing seasons, thanks to climate-driven changes in ice cover. Now, they are growing more concentrated, like a thickening algae soup."In a given volume of water, more phytoplankton were able to grow each year," said lead study author Kate Lewis, who worked on the research as a PhD student in Stanford's Department of Earth System Science. "This is the first time this has been reported in the Arctic Ocean."Phytoplankton require light and nutrients to grow. But the availability and intermingling of these ingredients throughout the water column depend on complex factors. As a result, although Arctic researchers have observed phytoplankton blooms going into overdrive in recent decades, they have debated how long the boom might last and how high it may climb.By assembling a massive new collection of ocean color measurements for the Arctic Ocean and building new algorithms to estimate phytoplankton concentrations from them, the Stanford team uncovered evidence that continued increases in production may no longer be as limited by scarce nutrients as once suspected. "It's still early days, but it looks like now there is a shift to greater nutrient supply," said Arrigo, the Donald and Donald M. Steel Professor in Earth Sciences.The researchers hypothesize that a new influx of nutrients is flowing in from other oceans and sweeping up from the Arctic's depths. "We knew the Arctic had increased production in the last few years, but it seemed possible the system was just recycling the same store of nutrients," Lewis said. "Our study shows that's not the case. Phytoplankton are absorbing more carbon year after year as new nutrients come into this ocean. That was unexpected, and it has big ecological impacts."The researchers were able to extract these insights from measures of the green plant pigment chlorophyll taken by satellite sensors and research cruises. But because of the unusual interplay of light, color and life in the Arctic, the work required new algorithms. "The Arctic Ocean is the most difficult place in the world to do satellite remote sensing," Arrigo explained. "Algorithms that work everywhere else in the world -- that look at the color of the ocean to judge how much phytoplankton are there -- do not work in the Arctic at all."The difficulty stems in part from a huge volume of incoming tea-colored river water, which carries dissolved organic matter that remote sensors mistake for chlorophyll. Additional complexity comes from the unusual ways in which phytoplankton have adapted to the Arctic's extremely low light. "When you use global satellite remote sensing algorithms in the Arctic Ocean, you end up with serious errors in your estimates," said Lewis.Yet these remote-sensing data are essential for understanding long-term trends across an ocean basin in one of the world's most extreme environments, where a single direct measurement of NPP may require 24 hours of round-the-clock work by a team of scientists aboard an icebreaker, Lewis said. She painstakingly curated sets of ocean color and NPP measurements, then used the compiled database to build algorithms tuned to the Arctic's unique conditions. Both the database and the algorithms are now available for public use.The work helps to illuminate how climate change will shape the Arctic Ocean's future productivity, food supply and capacity to absorb carbon. "There's going to be winners and losers," Arrigo said. "A more productive Arctic means more food for lots of animals. But many animals that have adapted to live in a polar environment are finding life more difficult as the ice retreats."Phytoplankton growth may also peak out of sync with the rest of the food web because ice is melting earlier in the year. Add to that the likelihood of more shipping traffic as Arctic waters open up, and the fact that the Arctic is simply too small to take much of a bite out of the world's greenhouse gas emissions. "It's taking in a lot more carbon than it used to take in," Arrigo said, "but it's not something we're going to be able to rely on to help us out of our climate problem."This research was supported by NASA's Earth and Space Science Fellowship program and the National Science Foundation.
Coral bleaching and the crown-of-thorns starfish represent the two biggest disturbances coral reefs face, while local stressors like pollution and overfishing represent the two biggest impediments to recovery following disturbances.Unlike other prediction tools, this study used the interaction of two major oceanographic modulators -- El NiÃ±o and Pacific Decadal Oscillation, or PDO -- to predict how "warm blobs" of seawater and excess nutrients move around the tropical Western Pacific to cause these two destructive events. Existing tools typically provide bleaching warnings two to three weeks in advance; however, this new tool extends the warning period to between three and five months.Advanced warnings have important implications for coral reef management efforts in the Pacific region and potentially beyond."It takes management from a reactive position to a more proactive one," said senior author Peter Houk, an associate professor of marine biology in the Marine Lab. "Not a lot can be accomplished with only a couple weeks' notice, but predicting bleaching and starfish disturbance events a few months out may give governments and other agencies more time to acquire supplies, create legislation, and create support networks to ensure reefs are better equipped to handle these forces."For example, it allows more time to revise temporary fisheries regulations, raise funds for the removal of starfish, and procure supplies needed to support these acts. The authors have predicted outbreaks of starfish to emerge in Eastern Micronesia this year, providing time for Kosrae's tourism industry and resources agencies to gather supplies and build monitoring and removal plans now. Further, the authors can provide warnings for other islands down current to be on the lookout as starfish outbreaks are known to spread across islands and reefs in the direction of prevailing currents.Above-average sea-surface temperatures are common across the tropical Pacific following El NiÃ±o Southern Oscillation events, which are increasingly exacerbated by climate change. However, islands -- from Palau to Kosrae -- can be affected differently. One may bleach, while another experiences little to none.That question motivated researchers to study the impact of El NiÃ±o interacting with the PDO. Together, the two patterns predict maximum sea-surface temperatures and also the movement of "nutrient plumes" filled with what is known as "chlorophyll a" around the Pacific Ocean that attract plankton and cause the crown-of-thorns starfish outbreaks that wreak havoc on coral. Both sea-surface temperatures and nutrient plumes have been mapped by satellites for years; however, predicting their future has been a challenge.The researchers analyzed sea temperatures dating back to 1980 and biological data dating back to 1998, including coral cover and chlorophyll a plumes, from 82 survey sites on the main islands of Micronesia to track how they are influenced by the interaction of these two cycles.Using those observations, they built models that accurately predicted both sea surface temperatures and nutrients. The models accounted for 77% of the variation in sea temperature and 55% of the variation in chlorophyll a concentrations between 1980 to the present, both of which support strong predictions.The study shows that including PDO events into forecasts may improve predictions of when and where bleaching and starfish outbreaks will occur. The next step will be to build an online resource to host the predictive model for scientists and resources managers to access and to keep improving the model to the extent possible."We provide the first insight into how PDO and El NiÃ±o cycles predicted sea-surface temperatures, chlorophyll a concentrations, and changes to coral cover across the tropical north Pacific Ocean," the authors said. "These results may be transferrable to other oceanic regions to help predict coral reef status at even larger scales."
"Understanding the history of soil tunnels shows us that certain types of soils and geographies are uniquely suited for tunneling. Countries with warfare or smuggling issues, including the U.S.-Mexico border and Israeli borders, need detailed soil and hydrology maps of their borders to identify soil types, typographies, and thus areas where soil tunnels could be constructed," according to study co-author Kenneth Olson, professor emeritus and soil scientist in the Department of Natural Resource and Environmental Sciences at the University of Illinois.Olson and co-author David Speidel looked at several tunnel systems throughout history, including examples in Syria, China, Cambodia, Vietnam, North Korea, South Korea, Iran, Iraq, Israel, Gaza, Egypt, Afghanistan, Mexico, and the United States.The authors discuss the history of each area's tunnels, including construction and use. They detail the geological materials, bedrock, water tables, and climate for each tunnel network, and note its resilience or demise.Using the case studies, the authors are able to identify site conditions that are most susceptible to soil tunneling and make specific recommendations for today's most vulnerable border crossings."Most cases of successful tunneling throughout history were in arid areas with a relatively low permanent water table," notes Olson. "These areas will need to be monitored for sound and vibrations to disrupt tunneling by smugglers."Olson's previous work explaining how soils and tunneling were an equalizer during the Vietnam War caught the eyes of several military groups, which led him to expand his soil tunnel warfare and smuggling research into this more recent study.Olson is a Vietnam-era veteran who served in the U.S. Army from 1969 to 1973. Speidel is a U.S. Army Iraq, Bosnia-Herzegovina, and Vietnam-era veteran as well as a USDA soil resource conservationist and retiree previously detailed by the Foreign Agricultural Service as a Civilian Response Crops Agricultural Advisor.
Soil classification, or scientific identification, can also help determine if the soil needs extra attention and resources for protection. For example, certain soils may not be safe for hiking, could be home to an endangered species, or foster a unique ecosystem like wetlands.However, soil classification is complex. Soil characteristics include color, texture, mineral composition, air and water content, and much more. Each of these characteristics can give added details to solve the story behind the soil.Many soils are simple for trained soil scientists to identify. But Karen Vaughan of the University of Wyoming and her team dug in to investigate an area of soil along the central coast of California that had some peculiar characteristics."The reason for this research site really comes from long ago in a wetlands field lab," she says. "Students kept saying the soil didn't meet all the field indicators of hydric -- or wetter -- soils. I thought, it has to. It's wet and there's plenty of water-loving vegetation. Then I realized it must be a problematic soil, so we set up this experiment to figure it out."Vaughan's experiment consisted of studying how dark the color of the soil was, as well as its water content, vegetation, and chemical composition. Looking at how wet the soils seemed, the vegetation that grew there, and microbes that lived there, a scientist would think they were wetland soils.However, other characteristics of the soil, such as its dark color, confused the researchers because it was so similar to the surrounding drier soil. This is where a way to analyze soil color more precisely, called the profile darkness index, was helpful. It allowed them to properly classify the soils.Soil classification is usually a pretty exact science. Hydric soils have a specific set of characteristics. One of the key characteristics of hydric soil is a pale, light greyish color. As a result of the uniquely dark color, they could be mistakenly identified as drier soils and not meet the requirements of wetlands.More clues for soil classification can sometimes be found in the landscape. Landslides are common on these cliffs, which cause soil to fall and be deposited in other areas. Often, these landslides result in depressions where a soil might be wetter than its surroundings."We get these situations where the soil characteristics don't match features we usually see in wetter soils," Vaughan explains. "This is, for example, because the transported soils inherited darker colors from the parent material. If someone looked at these soils, they would assume they are not as wet as they are. They then would not classify these areas as wetlands, despite them performing as wetlands.""This kind of proper identification is important so the wetlands can be better conserved," Vaughan says. "If researchers don't know about them, they can't be protected."This is because wetlands are so beneficial to the environment. They can help store water to protect against floods and erosion, as well as improve water quality. They also serve as a place for important plants and animals to live. Of course, they are also beautiful to observe when hiking out in nature."Soils tells the story of an ecosystem," she says. "If we look to the soil, we can understand ecosystem function."
A single crown-of-thorns starfish is formidable, with a large body covered in spiky, venomous thorns. But their true danger lies in their potent reproductive ability, with female crown-of thorns starfish releasing millions of eggs in a single spawning. This can quickly lead to plagues, with uncontrollably large numbers of starfish rapidly destroying vast areas of coral reef."Almost 40 years ago, Okinawa experienced a massive outbreak of crown-of-thorns starfish, where over 1.5 million starfish had to be removed by divers by hand," said Professor Noriyuki Satoh, senior author of the student and leader of the Marine Genomics Unit at OIST.Although outbreaks have recently become less frequent around Okinawa and other subtropical islands in the Ryukyu Archipelago, they have become an increasingly large threat to the Great Barrier Reef in Australia, along with coral bleaching and tropical cyclones. These starfish outbreaks are becoming more common and more severe, as increasingly polluted and warmer waters aid the survival of the larvae.In 2017, the OIST Marine Genomics Unit teamed up with Australian scientists to decode the genome of the crown-of-thorns starfish, with their results published in Nature. Now, in their latest study published in The researchers collected crown-of-thorns starfish from coral reefs around three different islands in the Ryukyu Archipelago -- Okinawa, Miyako and Iriomote. The scientists then sequenced the entire DNA found in the mitochondria, comprised of over 16,000 nucleotide bases, and used differences in the sequences between the individual starfish to construct an evolutionary tree.The unit also performed the same analyses on two other starfish species -- the blue starfish and the northern Pacific sea star. By comparing the crown-of-thorns starfish to these other two species, the scientists hoped to see whether their findings revealed anything unique to the crown-of-thorns starfish."The blue starfish is also a coral reef predator that lives in the same habitat as the crown-of-thorns starfish, but it doesn't produce these uncontrollable outbreaks," said Prof. Satoh. "Meanwhile, the northern Pacific sea star is the most common starfish in Japan and lives in colder waters around the Japanese mainland."The scientists found that the evolutionary tree for the northern Pacific sea star showed that the species had split into two major lineages. Starfish collected from three different locations in the seas around the north-eastern regions of Japan were composed of individuals from one lineage, whilst a single population in the Seto Inland Sea in south-west Japan was formed of individuals from a second, more recent lineage."We believe that in a rare migration event, starfish larvae dispersed to the Seto Inland Sea. As these two areas are so separated, no migration occurred afterwards between the two populations, which resulted in the species splitting into two lineages," said Prof. Satoh. "Meanwhile, shorter range ocean currents kept individuals from the first lineage mixed between the nearby locations in the north-east of Japan."For the blue starfish, the results were more surprising. The constructed evolutionary tree showed that the species had first split into two lineages, with the second lineage then diverging again into two smaller subgroups. But intriguingly, individuals from the two major lineages were found in both Okinawa and Ishigaki -- the two areas in the Ryukyus where the blue starfish was collected. This means that two distinct starfish populations are living in the same geographic regions but are not breeding and mixing their genes. Prof. Satoh believes that this is strong evidence for there being two cryptic species of blue starfish -- in other words, the starfish look the same despite being separate, non-breeding species.The results also suggest that blue starfish migration occurs in both directions between Okinawa and Ishigaki. This was unexpected as the scientists had previously assumed that the powerful northeastern current flowing from Ishigaki towards Okinawa prevented starfish larvae from being carried in the opposite direction."For migration to readily occur in both directions, this suggests that the ocean currents in the Ryukyu Archipelago may be more complex that previously imagined," said Prof. Satoh.The results from the evolutionary tree of the crown-of-thorns starfish also supported the idea of complex ocean currents in the region, with each crown-of-thorns starfish lineage also found in more than one geographic location. This has important implications for predicting where new outbreaks of crown-of-thorns starfish may occur in the Ryukyus, with the researchers now advocating for better understanding of the ocean currents in the area.Overall, the evolutionary tree for the crown-of-thorns starfish looked significantly different from the other two starfish, underlying key differences in the species' historical population dynamics. Despite being a much younger species than the other two species, diverging less than one million years ago, the tree showed that the starfish quickly fragmented into five small lineages. These findings suggest that the species underwent frequent genetic bottlenecks, where the population was reduced to just a small number of individuals, which then jumpstarted a new lineage."This implies that the starfish outbreaks are just one part of a larger 'boom and bust' population cycle, where if they are left to their natural devices, the starfish eat so much coral that they run out of food and die," said Prof. Satoh.For their next steps, the Marine Genomics Unit is collaborating with Australian scientists to analyze crown-of-thorns starfish from the Great Barrier Reef. Instead of just using DNA in the mitochondria, the scientists aim to sequence the entire genome of each starfish, including DNA in the nucleus."Ultimately, we hope our findings can help us understand the population trends of the starfish better and the role of ocean currents in seeding new outbreaks," concluded Prof. Satoh. "This could potentially help us predict and therefore mitigate future outbreaks."
Water is a key resource for the 21st century, and many lowland regions all over the world depend on water resources originating in mountain regions, not least when it comes to irrigating agricultural land. A study led by the University of Zurich has now quantified this dependence for the first time by comparing water supply and consumption in the world's lowland areas with runoff contributions from the mountains. Based on a high-resolution global model, the study provides detailed information on the dependence on mountain water resources around the globe. The comprehensive analyses were carried out using a regular grid and then compared for every river catchment area of at least 10,000 km2. This allowed for highly differentiated insights into regional characteristics and differences."Until now, research has focused mainly on river basins that originate in High Mountain Asia," says Daniel Viviroli from the Department of Geography at the University of Zurich, first author of the study. "But in many other regions, irrigated agriculture is heavily dependent on water from mountainous areas, such as in the Middle East and North Africa, as well as parts of North America, South America and Australia."This dependence has increased strongly since the 1960s -- despite more efficient water use and thus declining per-capita water consumption. Whereas only 7 percent of the lowland population used to be strongly dependent on contributions from mountain areas at that time, this figure is projected to rise to 24 percent by mid-21st century. This corresponds to about 1.5 billion people in lowland areas. Particular focus is on catchment areas such as those of the Ganges-Brahmaputra-Meghna, Yangtze and Indus rivers in Asia, the Nile and Niger in Africa, the Euphrates and Tigris in the Middle East as well as the Colorado River in North America. For their analyses, the researchers assumed a middle-of-the-road scenario in terms of population growth as well as technological, economic and social development."Ensuring the function of mountains as 'water towers' should be a major concern of the world's lowland populations," says Viviroli. Sustainable development of mountain regions is therefore essential, for example by preventing agricultural overuse and ensuring the functioning of ecosystems, the researchers say. In addition, climate action is of paramount importance: Due to the rising temperatures, meltwater peaks from snow-covered mountain regions sometimes already occur several weeks earlier and are thus not as useful for summer agriculture. Adjustments in water management will be necessary, and possibly also new infrastructure such as dams and water transfers."However, technical solutions go hand in hand with major ecological damage, and some rivers, such as the Indus, have little potential for expansion," says Viviroli. For the future, it will be crucial that lowland and mountain regions work closely together despite political, cultural, social and economic differences.
The new research projects the annual maximum wave height will get up to two to three times higher than it is now along coastlines in areas of the Arctic such as along the Beaufort Sea. The new study in AGU's In addition, extreme wave events that used to occur once every 20 years might increase to occur once every two to five years on average, according to the study. In other words, the frequency of such extreme coastal flooding might increase by a factor of 4 to 10 by the end of this century."It increases the risk of flooding and erosion. It increases drastically almost everywhere," said MercÃ¨ Casas-Prat, a research scientist with Environment and Climate Change Canada's (ECCC) Climate Research Division and the lead author of the new study. "This can have a direct impact to the communities that live close to the shoreline."Earth's northernmost regions are a global warming hotspot, with some areas experiencing up to three times the warming of the rest of the world, Casas-Prat said. But researchers lack information on how the impacts may play out.Casas-Prat and her co-author Xiaolan Wang, also with the ECCC, wanted to examine how global warming might impact extreme ocean surface waves in the Arctic. Casas-Prat said some northern communities are already reporting accelerated erosion in some areas and increased building damage due to extreme waves. A worsening of these ocean conditions will have a direct impact on coastal communities, energy infrastructure, shipping, and even ecosystems and wildlife.Much of the Arctic is frozen for most of the year, but the warming climate is contributing to increasing periods of open water, which can become an issue when extreme waves are factored into the equation.In the new study, the scientists gathered five sets of multi-model simulations of oceanic and atmospheric conditions like surface winds, which generate waves, as well as sea ice for the RCP8.5 scenario, a future scenario commonly used in climate change projections that assumes low efforts to curb emissions. Then they ran simulations of wave conditions for two periods, from 1979 to 2005 (historical), then from 2081 to 2100 (future). Using the ensemble of multi-model simulations, they were able to assess the uncertainty in the changes in the extreme Arctic waves due to the uncertainty present in the five climate models used.One of their main findings was a projected notable wave height increase between these two periods in almost every place in the Arctic.Among the hardest-hit areas was in the Greenland Sea, which lies between Greenland and the Norwegian archipelago of Svalbard. The study found maximum annual wave heights there could increase by as much as 6 meters (19.7 feet).Casas-Prat said the models present a degree of uncertainty about how much waves heights might change, but she is confident there is going to be an increase. The researchers' predictions also showed that by the end of the century, the timing of the highest waves may also change."At the end of the century, the maximum will on average come later in the year and also be more extreme," Casas-Prat said.Judah Cohen, a climatologist at the Massachusetts Institute of Technology who was not involved in Casas-Prat's research, said these waves could be particularly devastating to coastal areas that have never previously experienced open water."The main conclusions of the paper are that waves will increase in height in the Arctic region and that Arctic coastlines are at greater risk to erosion and flooding are fairly straightforward," he said. "We are already seeing these increased risks along Arctic coastlines with damage to coastline structures that previously were never damaged."The researchers examined one area of coastline along the Beaufort Sea in northern Alaska and Canada, which holds a number of communities as well as energy infrastructure, and also found notable wave height increases there.Since larger waves can lead to increased risks of flooding and damage to coastal infrastructure, communities and development in this area might be affected by these waves. Flooding can also impact the availability of fresh water in some areas, as storm and wave surges can get into freshwater lagoons that communities rely on."As more and more ice melts and more of the Arctic ocean surface becomes exposed to the wind, waves will increase in height because wave height is dependent on the distance the wind blows over open waters," Cohen said.In another recent study published in AGU's journal Geophysical Research Letters, Casas-Prat and Wang examined the contribution of sea ice retreat on the projected increases in extreme wave heights in the Arctic. They found that surface winds alone cannot explain the changes in the regional maximum wave heights."Sea ice retreat plays an important role, not just by increasing the distance over which wind can blow and generate waves but also by increasing the chance of strong winds to occur over widening ice-free waters," Casas-Prat said.Increased waves could also increase the speed of ice breakup. The loss of ice due to waves could affect animals like polar bears which hunt seals on polar ice as well as a number of other creatures that rely on ice. It could also affect shipping routes in the future."Waves definitely have to be taken into account as an important factor to ensure those routes are safe," Casas-Prat said.
The multi-institutional study led by a University of Maryland researcher revealed that churning along the edges of the Gulf Stream across areas as small as a kilometer could be a leading source of ocean mixing between the waters on either side of the current. The study was published in the "This long-standing debate about whether the Gulf Stream acts as a blender or a barrier to ocean mixing has mainly considered big ocean eddies, tens of kilometers to a hundred kilometers across," said Jacob Wenegrat, an assistant professor in UMD's Department of Atmospheric and Oceanic Science and the lead author of the study. "What we're adding to this debate is this new evidence that variability at the kilometer scale seems to be doing a lot of mixing. And those scales are really hard to monitor and model."As the Gulf Stream courses its way up the east coast of the U.S. and Canada, it brings warm salty water from the tropics into the north Atlantic. But the current also creates an invisible wall of water that divides two distinct ocean regions: the colder, fresher waters along the northern edge of the Gulf Stream that swirl in a counterclockwise direction, and the warmer, saltier waters on the southern edge of the current that circulate in a clockwise direction.How much ocean mixing occurs across the Gulf Stream has been a matter of scientific debate. As a result, ocean models that predict climate, weather and biological productivity have not fully accounted for the contribution of mixing between the two very different types of water on either side of the current.To conduct the study, the researchers had to take their instruments to the source: the edge of the Gulf Stream. Two teams of scientists aboard two global-class research vessels braved winter storms on the Atlantic Ocean to release a fluorescent dye along the northern front of the Gulf Stream and trace its path over the following days.The first team released the dye along with a float containing an acoustic beacon. Downstream, the second team tracked the float and monitored the concentration of dye along with water temperature, salinity, chemistry and other features.Back on shore, Wenegrat and his coauthors developed high-resolution simulations of the physical processes that could cause the dye to disperse through the water in the manner the field teams recorded. Their results showed that turbulence across areas as small as a kilometer exerted an important influence on the dye's path and resulted in significant mixing of water properties such as salinity and temperature."These results emphasize the role of variability at very small scales that are currently hard to observe using standard methods, such as satellite observations," Wenegrat said. "Variability at this scale is not currently resolved in global climate models and won't be for decades to come, so it leads us to wonder, what have we been missing?"By showing that small-scale mixing across the Gulf Stream may have a significant impact, the new study reveals an important, under-recognized contributor to ocean circulation, biology and potentially climate.For example, the Gulf Stream plays an important role in what's known as the ocean biological pump -- a system that traps excess carbon dioxide, buffering the planet from global warming. In the surface waters of the Gulf Stream region, ocean mixing influences the growth of phytoplankton -- the base of the ocean food web. These phytoplankton absorb carbon dioxide near the surface and later sink to the bottom, taking carbon with them and trapping it in the deep ocean. Current models of the ocean biological pump don't account for the large effect small-scale mixing across the Gulf Stream could have on phytoplankton growth."To make progress on this we need to find ways to quantify these processes on a finer scale using theory, state-of-the-art numerical models and new observational techniques," Wenegrat said. "We need to be able to understand their impact on large-scale circulation and biogeochemistry of the ocean."
Their study gives new insight into the swirling flow of iron 2800 kilometres below the planet's surface and how it has influenced the movement of the magnetic field during the past hundred thousand years.Our magnetic field is generated and maintained by a convective flow of molten metal that forms the Earth's outer core. Motion of the liquid iron creates the electric currents that power the field, which not only helps guide navigational systems but also helps shield us from harmful extra terrestrial radiation and hold our atmosphere in place.The magnetic field is constantly changing. Satellites now provide new means to measure and track its current shifts but the field existed long before the invention of human-made recording devices. To capture the evolution of the field back through geological time scientists analyse the magnetic fields recorded by sediments, lava flows and human-made artefacts. Accurately tracking the signal from Earth's core field is extremely challenging and so the rates of field change estimated by these types of analysis are still debated.Now, Dr Chris Davies, associate professor at Leeds and Professor Catherine Constable from the Scripps Institution of Oceanography, UC San Diego, in California have taken a different approach. They combined computer simulations of the field generation process with a recently published reconstruction of time variations in Earth's magnetic field spanning the last 100,000 yearsTheir study, published in They demonstrate that these rapid changes are associated with local weakening of the magnetic field. This means these changes have generally occurred around times when the field has reversed polarity or during geomagnetic excursions when the dipole axis -- corresponding to field lines that emerge from one magnetic pole and converge at the other -- moves far from the locations of the North and South geographic poles.The clearest example of this in their study is a sharp change in the geomagnetic field direction of roughly 2.5 degrees per year 39,000 years ago. This shift was associated with a locally weak field strength, in a confined spatial region just off the west coast of Central America, and followed the global Laschamp excursion -- a short reversal of the Earth's magnetic field roughly 41,000 years ago.Similar events are identified in computer simulations of the field which can reveal many more details of their physical origin than the limited paleomagnetic reconstruction.Their detailed analysis indicates that the fastest directional changes are associated with movement of reversed flux patches across the surface of the liquid core. These patches are more prevalent at lower latitudes, suggesting that future searches for rapid changes in direction should focus on these areas.Dr Davies, from the School of Earth and Environment, said: "We have very incomplete knowledge of our magnetic field prior to 400 years ago. Since these rapid changes represent some of the more extreme behaviour of the liquid core they could give important information about the behaviour of Earth's deep interior."Professor Constable said: "Understanding whether computer simulations of the magnetic field accurately reflect the physical behaviour of the geomagnetic field as inferred from geological records can be very challenging."But in this case we have been able to show excellent agreement in both the rates of change and general location of the most extreme events across a range of computer simulations. Further study of the evolving dynamics in these simulations offers a useful strategy for documenting how such rapid changes occur and whether they are also found during times of stable magnetic polarity like what we are experiencing today."
At first glance, it looks like a group of people with dirty shoes had left tracks all over the snow. But in reality, they are sediments, and even small pebbles and bivalves, which the on-going melting process has brought to light on the surface of the MOSAiC floe. When the sea ice formed, they were frozen inside; accordingly, they hail from the nursery of sea ice along the Siberian Shelf, which the experts have now used a combination of model simulations and satellite data to describe in detail.The MOSAiC floe had already drifted over 1200 nautical miles in a meandering course when the research icebreaker Polarstern moored to it on 4 October 2019, at the coordinates 85Â° North and 137Â° East, and began to drift with it through the Arctic Ocean. While the current expedition team is busy taking readings in the Arctic, their colleagues back at home are analysing the data gathered. The precise analysis confirms the first impressions from the beginning of the expedition: "Our assessment shows that the entire region in which the two ships looked for suitable floes was characterised by unusually thin ice," reports Dr Thomas Krumpen, a sea-ice physicist at the Alfred Wegener Institute, Helmholtz Centre for Polar and Marine Research (AWI). Last autumn, the first author of "Our study shows that the floe we ultimately chose was formed in the shallow waters of the Russian shelf seas in December 2018," Krumpen explains. Off the coast of Siberia, strong offshore winds drive the young ice out to sea after it forms. In the shallow water, sediments are churned up from the seafloor and become trapped in the ice. Ice formation can also produce pressure ridges, the undersides of which sometimes scrape along the seafloor. As a result, stones can also become embedded in the sea ice. Now that the summertime melting has begun, all of this material is being revealed at the ice's surface: "At several points we've found entire mounds of pebbles measuring several centimetres in diameter, plus a number of bivalves," reports MOSAiC expedition leader Prof Markus Rex directly from the Arctic.Meanwhile, back home in Bremerhaven, Germany, Thomas Krumpen is thrilled to see that the now emerging 'bivalve ice with pebbles', as he has affectionately dubbed it, so clearly confirms the study's findings. The team of authors led by the AWI expert used a combination of satellite imagery, reanalysis data and a newly developed coupled thermodynamics backtracking model to reconstruct the floe's origins. Now Krumpen and his colleagues are devising a strategy for gathering samples of the sediments. The extent to which these 'dirty' and therefore darker patches accelerate melting on the floe is an important question, and answering it could enhance our understanding of the interactions between the ocean, ice and atmosphere, of biogeochemical cycles, and of life in the Arctic in general.In addition to mineral components, the sea ice also transports a range of other biogeochemical substances and gases from the coast to the central Arctic Ocean. They are an important aspect of MOSAiC research on biogeochemical cycles, i.e., on the formation or release of methane and other climate-relevant trace gases throughout the year. However, as a result of the substantial loss of sea ice observed in the Arctic over the past several years, precisely this ice, which comes from the shallow shelves and contains sediments and gases, is now melting more intensively in the summer, causing this material transport flow to break down. In the 1990s, the Polarstern was often in the same waters where the MOSAiC expedition began its drift. Back then the ice was still ca. 1.6 metres thick at the beginning of winter, whereas it had shrunk to ca. 50 centimetres last year -- which made the search for a sufficiently thick floe in the autumn of 2019 all the more difficult."We were fortunate enough to find a floe that had survived the summer and formed in the Russian shelf seas. This allows us to investigate transport processes from the 'old Arctic', which now only partly function, if at all," says Krumpen. Particularly in the higher latitudes, global warming is causing temperatures to climb rapidly: in the summer of 2019, the last summer before the expedition, Russian meteorological stations reported record temperatures. These high temperatures sparked rapid melting and significantly warmed Russia's marginal seas. As a result, many parts of the Northeast Passage were ice-free for a 93-day period (the longest duration since the beginning of satellite observation). The experts predict that if CO2 emissions remain unchecked -- as they have in the past several years -the Central Arctic could be ice-free in summer by 2030.
The research published in In Australia's worst heatwave season, an additional 80Â°C of cumulative heat was experienced across the country. In Russia and the Mediterranean, their most extreme seasons baked in an additional 200Â°C or more."Not only have we seen more and longer heatwaves worldwide over the past 70 years, but this trend has markedly accelerated," said lead author Dr Sarah Perkins Kirkpatrick from the ARC Centre of Excellence for Climate Extremes."Cumulative heat shows a similar acceleration, increasing globally on average by 1Â°C-4.5Â°C each decade but in some places, like the Middle East, and parts of Africa and South America, the trend is up to 10Â°C a decade."The only heatwave metric that hasn't seen an acceleration is heatwave intensity, which measures the average temperature across heatwaves. This is because globally we see more heatwave days and heatwaves are lasting longer. When the average temperature is measured across longer heatwaves any shifts in intensity are almost undetectable. Only southern Australia and small areas of Africa and South America show a detectable increase in average heatwave intensity.The study also identified that natural variability impacts on heatwaves can be large at regional levels. This variability can overwhelm heatwave trends, so regional trends shorter than a few decades are generally not reliable. To detect robust trend changes, the researchers looked at how the trends had changed over multi-decade intervals between 1950-2017. The changes were stark.For example, the Mediterranean, saw a dramatic uptick in heatwaves when measured over multi-decade spans. From 1950-2017, the Mediterranean saw an increase in heatwaves by two days a decade. But the trend from 1980 to 2017 had seen that accelerate to 6.4 days a decade.The regional approach also showed how the trends vary. Regions like the Amazon, north-east Brazil, west Asia and the Mediterranean are experiencing rapid changes in heatwaves while areas like South Australia and North Asia are still seeing changes but at a slower rate.However, no matter whether these changes are rapid or slow, it seems inevitable that vulnerable nations with less infrastructure will be hit hardest by extreme heat. "Climate scientists have long forecast that a clear sign of global warming would be seen with a change in heatwaves," said Dr Perkins Kirkpatrick."The dramatic region-by-region change in heatwaves we have witnessed over the past 70 years and the rapid increase in the number of these events, are unequivocal indicators that global warming is now with us and accelerating."This research is just the latest piece of evidence that should act as a clarion call to policymakers that urgent action is needed now if we are to prevent the worst outcomes of global warming. The time for inaction is over."
In a new meta-study, experts from the Alfred Wegener Institute, Helmholtz Centre for Polar and Marine Research (AWI) have published ground-breaking findings on the effects of climate change for fish stock around the globe. As they report, the risks for fish are much higher than previously assumed, especially given the fact that in certain developmental stages they are especially sensitive to rising water temperatures. One critical bottleneck in the lifecycle of fish is their low tolerance for heat during mating. In other words, the water temperature in their spawning areas determines to a great extent how successfully they reproduce, making fish particularly vulnerable to the impacts of climate change -- not only in the ocean, but also in lakes, ponds and rivers. According to the researchers' analyses, if left unchecked, climate change and rising water temperatures will negatively affect the reproduction of up to 60 percent of all fish species. Their study was released today in the latest issue of the journal Organisms have to breathe in order for their bodies to produce energy; this is equally true for human beings and for fish. In addition, we know that the energy needs of humans and animals alike depend on the temperature: when it's warmer, the need for energy rises exponentially, and with it, the need for oxygen. On this basis, it follows that organisms can only adapt to rising temperatures in their immediate vicinity by providing their bodies with more oxygen. But there are certain species-specific limits on this ability; if those limits are exceeded, it can lead to cardiovascular collapse.Armed with this knowledge, in a new meta-study, experts from the Alfred Wegener Institute, Helmholtz Centre for Polar and Marine Research (AWI) have investigated in which life phases saltwater and freshwater fish around the world are most sensitive to heat. To do so, the biologists compiled scientific data on the temperature tolerance of 694 fish species and analysed the temperature ranges within which fish can survive as adults ready to mate, as embryos in eggs, as larvae, and as adults outside the mating season."Our findings show that, both as embryos in eggs and as adults ready to mate, fish are far more sensitive to heat than in their larval stage or sexually mature adults outside the mating season," says first author and AWI marine biologist Dr Flemming Dahlke. "On the global average, for example, adults outside the mating season can survive in water that's up to 10 degrees Celsius warmer than adults ready to mate or fish eggs can."The reason for this variable temperature tolerance lies in the anatomy of fish: fish embryos have no gills that would allow them to take in more oxygen. In contrast, fish that are ready to mate produce egg and sperm cells; this additional body mass also needs to be supplied with oxygen, which is why, even at lower temperatures, their cardiovascular systems are under enormous strain.These findings apply to all fish species, and make it clear why fish are sensitive to heat, especially during the mating season and in their embryonic stage. Accordingly, in a second step the team of researchers analysed to what extent water temperatures in the spawning areas of the species investigated would likely rise due to climate change. For this purpose, they employed new climate scenarios (Shared Socioeconomic Pathways -- SSPs), which will also be used in the IPCC's next Assessment Report.Their conclusions confirm that every degree Celsius of warming spells more trouble for the world's fish stocks. "If we human beings can successfully limit climate warming to 1.5 degrees Celsius by the year 2100, only ten percent of the fish species we investigated will be forced to leave their traditional spawning areas due to rising temperatures," explains AWI biologist and co-author Prof Hans-Otto PÃ¶rtner. In contrast, if greenhouse-gas emissions remain at a high or very high level (SSP 5 -- 8.5), it's likely to produce average warming of 5 degrees Celsius or more, which would endanger up to 60 percent of all fish species.Those species affected would then be forced to either adapt through biological evolution -- a process that would most likely take far too long -- or to mate at another time of year or in some other place. "Some species might successfully manage this change," says Flemming Dahlke. "But if you consider the fact that fish have adapted their mating patterns to specific habitats over extremely long timeframes, and have tailored their mating cycles to specific ocean currents and available food sources, it has to be assumed that being forced to abandon their normal spawning areas will mean major problems for them." In addition, fish living in rivers and lakes have the problem that their habitat is limited by the size and geographic location of the waters they live in: migrating to deeper waters or to cooler regions is nearly impossible."Our detailed analyses, which cover all of the fishes' developmental stages, will help us to understand how these species are being affected by climate change, and to what extent the loss of suitable habitats is being driven by the climate-related transformation of ecosystems," says Hans-Otto PÃ¶rtner.Wherever fish migrate or their reproduction rates decline, there will be new interactions between species, and in some cases the ecosystems will experience a drop in productivity. The IPCC published corresponding projections on the future of worldwide fish stocks in its Special Report on the Ocean and Cryosphere in a Changing Climate. According to PÃ¶rtner: "Our new detailed assessments will help to improve those projections."
Now, in a new study, scientists have discovered previously unrecognized structural lines 100 miles or more down in the earth that appear to signal the locations of giant deposits of copper, lead, zinc and other vital metals lying close enough to the surface to be mined, but too far down to be found using current exploration methods. The discovery could greatly narrow down search areas, and reduce the footprint of future mines, the authors say. The study appears this week in the journal "We can't get away from these metals-they're in everything, and we're not going to recycle everything that was ever made," said lead author Mark Hoggard, a postdoctoral researcher at Harvard University and Columbia University's Lamont-Doherty Earth Observatory. "There's a real need for alternative sources."The study found that 85 percent of all known base-metal deposits hosted in sediments-and 100 percent of all "giant" deposits (those holding more than 10 million tons of metal)-lie above deeply buried lines girdling the planet that mark the edges of ancient continents. Specifically, the deposits lie along boundaries where the earth's lithosphere-the rigid outermost cladding of the planet, comprising the crust and upper mantle-thins out to about 170 kilometers below the surface.Up to now, all such deposits have been found pretty much at the surface, and their locations have seemed to be somewhat random. Most discoveries have been made basically by geologists combing the ground and whacking at rocks with hammers. Geophysical exploration methods using gravity and other parameters to find buried ore bodies have entered in recent decades, but the results have been underwhelming. The new study presents geologists with a new, high-tech treasure map telling them where to look.Due to the demands of modern technology and the growth of populations and economies, the need for base metals in the next 25 years is projected to outpace all the base metals so far mined in human history. Copper is used in basically all electronics wiring, from cell phones to generators; lead for photovoltaic cells, high-voltage cables, batteries and super capacitors; and zinc for batteries, as well as fertilizers in regions where it is a limiting factor in soils, including much of China and India. Many base-metal mines also yield rarer needed elements, including cobalt, iridium and molybdenum. One recent study suggests that in order to develop a sustainable global economy, between 2015 and 2050 electric passenger vehicles must increase from 1.2 million to 1 billion; battery capacity from 0.5 gigawatt hours to 12,000; and photovoltaic capacity from 223 gigawatts to more than 7,000.The new study started in 2016 in Australia, where much of the world's lead, zinc and copper is mined. The government funded work to see whether mines in the northern part of the continent had anything in common. It built on the fact that in recent years, scientists around the world have been using seismic waves to map the highly variable depth of the lithosphere, which ranges down to 300 kilometers in the nuclei of the most ancient, undisturbed continental masses, and tapers to near zero under the younger rocks of the ocean floors. As continents have shifted, collided and rifted over many eons, their subsurfaces have developed scar-like lithospheric irregularities, many of which have now been mapped.The study's authors found that the richest Australian mines lay neatly along the line where thick, old lithosphere grades out to 170 kilometers as it approaches the coast. They then expanded their investigation to some 2,100 sediment-hosted mines across the world, and found an identical pattern. Some of the 170-kilometer boundaries lie near current coastlines, but many are nestled deep within the continents, having formed at various points in the distant past when the continents had different shapes. Some are up to 2 billion years old.The scientists' map shows such zones looping through all the continents, including areas in western Canada; the coasts of Australia, Greenland and Antarctica; the western, southeastern and Great Lakes regions of the United States; and much of the Amazon, northwest and southern Africa, northern India and central Asia. While some of the identified areas already host enormous mines, others are complete blanks on the mining map.The authors believe that the metal deposits formed when thick continental rocks stretched out and sagged to form a depression, like a wad of gum pulled apart. This thinned the lithosphere and allowed seawater to flood in. Over long periods, these watery low spots got filled in with metal-bearing sediments from adjoining, higher-elevation rocks. Salty water then circulated downward until reaching depths where chemical and temperature conditions were just right for metals picked up by the water in deep parts of the basin to precipitate out to form giant deposits, anywhere from 100 meters to 10 kilometers below the then-surface. The key ingredient was the depth of the lithosphere. Where it is thickest, little heat from the hot lower mantle rises to potential near-surface ore-forming zones, and where it is thinnest, a lot of heat gets through. The 170-kilometer boundary seems to be Goldilocks zone for creating just the right temperature conditions, as long as the right chemistry also is present."It really just hits the sweet spot," said Hoggard. "These deposits contain lots of metal bound up in high-grade ores, so once you find something like this, you only have to dig one hole." Most current base-metal mines are sprawling, destructive open-pit operations. But in many cases, deposits starting as far down as a kilometer could probably be mined economically, and these would "almost certainly be taken out via much less disruptive shafts," said Hoggard.The study promises to open exploration in so far poorly explored areas, including parts of Australia, central Asia and western Africa. Based on a preliminary report of the new study that the authors presented at an academic conference last year, a few companies appear to have already claimed ground in Australia and North America. But the mining industry is notoriously secretive, so it is not clear yet how widespread such activity might be."This is a truly profound finding and is the first time anyone has suggested that mineral deposits formed in sedimentary basins ... at depths of only kilometers in the crust were being controlled by forces at depths of hundreds of kilometers at the base of the lithosphere," said a report in Mining Journal reviewing the preliminary presentation last year.The study's other authors are Karol Czarnota of Geoscience Australia, who led the initial Australian mapping project; Fred Richards of Harvard University and Imperial College London; David Huston of Geoscience Australia; and A. Lynton Jaques and Sia Ghelichkhan of Australian National University.Hoggard has put the study into a global context on his website: 
Fogt, professor of meteorology and director of the Scalia Laboratory for Atmospheric Analysis, and Clem coauthored a paper with an international team of scientists published in the journal Clem, a current postdoctoral research fellow in climate science at Victoria University of Wellington in New Zealand, is the lead author of the study and studied under Fogt for both his bachelor's and master's degrees at Ohio University."I've had a passion for understanding the weather and fascination of its power and unpredictability as far back as I can remember," Clem said. "Working with Ryan I learned all about Antarctic and Southern Hemisphere climate, specifically how West Antarctica was warming and its ice sheet was thinning and contributing to global sea level rise. I also learned that Antarctica experiences some of the most extreme weather and variability on the planet, and due to its remote location we actually know very little about the continent, so there are constant surprises and new things to learn about Antarctica every year."The Antarctic climate exhibits some of the largest ranges in temperature during the course of the year, and some of the largest temperature trends on the planet, with strong regional contrasts. Most of West Antarctica and the Antarctic Peninsula experienced warming and ice-sheet thinning during the late 20th century. By contrast, the South Pole -- located in the remote and high-altitude continental interior -- cooled until the 1980s and has since warmed substantially. These trends are affected by natural and anthropogenic climate change, but the individual contribution of each factor is not well understood.Clem and his team analyzed weather station data at the South Pole, as well as climate models to examine the warming in the Antarctic interior. They found that between 1989 and 2018, the South Pole had warmed by about 1.8 degrees Celsius over the past 30 years at a rate of +0.6 degrees Celcius per decade -- three times the global average.The study also found that the strong warming over the Antarctic interior in the last 30 years was mainly driven by the tropics, especially warm ocean temperatures in the western tropical Pacific Ocean that changed the winds in the South Atlantic near Antarctica and increased the delivery of warm air to the South Pole. They suggest these atmospheric changes along Antarctica's coast are an important mechanism driving climate anomalies in its interior.Clem and Fogt argue that these warming trends were unlikely the result of natural climate change alone, emphasizing the effects of added anthropogenic warming on top of the large tropical climate signal on Antarctic climate have worked in tandem to make this one of the strongest warming trends worldwide."From the very beginning, Kyle and I worked very well together and were able to accomplish more as a team than we were individually," Fogt said. "We have published every year together since 2013, with one of our continuing collaborations being the annual State of the Climate reports. Our work on this project together each year ultimately led to this publication documenting the warming at the South Pole, however, most importantly for me, apart from being a fantastic scientist and collaborator, my family and I are both honored to consider Kyle one of our closest friends."
While European countries have developed world-leading waste management infrastructure, 46% of European separated plastic waste is exported outside the country of origin. A large share of this plastic is transported thousands of kilometres to countries with poor waste management practices, largely located in Southeast Asia. Once in these countries, a large share of the waste is rejected from recycling streams into overstretched local waste management systems that have been found to contribute significantly to ocean littering.This new research, published in the scientific journal Speaking today, George Bishop, lead author of the study said: "The results indicate an important and previously undocumented pathway of plastic debris entering the oceans, which will have considerable environmental and social impacts on marine ecosystems and coastal communities."Using detailed international trade data and data on waste management in destination countries, the study modelled the fate of all polyethylene exported for recycling from Europe, accounting for different fates ranging from successful conversion into recycled resins, or ending up as landfill, incineration, or ocean debris.Dr David Styles, a lecturer at the University of Limerick and co-author, explains, "Given that such a large share of waste destined for recycling is exported, with poor downstream traceability, this study suggests that 'true' recycling rates may deviate significantly from rates reported by municipalities and countries where the waste originates. In fact, our study found that up to 31% of the exported plastic wasn't actually recycled at all."The study was part of the Science Foundation Ireland funded, 'Innovative Energy Technologies for Bioenergy, Biofuels and a Sustainable Irish Bioeconomy: IETSBIO3' led by Professor Piet Lens, Established Professor of New Energy Technologies at the National University of Ireland, Galway.Professor Lens added: "To successfully move towards a more circular economy, European municipalities and waste management companies need to be held accountable for the final fate of "recycled" waste. Our study highlights the lack of available data on plastic waste and the need to consider extended audit trails, or "on-shoring" of recycling activities as part of emerging regulations around trade in plastic waste."The authors caution that these findings should not discourage people to recycle as it remains the best waste management treatment, environmentally speaking. However, there is considerable work to be done to improve aspects of these plastic recycling chains, to reduce the 'leakage' of these systems.
Four researchers of Northern Arizona University's School of Earth and Sustainability (SES) led the study, with Regents' professor Darrell Kaufman as lead author and associate professor Nicholas McKay as co-author, along with assistant research professors Cody Routson and Michael Erb. The team worked in collaboration with scientists from research institutions all over the world to reconstruct the global average temperature over the Holocene Epoch -- the period following the Ice Age and beginning about 12,000 years ago."Before global warming, there was global cooling," said Kaufman. "Previous work has shown convincingly that the world naturally and slowly cooled for at least 1,000 years prior to the middle of the 19th century, when the global average temperature reversed course along with the build-up of greenhouse gases. This study, based on a major new compilation of previously published paleoclimate data, combined with new statistical analyses, shows more confidently than ever that the millennial-scale global cooling began approximately 6,500 years ago."Earlier this year, an international group of 93 paleoclimate scientists from 23 countries -- also led by Kaufman, McKay, Routson and Erb -- published the most comprehensive set of paleoclimate data ever compiled for the past 12,000 years, compressing 1,319 data records based on samples taken from 679 sites globally. At each site, researchers analyzed ecological, geochemical and biophysical evidence from both marine and terrestrial archives, such as lake deposits, marine sediments, peat and glacier ice, to infer past temperature changes. Countless scientists working around the world over many decades conducted the basic research contributing to the global database."The rate of cooling that followed the peak warmth was subtle, only around 0.1Â°C per 1,000 years. This cooling seems to be driven by slow cycles in the Earth's orbit, which reduced the amount of summer sunlight in the Northern Hemisphere, culminating in the 'Little Ice Age' of recent centuries," said Erb, who analyzed the temperature reconstructions.Since the mid-19th century, global warming has climbed to about 1Â°C, suggesting that the global average temperature of the last decade (2010-2019) was warmer than anytime during the present post-glacial period.McKay, who developed some of the statistical approaches to synthesizing data from around the world, notes that individual decades are not resolved in the 12,000-year-long temperature reconstruction, making it difficult to compare it with any recent decade. "On the other hand, this past decade was likely cooler than what the average temperatures will be for the rest of this century and beyond, which are very likely to continue to exceed 1Â°C above pre-industrial temperatures," McKay said."It's possible," Kaufman said, "that the last time the sustained average global temperature was 1Â°C above the 19th century was prior to the last Ice Age, back around 125,000 years ago when sea level was around 20 feet higher than today.""Investigating the patterns of natural temperature changes over space and time helps us understand and quantify the processes that cause climate to change, which is important as we prepare for the full range of future climate changes due to both human and natural causes," said Routson. He used an earlier version of the database to link Arctic warming to a reduction in precipitation at mid latitudes (see related article)."Our future climate will largely depend on the influence of human factors, especially the build-up of greenhouse gases. However, future climate will also be influenced by natural factors, and it will be complicated by the natural variability within the climate system. Future projections of climate change will be improved by better accounting for both anthropogenic and natural factors," he said.The reconstruction of past global temperature is the outgrowth of several NAU research projects aimed at understanding the causes and effects of natural climate variability, work that was funded through more than $1.2 million in grants from the National Science Foundation. The team was recently awarded another $678,000 in grants from the NSF for related work extending through 2023.
Describing the likely dispersal corridor for the ancestral lineage of the bee genus Homalictus will help understand the social evolution of the vibrant halictine bees, South Australian, Czech and PNG researchers say in a new paper.It follows earlier research connecting the origin of other Australian bees to the polar south or Antarctica routes millions of years ago -- helping to explain the diversity and complexity of natural ecosystems and their resilience or susceptibility during periods of climate change.Ecologists are hopeful that the diverse origins of native bees are giving them an edge in withstanding and adapting further to climate change."Homalictus bees are a leading generalist plant pollinator across Australia and as far north as southern China," says Flinders University PhD candidate, photographer and native bee expert James Dorey."Our study highlights the importance of the habitat and ecology of tropical regions, including Papua New Guinea and the Fijian islands, for our endemic species and shows us how these bees might have expanded across the Pacific and possibly higher latitudes of Southeast Asia."SA Museum senior researcher Associate Professor Mark Stevens says the ongoing research aims to better understand the origin and radiation of insects and other animals, help environmental management during changing climates and mitigate the effects of further human expansion and habitat destruction."Many species historically evolved under difference climatic conditions and those different histories may determine how they will cope with new climates," he says."As climates change, species that have narrow thermal tolerances that are unable to adapt either track their preferred climate by moving, or become extinct. We see this in our studies on tropical bees and also in the studies of Antarctic biodiversity.""What has not been fully appreciated is the movement of bees in the southern hemisphere that included Antarctica as a likely dispersal corridor before it became the glacial continent that it is today."Antarctica was the crossroads between South America, Africa and Australia as the supercontinent of Gondwana was breaking up. The last landmass connections between Australia and Antarctica finished about 35 million years ago while the interchange with Asia began about 20 million years ago.In contrast to the colourful tropical varieties, SA researchers have previously explored the origins of the cooler adapted and less colourful Exoneurine allodapine bees, believed to have originated in Africa but dispersed to Australia about 42-34 million years ago from Antarctica when there was still a land bridge connection to Tasmania.Co-author on the online Homalictus paper, Associate Professor Mike Schwarz says Australia has the most unusual bee fauna in the world, resulting from three major events -- the gradual breakup of Gondwana, then a period when the bees evolved in "splendid isolation," long before humans arrived."Thirdly, there was a northern influx of species from tropical Asia as the Australian continent collided with Asia. "Australia's complex systems diversity if a key ingredient for survival of our species," Flinders Associate Professor Schwarz says."Hopefully, the diversity of our native bees will make them more resilient to future climate scenarios, which will be critical for agriculture in a changing world.
When it comes to completely transforming a landscape, beavers are hard to beat. Very few other animals are capable of changing their habitat as precisely as these brown-furred rodents, which can weigh up to 30 kilograms. Armed with sharp teeth, they fell trees and shrubs and build dams, causing small valleys to fill with water and forming new lakes, which can easily measure a few hectares. "Their methods are extremely effective," says Dr Ingmar Nitze from the Alfred Wegener Institute, Helmholtz Centre for Polar and Marine Research (AWI) in Potsdam/Germany. They often build their dams at precisely those points where they can achieve major effects with minimal effort.This is something that Ingmar Nitze has repeatedly seen in the Arctic regions of Alaska, where the North American beaver is active. The researcher is an expert on remote sensing, and is especially interested in those parts of the Earth where the soil is permanently frozen. Climate researchers fear that, as temperatures rise, this permafrost could increasingly thaw and become unstable. If that happens, it could release massive quantities of greenhouse gases, which would intensify climate change.Accordingly, Nitze and his colleagues are monitoring the development of these landscapes with the aid of satellite images. One interesting aspect in this regard: how the lakes and other bodies of water are distributed. Because the water they contain is somewhat warmer than the surrounding soil, these lakes and ponds can further accelerate permafrost thawing. And beavers would seem to be actively contributing to the process.Back in 2018, Ingmar Nitze and Guido Grosse from the AWI, together with colleagues from the USA, determined that the beavers living in an 18,000-square-kilometre section of northwest Alaska had created 56 new lakes in just five years. For their new study, the team from the AWI, the University of Alaska in Fairbanks, and the University of Minnesota in Minneapolis have now taken a closer look at this trend. Using detailed satellite data and extended time series, the experts tracked the beavers' activities in two other regions in Alaska -- and were surprised by what they found."Of course, we knew that the beavers there had spread substantially over the last few decades," says Nitze. This is partly due to climate change; thanks to rising temperatures, now more and more habitats offer the shrubs that the animals need for food and building material. Furthermore, the lakes, which used to freeze solid, now offer beaver-friendlier conditions, thanks to their thinner seasonal winter ice cover. Lastly, the rodents aren't hunted as intensively as in the past. As a result, it's a good time to be a beaver in the Arctic."But we never would have dreamed they would seize the opportunity so intensively," says Nitze. The high-resolution satellite images of the roughly 100-square-kilometre study area near the town of Kotzebue reveal the scale of the animals' activities there. From just two dams in 2002, the number had risen to 98 by 2019 -- a 5,000-percent increase, with more than 5 new dams being constructed per year. And the larger area surveyed, which covers the entire northern Baldwin Peninsula, also experienced a beaver dam boom. According to Nitze, "We're seeing exponential growth there. The number of these structures doubles roughly every four years."This has already affected the water balance. Apparently, the rodents intentionally do their work in those parts of the landscape that they can most easily flood. To do so, sometimes they dam up small streams, and sometimes the outlets of existing lakes, which expand as a result. "But they especially prefer drained lake basins," Benjamin Jones, lead author of the study, and Nitze report. In many cases, the bottoms of these former lakes are prime locations for beaver activity. "The animals have intuitively found that damming the outlet drainage channels at the sites of former lakes is an efficient way to create habitat. So a new lake is formed which degrades ice-rich permafrost in the basin, adding to the effect of increasing the depth of the engineered waterbody," added Jones. These actions have their consequences: in the course of the 17-year timeframe studied, the overall water area in the Kotzebue region grew by 8.3 percent. And roughly two-thirds of that growth was due to the beavers.The researchers suspect that there have been similar construction booms in other regions of the Arctic; accordingly, they now want to expand their 'beaver manhunt' across the Arctic. "The growth in Canada, for example, is most likely even more extreme," says Nitze. And each additional lake thaws the permafrost below it and on its banks. Granted, the frozen soil could theoretically bounce back after a few years, when the beaver dams break; but whether or not the conditions will be sufficiently cold for that to happen is anyone's guess. For Ingmar Nitze, all of these aspects mean there are plenty of reasons to keep an eye on these four-legged landscape engineers: "Anyone who wants to predict the future of the permafrost should be sure to keep the beaver in mind."
Multiple regions around the world plan energy production, agricultural practices and other essential economic endeavors based on the annual arrival of monsoons, which entails a seasonal shift in the direction of winds that provides periods of steady rainfall. However, unchecked greenhouse gas emissions could disrupt these traditionally predictable events.Using RegCM4, the latest version of a popular regional climate model developed by the International Centre for Theoretical Physics in Italy, the team ran a series of simulations to project and evaluate changes in nine monsoon regions across five continents. The researchers designed the simulations with a tight grid of each region containing spacing of less than 16 miles, which provided a substantial level of detail.The team, part of a global effort called the Coordinated Regional Downscaling Experiment, or CORDEX, published its findings in "This is the first time that a regional climate model has been used to provide a global view of changes in monsoons," said lead author Moetasim Ashfaq, a climate computational scientist at ORNL. "It took a great deal of time and effort to compile and analyze such high-profile, high-resolution data, and these detailed simulations would not have been possible without a significant international collaboration."ORNL researchers simulated the South Asian monsoon region using resources of the laboratory's Compute and Data Environment for Science and the compute cluster Eos, and the rest of the simulations were conducted at various other computing centers. The team uncovered commonalities in regional monsoon responses to increases in greenhouse gas emissions. These responses included monsoon onset delays, shorter monsoon seasons and more intense seasonal fluctuation.The simulations predicted and compared changes that would occur in different scenarios provided by the Intergovernmental Panel on Climate Change, or IPCC, known as Representation Concentration Pathway, or RCP8.5 and RCP2.6.RCP8.5 assumes that carbon emissions follow a "business as usual" scenario without policy interventions, whereas RCP2.6 is based on much lower increases in emissions with aggressive mitigation policies. Although the monsoon patterns will likely change for both RCPs, the simulations revealed that the amount of change would likely be minimal under RCP2.6 but could be significant under RCP8.5."If emissions are reduced based on RCP2.6 out to the year 2100, the simulations show that the long, damaging shifts in monsoon behaviors can mostly be avoided," Ashfaq said. "If you look at the best-case scenario, we do still see changes, but they are insignificantly different from the typical year-to-year variation in regional monsoons that communities are already accustomed to."Seven of the nine monsoon regions showed a gradual delay in monsoon onset with a continuous increase in global emissions, which could create wide-ranging consequences that directly affect approximately two-thirds of the world's population by the end of this century. Unlike the areas that receive relatively even amounts of precipitation in all seasons, heavily populated monsoon regions receive 60% to 70% of their precipitation during the summer monsoon season."The RCP8.5 simulations reveal robust delays in the start of rainy seasons that ripple through many aspects of everyday life in these regions," Ashfaq said. "For example, a monsoon that usually starts in the first week of June in South Asia and West Africa may be delayed as long as 15 (days) to 20 days or even an entire month over parts of these regions by the end of the 21st century."Although the simulations also showed a delay in the end of the rainy season, otherwise known as monsoon demise, this shift was not nearly as dramatic as the delay in monsoon onset, shortening the length of the entire monsoon season. The researchers also discovered that affected monsoon regions are likely to see more precipitation during that period, leading to more intense rains. Conversely, the rest of the year would see longer dry periods.This increased seasonality could exacerbate the prevalence of floods, droughts, wildfires and other extreme climate events that already pose challenges to these regions. Significant changes in monsoon behavior could contribute to outbreaks of vector-borne diseases, such as cholera, dengue and malaria.Since agricultural activities in monsoon regions are typically timed to coincide with the periodic onset and demise of the rainy season, these factors could alter the production of rain-dependent crop yields."More than half of the world's arabica coffee supply is produced in Brazil, and more than 70% of the cacao used to make chocolate comes from West Africa, whereas more than one-third of rice exports come from India and Pakistan," Ashfaq said. "If regional agriculture is subjected to monsoon onset delays and shorter rainy seasons, production of these types of commodities will be reduced and have a significant impact on the global economy."Many countries located in these regions rely on hydropower to generate electricity, including Brazil, which produces 75% of its energy via this method. Shorter monsoon seasons would not provide enough rainfall at the correct time to supply adequate power without overhauling current operations.In addition to identifying potential monsoon changes and their implications, the team also investigated the root causes responsible for these shifts.In the absence of organized weather systems and a sustained moisture supply, the relatively dry pre-monsoon season receives only intermittent and convective rainfall, which is thermally driven. Lands in these regions get warmer every year during the pre-monsoon period, commonly reaching surface temperatures of 120 degrees Fahrenheit. The combination of convective precipitation warming the upper atmosphere and hot surface conditions warming the lower atmosphere causes disparities between warm air over the land and ocean that force the dry season to give way to monsoon rains.However, the simulations revealed that a continuous increase in global emissions will make the pre-monsoon environment less conducive for convective precipitation, which will delay the warming of upper atmosphere and the transition from the dry to the rainy season. One key factor the researchers determined will decrease convective rainfall during the pre-monsoon period is the formation of a deeper and less saturated boundary layer -- a part of the lower atmosphere where moisture and energy are exchanged between the land and the atmosphere."The upward force needed to lift air parcels to their level of free convection increases with the depth of the boundary layer," Ashfaq said. "And the warmer the atmosphere, the more moisture needed for convective instability, which is essential for the development of thunderstorms. Fulfilling the requirement during the pre-monsoon period is challenging because of the limited moisture supply as winds blow away from the land."The team will contribute their CORDEX simulations to the regional climate change chapter of the next IPCC assessment.This research used resources of the Oak Ridge Leadership Computing Facility, a DOE Office of Science User Facility located at ORNL. The team received support from the National Climate Computing Research Center, a collaboration between DOE and the National Oceanic and Atmospheric Administration.
Salt marshes have reduced the number of dike breaches during the well-known 1717 historic flood disaster. More interestingly, the 1953 flood disaster also tells us that salt marshes are not only 'wave absorbers' that ease wave attacks on the dike, but are also 'flood fighters' that lower the flood depth by limiting the size of breaches when the dike would fail during severe storms. And having smaller and shallower breaches because of salt marsh protection can save many lives.Rising sea levels and stronger storms raise coastal flood risks and inspire development of new strategy of flood dense: supplementing engineered structures with coastal wetlands like salt marshes. Although we have learnt from experiments and models that these natural buffers are 'wave absorbers' that reduce storm impact, it is unclear whether and how they can indeed add considerable safety to engineered defenses during severe, real world storms. 'Evidence from two notorious flood disasters that killed thousands of people after dike breaching: 1717 Christmas flood and 1953 North Sea flood, however, show that salt marshes have already displayed their role of 'flood fighter' for hundreds of years', says Zhenchang Zhu, the leading author of this paper, who conducted this research at NIOZ, but is currently working at Guangdong University of Technology, China. 'Salt marshes not only reduced the number and total width of dike breaches during the 1717 Christmas flood, but was also found to confine the breach depth during the 1953 North Sea flood. Especially the latter, previously unknown function of natural defenses, can greatly reduce flood damage by lowing inundation depth', Zhu continues.What can we learn from historic lessons? 'Flood defenses combining green and gray features are actually more beneficial than considered earlier. Beyond wave attenuation, salt marshes can lower flood impacts simply by limiting the size of dike breach, and continues to do so under sea level rise', Zhu adds. This generally overlooked function of salt marshes is actually more applicable than wave dissipation, as it is not limited to wave-exposed locations. To harness natural defense, marshes ideally have to be preserved or developed at the seaside of the dike to buffer the waves. This may, however, not always be possible. The study implies that even in this situation, it may still be possible to enhance coastal safety by creating salt marshes in between double dikes, where a secondary more landward dike is present and the most seaward primary dike is opened to allow natural processes to ensure marsh development. Despite no longer useful for wave reduction, such marshes are still very helpful for flood protection by making the landward dike more stable during extreme storms and buffer the effects of the rising sea in the long run. 'Overall this research enables novel designs of nature-based coastal defenses by smartly harnessing different natural flood defense functions', says Zhenchang Zhu.
The study, published today in The production and removal of methane from ecosystems is regulated by two types of microorganisms, methanogens -- which naturally produce methane -- and methanotrophs that remove methane by converting it into carbon dioxide. Previous research has suggested that these two natural processes show different sensitivities to temperature and could therefore be affected differently by global warming.Research led by Queen Mary University of London and the University of Warwick studied the impact of global warming on freshwater microbial communities and methane emissions by observing the effect of experimental warming of artificial ponds over 11 years. They found that warming produced a disproportionate increase in methane production over methane removal, resulting in increased methane emissions that exceeded temperature-based predictions.Professor Mark Trimmer, Professor of Biogeochemistry at Queen Mary, said: "Our observations show that the increase in methane emissions we see is beyond what you could predict based on a simple physiological response to the temperature increase. Long-term warming also changes the balance in the methane-related microbial community within freshwater ecosystems so they produce more methane while proportionately less is oxidised to carbon dioxide. As methane is a far more potent greenhouse gas than carbon dioxide, together these effects increase the global warming potential of the carbon gases released from these ecosystems."The experimental observations were supported by a meta-analysis of available data on methane emissions collected from wetlands, forests and grasslands worldwide, which showed that naturally warmer ecosystems also produce disproportionately more methane.Professor Trimmer, said: "Our findings fit with what we see in the real world for a wider variety of ecosystems. Together these results suggest that as Earth temperatures increase through global warming, natural ecosystems will continually release more methane into the atmosphere."Dr Kevin Purdy, Associate Professor of Microbial Ecology at Warwick, added: "Our studies have led to a better understanding of how global warming can affect methane emissions from freshwaters. This means that future predictions of methane emissions need to take into account how ecosystems and their resident microbial communities will change as the planet warms."Methane is a powerful greenhouse gas with some 28 times the global warming potential of carbon dioxide over a 100 year period. Over 40 per cent of methane is released from freshwaters such as wetlands, lakes and rivers making them a major contributor to global methane emissions.
Most volcanic eruptions take place unseen at the bottom of the world's oceans. In recent years, oceanography has shown that this submarine volcanism not only deposits lava but also ejects large amounts of volcanic ash."So even under layers of water kilometers thick, which exert great pressure and thus prevent effective degassing, there must be mechanisms that lead to an 'explosive' disintegration of magma," says Professor Bernd Zimanowski, head of the Physical-Volcanological Laboratory of Julius-Maximilians-UniversitÃ¤t (JMU) WÃ¼rzburg in Bavaria, Germany.An international research group led by Professors James White (New Zealand), Pierfrancesco Dellino (Italy) and Bernd Zimanowski (JMU) has now demonstrated such a mechanism for the first time. The results have been published in the journal The lead author is Dr. Tobias DÃ¼rig from the University of Iceland, a JMU alumnus and former RÃ¶ntgen Award winner of the JMU Institute of Physics. Before he went to Iceland, DÃ¼rig was a member of the research groups of Professor Zimanowski and Professor White.The team did research at the Havre Seamount volcano lying northwest of New Zealand at a depth of about 1,000 metres below the sea surface. This volcano erupted in 2012, and the scientific community became aware of it.The eruption created a floating carpet of pumice particles that expanded to about 400 square kilometres -- roughly the size of the city of Vienna. Now a diving robot was used to examine the ash deposits on the seabed. From the observational data the group of James White detected more than 100 million cubic meters of volcanic ash.The diving robot also took samples from the seafloor, which were then used in joint experimental studies in the Physical-Volcanological Laboratory of JMU."We melted the material and brought it into contact with water under various conditions. Under certain conditions, explosive reactions occurred which led to the formation of artificial volcanic ash," explains Bernd Zimanowski. The comparison of this ash with the natural samples showed that processes in the laboratory must have been similar to those that took place at a depth of 1,000 meters on the sea floor.Zimanowski describes the decisive experiments: "In the process, the molten material was placed under a layer of water in a crucible with a diameter of ten centimeters and then deformed with an intensity that can also be expected when magma emerges from the sea floor. Cracks are formed and water shoots abruptly into the vacuum created. The water then expands explosively. Finally, particles and water are ejected explosively. We lead them through an U-shaped tube into a water basin to simulate the cooling situation under water." The particles created in this way, the "artificial volcanic ash," corresponded in shape, size and composition to the natural ash."With these results, we now have a much better understanding of how explosive volcanic eruptions are possible under water," says the JMU professor. Further investigations should also show whether underwater volcanic explosions could possibly have an effect on the climate."With submarine lava eruptions, it takes a quite long time for the heat of the lava to be transferred to the water. In explosive eruptions, however, the magma is broken up into tiny particles. This may create heat pulses so strong that the thermal equilibrium currents in the oceans are disrupted locally or even globally." And those very currents have an important impact on the global climate.There are around 1,900 active volcanoes on land or as islands. The number of submarine volcanoes is estimated to be much higher. Exact numbers are not known because the deep sea is largely unexplored. Accordingly, most submarine volcanic eruptions go unnoticed. Submarine volcanoes grow slowly upwards by recurring eruptions. When they reach the water surface, they become volcanic islands -- like the active Stromboli near Sicily or some of the Canary Islands.
The soft coral garden, presented in a new The study has direct implications for the management of economically important deep-sea trawl fisheries, which are immediately adjacent to the habitat. The researchers hope that a 486 km2 area will be recognised as a 'Vulnerable Marine Ecosystem' under UN guidelines, to ensure that it is protected.PhD researcher Stephen Long (UCL Geography and ZSL (Zoological Society London)), first author on the study, said: "The deep sea is often over-looked in terms of exploration. In fact we have better maps of the surface of Mars, than we do of the deep sea."The development of a low-cost tool that can withstand deep-sea environments opens up new possibilities for our understanding and management of marine ecosystems. We'll be working with the Greenland government and fishing industry to ensure this fragile, complex and beautiful habitat is protected."The soft coral garden discovered by the team exists in near total darkness, 500m below the surface at a pressure 50 times greater than at sea-level. This delicate and diverse habitat features abundant cauliflower corals as well as feather stars, sponges, anemones, brittle stars, hydrozoans bryozoans and other organisms.Dr Chris Yesson (ZSL), last author on the study, said "Coral gardens are characterised by collections of one or more species (typically of non-reef forming coral), that sit on a wide range of hard and soft bottom habitats, from rock to sand, and support a diversity of fauna. There is considerable diversity among coral garden communities, which have previously been observed in areas such as northwest and southeast Iceland."The discovery is particularly significant given that the deep sea is the most poorly known habitat on earth, despite being the biggest and covering 65% of the planet. Until very recently, very little was known about Greenland's deep-sea habitats, their nature, distribution and how they are impacted by human activities.Surveying the deep sea has typically proved difficult and expensive. One major factor is that ocean pressure increases by one atmosphere (which is the average atmospheric pressure at sea level) every 10 metres of descent. Deep-sea surveys therefore have often only been possible using expensive remote operating vehicles and manned submersibles, like those seen in Blue Planet, which can withstand deep-sea pressure.The UK-Greenland research team overcame this challenge by developing a low-cost towed video sled, which uses a GoPro video camera, lights and lasers in special pressure housings, mounted on a steel frame.The lasers, which were used to add a sense of scale to the imagery, were made by combining high-powered laser pointers with DIY housings made at UCL's Institute of Making, with help from UCL Mechanical Engineering.The team placed the video sledge -- which is about the size of a Mini Cooper -- on the seafloor for roughly 15 minutes at a time and across 18 different stations. Stills were taken from the video footage, with 1,239 images extracted for further analysis.A total of 44,035 annotations of the selected fauna were made. The most abundant were anemones (15,531) and cauliflower corals (11,633), with cauliflower corals observed at a maximum density of 9.36 corals per square metre.Long said: "A towed video sled is not unique. However, our research is certainly the first example of a low-cost DIY video sled led being used to explore deep-sea habitats in Greenland's 2.2million kmÂ² of sea. So far, the team has managed to reach an impressive depth of 1,500m. It has worked remarkably well and led to interest from researchers in other parts of the world."Dr Yesson added: "Given that the ocean is the biggest habitat on earth and the one about which we know the least, we think it is critically important to develop cheap, accessible research tools. These tools can then be used to explore, describe and crucially inform management of these deep-sea resources."Dr Martin Blicher (Greenland Institute of Natural Resources) said: "Greenland's seafloor is virtually unexplored, although we know is it inhabited by more than 2000 different species together contributing to complex and diverse habitats, and to the functioning of the marine ecosystem. Despite knowing so little about these seafloor habitats, the Greenlandic economy depends on a small number of fisheries which trawl the seabed. We hope that studies like this will increase our understanding of ecological relationships, and contribute to sustainable fisheries management."
Gold mining has rapidly increased across the Amazon in recent years, especially along the Guiana Shield, where it is responsible for as much as 90% of total deforestation. The Shield encompasses Guyana, Suriname, French Guiana, Venezuela and small parts of Colombia and northern Brazil, and its forests hold roughly twenty billion tonnes of aboveground carbon in its trees.The ability of tropical forests to recover from gold mining activities has remained largely unquantified. Now, an international study led by the University of Leeds is the first to provide detailed field-based information on the regeneration of forests in Guyana after gold mining, and the first ground-based estimate of carbon sink lost as a result of gold mining activities across the Amazon.The team's findings, published in the They estimate that mining-related deforestation results in the annual loss of over two million tons of forest carbon across the Amazon. The lack of forest regrowth observed following mining suggests that this lost carbon cannot be recovered through natural regeneration.Lead author Dr Michelle Kalamandeen, began this research as a postgraduate researcher in the School of Geography at Leeds she is now a postdoctoral researcher at Cambridge University. She said: "This study shows that tropical forests are strongly impacted by mining activities, and have very little capacity to re-establish themselves following mining."Our results clearly show the extraction process has stripped nitrogen from the soil, a critical component to forest recovery, and in many cases directly contributed to the presence of mercury within neighbouring forests and rivers. Active mining sites had on average 250 times more mercury concentrations than abandoned sites."Not only does this have serious consequences for our battle against global warming by limiting Amazonian forests' ability to capture and store carbon, but there is also a larger implication of contaminating food sources especially for indigenous and local communities who rely on rivers."A positive finding from this study shows that overburden sites, areas where topsoil is deposited during the mining process, recorded similar recovery rates as other Central and South American secondary tropical forests abandoned after agriculture or pasture."Active management and enforcement of laws is clearly needed to ensure recovery and to safeguard communities and there are methods available, such as replacing the soil using the overburdens at abandoned sites. But there is an urgent need for large-scale recovery management to be tested and implemented."We could be facing a race against the clock. The current crisis is significantly increasing the demand for gold, given its perceived role as an economic stabiliser. With current gold price more than US$1700 per ounce and estimated to reach US$2000-3000 in the coming months, many artisanal and small-scale miners are already rapidly responding to this increase in pricing, and the weakening of environmental laws and policies as we've seen in Brazil, leading to further deforestation in the Amazon."The team used forest inventory plots installed on recently abandoned mines in two major mining regions in Guyana, and re-censused the sites 18 months later. The study analysed soil samples and determined individual trees' above-ground biomass -- the tree's living plant material -- to determine recovery and chemical changes caused by mining.Their results suggest that forest recovery is more strongly limited by severe mining-induced depletion of soil nutrients, especially nitrogen, rather than by mercury contamination. The high rate of mercury does however have serious implications for negative impacts on food security, water supply and local biodiversity.Study co-author, Dr David Galbraith, Associate Professor in Earth System Dynamics at Leeds, said: "Currently approximately 1.3 million square kilometres of the Amazon is under prospecting for mining activities."This research provides support to local and national governance structures to critically approach policy implementation and development for land management, including how and where mining occurs, and more stringent monitoring and action for forest recovery. It shows that carefully planned active restoration projects will be critical in this regard."But responsibility lies beyond remediation efforts to mitigate the damage done. Investors and consumers alike need increased awareness and accountability of the environmental footprints of gold mining."The Guyana Geology and Mines Commission (GGMC) who supported the fieldwork are optimistic that the results from this research will help in making more informed decisions for their reclamation policies and programmes, monitoring and enforcement.Mr Newell Dennison, Commissioner of the GGMC said: "The research results showed two important aspects: that overburden areas recovered relatively well and there was limited recovery in mining pits and tailing ponds. The latter being areas where we need improved management. The more data we can accumulate for recovery of secondary forests in mined out areas, the better we are all positioned for the implementation of effective programmes and operations that aid in the recovery of our rainforests. We look forward to working with Dr Kalamandeen and her team in the future."The Guyana Forestry Commission (GFC) expressed gratitude and appreciation to the research team for the important and impressive empirical work done in [this] paper.Mr Gavin Agard, Commissioner of the GFC said: "We expect that this scientific work has greatly improved Guyana's baseline and understanding of the forest degradation impacts of mining with respect to biomass recovery and sets a foundation for more dynamic, focused studies to advise planning and policy for improving secondary forest growth and restoring biomass capacity."The findings and recommendations from this study will significantly impact policy and management strategies for forest restoration and rehabilitation in mined-out areas, which is a key objective for Guyana under the Paris Agreement of the UNFCCC."The contribution of deforestation and degradation to climate change cannot be ignored, and thus we welcome the contributions of this research team to build and improve our communal knowledge and understanding of our changing forests as we continue to pursue the highest standards of sustainable forestry in Guyana."
Alien species are plants, animals and microbes that are introduced by people, accidentally or intentionally, into areas where they do not naturally occur. Many of them thrive, spreading widely with harmful effects on the environment, economy, or human health.The study, published in the journal According to Laura Meyerson, URI associate professor of natural resources science, the escalation in biological invasions is due to the increase in the number and variety of pathways along which species spread, and to the increasing volume of traffic associated with those pathways. For example, she notes the role played by emerging pathways such as the online trade in unusual pets and the transport of species across oceans on rafts of plastic.The researchers note that the scale of the problem is enormous. A 2017 analysis of global extinctions revealed that alien species contributed to 25 percent of plant extinctions and 33 percent of terrestrial and freshwater animal extinctions. Meanwhile, annual environmental losses caused by introduced species in the United States, United Kingdom, Australia, South Africa, India and Brazil have been calculated at more than $100 billion.The study also shows how drivers of global change, such as climate change, land-use change, and international trade, are exacerbating the impacts of biological invasions. Species transported through shipping can now thrive in new regions, for instance, owing to climate warming. And the permanent opening of the Arctic Ocean due to global warming is allowing marine species to move between the Atlantic and Pacific Oceans.The research paper is part of an initiative called World Scientists' Warning to Humanity: A Second Notice, which calls for urgent change in stewardship of the Earth and the life on it. The first notice, in 1992, was supported by 1,700 eminent scientists from around the globe who warned that humanity was on a collision course with the rest of the natural world. Twenty-five years later, a follow-up evaluation supported by 15,000 scientists declared that humanity had failed to make sufficient progress in dealing with the environmental challenges. Indeed, they found that most of these problems had worsened.The authors of the new paper stress that biological invasions can be managed and mitigated. They point to approaches that are working around the world and make specific recommendations for improved management. For example, the introduction of more stringent border controls, including X-ray machines and detector dogs, has led to a progressive decline in the rate of fungal plant pathogens entering New Zealand.Professor Petr PyÅ¡ek of the Czech Academy of Sciences and Charles University in Prague, lead author of the study, said: "As our knowledge about invasive alien species increases, the problems associated with biological invasions are becoming clearer. The threats posed by invasive alien species to our environment, our economies and our health are very serious, and getting worse. Policy makers and the public need to prioritize actions to stem invasions and their impacts."Professor David Richardson of the Centre for Invasion Biology at Stellenbosch University in South Africa, the other lead author, added: "Nations such as Australia and New Zealand have made biosecurity a national priority. South Africa has invested heavily in a massive national programme focussed on reducing the negative impacts of widespread invaders on ecosystem services, especially the delivery of water from catchments invaded by alien trees. But action is needed more widely at both national and international levels in order to tackle the challenges effectively."Meyerson, who contributed to the paper and is leading the chapter on trends in invasions for a report on invasive alien species for the Intergovernmental Science-Policy Platform on Biodiversity and Ecosystem Services, said, "It has been so exciting to see developments in our knowledge and understanding of biological invasions in recent decades, achieved through truly inspiring global collaborations. It is so important that we continue to share our knowledge and engage with relevant stakeholders across sectors and borders."
But much of what happens below that layer remains a mystery, including the fate of sections of crust that vanish back into the Earth. Now, a team of geochemists based at the Florida State University-headquartered National High Magnetic Field Laboratory has uncovered key clues about where those rocks have been hiding.The researchers provided fresh evidence that, while most of the Earth's crust is relatively new, a small percentage is actually made up of ancient chunks that had sunk long ago back into the mantle then later resurfaced. They also found, based on the amount of that "recycled" crust, that the planet has been churning out crust consistently since its formation 4.5 billion years ago -- a picture that contradicts prevailing theories.Their research is published in the journal "Like salmon returning to their spawning grounds, some oceanic crust returns to its breeding ground, the volcanic ridges where fresh crust is born," said co-author Munir Humayun, a MagLab geochemist and professor at Florida State's Department of Earth, Ocean and Atmospheric Science (EOAS). "We used a new technique to show that this process is essentially a closed loop, and that recycled crust is distributed unevenly along ridges."In addition to Humayun, the research team included MagLab postdoctoral researcher Shuying Yang, lead author on the paper, and MagLab Geochemistry Group Director and EOAS Chair Vincent Salters.The Earth's oceanic crust is formed when mantle rock melts near fissures between tectonic plates along undersea volcanic ridges, yielding basalt. As new crust is made, it pushes the older crust away from the ridge toward continents, like a super slow conveyer belt. Eventually, it reaches areas called subduction zones, where it is forced under another plate and swallowed back into the Earth.Scientists have long theorized about what happens to subducted crust after being reabsorbed into the hot, high-pressure environment of the planet's mantle. It might sink deeper into the mantle and settle there, or rise back to the surface in plumes, or swirl through the mantle, like strands of chocolate through a yellow marble cake. Some of that "chocolate" might eventually rise up, re-melt at mid-ocean ridges, and form new rock for yet another millions-year-long tour of duty on the sea floor.This new evidence supports the "marble cake" theory.Scientists had already seen clues supporting the theory. Some basalts collected from mid-ocean ridges, called enriched basalts, have a higher percentage of certain elements that tend to seep from the mantle into the melt from which basalt is formed; others, called depleted basalts, had much lower levels.To shed more light on the mystery of the disappearing crust, the team chemically analyzed 500 samples of basalt collected from 30 regions of ocean ridges. Some were enriched, some were depleted and some were in between.Early on, the team discovered that the relative proportions of germanium and silicon were lower in melts of recycled crust than in the "virgin" basalt emerging from melted mantle rock. So they developed a new technique that used that ratio to identify a distinct chemical fingerprint for subducted crust.They devised a precise method of measuring that ratio using a mass spectrometer at the MagLab. Then they crunched the numbers to see how these ratios differed among the 30 regions sampled, expecting to see variations that would shed light on their origins.At first the analysis revealed nothing of note. Concerned, Yang, a doctoral candidate at the time, consulted with her adviser. Humayun suggested looking at the problem from a wider angle: Rather than compare basalts of different regions, they could compare enriched and depleted basalts.After quickly re-crunching the data, Yang was thrilled to see clear differences among those groups of basalts."I was very happy," recalled Yang, lead author on the paper. "I thought, 'I will be able to graduate!'"The team had detected lower germanium-to-silicon ratios in enriched basalts -- the chemical fingerprint for recycled crust -- across all the regions they sampled, pointing to its marble cake-like spread throughout the mantle. Essentially, they solved the mystery of the vanishing crust.It was a lesson in missing the forest for the trees, Humayun said."Sometimes you're looking too closely, with your nose in the data, and you can't see the patterns," he said. "Then you step back and you go, 'Whoa!'"Digging deeper into the patterns they found, the scientists unearthed more secrets. Based on the amounts of enriched basalts detected on global mid-ocean ridges, the team was able to calculate that about 5 to 6 percent of the Earth's mantle is made of recycled crust, a figure that sheds new light on the planet's history as a crust factory. Scientists had known the Earth cranks out crust at the rate of a few inches a year. But has it done so consistently throughout its entire history?Their analysis, Humayun said, indicates that, "The rates of crust formation can't have been radically different from what they are today, which is not what anybody expected."The MagLab is funded by the National Science Foundation and the State of Florida. It is headquartered at Florida State University with additional locations at University of Florida and Los Alamos National Laboratory.
Two new studies, one led by Associate Professor Sebastiaan Swart and the other led by Dr Louise Biddle, both working at the University of Gothenburg, use highly novel techniques to collect rare data in the ocean both under and near the sea ice surrounding Antarctica.These papers present for the first time upper ocean currents of approximately 0.1-10 km in size. These currents, which are invisible to satellite and ship-based data, are seen to interact with strong Southern Ocean storms and with physical processes occurring under sea ice."Using the data collected by the seals, we're able to look at the impact these upper ocean currents have underneath the sea ice for the first time. It's a really valuable insight into what was previously completely unknown in the Southern Ocean," says Dr Louise Biddle, Department of Marine Sciences, University of Gothenburg.The winter had assumed to be a "quiet" time due to the dampening effect of sea ice on the ocean's surface. However, the two studies show that these upper ocean currents have a significant effect on the ocean during winter.Some of the findings by Sebastiaan Swart and his team gives further insight how these observed ocean currents work. Their study highlights that during times when there are no storms and winds are weak, upper ocean currents start to become much more energetic. This energy enhances the rate of ocean mixing and transport of properties, like heat, carbon and nutrients, around the ocean and into the deep ocean."These new ocean robots, so-called gliders, which we control by satellite for months at a time, have allowed us to measure the ocean at unprecedented high resolution. The measurements have revealed strong physical linkages between the atmosphere and ocean. It's pretty amazing we can remotely 'steer' these robots in the most far-flung parts of the world -- the ocean around Antarctica -- while collecting new science data," says Associate Professor Sebastiaan Swart, Department of Marine Sciences, University of Gothenburg.Together, these studies contribute to improving our understanding of small-scale ocean and climate processes that have impacts globally. These kinds of observations are a critical knowledge gap in the ocean that has an impact on various processes occurring at global scale, such as ecosystems and climate."We are excited to grow this research capability at the University of Gothenburg. This is really a world-leading direction we should be taking to collect part of our data in marine sciences," says Sebastiaan Swart.
Studies within the Maryland Wind Energy Area -- the coastal shelf waters leased by the Bureau of Ocean Energy Management for offshore wind farms -- prior to construction activities reveal that Atlantic sturgeon and striped bass are frequent visitors. Seasonal trends lead scientists to believe that the wind energy area lies within an important migration corridor for both species. Atlantic sturgeon were most commonly observed moving through the area during the spring and fall, while striped bass had an increased migratory presence in spring and winter. The Atlantic sturgeons' "flyway" tended to favor shallower, warmer waters, while striped bass were more likely to be found at great depths and cooler conditions.Both species spent longer periods of time in the corridor during the autumn and winter. This trend was particularly strong for striped bass, with many individuals prolonging their presence on the outer shelf during winter. However, during the summer, Atlantic sturgeon were rarely detected and striped bass were absent.The construction of an off-shore wind farm creates loud noises and increased activity that can disrupt typical animal behaviors. The low occurrence of these important fish species during the summer months suggests a potential window for wind turbine construction, when impacts could be minimized."Scientists have learned a lot about the Atlantic sturgeon and striped bass' seasonal patterns of habitat selection within spawning rivers, estuaries, and shelf foraging habitats," says study author Ellie Rothermel, who recently received her master's degree from the University of Maryland Center for Environmental Science. "During these times, we know where the fish are likely to be and when to expect them there, but information on the location and timing of key coastal migrations is limited. Coastal waters have been largely inaccessible to scientists. Our study uses acoustic telemetry to understand the critical migratory periods in the lives of these fish species."Rothermel compares acoustic telemetry to the E-ZPass system used for vehicles. When a car with E-ZPass is driven over the Bay Bridge, a toll booth collects its identification number, along with the time and date. Just like toll booths and the E-Z Pass system, scientists use acoustic receivers and tags to track where fish go, and when they go there.After catching and determining the size, weight and sex of a striped bass, scientists surgically implanted an acoustic tag into the fish prior to releasing it. An acoustic tag is a small device, about the size of a thumb, that has a unique ID and makes a "ping" sound every few seconds.Scientists also deployed 20 acoustic receivers in the Maryland Wind Energy Area. When a tagged fish swims past a receiver, a listening device about the size of a liter soda bottle, the receiver records the "ping" sent out by the tag. Each "ping" transmits its unique ID and the depth at which the fish was swimming to the receiver, which also records the time and date. The array of receivers allows scientists to monitor the movements of tagged fish. During the study, "pings" from 352 individual Atlantic sturgeon and 315 individual striped bass were recorded by receivers.Scientists believe that Maryland's future offshore wind farm could become a stop-over region where striped bass and sturgeon might linger longer. The DelMarVa coastal shelf is a fairly barren area. The development of high relief wind turbines would provide structure around which fish may gather and linger during migrations."To extend the highway travel metaphor, the wind farm that will be built in the area off-shore from Ocean City may become a 'rest stop' where fish and sharks can grab a bite to eat and take a break before resuming their travels," says study co-author Dave Secor of the University of Maryland Center for Environmental Science.As wind farms are developed and operated offshore of the Mid-Atlantic and Southern New England regions, which together comprises a multispecies "flyway," scientists could use the telemetry array design to monitor potential impacts. Cooperation among researchers, expanded scale of acoustic telemetry arrays, and increased incorporation of oceanographic data will improve understanding of how fishes will respond to wind energy development in the northwest Atlantic Ocean.
The Australian science team discovered the deepest living hard corals in Eastern Australian waters, sighted fish in regions where they had never been found before, and identified up to 10 new marine species of fish, snails, and sponges.Schmidt Ocean Institute's research vessel Falkor -- the only year-round philanthropic research vessel in the world -- spent the last 46 days in one of the world's largest protected areas, the Coral Sea Marine Park.The team of Australian scientists connected remotely to the ship from their homes, collecting high-resolution seafloor maps and video footage of the deep ocean down to 1,600 meters. Led by chief scientist Dr. Robin Beaman of James Cook University, the expedition enabled the team to develop a better understanding of the physical and long-term changes that have occurred on the deep reefs. This marked the first time the region had been viewed, using an underwater robot that streamed real-time 4K video.The extraordinary mapping effort has illuminated a complex seafloor of 30 large coral atolls and banks, revealing submarine canyons, dune fields, submerged reefs, and landslides. More than 35,500 square kilometers were mapped-an area larger than half of Tasmania, transforming the Queensland Plateau from one of the poorest-mapped to one of the best-mapped frontier areas of Australia's marine estate. The maps created will be available through AusSeabed , a national Australian seabed mapping program, and will also contribute to the Nippon Foundation GEBCO Seabed 2030 Project . Only the shallower parts of these reefs had been mapped previously, and until now no detailed mapping data existed of the deeper areas."This expedition has provided us with a unique window into both the geological past and the present day conditions, allowing scientists and park managers to be able to see and tell the full story of the interconnected environments," said Dr. Beaman. "This vision is invaluable for science, management, and education."Over 91 hours of high-resolution video surveys were collected with Falkor's underwater robot, SuBastian, showing no evidence of coral bleaching below 80 meters."We know that the shallower coral counterparts are currently undergoing their third mass bleaching event in five years, so it's an invaluable insight for scientists and managers to know how deep that bleaching extends, " said Dr. Jyotika Virmani, executive director of Schmidt Ocean Institute. "It's important to note, however, that the corals discovered are specialized to these deep habitats and are not found in the shallows. This expedition was the first time these species have been recorded in such high abundance in the Coral Sea."The 14 historic deep sea dives completed with SuBastian have also helped give a much better understanding of the depth and habitat preferences of the Coral Sea deep reef community. All of the data collected has been publicly shared through more than 74 hours of video surveys and highlights available on the Schmidt Ocean Institute YouTube channel and website . The live streamed dives created an online platform, drawing spectators from around the world to witness unique species like deep water sharks and chambered nautiluses -- a distant cousin to squids that uses jet propulsion to move."The footage coming from our dives is just astounding, '' Virmani said. "The Falkor 's robust telepresence technology has allowed scientists from all over the world to collaborate on some of these discoveries. The data will greatly advance the characterization of Australia's massive and ecologically important marine estate."Research Vessel Falkor will return to the Coral Sea Marine Park for an additional month of research at the end of July.
Arctic spiders are at the top of the food chain among invertebrates and are numerous on the Arctic tundra. They typically take several years to become adults, and only produce offspring .But something is happening in the high north in these years. A lot, actually.Climate change is more dramatic here than in no other place on Earth. The average temperature is increasing significantly and this affects the ecosystems.Researchers have previously reported how plants bloom earlier and earlier in the season. There are also signs that species move farther north and up into the mountains.A team of researchers led by senior researcher Toke T. HÃ¸ye from the Arctic Research Centre and Department of Bioscience at Aarhus University has now shown that changes are also occurring in the reproduction of invertebrates.For almost 20 years, researchers at the Zackenberg Research Station in north-eastern Greenland have caught wolf spiders as part of the monitoring programme Greenland Ecosystem Monitoring. The spiders were caught in small pitfall traps set up in different vegetation types.Wolf spiders carry their eggs in a so-called egg sac. The researchers counted the number of eggs in the individual spider's egg sacs and compared this information with the time of the season that the animal was caught. By looking at the distribution of the number of eggs in the egg sacs throughout the season, it became clear that in some summers the spiders produced two egg sacs -- a phenomenon that is known from warmer latitudes, but which has not previously been observed in the Arctic."We now have the longest time series of spiders collected the Arctic. The large amount of data allows us to show how small animals in the Arctic change their life history in response to climate change," says Toke T. HÃ¸ye.The long time series tells the researchers that the earlier the snow disappears from the ground, the greater the proportion of spiders that can produce a second clutch of offspring."These changes in the life history have not been seen earlier and evidence suggests that the phenomenon plays an important role for Arctic insects and spiders," Toke T. HÃ¸ye says.The researchers see the spiders' response to climate change as an ability to adapt to the new conditions.Wolf spiders feed on small organisms such as springtails in the soil. If there are more spiders -- or insects -- in the future Arctic, it can have an influence on the food chains on land."We can only speculate about how the ecosystems change, but we can now ascertain that changes in the reproduction of species are an important factor to include when we try to understand how Arctic ecosystems react to the rising temperatures on the planet," Toke T. HÃ¸ye says.
Now University of Montana researcher Michael DeGrandpre and his patented sensors have helped an international team determine that, indeed, COThe work was published this month in the journal DeGrandpre is a UM chemistry professor, and in 2015 he and the company he founded, Sunburst Sensors, won two coveted XPRIZE awards for developing inexpensive, durable sensors to better understand ocean acidification. Sunburst Sensor technology also was used in this recent study for a CODeGrandpre said ocean measurements are taken while the icebreaker is underway, sometimes crashing through ice one to two meters thick. DeGrandpre and UM research associate Cory Beatty have participated in these research cruises since 2012 with support from the National Science Foundation Office of Polar Programs."Because of the inaccessibility of the Arctic and the typically harsh work conditions, we really need a world-class icebreaker to access these areas," DeGrandpre said. "It also has given us a high-quality, consistent dataset, which really helped with this latest study. Most Arctic COHe said the new study combines sporadic data dating back to 1994 with the more-frequent data they have collected since 2012. DeGrandpre said their consistent dataset will only improve, as NSF recently awarded them an $890,000 grant to continue the icebreaker project through 2023.
"Shingle Shanty Preserve was an ideal location to conduct this research," said Stephen Langdon, Shingle Shanty Director and principal investigator. "Peatlands, like those at Shingle Shanty Preserve, are some of the best protected, most-intact examples of the ecosystem around the world at this latitude: a fact that makes them a critical resource for understanding the biological response to climate change and nitrogen deposition." Langdon has 25 years of experience in the Adirondacks working in conservation from shovel-in-hand trail maintenance to biodiversity research with government and private organizations."These are hard-earned data," Langdon said. "The result of weeks of bushwhacking through buggy bogs and thick black spruce forests."Researchers collected data on vascular species, including their composition, environmental drivers, and ages in 50 plots spread throughout a nearly 1000-acre portion of the Preserve."A peatland complex of this size at its southern geographical limit in the eastern U.S. is highly significant ecologically and for its conservation values," said Don Leopold, ESF Distinguished Teaching Professor and research collaborator. Leopold has studied peatlands throughout the U.S. for the past 35 years.Large peatlands, like Shingle Shanty Preserve near their southern range limits in eastern North America, are particularly important for biodiversity conservation because they are nested in a relatively intact biome and they are a refuge for many disjunct boreal species at their southern range limits, like the threatened spruce grouse. The biodiversity in these peatlands is threatened by direct modification (e.g., drainage for agriculture) and by invasions of woody species linked to human-caused environmental changes such as climate warming and atmospheric nitrogen deposition"This research should serve as a wake-up call, as it provides an early warning that even the most remote and protected boreal peatlands may be lost at their southern range limits, in potentially just over a few decades, due to this ongoing and abundant colonization by temperate tree species -a process likely to be dramatically accelerated by continuously warming climate and fertilizing effects of nitrogen emissions," said Martin Dovciak, ESF Associate Professor and research collaborator. Dovciak has studied forest dynamics in a variety of forested ecosystems in North America and Europe over the last 25 years.Shingle Shanty Preserve is a 23-square-mile remote tract of land located in the middle of the 6-million-acre Adirondack Park, about nine miles west of Long Lake, NY. Although all of the Preserve is protected by a Forever Wild conservation easement, it is still quite susceptible to large-scale changes due to climate. The Preserve and Research Station was formally established as a 501(c)3 non-profit biological field research station in 2008 with a mission of supporting scientific research to improve the understanding and management of Adirondack Ecosystems. This remote, private Preserve is positioned at the top of the Beaver, Raquette and Moose River watersheds and has 2000 acres of pristine boreal wetlands, 9 lakes and ponds, 6 miles of headwater streams and over 12,500 acres of northern hardwood and successional northern hardwood forests. Shingle Shanty is home to numerous species that benefit from large scale protection, including a suite of boreal bird species such as spruce grouse, rusty black birds and olive-sided flycatchers, as well as moose, American martin and river otters. The Preserve is located in an unusually cold area for its latitude in the southernmost area of USDA hardiness Zone 3 in the northeastern United States. Temperature data loggers at the site recorded a growing season of only 19-days as recently as 2014 in the low-lying peatland complex.
In some cases, this leads to the creation of new jobs for local communities, and governments often welcome these investments as a means to promote the transfer of technologies and the inflow of capital. But the investments can also have adverse outcomes for local people, who rely on the acquired areas for food and income but have no legal claim to the land, and the environment -- as the land will likely need to be converted to serve its intended use.An international group of researchers led by the University of Delaware's Kyle Davis has recently published a study in The study's findings show that large-scale land acquisitions can lead to elevated deforestation of tropical forests and highlight the role of local policies in the sustainable management of these ecosystems.Researchers used a georeferenced database of more than 82,000 land deals -- covering 15 countries in Latin American, sub-Saharan Africa and Southeast Asia -- with global data on annual forest cover and loss between 2000 and 2018.They found that since the start of the century, 76% of all large-scale land acquisitions in the Global South -- an emerging term which refers to the regions of Latin America, Asia, Africa and Oceania -- can be attributed to foreign land investment. These land acquisitions covered anywhere from 6% to 59% of a particular country's land area and 2% to 79% of its forests.The information came from the Global Forest Watch database run by the World Resources Institute as well as other sources such as government ministries, which provides information for thousands of individual investments that show the exact area, boundary and intended use."This collection of datasets on individual land investments provided me with information on the exact area, boundary, and intended use of each deal. I then combined these data with satellite information on forest cover and forest loss to understand whether large-scale land investments are associated with increased rates of forest loss," said Davis, assistant professor in the Department of Geography and Spatial Sciences in UD's College of Earth, Ocean and Environment and the Department of Plant and Soil Sciences in UD's College of Agriculture and Natural Resources.With regards to the environmental damage done by oil palm, wood fiber and tree plantations, Davis said a lot of it has to do with the ways in which those products are grown."Investments to establish new oil palm or tree plantations seem to consistently have higher rates of forest loss, and that makes sense because basically, you have to completely clear the land in order to convert it to that intended use," said Davis. "If you want to establish a tree plantation or a palm oil plantation in place of natural vegetation, you've first got to cut down the forest."For the other investment types, such as logging and mining, however, the results were much more mixed. Logging investments, in fact, served a small, protective role where the rates of forest loss in logging concessions were slightly lower than the rates of forest loss in surrounding, comparable areas. Davis attributed this to the specific requirements for the logging industry where only trees of a certain size or species can often be harvested.These large-scale land acquisitions are now widespread across the planet, which was caused largely by rising globalization and the world's increasing interconnectedness."There's been a rapid increase in land investments in recent decades due to growing global demands for food, fuel, and fiber," said Davis.He pointed to the global food crisis in 2008 when many import-reliant countries realized they were vulnerable to food or resource shortages. To help offset that vulnerability, they have pursued investments abroad to expand the pool of resources available to them in case another large-scale shock occurs.Davis emphasized the importance for governments to provide detailed information on land investments, to ensure that these deals were carried out transparently and to allow researchers to objectively assess their effects.He also said that by performing this comparison across different countries, it makes it possible to start identifying specific policies that are more effective in protecting forests."If you see deals in one country that aren't leading to enhanced forest loss but the same type of investment in another country is accelerating deforestation, then this suggests that there are opportunities to compare the policies in both places and leverage what's working in one country and adapt that to another context," said Davis. "But it also clearly shows that countries will inevitably experience deforestation should they seek to promote certain investments such as palm oil, wood fiber, and tree plantations, which we found were consistently associated with increased forest loss."
In their model simulations, climate researchers always have to make compromises. Even with the largest computers available worldwide, they can only reproduce the real world to a limited extent. Depending on the application, simplifications have to be made in the spatial resolution, but also in the physical processes represented by the model. While model experiments over periods of months to a few years can often still be made with high spatial resolution, integrations over centuries to millennia can only be performed at coarser resolution. In the past, models were developed for a specific purpose. Now, GEOMAR Helmholtz Centre for Ocean Research Kiel presented a flexible model kit, called FOCI (Flexible Ocean and Climate Infrastructure). It is based on the Earth system model of the Max Planck Institute for Meteorology in Hamburg and has been modified with the NEMO ocean model, in order to represent small-scale processes in the oceans at higher resolution."In FOCI we combine decades of expertise in ocean and climate modelling at GEOMAR. The new system enables the investigation of new questions such as the influence of the stratospheric ozone hole on the circulation in the Southern Ocean or the impact of the Gulf Stream on atmospheric processes," explains Professor Dr. Katja Matthes from the Maritime Meteorology Research Unit at GEOMAR."With the new system, we can investigate many different research questions on ar range of time scales," Professor Dr. Arne Biastoch, head of the Ocean Dynamics Research Unit at GEOMAR, points out. "We initially performed a set of standardised basic tests with the FOCI system," the oceanographer continues. "We had to find out whether the model system is capable of reproducing the observed climate and the present ocean circulation. Only if we are confident that the system can successfully simulate the present conditions within limited error bands it can be used to investigate unknown phenomena or for the predictions of future climate conditions." The results, which have been published in the international journal The basic experiments carried out so far include a control run over 1,500 years with pre-industrial greenhouse gas concentrations and several experiments covering the period from 1850 to the present day, for which observational data are available for verification. "The current results are very encouraging," says Katja Matthes. The system will be further improved and used for various questions to study natural climate fluctuations, but also anthropogenic climate change. "From our point of view, FOCI is the ideal system for GEOMAR to simulate small-scale processes in the ocean, interactions between stratosphere and troposphere as well as biogeochemical processes in the ocean. It also allows us to carry out complex projects such as a large number of model simulations over several decades with a reasonable amount of computing time," Professor Matthes concludes.
For the study an international team of researchers, led by Keele University and including experts from the University of Exeter, demonstrated that seasonal growth and destruction of sea ice in a warming world enhances the amount of marine life present in the sea around Antarctica, which draws down carbon from the atmosphere and stores it in the deep ocean.Having captured half of all human-related carbon that has entered the ocean to date, the Southern Ocean around Antarctica is crucial for regulating carbon dioxide levels resulting from human activity, so understanding the processes that determine its effectiveness as a carbon sink through time are crucial to reducing uncertainty in future climate change models.To understand this process further, the researchers studied data relating to one period where atmospheric COThis occurred after the Last Ice Age, around 18,000 years ago, when the world transitioned naturally into the warm interglacial world we live in today.During this period, COThe cause of this plateau, which occurred around 14,600 years ago, is unknown, but understanding what happened during this period could be crucial for improving climate change projections.Professor John Love, from Exeter's Biosciences department and co-author of the study said: "My research group and I are very excited about being part of this important investigation. We developed new techniques in cell biology to find, collect and analyse the rare and very tiny particles and cells that had been frozen in the ice for millennia."Like flies in amber, these minute fragments give us a unique window into past events, enabling our colleagues in the Earth, Atmosphere and Ocean sciences to develop a better understanding of climate change then, and now."Lead author Professor Chris Fogwill, Director of Keele University's Institute for Sustainable Futures said: "The cause of this long plateau in global atmospheric COTo resolve this question, researchers travelled to the Patriot Hills Blue Ice Area of Antarctica to develop new records of evidence of marine life that are captured in ice cores, with support from Antarctic Logistics and Expeditions (ALE).Blue ice areas are the perfect laboratory for Antarctic scientists due to their unique topography. Created by fierce, high-density katabatic winds, the top layer of snow is effectively eroded, exposing the ice below. As a result, ice flows up to the surface, providing access to ancient ice below.Professor Chris Turney, a visiting Fellow at Keele's Institute for Liberal Arts and Sciences from UNSW Sydney said: "Instead of drilling kilometres into the ice, we can simply walk across a blue ice area and travel back through time."This provides the opportunity to sample large amounts of ice for studying past environmental changes in detail. Organic biomarkers and DNA from the Southern Ocean are blown onto Antarctica and preserved in the ice, providing a unique record in a region where we have few scientific observations."Using this approach the team discovered that there was a marked increase in the number and diversity of marine organisms present across the 1,900 year period when the COThis provides the first recorded evidence of increased biological productivity and suggests that processes in the high latitude Southern Ocean may have caused the COThis modelling revealed that the plateau period coincided with the greatest seasonal changes in sea ice during a pronounced cold phase across the Southern Ocean known as the Antarctic Cold Reversal. During this period, sea ice grew extensively across the Southern Ocean, but as the world was warming rapidly, each year the sea ice would be rapidly destroyed during the summer.The researchers will now use these findings to underpin the development of future climate change models. The inclusion of sea ice processes that control climate-carbon feedbacks in a new generation of models will be crucial for reducing uncertainties surrounding climate projections and will help society adapt to future warming.
Surrounding the remote continent of Antarctica, the Southern Ocean is one of the most important yet poorly understood components of the global carbon cycle. Having captured half of all human-related carbon that has entered the ocean to date, the Southern Ocean is crucial to regulating human-induced COAfter the Last Ice Age, around 18,000 years ago, the world transitioned naturally into the warm interglacial world we live in today. During this period, COOne period stands out: a 1,900-year plateau of near-constant CO"We found that in sediment cores located in the sea-ice zone of the Southern Ocean biological productivity increased during this critical period, whereas it decreased farther north, outside of the sea-ice zone," says Michael Weber, co-author of the study from the Institute for Geosciences at the University of Bonn. "It was now important to find out how climate records on the Antarctic continent depict this critical time period."To resolve this question researchers from Keele University, U.K., and the University of New South Wales (UNSW) in Sydney, Australia, travelled to the Patriot Hills Blue Ice Area to obtain new records of marine biomarkers captured in ice cores. Chris Fogwill, lead author of the study from Keele University, says "the cause of this long plateau in global atmospheric COBlue ice areas are created by fierce, high-density katabatic winds that erode the top layer of snow effectively and expose the ice below. As a result, ice flows up to the surface, providing access to ancient ice below. While most Antarctic researchers drill down into the ice to extract samples with a conventional ice core, this team used a different method: horizontal ice core analysis. Chris Turney (UNSW, Sydney) says "Instead of drilling kilometres into the ice, we can simply walk across a blue ice area to travel back through time. This provides the opportunity to sample large volumes of ice necessary for studying new organic biomarkers and DNA that were blown from the Southern Ocean onto Antarctica and preserved in the blue ice."The results demonstrated a marked increase in the number and diversity of marine organisms across the 1,900 year period of the COThe team will use this work to underpin the development of climate models that seek to improve our understanding of future climate change. The inclusion of sea ice processes that control climate-carbon feedbacks in a new generation of models will be crucial for reducing uncertainties surrounding climate projections and help society adapt to future warming.
The three-spined stickleback ("What is really remarkable in our results is that the repeatability of evolution in response to similar selection pressures in different oceans can be so different," says group leader Juha MerilÃ¤, Professor at the Faculty of Biological and Environmental Sciences, University of Helsinki.The genetic underpinnings of such parallel evolution have fascinated scientists for years, and they have discovered that the observed marine-freshwater differentiation is underlain by surprisingly parallel changes also at the genetic level. However, most studies on this topic have been based on either limited geographic sampling or focused only on populations in the Eastern Pacific region."As scientists, we are often tempted to provide simple narratives to extremely complex problems. What I liked the most about this project is that we did the exact opposite: we show that the story behind the three-spined stickleback's spectacularly fast adaptation to novel habitats may be more complex than previously thought. I think that deciphering the role of demographic history in shaping evolutionary adaptation is a necessary step in solving the mystery," says co-author Paolo Momigliano, postdoctoral researcher at the Faculty of Biological and Environmental Sciences, University of Helsinki.With novel and powerful methods, a group of researchers from the University of Helsinki disentangled patterns of parallel evolution of freshwater three-spined sticklebacks at different geographic scales across their distribution range. They found that the extraordinary level of genetic parallelism observed in the Eastern Pacific region is not observed in the rest of the species' range. In fact, they found approximately 10-fold higher levels of genetic parallelism in the Eastern Pacific compared to the rest of the world."I have been studying the worldwide population histories of the species in my PhD. We found their ancestral populations are residing in the Eastern Pacific. We predicted that the region harbours the source of ancestral genetic variations for parallel evolution, and such genetic variation could be lost during colonisation to the rest of the world, for instance in the Atlantic. These predictions were tested by both empirical and simulated data," explains first author Bohao Fang, PhD candidate from the Faculty of Biological and Environmental Sciences, University of Helsinki.Their simulations showed that this difference in the degree of parallelism likely depends on the loss of standing genetic variation -- the raw material upon which selection acts -- during the colonisation of the Western Pacific and Atlantic Oceans from the Eastern Pacific Ocean.This discrepancy could have been further accentuated by periods of strong isolation and secondary contact between marine and freshwater habitats in the Eastern Pacific, consistent with the group's results and the geological history of the area. This secondary contact likely happened after the colonisation of the Atlantic Basin, resulting in much more genetic variation available for local adaptation in the Eastern Pacific -- variation that never had the chance to spread to the Atlantic. In other words, the discrepancy in genetic patterns of parallel evolution between the two oceans is a result of the complex demographic history of the species, which involved range expansions and demographic bottlenecks."Our less assumption-burdened methods have been a key to quantifying parallel evolution at different geographic scales for the type of data that was available for this study. I thoroughly enjoy developing novel methods to study adaptation and evolution, and the idea that parallel evolution might be exceptional in the Eastern Pacific compared to the rest of the world has intrigued me for a long time. It was a lucky coincidence that I became a part of the Ecological Genetics Research Unit led by Juha MerilÃ¤ where the samples to finally test this hypothesis became available," concludes Petri Kemppainen, co-first author, method developer, and postdoctoral researcher at the Faculty of Biological and Environmental Sciences, University of Helsinki.
The research, led by the University of Edinburgh and the University of St Andrews, investigated the impacts of forest loss on species and biodiversity over time and around the world, revealing both losses and gains in species.Focussing on biodiversity data spanning 150 years and over 6,000 locations, the study, published in the journal Forest loss amplifies the gains and losses of biodiversity - the numbers of individual plant and animal species, as well as the wider diversity and composition of ecosystems around the planet.Forests support around 80% of all species living on land, from eagles, bluebells, beetles, and many more. This biodiversity provides important ecosystem services and some species, such as the rosalia longicorn beetle, survive best in intact old forests. However, forests are being altered by human activities, for example deforestation for the cultivation of agricultural crops or the conversion to rangeland for grazing cattle. The research reveals that forest loss amplified both gains and losses in the abundance of different species as well as in the overall biodiversity.This study used the BioTIME and Living Planet biodiversity databases - that contain data collected by researchers working at sites around the world. Bringing together over 5 million records of the numbers of different plants and animals with information on both historic and contemporary peaks in forest loss, the researchers analysed the worldwide impacts of forest loss on biodiversity.The international research team discovered both immediate and delayed effects of forest loss on ecosystems, indicating that biodiversity responses to human impacts are diverse and play out across decades.Findings also reveal that some tropical areas experience more forest loss now than they have ever seen in the past, resulting in declining numbers of different animal species. In North America and Europe, the greatest loss of forests often occurred centuries ago, however even the smaller amounts of forest loss in the present day led to different biodiversity responses, escalating gains in certain species and losses in others.The pace at which biodiversity responds to forest loss varies from a few years, as is the case for many short-lived grasses, light-loving plants and insects, to decades for long-living trees and larger birds and mammals.For long-lived species, the effects of forest loss do not happen right away and could take decades to become apparent in the biodiversity data that scientists collect.Gergana Daskalova, PhD student in the School of GeoSciences at the University of Edinburgh and lead author of the study, said: "Biodiversity, the types of species like different plants and animals around the world, is always changing and the species we see on our forest walks today are likely different from the ones we saw growing up."We're harnessing the power of generations of scientists recording data as they walk through forests. This allowed us to find signals amidst the noise and pick apart the influence of forest loss from the natural variation in biodiversity over time."Surprisingly, we found that forest loss doesn't always lead to biodiversity declines. Instead, when we lose forest cover, this can amplify the ongoing biodiversity change. For example, if a plant or animal species was declining before forest loss, its decline becomes even more severe after forest loss. That same intensification of the signal was also true for increasing species."Changes in the biodiversity of the planet's forests matter because they will echo through how these landscapes look, the types of species they support and the benefits that forests provide for society like clean air and water."Dr Isla Myers-Smith, co-senior author, from the School of GeoSciences at the University of Edinburgh, continued: "To get a global picture of how the planet is changing we need to combine different types of information from observations of plants and animals on the ground through to satellite records of ecosystem change from space. Our study brings together these two perspectives to make new insights into how biodiversity responds when forests are lost around the world."Ecology is being reshaped by the new tools available to us as researchers. From satellite observations through to high-performance computers, we ecologists can now ask questions with larger and more complex datasets. We are now coming to a new understanding of how ecosystems are responding to human impacts around the planet."Dr Maria Dornelas, co-senior author from the School of Biology at the University of St Andrews, added: "Humans are undoubtedly changing the planet. Yet, global analyses of how biodiversity is changing over time, like our study, are revealing biodiversity changes are nuanced and variable."With a better understanding of the different ways, both positive and negative, in which forest loss influences biodiversity, we can improve future conservation and restoration of global ecosystems. Only with collaborative science combining datasets from around the world can we assess both the state of the world's forests, as well as the millions of plants and animals they support.Â 
Did you know that key components for things like wind turbines, LEDs and rechargeable batteries rely heavily on a group of metals known as rare-earth elements and yttrium (REY)? At present, the world's supply of these metals mainly comes from mines in China; however, a large deposit near the Japanese island of Minamitorishima could soon help satisfy the ever-increasing demand. But how did the REY deposit get there and why that location?"That story begins back in time in the Eocene epoch 34.5 million years ago, about halfway between now and the time of the dinosaurs," said Assistant Professor Junichiro Ohta. "At that time, several things happened that led to the REY deposit. Firstly, vast amounts of nutrients accumulated in the deep ocean. Secondly, the planet underwent cooling which altered sea currents, stirring up these nutrient deposits. The seamounts then caused upwellings of nutrients delivering them to the fish, which thrived as a result."Surprisingly, it's these fish, or rather their fossilized remains around Minamitorishima, that account for the REY deposits. As the fish died and underwent fossilization, REY metals in the environment, which would otherwise remain diffuse, accumulate inside the fossils. The research group had previously made this fish-to-REY deposit connection, but how and when the fossil deposits formed was an open question until now."I'm really pleased we made this discovery by looking at fragments of bones and teeth," said Ohta. "It was a difficult but satisfying task dating the deposits by comparing fossils we uncovered against a database of fossils with known ages. Equally so was another way we dated the deposits, by measuring the ratio of osmium isotopes in seawater trapped in REY-rich mud and comparing those to established records."The story of fish that became a useful resource for renewable energy technology is, ironically, parallel to that of the ancient organisms that became oil, which led to the very problems renewable technologies now aim to solve. And how could this study help?"Based on this new theory for the genesis of REY deposits in the ocean, we can improve the way we find future deposits," said Ohta. "We can target the feet of large seamounts on the seabed, many of which are distributed from the western North Pacific Ocean to the Central Pacific Ocean, so are in theory accessible to Japan."The REY sources by Minamitorishima could sufficiently satisfy current global demand for hundreds of years. However, getting to them may be extremely difficult as the deposit is just over 5 kilometers below sea level, and at present no resource has ever been commercially mined from such a depth. Additional or alternative sources may be useful so improved ways to find them would be a great benefit.
The ocean takes up large amounts of human-made COA study that was recently published in the scientific journal Ocean acidification negatively impacts organisms that build calcium carbonate skeletons and shells. In sufficiently acidic waters, these shells become unstable and begin to dissolve. "Our results suggest that it will be more difficult for Arctic organisms to adapt to ocean acidification than previously expected," says co-author Lester Kwiatkowski. A loss of these organisms is likely to impact the entire Arctic food chain up to fish and marine mammals.The international research team exploited the large divergence in simulated Arctic Ocean carbon uptake by current climate models. The researchers found a physical relationship across the models between the simulation of present-day Arctic sea surface densities and associated deep-water formation, with greater deep-water formation causing enhanced transport of carbon into the ocean interior and therefore enhanced acidification. Using measurements of Arctic sea surface density the research team was able to correct for biases in the models and reduce the uncertainty associated with projections of future Arctic Ocean acidification.
Sea ice surrounding Antarctica provides an important habitat for many species including penguins and seals, which rely on it to access food and to breed.An international team of researchers studied satellite records of sea ice extent and weather analyses starting in the late 1970s to understand why summer sea ice in the Weddell Sea area of Antarctica has reduced by a third over the last five years. They found that ice loss occurred due to a series of severe storms in the Antarctic summer of 2016/17, along with the re-appearance of an area of open water in the middle of the 'pack ice' (known as a polynya), which had not occurred since the mid-1970s.Lead author Professor John Turner, a climate scientist at British Antarctic Survey, says:"Antarctic sea ice continues to surprise us. In contrast to the Arctic, sea ice around the Antarctic had been increasing in extent since the 1970s, but then rapidly decreased to record low levels, with the greatest decline in the Weddell Sea. In summer, this area now has a third less sea ice, which will have implications for ocean circulation and the marine wildlife of the region that depend on it for their survival."The ocean around Antarctica freezes and doubles the size of the continent in the austral winter, with the sea ice extent reaching over 18 million square kilometres by late September. Through the spring and summer, the sea ice almost completely melts in most parts of the Antarctic, with only the Weddell Sea retaining a significant amount of sea ice.There are few storms around the Antarctic in the austral summer, but in December 2016, a number of intense and unseasonal storms developed in the Weddell Sea and drew warm air towards the Antarctic, melting a large amount of sea ice. The ice-free ocean absorbed energy from the Sun and then created a warm ocean temperature anomaly that still persists today.The winter of 2016 also saw the development of a polynya in the Weddell Sea, a large area of open water within the sea ice, which also contributed to the overall decline in sea ice extent. This polynya was created by the strong winds associated with the storms and unprecedented warm ocean conditions.This recent rapid sea ice loss is affecting both the Weddell Sea ecosystem and the wider Antarctic wildlife/plants and animals. Many species, ranging from tiny ice algae and shrimp-like crustaceans called krill to seabirds, seals and whales, are highly adapted to the presence of sea ice. If the drastic changes observed continue, they will have repercussions throughout the food chain, from affecting nutrients to the reduction of essential habitat for breeding and feeding for vast numbers of animals, such as ice seals and some species of penguins.Author and ecologist Professor Eugene Murphy from British Antarctic Survey says:"The dramatic decline in sea ice observed in the Weddell Sea is likely to have significant impacts on the way the entire marine ecosystem functions. Understanding these wider consequences is of paramount importance, especially if the decline in ice extent continues."Because of the large year-to-year variability in Antarctic sea ice extent the scientists cannot be sure if the ice in the Weddell Sea will in the short-term recover to the values seen before 2016 or whether they are seeing the start of the expected long-term decline of sea ice.
Researchers at Virginia Tech are part of a multi-institutional group using mathematical techniques with ocean models and experiments to better understand near-surface flow patterns and hidden flow structures. With more accurate modeling data, response teams can better predict the search area grid from the air, and reduce emergency response time when lives are on the line.Throughout this study, published in "From the moment they are alerted that someone is lost, search and rescue teams use sophisticated software to try to pinpoint the last known location in the water, factor in how much time has passed, and make their best prediction on how far they have drifted," said Shane Ross, professor in the Kevin T. Crofton Department of Aerospace and Ocean Engineering. "By improving the modeling of drifting objects in unsteady currents, search teams will have more efficient probability computations that enable them to set a tighter search grid and make faster, safer rescues."Current flow models used in search and rescue operations factor in ocean dynamics, weather prediction, and in-situ observations, such as self-locating datum marker buoys deployed from air. According to the research team, even with high-resolution ocean models and improved weather prediction, search and rescue planning is still based on conventional practices, and rescuers rely on their hunches as much as sophisticated prediction tools.Computational tools can predict how particles or objects are transported and reveal areas of the flow where drifting objects are likely to converge. In engineering terms, these patterns are called Lagrangian coherent structures. Unfortunately, calculating Lagrangian structures can often be time-consuming and computationally expensive.For use in disaster response scenarios, transient attracting profiles are easily interpreted and can be computed and updated instantaneously from snapshots of ocean velocity data. This eliminates very expensive and timely computation, especially when short-time predictions are critically important in search and rescue. After six hours, the likelihood of rescuing people alive drops significantly.These attracting profiles, where persons in the water are likely to collect, provide continuously updated and highly specific search paths. The inset shows a migrant boat that capsized on April 12, 2015 in the Mediterranean Sea.In order to prove the predictive influence of transient attracting profiles in coastal waters ? -- or identify the regions where objects or people are most likely to accumulate over a two- to three-hour period of time ? -- the research team conducted multiple field experiments off the coast of Martha's Vineyard in Massachusetts.Using both Coastal Ocean Dynamics Experiment drifters and 180-pound OSCAR Water Rescue Training manikins, targets were released around areas of predicted transient attracting profiles with GPS tracking devices that reported location every five minutes. Even without accounting for wind-drag or inertial effects, the researchers observed that the TRAPs invariably attracted the floating drifters and manikins in the water over a two- to three-hour period.Identifying transient attracting profiles on ocean surface velocity data can also have significant impact on the containment of environmental disasters, such as catastrophic oil spills. TRAPs provide critical information for environmental hazard response teams and have the potential to limit the spread of toxic materials and reduce damaging impact on the surrounding ecological systems.
Carolin Frueh is among only a handful of researchers who have persisted in using a complex technique that can diagnose a problem from thousands of miles away based on how the satellite reflects sunlight."While you're driving a car, you can't get out of the car to check if something has fallen off or gotten damaged. But you know that there might be a problem," said Frueh (pronounced "free"), an assistant professor in Purdue University's School of Aeronautics and Astronautics."An operator might notice that a satellite is unstable or not charging properly. An outside perspective can tell if it's because something broke off, or if a panel or antenna is not properly oriented, for example."Not diagnosing the problem increases chances of losing or not being able to reestablish communication with the satellite. When communication is lost, a satellite could become pieces of debris that stay in space for hundreds of years or indefinitely unless actively removed.This "space junk" poses a danger to other spacecraft. There are about 100,000 pieces of debris larger than a penny orbiting Earth, according to a U.S. Strategic Command database.Space is a vacuum that immediately puts stress on a satellite. Constant transitions between the deep cold of Earth's shadow and the extreme heat of the sun also take a toll over time."You know everything about a satellite when it's on the ground. But that configuration changes because, to carry the satellite up, parts of it need to be folded in. Once in space, you want the panels unfolded, stably oriented toward the sun and the antenna pointed toward Earth," Frueh said."The longer a satellite is out there, the less you know about it."Satellites are almost always illuminated by the sun, apart from short transitions to Earth's shadow. The light that a satellite reflects can help reveal the solution to a structural malfunction.The method calls for using telescopes on Earth to collect the light reflected by a satellite or one of its parts. Because satellites are far away, these objects might simply appear as white dots even on a telescope image, similar to stars on a night sky.Changes in the brightness of a "dot" over time are recorded as light curves. These light curves are then processed and used to extract information about an object's appearance or rotational state.A video describing this research at Purdue is available on YouTube at Light curves could be a less expensive and more practical way to identify satellite problems compared with radar. While radar can get a more detailed image of a satellite if conditions are favorable and the satellite is at low altitudes, light curves can provide information no matter how far away the satellite is from Earth's surface. Light curves also passively rely on sunlight, whereas radar actively illuminates an object to make it visible.The more complex an object is, the harder it is to estimate or solve for what the object looks like using light curves. The results also can be ambiguous; what if a satellite component just looks broken because it's casting a shadow on itself?Identifying and characterizing human-made objects with light curves is so mathematically complex that more researchers, instead, use the technique to study asteroids. As natural bodies, asteroids have less diverse materials on the surface and fewer sharp edges, making the math somewhat simpler.But even partial answers from light curves could provide valuable information about a satellite.In 2015, Frueh's lab observed a mystery object known simply as "WT1190F" using the Purdue Optical Ground Station telescope. She and her collaborators discovered from light curves and associated modeling that the object was almost certainly human-made and a likely candidate for a piece of "Snoopy," a missing Apollo 10 lunar module. The mission was part of a test run ahead of the Apollo 11 landing in 1969, when Neil Armstrong walked on the moon.A team of astronomers confirmed that the findings suggested the object came from Snoopy. Successes like these show that improving space object identification with light curves might be worth the struggle.Â  "It matters when we can say with 80% certainty what an object is, even though getting that answer can be extremely difficult. It would be far less helpful, but easier, to give a hundred different answers for what an object is, all with about 1% probability," Frueh said.Frueh's lab is working on improving the likelihood that a light curve successfully identifies and characterizes both simple and complex space objects.The goal is that in five to 10 years, the technique could not only reliably assist a satellite operator, but also provide full shape and rotation models even when no information or guesses about the object are available. These models would more clearly show the different surface materials and sharp edges of satellites, making them easier to identify.With funding from the Air Force Office of Scientific Research, Frueh is developing ways to use light curves to increase knowledge of human-made objects in the absence of information from a satellite operator.Information that light curves provide about satellites also could improve how they are designed in the future. Frueh's lab has identified objects orbiting Earth that appear to be the gold foil of satellites flaking off over time. These flakes could dangerously create tiny objects that are difficult to track."The whole idea is improving space situational awareness," Frueh said.
Read the paper, "Herbaria macroalgae as a proxy for historical upwelling trends in Central California," at the journal Deep marine canyons, a myriad migratory species and an abundant source of nutrients supplied by natural upwelling have attracted the massive concentration of marine science currently focused on Monterey Bay. Despite this proliferation of study and observation here, scientists had always been limited in their attempts to establish baselines of ecosystem health by the extent of available data, which in Monterey Bay extends back to 1946 when the patterns of its natural upwelling started being recorded."This part of California's Central coast is renowned for the sheer amount of marine life it can sustain. Even through the pressures of the past century, Monterey Bay is still teeming with birds, whales, fishes and seaweeds," said Monterey Bay Aquarium Chief Scientist Kyle Van Houtan. "These plants and animals were around long before scientists, so we thought if we could find historical samples we might learn something by extracting the information stored in their tissues."Using that approach, the Ocean Memory Lab generates new information about the ocean's past by combing through scientific collections, museums, and other historical archives. These repositories contain specimens of marine life that have data on ocean conditions locked within their fronds, feathers, shells and other tissues. Aquarium scientists use a variety of chemical analyses to unlock the data held within sample tissues to provide more accurate baselines, and help inform decisions intended to maintain or restore ocean health."We were able to add nearly seven decades of data, extracted from seaweed samples more than a century old, to better understand historical changes in Monterey Bay," said Emily Miller, the lead author of the study for the Aquarium and now a researcher at partner institution, the Monterey Bay Aquarium Research Institute. "This information offers us a new perspective on one of the features that makes Monterey Bay home to such diversity, its upwelling cycles. Documenting these patterns helps us to understand shifts in the foundation of the food web, and to make more informed conservation decisions in the future."Working with colleagues from Stanford University's Hopkins Marine Station and the University of Hawaii, Aquarium researchers based the study on data from the chemical analysis of pressed seaweed samples sourced from herbarium collections from several institutions, dating back to 1878, as well as freshly collected specimens. The samples analyzed came from six species of seaweed, also called macroalgae, that included giant kelp, rockweed, sea lettuce, and grape tongue."Izzy Abbott, who was professor of biology at Hopkins, helped to curate and build our collection of algae for over 25 years," said Stephen Palumbi, a professor of marine biology at Stanford University's Hopkins Marine Station. "She and the algae biologists that came before her knew that preserving specimens was vital. But it took this new approach from Monterey Bay Aquarium to dig into the very atoms of the algae and ask the kelp forest questions about the history of the oceans."Researchers calibrated the accuracy of their chemical analysis by comparing nitrogen stable isotopes from a red algae, Gelidium, with the Bakun upwelling index, a record of the natural Monterey Bay phenomenon going back to 1946. They found a high correlation between the index and data derived from the algae samples from 1946-2018, which demonstrated the nitrogen isotopes in the algae could be used to determine the upwelling pattern. Researchers then used older algae specimens to extend the Bakun upwelling index back to 1878, 70 years before it began being monitored.One of the research's novel findings, drawn from the additional seven decades of information offered within the seaweed samples, shed more light into ocean conditions in Monterey Bay during the sardine fishery's famous boom and bust in the 1940s and 1950s. Researchers documented poor upwelling conditions in Monterey Bay in the years immediately prior to the crash. This discovery adds a new dimension to an understanding of what role ecosystem changes may have played in the shift from a sardine-dominated system to one that is anchovy-dominated. It could also further inform how fishery management practices are implemented to respond to environmental conditions, something known as ecosystem-based management.
For this study, the international team led by Elkins-Tanton focused on the volcaniclastic rocks (rocks created by explosive volcanic eruptions) of the Siberian Traps, a region of volcanic rock in Russia. The massive eruptive event that formed the traps is one of the largest known volcanic events in the last 500 million years. The eruptions continued for roughly two million years and spanned the Permian-Triassic boundary. Today, the area is covered by about three million square miles of basaltic rock.This is ideal ground for researchers seeking an understanding of the Permo-Triassic extinction event, which affected all life on Earth approximately 252 million years ago. During this event, up to 96% of all marine species and 70% of terrestrial vertebrate species became extinct.Calculations of sea water temperature indicate that at the peak of the extinction, the Earth underwent lethally hot global warming, in which equatorial ocean temperatures exceeded 104 degrees Fahrenheit. It took millions of years for ecosystems to be re-established and for species to recover.Among the possible causes of this extinction event, and one of the most long-hypothesized, is that massive burning coal led to catastrophic global warming, which in turn was devastating to life. To search for evidence to support this hypothesis, Elkins-Tanton and her team began looking at the Siberian Traps region, where it was known that the magmas and lavas from volcanic events burned a combination of vegetation and coal.While samples of volcaniclastics in the region were initially difficult to find, the team eventually discovered a scientific paper describing outcrops near the Angara River. "We found towering river cliffs of nothing but volcaniclastics, lining the river for hundreds of miles. It was geologically astounding," says Elkins-Tanton.Over six years, the team repeatedly returned to Siberia for field work. They flew to remote towns and were dropped by helicopter either to float down rivers collecting rocks, or to hike across the forests. They ultimately collected over 1,000 pounds of samples, which were shared with a team of 30 scientists from eight different countries.As the samples were analyzed, the team began seeing strange fragments in the volcaniclastics that seemed like burnt wood, and in some cases, burnt coal. Further field work turned up even more sites with charcoal, coal, and even some sticky organic-rich blobs in the rocks.Elkins-Tanton then collaborated with fellow researcher and co-author Steve Grasby of the Geological Survey of Canada, who had previously found microscopic remains of burnt coal on a Canadian arctic island. Those remains dated to the end-Permian and were thought to have wafted to Canada from Siberia as coal burned in Siberia. Grasby found that the Siberian Traps samples collected by Elkins-Tanton had the same evidence of burnt coal."Our study shows that Siberian Traps magmas intruded into and incorporated coal and organic material," says Elkins-Tanton. "That gives us direct evidence that the magmas also combusted large quantities of coal and organic matter during eruption."And the changes at the end-Permian extinction bear remarkable parallels to what is happening on Earth today, including burning hydrocarbons and coal, acid rain from sulfur, and even ozone-destroying halocarbons."Seeing these similarities gives us extra impetus to take action now, and also to further understand how the Earth responds to changes like these in the longer term," says Elkins-Tanton.
The study examined fossil reefs near to the now-submerged Red Sea shorelines that marked prehistoric migratory routes from Africa to Arabia. The findings suggest this coast offered the resources necessary to act as a gateway out of Africa during periods of little rainfall when other food sources were scarce.The research team, led by the University of York, focused on the remains of 15,000 shells dating back 5,000 years to an arid period in the region. With the coastline of original migratory routes submerged by sea-level rise after the last Ice Age, the shells came from the nearby Farasan Islands in Saudi Arabia.The researchers found that populations of marine mollusks were plentiful enough to allow continuous harvests without any major ecological impacts and their plentiful availability would have enabled people to live through times of drought.Lead author, Dr Niklas Hausmann, Associate Researcher at the Department of Archaeology at the University of York, said: "The availability of food resources plays an important role in understanding the feasibility of past human migrations -- hunter-gatherer migrations would have required local food sources and periods of aridity could therefore have restricted these movements."Our study suggests that Red Sea shorelines had the resources necessary to provide a passage for prehistoric people."The study also confirms that communities settled on the shorelines of the Red Sea could have relied on shellfish as a sustainable food resource all year round.Dr Hausmann added: "Our data shows that at a time when many other resources on land were scarce, people could rely on their locally available shellfish. Previous studies have shown that people of the southern Red Sea ate shellfish year-round and over periods of thousands of years. We now also know that this resource was not depleted by them, but shellfish continued to maintain a healthy population."The shellfish species found in the archaeological sites on the Farasan Islands were also found in abundance in fossil reefs dating to over 100 thousand years ago, indicating that these shellfish have been an available resource over longer periods than archaeological sites previously suggested.Co-author of the study, Matthew Meredith-Williams, from La Trobe University, said: "We know that modelling past climates to learn about food resources is extremely helpful, but we need to differentiate between what is happening on land and what is happening in the water. In our study we show that marine foods were abundant and resilient and being gathered by people when they couldn't rely on terrestrial food."
When present, tanaids are often one of the dominant animals in the community. Due to their sheer number, tanaids are likely to play important ecological roles but information on their biology remains elusive. The knowledge gaps include answers to the most basic questions -- How many species are there? What are their names? Experts have estimated that there could be up to 57,000 tanaidacean species worldwide. Currently, however, less than 1,500 species have been described, and the majority of these are in the temperate environments.Research Associate Mr Chim Chee Kong and Research Assistant Ms Samantha Tong from the Tropical Marine Science Institute at the National University of Singapore (NUS) are on a quest to discover more of these nameless taxa, specifically in the relatively species-rich but poorly studied tropical Indo-Pacific.Both researchers recently described two new species found in the abyssal polymetallic nodule fields in the eastern Pacific Ocean during a 2015 expedition. One of them was named Unispinosus eopacificus after the locality of where it was discovered, and the other was named Portaratrum birdi in honour of a leading tanaidacean taxonomist. They also erected the genus Unispinosus in the same paper, which was published in the journal The discovery of these two new species are of significant importance for environmental management because they were found in the Clarion-Clipperton Zone (CCZ), an understudied area in the middle of the Pacific Ocean characterised by polymetallic nodule fields. These fields contain commercially valuable metals such as nickel, copper, and rare earth elements that were formed over millions of years."Data on the biodiversity in this resource-rich region can allow the International Sea Authority to make well-informed decisions on whether to prioritise certain areas for conservation," explained Ms Tong.Many tanaids new to science were also uncovered during another deep-sea expedition in South Java in 2018, and are in the process of being described by Mr Chim and Ms Tong.With access to a large amount of local material, primarily collected during the Comprehensive Marine Biodiversity Survey conducted in 2013, the two NUS researchers have also been able to identify more tanaids in local waters. To date, Mr Chim has identified more than 20 species of tanaids from local waters and, as a result, raised the current knowledge of our natural heritage. Prior to this study, only one tanaid species had been formally recorded from Singapore waters, based on specimens that were collected in the 1900s.Last year, he and Ms Tong described an unusual tanaidacean species found in Singapore that were living inside dead barnacles, which is a novel microhabitat recorded for this group of crustaceans. The findings on the newly named Xenosinelobus balanocolus were reported in the journal "Taxonomic studies are extremely time-consuming, especially for microscopic animals such as tanaids, but at the same time, they are very rewarding as the results provide the strong foundation for further scientific hypotheses to build upon," said Mr Chim, who is also a part-time doctoral student at the Department of Biological Sciences at the NUS Faculty of Science.
The research team's findings -- published Monday, June 15 in Arctic Ocean sea-ice loss is a critical consequence of climate change. As sea ice continues to melt in the western Arctic Ocean, more fresh water is entering the upper portion of the water in the Canada Basin, which sits off the coast of Alaska and Canada, south of the Chukchi Shelf.This summertime melt cycle is exacerbating seasonal changes and increasing the amount of carbon dioxide present in the water's topmost layer, which comprises the upper 70 feet of the water column. This is reducing the basin's capacity to remove carbon dioxide from the atmosphere.Prevailing thought, based on data measurements from under the ice and in newly melted ocean margin areas in the 1990s and early 2000s, had suggested that when the ice melted it would allow the Arctic Ocean to draw large amounts of carbon dioxide out of the atmosphere, acting as a carbon sink and helping to mitigate greenhouse gases. However, this may not be the case in all places, particularly in the Canada Basin where summer ice retreat has advanced into the deep basin since 2007.The research team's latest findings are based on an analysis of over 20 years of global data sets collected between 1994-2017 by researchers across the United States, China, Japan and Canada. They provide a more accurate depiction of what is happening in this region and build on Cai's previous work from 2010, which indicated that carbon dioxide levels at the sea surface increase rapidly and unexpectedly toward levels found in the atmosphere in newly ice-free Arctic Ocean basins.For example, the research team's work showed that as the ice breaks up and melts in the Canada Basin, this meltwater lays on top of the sea surface, creating a "blanket" of sorts that inhibits the ocean's ability to absorb carbon dioxide from the atmosphere into the deep ocean and store it there. Cai's team refers to this phenomenon as a "new normal" that is created by extreme seasonal warming and meltwater in the region."As carbon dioxide accumulates in the surface layer of the water from melting ice, the amount of carbon dioxide this area of the Arctic Ocean can take from the atmosphere will continue to shrink," said Cai, the Mary A.S. Lighthipe Professor in the College of Earth, Ocean and Environment. "We predict by 2030, the Canada Basin's ability to serve as a carbon sink will be really minimal."Additionally, this rapid increase of carbon dioxide content in the basin may have rapidly acidified the surface water, a process that can endanger marine calcifying organisms and disrupt ecosystem functioning there.In stark contrast, farther south in the shallow Chukchi Sea, the amount of carbon dioxide in the water's topmost layer remains very low, much lower than what is present in the atmosphere. This means that as air passes over the water's surface, the sea can more quickly absorb carbon dioxide from the air.The researchers suggest that this difference is the result of high biological production in the Chukchi Sea due to rich nutrients being transported there on currents coming from the Pacific Ocean since the Bering Strait has opened up due to earlier ice loss. These nutrients enable abundant growth of phytoplankton and other marine organisms that form the base of the marine food web and feed the broader ecosystem. Phytoplankton also consume carbon dioxide dissolved in the water during photosynthesis, allowing more carbon dioxide to be taken from the surrounding atmosphere.The research team suspects that the Chukchi Sea will become a larger carbon sink in the future and impact the deep ocean carbon cycle and ecosystem, while the Canada Basin likely will remain less so as sea ice in the region continues to melt and change the water chemistry.According to Lisa Robbins, a retired senior scientist with the United States Geological Survey (USGS) and a co-author on the paper, these changes could have important implications for organisms in the Arctic. For instance, Arctic cod is an important fishery in the western Arctic that contributes to the region's overall economy and serves an important role in the marine food web as a food source for other organisms, such as Beluga whales and ringed seals. Biologists have noted that as temperature and sea ice melt have increased, Atlantic cod are responding by moving farther north. Changing water chemistry also may be playing a role, said Robbins, who led three expeditions to study the region's water chemistry in the Arctic aboard the United States Icebreaker R/V Healy while with the USGS.Long-term data sets, such as those used in this study, are key to understanding and predicting future changes in the Arctic."The amount of insight we get from these data sets into how our earth-ocean works is tremendous. If scientists hadn't collected data in 1994, we wouldn't have a place to start and compare with," said Robbins, now a courtesy professor in the College of Marine Science at University of South Florida.A 2019 article in Wired magazine found that in northern Canada near Greenland, glacial meltwater seems to be aiding watersheds in absorbing carbon dioxide from the atmosphere. While alone it cannot counterbalance the amount of carbon dioxide in the atmosphere due to carbon emissions, it is an important illustration that the changes aren't uniform and the subsequent effects -- positive and negative -- are the result of a complex combination of multiple different drivers. Further research and more international collaborative efforts can help to answer challenging unanswered questions.As sea-ice loss accelerates, the researchers expect these seasonal variations will cause the ocean water in the Canada Basin to have high levels of carbon dioxide and become increasingly acidic. This will further reduce the basin's capacity to take up carbon dioxide from the atmosphere and potentially reduce its capacity to mitigate climate change.While this problem might seem very far away from Delaware, it's important to remember that the ocean is one global system with circulation currents that transport water around the world, even to the Atlantic Ocean on the East Coast. And greenhouse gases are a global issue.Understanding how fundamentally important ice melt is to driving carbonate chemistry and seasonal changes in carbon dioxide in this region of the Arctic Ocean will help advance the science in this area, maybe not immediately but over the long-run, said Cai."We are trying to understand the processes at work and if the Arctic Ocean will continue to be a large carbon sink, while providing data that can help Earth systems modelers to predict global changes to the carbon cycle, and the ocean's biology and water chemistry," Cai said.This work is funded by multiple nations, including Cai's work which is supported through the National Science Foundation's Arctic Natural Science Program.Co-authors on the paper include researchers at The Third Institution of Oceanography (China), Columbia University, University of Montana, Ocean University of China, Japan Agency for Marine-Earth Science and Technology, University of South Florida and the International Arctic Research Center.
Lasting from approximately 1,000 to 540 million years ago, the dramatic chapter is an important part of Earth's 4.5-billion-year history. Known as the Neoproterozoic Era, the period of severe glaciation was a time when multicellular organisms were beginning to diversify and spread across the planet.Many researchers posit that ice may have covered every surface of the planet, stretching from the poles all the way to the hot tropics of the equator -- a hypothesis known as "Snowball Earth."How was it possible there was global ice -- even in the warmest areas of Earth?Researchers from the University of Rochester are shedding new light on that question. By analyzing mineral data left by glaciers before the onset of the Neoproterozoic Era, Scott MacLennan, a postdoctoral research associate in the lab of Mauricio Ibanez-Mejia, an assistant professor in the Department of Earth and Environmental Sciences, present the first geological evidence that Earth may have had a cool climate before Snowball Earth.The study, published in "This is a fascinating period, as these dramatic environmental changes happened right as the first true animals were beginning to appear and evolve on Earth," Ibanez-Mejia says.A critical aspect of understanding a period of planetwide glaciation is determining what the climate was like before Snowball Earth. Computer models indicate that a cool global climate was necessary in order to initiate a Snowball Earth state, but such a state has not been confirmed by geological evidence. Instead, geological evidence has previously suggested that Earth had a warm and ice-free climate immediately prior to the Neoproterozoic glaciation.While scientists don't know the exact mechanisms that may have caused Snowball Earth, they suspect that whatever they were, the mechanisms involved a massive decrease in atmospheric carbon dioxide concentrations. There are several scenarios in which the atmospheric carbon dioxide may have decreased. They include an increase in biomass in the oceans, which may have taken carbon dioxide out of the atmosphere and turned it into organic matter, or an increase in the weathering of the continental crust, which also takes up carbon dioxide.In order to determine whether these scenarios are feasible, however, it's critical to know more about Earth's climate before the massive glaciation events started."If the Earth was very hot, it would mean the ocean was storing a lot of heat, which would take a lot of time to get rid of in order to create a Snowball Earth," MacLennan says.Scientists can determine Earth's climate at points in time by studying rocks that were deposited at different times throughout Earth's history. MacLennan and his colleagues used zircon dating methods to very precisely date glacial rocks found in modern-day Virginia. Paleomagnetic data, which allows researchers to determine where the continents were located thousands and even millions of years ago, have established that Virginia was located in the middle of a supercontinent within the tropics while the glacial rocks were being deposited. The supercontinent later broke up into smaller parts.The researchers discovered that the glacial rocks were actually deposited 30 million years before the first Snowball Earth. The observation was surprising because they had expected the glacial rocks to be related to the Snowball Earth event. Instead, the discovery indicates that there were glaciers in the tropics near the equator -- albeit at potentially high altitudes -- even before Snowball Earth."The planet always gets colder away from the tropics and toward the poles because Earth receives most of its incoming sunlight at the equator," MacLennan says. "If there are glaciers in the tropics, the rest of the planet must have also been very cold. This means that our previous vision of a hot, humid world before the Snowball Earth is probably incorrect."The potential trigger mechanism for the massive global cooling therefore may not have been as extreme as some researchers believe; the planet didn't immediately turn from a warm state to a frozen state but instead appears to have experienced a more gradual cool-off into a Snowball Earth state.This research raises interesting questions about what Earth was really like 800 to 700 million years ago, before Snowball Earth events, during a time when interesting biological innovations were taking place as multicellular organisms were beginning to diversify."There have been a lot of questions about how multi- and single-cellular life forms would survive the Snowball Earths, especially if there was a rapid transition from a hot greenhouse world," MacLennan says. "Our estimates for pre-Snowball climate imply the planet was probably colder than the modern world, which means there may have been ample cold environments at high latitude and altitude where organisms could have adapted to these cold conditions."
The finding is the latest in a pattern of discoveries that are leading experts to contemplate a Canada-Australia connection not previously considered. Paleontologists Bruce Archibald of Simon Fraser University and the Royal British Columbia Museum and Vladimir Makarkin of the Russian Academy of Sciences in Vladivostok published their findings in According to Makarkin, the fossil is part of the "split-footed lacewing" family. Little is known about this group over the 66-million-years following the extinction of the dinosaurs. "These fossils are rare," he says. "This is only the fourth one found from this time-span world-wide, and it's the most completely preserved. It adds important information to our knowledge of how they became modern."The paleontologists identified the fossil by the characteristic network of veins covering its wings. They emphasize that fossils like the new lacewing species help in understanding large-scale patterns of the modern distribution of life across the globe.Previous fossil insects of this age found in B.C. and neighbouring Washington have shown connections with Pacific-coastal Russia to the west and with Europe to the east -- patterns that are not surprising since the northern continents were connected then."Fifty million years ago, sea levels were lower, exposing more land between North America and Asia, and the Atlantic Ocean had not widened, leaving Europe and North America still joined across high latitudes," says Archibald. He explains that the far-north experienced warmer climates then as well, helping a variety of animals and plants to disperse freely between northern continents.The Australian connection is more puzzling though, as there is no such clear land connection. That continent was closer to Antarctica then and farther from Asia than today, leaving formidable ocean barriers for life to disperse between it and Canada's west coast.This lacewing joins other insect fossils from B.C. and Washington whose modern relatives only live in the Australian region. These include bulldog ants, a family of termites, and a kind of parasitoid wasp.Archibald says that "a pattern is emerging that we don't quite understand yet, but has interesting implications."The researchers suggest that the answer might be connected to climate. The forests of the ancient British Columbian temperate upland where this lacewing lived had very mild winters, in fact, probably without frost days.The climate of modern Australia shares these mild winters even in temperate regions. "It could be that these insect groups are today restricted to regions of the world where climates in key ways resemble those 50 million years ago in the far western Canadian mountains," says Archibald.Archibald and Makarkin emphasise that it's important to understand the little things in order to appreciate the big picture. "The more we know about these insects, the more we can piece together the history of how climate and the movement of continents have shaped global patterns of the distributions of life that we see in our modern world," says Makarkin."To understand where we are today and where we may be going with the big changes that we are seeing in global climates, we need to understand what's happened in the deep past."
Currently, scientists estimate that 5-15% of the carbon stored in surface permafrost soils could be emitted as the greenhouse gas carbon dioxide by 2100, given the current trajectory of global warming. This emission, spurred by microbial action, could lead to 0.3 to 0.4 degrees Celsius of additional global warming.But this estimation is missing a crucial path that carbon dioxide may be entering the atmosphere: sunlight.According to a University of Michigan study, organic carbon in thawing permafrost soils flushed into lakes and rivers can be converted to carbon dioxide by sunlight, a process known as photomineralization.The research, led by aquatic geochemist Rose Cory, has found that organic carbon from thawing permafrost is highly susceptible to photomineralization by ultraviolet and visible light, and could contribute an additional 14% of carbon dioxide into the atmosphere. Her team's study is published in the journal "Only recently have global climate models included greenhouse gases from thawing permafrost soils. But none of them contain this feedback pathway," said Cory, an associate professor of earth and environmental sciences."To get a number on how much carbon could be released from permafrost soils through oxidation, we have to understand what are the processes and what is the timescale: maybe this carbon is just so resistant to oxidation that, even if thawed out, it would just flow into the Arctic ocean and be buried in another freezer."This pathway has been debated because measuring how sunlight degrades soil carbon is difficult. Each wavelength of light has a different effect on soil organic carbon, as does the level of iron in the soil. To precisely measure how carbon dioxide is emitted when organic carbon is exposed to sunlight, Cory's co-corresponding author Collin Ward, a scientist at Woods Hole Oceanographic Institution and U-M alum, developed a method to measure each wavelength's effect on soil organic carbon. To do this, he built a new instrument that uses LED lights to mimic different wavelengths of the sun."This new LED-based method makes it far easier and cheaper to figure out how light-driven reactions vary for different wavelengths of the sun," Ward said. "After I built the instrument I immediately called Rose and told her that I wanted to first use it on permafrost samples."The researchers placed organic carbon leached from soil samples from six Arctic locations in the instrument, and then subjected the samples to the LED light. After the light exposure, they extracted the carbon dioxide cryogenically and used a mass spectrometer to measure the age and amount of carbon dioxide given off by the soil carbon.They found that not only did the wavelength of sunlight impact the amount of carbon dioxide released, the amount of iron in the sample did as well. Iron acted as a catalyst, increasing the reactivity of the soil."What we have long suspected is that iron catalyzes this sunlight-driven process, and that's exactly what our results show," Cory said. "As the total amount of iron increases, the amount of carbon dioxide increases."Cory's team also used carbon dating to age the soil organic carbon and the carbon dioxide emitted from it to demonstrate this oxidation was happening to ancient permafrost, not just soil that thaws annually. This is important because soil that thaws annually would release a much smaller amount of carbon dioxide than what's available in permafrost.The researchers found that it was between 4,000 and 6,300 years old, and by demonstrating how old the soil is, they show that permafrost carbon is susceptible, or labile, to oxidation to carbon dioxide."Not only do we have the first wavelength specific measurement of this sunlight-driven reaction but we have verification that it's old carbon that is oxidized to carbon dioxide," Cory said. "We can put to rest any doubt that sunlight will oxidize old carbon and we show what is controlling this process -- it's the iron that catalyzes the sunlight oxidation of ancient (or old) carbon."Including the U-M team's finding into climate change models means that -- conservatively -- there could be a release of 6% of the 100 billion metric tons of carbon currently stored in Arctic permafrost. If 6% doesn't sound like much, consider that's the carbon equivalent of approximately 29 million cars evaporating into the atmosphere.
It turns out, getting a true read on how long it takes for plastic to break down in the environment is tricky business, says Collin Ward, a marine chemist at Woods Hole Oceanographic Institution and member of the its Microplastics Catalyst Program, a long-term research program on plastics in the ocean."Plastics are everywhere, but one of the most pressing questions is how long plastics last in the environment," he says. "The environmental and human health risks associated with something that lasts one year in the environment, versus the same thing that lasts 500 years, are completely different."Knowing the fate of plastics may be tricky, but it's critical. Consumers need the information to make good, sustainable decisions; scientists need it to understand the fate of plastics in the environment and assess associated health risks; and legislators need it to make well-informed decisions around plastic bans.The long-standing mystery around the life expectancy of plastic goods has prompted a new study from Woods Hole Oceanographic Institution looking at how the lifetime estimates of straws, cups, bags, and other products are being communicated to the public via infographics. Ward, the lead author of a new paper published in the journal "The estimates being reported to the general public and legislators vary widely," says Ward. "In some cases, they vary from one year to hundreds of years to forever."On the other end of the spectrum, certain lifetime estimates seemed far too similar among the infographics. Of particular interest, Ward notes, were the estimates for how long fishing line lasts in the ocean. He says that all 37 infographics that included a lifetime for fishing line reported 600 years."Every single one said 600 years, it was incredible" he says. "I'm being a little tongue-in-cheek here, but we're all more likely to win the lottery than 37 independent science studies arriving at the same answer of 600 years for fishing line to degrade in the environment."In reality, these estimates didn't stem from actual scientific studies. Ward said he did a lot of digging to find peer-reviewed literature that was either funded, or conducted, by the agencies putting the information out there and couldn't find a single instance where the estimates originated from a scientific study. He and Reddy believe that while the information was likely well intentioned, the lack of traceable and documented science behind it was a red flag."The reality is that what the public and legislators know about the environmental persistence of plastic goods is often not based on solid science, despite the need for reliable information to form the foundation for a great many decisions, large and small," the scientists state in the paper.In one of their own peer-reviewed studies on the life expectancy of plastics published last year, Ward and his team found that polystyrene, one of the world's most ubiquitous plastics, may degrade in decades when exposed to sunlight, rather than thousands of years as previously thought. The discovery was made, in part, by working with researchers at WHOI's National Ocean Sciences Accelerator Mass Spectrometry (NOSAMS) facility to track the degradation of the plastic into gas and water phases, and with the aid of a specialized weathering chamber in Ward's lab. The chamber tested how environmental factors such as sunlight and temperature influenced the chemical breakdown of the polystyrene, the first type of plastic found in the coastal ocean by WHOI scientists nearly fifty years ago.Reddy feels that one of the biggest misconceptions surrounding the fate of plastics in the environment is that they simply break down in to smaller bits that hang around forever."This is the narrative we see all the time in the press and social media, and it's not a complete picture," says Reddy. "But through our own research and collaborating with others, we've determined that in addition to plastics breaking down into smaller fragments, they also degrade partially into different chemicals, and they break down completely into CO2." These newly identified breakdown products no longer resemble plastic and would be otherwise missed when scientists survey the oceans for missing plastics.Chelsea Rochman, a biologist at the University of Toronto who wasn't involved in the study, says that understanding the various forms of plastic degradation will be key to solving one of the enduring mysteries of plastic pollution: more than 99 percent of the plastic that should be detected in the ocean is missing."Researchers are beginning to talk about the global plastic cycle," says Rochman. "A key part of this will be understanding the persistence of plastics in nature. We know they break down into smaller and smaller pieces, but truly understanding mechanisms and transformation products are key parts of the puzzle."Overall, analyzing the infographics turned out to be an eye-opening exercise for the scientists, and unscored the importance of backing public information with sound science."The question of environmental persistence of plastics is not going to be easy to answer," says Ward. "But by bringing transparency to this environmental issue, we will help improve the quality of information available to all stakeholders -- consumers, scientists, and legislators -- to make informed, sustainable decisions."This research was funded by The Seaver Institute and internal funding from the WHOI Microplastics Catalyst Program.
That is the main finding of a new University of Wyoming study, which shows the benefits of migration are likely to decrease for mule deer and other migratory herbivores as drought becomes more common due to ongoing climate change.Drought reduces the availability of key food resources by shortening the duration of spring green-up -- and altering the progression of the "green wave" across the landscape.The study was conducted by a team of researchers working with lead author Ellen Aikens, a 2019 graduate of the Wyoming Cooperative Fish and Wildlife Research Unit at UW. The paper was published this week in Global Change Biology, a leading journal documenting the biological effects of global change."This research shows that climate change can alter the underlying distribution of food resources by compressing the time when optimal forage is available, which reduces the benefit of migration," Aikens says. "This work highlights an emerging threat to migratory mule deer and likely many other migratory species."Aikens' analysis combined 19 years of drought data going back to 2001, with a 2013-15 GPS dataset of mule deer migrations in the Wyoming Range.In a wet year, the study found that mule deer have access to newly sprouted springtime plants during an extended period, up to 120 days. That's a full four months when snow is melting, and runoff is saturating the soil and causing forage plants such as sticky purple geranium to emerge.Deer get a significant portion of their forage benefit for the entire year by following this green wave of plants, which, in wet years, progresses in an orderly fashion from low-elevation winter ranges to summer ranges in the high mountains.Previous work by Aikens has shown that mule deer are experts at "surfing the green wave" across the landscape. Their movements allow them to always be in the right place at the right time to consume plants at their peak green-up, when they are protein-rich and easy to digest.Access to green-up provides mule deer their best chance to recover from harsh winters and to replenish lost body fat. They need sufficient fat to rear young and survive the coming winter.In dry years, the green wave sweeps across the landscape in about half the time, roughly 60 days, the researchers found.In essence, the good times don't last as long.Although deer surf these altered green waves as best they can, they only have half the time -- only two months -- to eat plants at peak forage quality.The researchers found that drought also makes for more patchy migration routes, where the green-up does not occur in sequence from low to high elevation. Patterns of green-up in dry years were quicker, less wave-like and, consequently, provided less of a foraging benefit to migrating mule deer.One thing that didn't change in drought years was the remarkable ability of deer to move and track plants at the highest nutritional value. Deer "surfed" right along with these same peak waves of plant growth in wet years and in dry years. Even in drought, there was no "trophic mismatch," a situation where migration timing is mismatched with food resources.Though researchers hoped to find that some migration routes were buffered from drought effects -- perhaps those that traverse shady north-facing slopes -- they found such routes did not exist. Instead, the best migration routes that produced the most abundant forage and the longest duration of green-up in wet years also were the most severely impacted by drought."This is a globally important study, because the findings ought to be relevant across the temperate landscapes of North America and Europe," says Matthew Kauffman, director of the Wyoming Cooperative Fish and Wildlife Research Unit and a co-author of the study."This study has revealed an underappreciated mechanism by which climate change is altering green-up and making migration less profitable for ungulates," Kauffman says. "We are identifying a new threat for migrating ungulates, which will likely worsen as climate change continues."
The study, published in the journal "The encouraging takeaway from this study is that if we act quickly and decisively, there is a slim window in which we can still conserve roughly half of Earth's land in a relatively intact state," said lead author Jason Riggio, a postdoctoral scholar at the UC Davis Museum of Wildlife and Fish Biology.The study, published June 5 on World Environment Day, aims to inform the upcoming global Convention on Biological Diversity -- the Conference of Parties 15. The historic meeting was scheduled to occur in China this fall but was postponed due to the coronavirus pandemic. Among the meeting's goals is to establish specific, and higher, targets for land and water protection.Approximately 15 percent of the Earth's land surface and 10 percent of the oceans are currently protected in some form. However, led by organizations including Nature Needs Half and the Half-Earth Project, there have been bold global calls for governments to commit to protecting 30 percent of the land and water by 2030 and 50 percent by 2050.Intact natural lands across the globe can help purify air and water, recycle nutrients, enhance soil fertility and retention, pollinate plants, and break down waste products. The value of maintaining these vital ecosystem services to the human economy has been placed in the trillions of U.S. dollars annually.The coronavirus pandemic now shaking the globe illustrates the importance of maintaining natural lands to separate animal and human activity. The leading scientific evidence points to the likelihood that SARS-CoV2, the virus that causes the disease COVID-19, is a zoonotic virus that jumped from animals to humans. Ebola, bird flu and SARS are other diseases known to have spilled over into the human population from nonhuman animals."Human risk to diseases like COVID-19 could be reduced by halting the trade and sale of wildlife, and minimizing human intrusion into wild areas," said senior author Andrew Jacobson, professor of GIS and conservation at Catawba College in North Carolina.Jacobson said that regional and national land-use planning that identify and appropriately zone locations best suited to urban growth and agriculture could help control the spread of human development. Establishing protections for other landscapes, particularly those currently experiencing low human impacts, would also be beneficial.Among the largest low-impact areas are broad stretches of boreal forests and tundra across northern Asia and North America and vast deserts like the Sahara in Africa and the Australian Outback. These areas tend to be colder and/or drier and less fit for agriculture."Though human land uses are increasingly threatening Earth's remaining natural habitats, especially in warmer and more hospitable areas, nearly half of Earth still remains in areas without large-scale intensive use," said co-author Erle Ellis, professor of geography at the University of Maryland-Baltimore County.Areas having low human influence do not necessarily exclude people, livestock or sustainable management of resources. A balanced conservation response that addresses land sovereignty and weighs agriculture, settlement or other resource needs with the protection of ecosystem services and biodiversity is essential, the authors note."Achieving this balance will be necessary if we hope to meet ambitious conservation targets," said Riggio. "But our study optimistically shows that these targets are still within reach."
This applies particularly to the deep sea that is only poorly explored itself. Plastic objects that are found by chance with the help of deep-sea robots or other underwater vehicles are difficult to date. However, during an expedition with the German research vessel SONNE in 2015, researchers from the GEOMAR Helmholtz Centre for Ocean Research Kiel, the Max Planck Institute for Marine Microbiology in Bremen and the Kiel University were able to recover several pieces of waste from the seabed of the Eastern Pacific Ocean in a depth of more than 4000 metre. Conducting a little detective work allowed to constrain the age of deposition quite accurately. For the first time, this offered the opportunity to conduct a long-term study on plastic degradation in the deep sea. The study was published today in the international journal In reality, in 2015 the team was out in the Pacific about 440 nautical miles (815 km) off the coast of Peru to investigate another long-term experiment in the so-called DISCOL area. There, German scientists had ploughed a piece of seafloor in 1989 in order to understand the environmental impacts arising from potential future mining of manganese nodules. They visited this site again in 1992, 1996 and in 2015 to study the recovery of the deep-sea ecosystem.In 2015, the remotely operated deep-sea robot ROV KIEL 6000 observed almost incidentally some waste and recovered it from the seafloor. Among it was a plastic bag containing a Coke can, which was part of a special edition produced for the Davis Cup 1988. "The aluminum can itself would have corroded in the deep sea, if it was not wrapped tightly inside a plastic garbage bag that preserved it. This also indicates that the garbage bag must be of the same age," says Dr. Matthias Haeckel from GEOMAR, project manager on board back then and now co-author of the study.A second recovered item was a curd box from a German manufacturer. The printed address shows a five-digit postal code. These were not introduced in Germany until 1990. However, the manufacturer was bought by a rival company in 1999, and the brand name disappeared."Since the DISCOL area is far away from important shipping routes, the plastic bag and the curd box could be attributed to the DISCOL expeditions in 1989 and 1992 or 1996," says Dr Haeckel. After all, this offered the extremely rare opportunity to examine in detail datable plastic objects from the deep sea. "It turned out that neither the bag nor the curd box showed signs of fragmentation or even degradation," says biochemist Dr. Stefan Krause from GEOMAR, lead author of the study. He led the onshore analyses in the home laboratories.A scientifically most interesting finding was that the microbial community on the plastic surfaces differed from the one identified in the surrounding seafloor sediments. "All of the species can be found in the deep-sea sediment, but apparently, larger accumulations of plastics could locally cause a shift in the ratio of the predominant species," says Dr. Krause.Overall, the study provides the first scientifically sound indication of the fate of plastic debris in the deep sea. "This study builds also an important basis for our new project HOTMIC, where we aim to trace the plastic waste entering the ocean from the continents to the large oceanic eddies and further to their final sink, the abyssal seafloor," says Dr Haeckel.At the same time, the findings provide a good argument for him to pay even closer attention to compliance with regulations regarding waste on board. "Fortunately, the mentality has changed considerably since the 1990s. Today, both, the crews of the ships and the research teams on board take great care to ensure that no waste is disposed overboard," says Dr Haeckel.
The international study, led by the University of Leeds, highlights the importance of understanding the inter-connectedness of ecosystems as our modern environment struggles with the devastating effects of a rapidly warming planet.The Permian-Triassic extinction, also known as the Great Dying, took place roughly 252 million years ago. It saw the loss of an estimated 90% of marine species, 70% of land species, widespread loss of plant diversity and extreme soil erosion.While the exact cause of the terrestrial mass extinction is still debated, it is becoming apparent that the terrestrial ecosystems were wiped out prior to the marine ecosystems. However, until now it was unclear if or how the terrestrial extinction consequently impacted the chemistry of Earth's ancient oceans.The team built a computer model that mapped chemical changes in Earth's oceans during the period of the Permian-Triassic extinction. The model tracks the cycling of the poisonous element mercury, which is emitted from volcanoes but also gets incorporated into living organisms. By tracing both the mercury and carbon cycles, and comparing to measurements in ancient rocks, the team were able to separate out biological and volcanic events.This revealed that a massive collapse of terrestrial ecosystems cascaded organic matter, nutrients, and other biologically-important elements into the marine system.While further research is needed to understand the exact effect this had on marine life, the fact that many marine species rely on chemical stability in their environment means that it is unlikely it was without consequence.Study co-author Dr Jacopo Dal Corso, who conceived the study during a research placement at Leeds said: "In this study we show that during the Permian-Triassic transition, roughly. 252 million years ago, the widespread collapse of the terrestrial ecosystems caused sudden changes in marine chemistry."This likely played a central role in triggering the most severe known marine extinction in Earth's history. This deep-time example shows how important the terrestrial reservoir is in regulating global biogeochemical cycles and calls for the greater conservation of these ecosystems."Study co-author Dr Benjamin Mills, from the School of Earth and Environment at Leeds said: "252 million years ago the effects of mass plant death and soil oxidation appear to have seriously altered the chemistry of the oceans. This is an uncomfortable parallel with our own human-driven land use change, and we too are transferring large quantities of nutrients and other chemicals to the oceans."As we look to re-start the world's economies in the wake of the current pandemic, protecting our life-sustaining ecosystems should be a priority."
The team consisted of Researcher ITAKURA Hikaru (of Kobe University's Graduate School of Science, and a JSPS Overseas Research Fellow at the University of Maryland), Specially Appointed Researcher WAKIYA Ryoshiro (of The University of Tokyo), Dr. Matthew Gollock (of The Zoological Society of London) and Associate Professor KAIFU Kenzo (Chuo University).The results of this research were published in the British scientific journal 'Although freshwater covers only 2.3% of the Earth's surface, it provides diverse habitats that support a far greater number of species per area than terrestrial or marine ecosystems. However, at the same time freshwater ecosystems have suffered significant deterioration and loss of biodiversity due to the human populations concentrated around them. As a result far more freshwater species are in danger of extinction than species belonging to other ecosystems. One third of freshwater species have been classified as 'Endangered' in the International Union for Conservation of Nature (IUCN)'s Red List of Threatened Species.It is challenging to monitor and manage all the species that make up these ecosystems in order to protect biodiversity. For this reason, it is thought that by focusing conservation efforts on one or a few species, we can understand the functions, resource dynamics and structures of the biological communities to which they belong. This knowledge can be used to manage and conserve biodiversity. These surrogate species are classified as umbrella, indicator or flagship species according to conservation goals. So far some large mammal and bird species have been proposed as surrogate species.The two kinds of eel that were the subject of this study are catadromous, meaning that they are migratory species that spawn in the ocean and grow in rivers and coastal waters. Anguillid eels can be found almost worldwide (except for the polar areas); in the varied aquatic environments of 150 countries, including inner bays, and all parts of rivers from the source to mouth.In this study, the researchers focused on the eels' unique life cycle and confirmed that they can serve as umbrella, indicator and flagship species. They propose that eels are a comprehensive surrogate species for the conservation of freshwater biodiversity.Eel and other freshwater organisms (fish and large crustaceans such as crab and shrimp) were collected from 78 sites spanning upstream to downstream regions in six rivers in Japan using an electric shocker (three mainland rivers in Kyushu and Honshu, and three rivers on Amami-Oshima island). The Japanese eel is mostly found in the mainland rivers, whereas the giant mottled eel largely inhabits Amami-Oshima's rivers. In order to determine these two species' suitability as indicator and umbrella species for biodiversity conservation, the distribution of the sampled eels and freshwater organisms in the rivers was analyzed and their trophic levels in the food web were researched. Furthermore, the researchers also investigated the quantitative relationship between the number of eels and the number of other migratory diadromous species (biodiversity), and the environmental factors affecting this. Japan is a mountainous country and there are many small, fast flowing rivers. It was predicted that the migratory species that travel between the sea and the rivers during their life cycles would be predominant in freshwater rivers' ecosystems. Therefore, a large number of migratory species was interpreted as an indicator of biodiversity.The results from each of the field studies on Japanese eels and giant mottled eels showed that they were the most widely distributed of all freshwater species in river habitats. Japanese eels covered 87% of the study rivers in mainland Japan, whereas the giant mottled eel was found in 94% of the Amami Oshima rivers used in this study. Stable isotope analyses of the muscle tissue of eel and other freshwater organisms were carried out to estimate their trophic levels. The results showed that the mean trophic levels of eel species were greater than three which indicates that they are higher-order predators, and these values were significantly higher than those for other freshwater organisms. These results support the eels' potential as umbrella species and show that they require a diverse range of lower trophic level animals for food.This study confirmed the presence of 48 species of freshwater organisms, including fish and crustaceans. As predicted, a total of 80% of these were migratory species (78% in Honshu/Kyushu and 91% on Amami Oshima island). Furthermore, there was a positive correlation between the number of Japanese eels or giant mottled eels and the number of other migratory species. A statistical model was used to investigate various environmental factors that may have an impact on both of these groups. The researchers found a strong negative correlation between the number of eels and other migratory species and the following two points; 'the distance of the study site from the sea' and the 'cumulative height of trans-river structures, such as dams or weirs, that species have to pass in order to get from the sea to the study site'. These factors have an impact on river-ocean connectivity for migratory species. In other words, these results imply that the positive correlation found between the number of eels and the number of other migratory species is probably an indirect relationship through river-ocean connectivity. In areas where river-ocean connectivity is high (i.e., it's easy for them to swim upstream), there will be greater numbers of eels and other migratory species. Conversely, if river-ocean connectivity is low, there will be fewer of these species. These results show that eels are an indicator of good river-ocean connectivity, and through this they are an indicator of biodiversity.This research showed that trans-river structures have a negative impact on eels and other migratory species. It has been indicated that eels can climb such structures vertically, if the structures are wet. However, trans-river structures inhibit eel movement, moreover they have been shown to cause a decline in the numbers of many eel species. In this study, it was shown that even barriers under 1m high could have a negative impact on eel distribution. Previous studies have indicated that the habitat loss caused by these trans-river structures is a leading factor in the decline in eel numbers. Many other studies have reported that the distribution of other migratory species is limited by these structures in a similar way to eels. Eels are an indicator of river-ocean connectivity. It is hoped that improving and maintaining this connectivity for eels will greatly boost the biodiversity of freshwater ecosystems.In 2016, IUCN decided upon the 'Promotion of Anguillid eels as flagship species for aquatic conservation'. This designation was based on the widespread decline of eel numbers, the effects of habitat deterioration and destruction, as well as eels' global distribution and their unique catadromous migration. As shown in this study, eels have the following important aspects that make them suitable as a flagship species; they are widely distributed, higher-order predators that are generally larger than other freshwater organisms, and are easily identifiable.Looking at eels in terms of their importance ecologically, commercially and culturally, we can conclude that they have provided a diverse ecological service worldwide since ancient times. Eels are found almost all over the world, and have served as a source of food in various lands and eras. They have played roles in food cultures, in literature and art, in legends and belief systems. Therefore, the researchers concluded that eels have the ability to stir up great public awareness worldwide about environmental issues, which is connected to their value as a flagship species.In conclusion, eels can serve as indicator, umbrella and flagship species, making them a comprehensive surrogate for the conservation of freshwater biodiversity.This study confirmed the possibility that eels could be used as a surrogate species by using Japanese rivers as a model. These results could be applied to regions where, like in Japan, migratory species dominate freshwater ecosystems, such as islands that are relatively new geologically. On the other hand, continental freshwater ecosystems, for example, have a higher diversity of primary freshwater species that spend their entire lives in freshwater compared to Japan, therefore it is predicted that the impact of river-ocean connectivity on biodiversity would be lower than in the results of this study. However, trans-river structures also inhibit the mobility of primary freshwater species, such as upriver migrations for egg laying.Sixteen species of eel have been discovered so far and they are globally distributed. Consequently, eels have the potential to be a surrogate species for freshwater biodiversity conservation worldwide, due to their importance in ecosystems as widely distributed higher-order predators, in addition to their commercial and cultural importance. It is hoped that further research could investigate this possibility in continental rivers and elsewhere.*1. Umbrella, indicator and flagship species:Umbrella species: Conserving an umbrella species enables the conservation of many other species in that biological community. This method is often applied to species that are widely distributed or are higher-order predators.Indicator Species: A species that enables factors such as human impact, habitat changes, biodiversity and the resource dynamics of other species to be evaluated.Flagship species: A species that is used to promote conservation planning and cooperation in the face of environmental issues in a particular area, country or on a global scale, with the aim of achieving successful results. Popular, appealing and familiar species are often chosen for these measures; they are usually higher-order predators (for example, large mammal or bird species) that are in danger of becoming extinct.*2. Stable isotope analysis:Isotopes of a chemical element have the same number of protons but a different number of neutrons in each atom. Isotopes that remain unchanged are called stable isotopes. Of the elements in organisms' compositions, the stable isotopes of nitrogen and carbon are often used when researching food-web structure. Since stable nitrogen isotopes vary depending on the consumed and the consumer, they show the target organism's trophic level in the food web.This study was conducted with support from the Environmental Research Fund by the Japanese Ministry of the Environment, and the Japanese eel research project by the Fisheries Agency of Japan.
Yet in some areas, sand is in short supply and scientists have discovered the way we keep track of this resource has given us misleading information.In many instances, we have simply been measuring sand the wrong way."Not all sand is the same," said Associate Professor Ana Vila-Concejo from the University of Sydney School of Geosciences. "Yet the models for assessing sand and how it moves mostly rely on one type. This means we have an inaccurate picture of what is happening, especially in coastal areas that are vulnerable to climate change."Dr Amin Riazi from Eastern Mediterranean University worked with Associate Professor Vila-Concejo during a short stay at the University of Sydney to develop new engineering models that account for the different shapes of sand grains. Standard models assume sand grains are spherical, which is fine for common sands made up of ground-down silica and quartz rocks.However, carbonate sands derived from shells, corals and the skeletons of marine animals tend to be elliptical, less dense and have more holes and edges. The new research has taken this into account with astounding results, finding that existing models underestimate the surface area of carbonate sands by 35 percent.Published today in the "This means we are not accounting for sand correctly," she said. "While this has impact on construction and manufacturing, it could also have a big effect on the management of coastal areas impacted by climate change."Sand is used throughout industry. From the glass in your mobile phone to base for roads, sand is used across our economy. In fact, sand and gravel are the most extracted materials on the planet, exceeding that of fossil fuels.Associate Professor Vila-Concejo said: "While sand wars are not happening in Australia, we do have areas with chronic coastal erosion and sand loss such as at Jimmys Beach in Port Stephens."Her team took carbonate sand from near Heron Island on the Great Barrier Reef and observed how it responded under experimental conditions. Based on these observations, they developed new mathematical equations that much better predict how carbonate sands move.The team confirmed this by applying their equations to existing data on carbonate sand movement accumulated over six years from observations off the north coast of Oahu, Hawaii."Keeping track of carbonate sand will become increasingly important," said Dr Tristan Salles, also from the School of Geosciences in the Faculty of Science."If islands and atolls are at risk from erosion caused by sea-level rise, it will be vital to understand how the sands protecting them will respond to the ocean currents, waves and high-energy sea swells battering them."He said these new equations are likely to be used to update all sediment transport models. "This will include evaluating beach and atoll responses to ocean hydrodynamics in carbonate-sand-rich regions, some of which are most vulnerable to the impacts of climate change," Dr Salles said.At present, coastal engineering uses models based on siliciclastic sands. Associate Professor Vila-Concejo hopes that the models her team has developed can be used to improve management of coastal areas."This means we can develop a far more accurate picture of how changing oceans will affect marine ecosystems where carbonate sands are dominant," Associate Professor Vila-Concejo said."Understanding how, why and when sediments move is crucial to managing and predicting the effects of climate change and our new work will help in the development of mitigation and adaptation strategies."
The increased flooding caused by the changing global climate has been predicted to render such communities -- where sandy or gravel islands sit on top of coral reef platforms -- uninhabitable within decades.However, an international study led by the University of Plymouth (UK) suggests that perceived fate is far from a foregone conclusion.The research, published in The results show that islands composed of gravel material can evolve in the face of overtopping waves, with sediment from the beach face being transferred to the island's surface.This means the island's crest is being raised as sea level rises, with scientists saying such natural adaptation may provide an alternative future that can potentially support near-term habitability, albeit with additional management challenges, possibly involving sediment nourishment, mobile infrastructure and flood-proof housing.The research was led by Gerd Masselink, Professor of Coastal Geomorphology in Plymouth, working with colleagues at the University of Auckland (New Zealand) and Simon Fraser University (Canada).Professor Masselink, who heads Plymouth's Coastal Processes Research Group, said: "In the face of climate change and sea level rise, coral reef islands are among the most vulnerable coastal environments on the planet. Previous research into the future habitability of these islands typically considers them inert structures unable to adjust to rising sea level. Invariably, these studies predict significantly increased risk of coastal flooding and island inundation, and the concept of 'island loss' has become entrenched in discourses regarding the future of coral reef island communities. In turn, this has led to attention being focused on either building structural coastal defences or the exodus of island communities, with limited consideration of alternative adaptation strategies."It is important to realise that these coral reef islands have developed over hundreds to thousands of years as a result of energetic wave conditions removing material from the reef structure and depositing the material towards the back of reef platforms, thereby creating islands. The height of their surface is actually determined by the most energetic wave conditions, therefore overtopping, flooding and island inundation are necessary, albeit inconvenient and sometime hazardous, processes required for island maintenance."Co-author Professor Paul Kench, currently Dean of Science at Simon Fraser University, Canada, said: "The model provides a step-change in our ability to simulate future island responses to sea level rise and better resolve what the on-ground transformations will look like for island communities. Importantly, our results suggest that island drowning within the next few decades is not universally inevitable. Understanding how islands will physically change due to sea level rise provides alternative options for island communities to deal with the consequences of climate change. It is important to stress there is no one-size-fits-all strategy that will be viable for all island communities -- but neither are all islands doomed."For the research, scientists created a scale model of Fatato Island, part of the Funafuti Atoll in Tuvalu, and placed it in the Coastal Ocean and Sediment Transport (COAST) Lab at the University of Plymouth.It was then subjected to a series of experiments designed to simulate predicted sea level rises with the results showing that the island's crest rose with the rising sea level, while retreating inland, as a result of water overwashing the island and depositing sediment on the island's surface.A numerical model was validated using these laboratory experiments, and three numerical modelling scenarios were then used to assess how the island adjusted to a sea level rise of 0.75m, the global average increase predicted for 2100 by the Intergovernmental Panel on Climate Change.During the numerical simulations, the island crest rose by just under 0.7m, showing that islands can keep up with rising level and confirming the laboratory experiments, although the precise future rate of sea level rise will be critical in determining their future.
The results have implications for forest management, researchers suggest, because forests growing on shale bedrock store 25% more live, aboveground carbon and grow faster, taking up about 55% more carbon each year than forests growing on sandstone bedrock.The findings demonstrate that forests underlain by shale in this region provide more ecosystem services such as carbon uptake and biodiversity, explained researcher Margot Kaye, associate professor of forest ecology in the College of Agricultural Sciences. Also, shale forests make up a smaller portion of the landscape and should be high-priority candidates for management or conservation."As forests grow and respond to warming, shifts in precipitation and invasive species, managers will benefit from incorporating lithological influences and considerations on forest composition and productivity," she said. "For example, conserving forests growing on shale with higher species diversity will likely lead to forests that are resilient to stressors and can grow more vigorously."Forest managers -- now realizing the disparity of productivity -- may target forests growing over shale for conservation and carbon sequestration, Kay contends. In contrast, they may decide that forests growing over sandstone are better suited for wildlife habitat management or recreation.To reach their conclusions, researchers analyzed forest inventory data from 565 plots on state forest and game lands managed by the Pennsylvania Department of Conservation and Natural Resources and the state Game Commission in the Appalachian Ridge and Valley Region. They used a suite of GIS-derived landscape metrics, including measures of climate, topography and soil physical properties, to identify drivers of live forest carbon dynamics in relation to bedrock.Those forest plots contained more than 23,000 trees, ranging from 20 to 200 years old, with most being 81 to 120 years old, according to the most recent available forest inventory data. In the study dataset, 381 plots were on sandstone bedrock and 184 were on shale -- a similar ratio to the amount of Pennsylvania public land on each bedrock type in the Ridge and Valley Region. There are 812,964 acres of forest on sandstone and 262,025 acres of forest on shale in the region."That is an eye-opening number," said lead researcher Warren Reed, a doctoral student in ecology.While forests underlain by both shale and sandstone bedrock were oak dominated, the tree communities are quite different, Reed pointed out. Northern red oak is more dominant on shale bedrock, and chestnut oak dominates on sandstone. Most species in the forest tend to be more productive on shale, and the diversity of tree species is higher in sites on shale bedrock.Forests grow faster over shale bedrock than sandstone bedrock because of soil characteristics that generally make water more available to trees, Reed hypothesized. Over millions of years, bedrock breaks down, becomes parent material and soils develop. Because of the composition of the rock types, shales break down into soils with finer texture than sandstone, which is coarser.Forests above shale bedrock growing in finer soils typically have better access to water during the growing season."We see this across the landscape, so forest productivity is indirectly related to bedrock," Reed said. "Oaks growing on sandstone are more sensitive to annual climate and water availability -- or put differently, oak growth on sandstone is more limited by water than on shale."The findings of the research, recently published in The concept of geologic influences on forest growth will be especially valuable in Pennsylvania, Reed said, because it is a major producer of hardwood lumber, and the state has so much forest growing on its portion of the Appalachian Ridge and Valley Region. The Ridge and Valley is a major portion of the forested Appalachian Mountains, so these rules should apply from southern New York to northern Georgia within that landscape."Sequestering carbon in forests is one of the many nature-based solutions we have to combat global climate change," he said. "I believe this is an ecosystem service that will continue to gain traction and eventually greater market value."The National Science Foundation and the U.S. Department of Agriculture's National Institute of Food and Agriculture supported this research.
Although savanna habitats (treed grasslands) are only found in the tropics today, around 18 million years ago, during the Miocene epoch, savanna ecosystems, similar to those of modern Africa, existed in the mid latitudes of North America. At their peak -- around 12 million years ago -- they were comparable in their mammalian diversity to that of the Serengeti today.The study, published in Lead author of the research, Nuria Melisa Morales GarcÃ­a from the University of Bristol, said: "The North American savannas housed a vast diversity of camelids. In fact, camelids actually originated and first diversified in North America where they lived for more than 40 million years and were incredibly successful and widespread."The researchers measured the skulls, jaws and limb bones of dozens of extinct North American artiodactyls, including camelids, and compared them with those living today in the Serengeti savanna of East Africa. The researchers recorded data on body size and on aspects of the anatomy of the animals that are linked with their ecology."The Serengeti mammals are very well known to research: we know how they live, how they eat and we have all their measurements. By using what we know about them, we can make solid inferences on how the extinct artiodactyls of North America were behaving," said Professor Christine Janis, from the University of Bristol's School of Earth Sciences and supervising author of the study.The analysis showed that while there was considerable overlap between the ecologies of extinct and modern species, the majority of extinct camelids were most similar to the modern common eland, an arid-adapted antelope with a diet of grass and leaves. This reveals important information about the ecosystem they inhabited and suggests the North American savannas were drier than modern African savannas (a notion supported by other research)."We also studied how these faunas were affected by the climatic changes of the Neogene: as temperatures dropped and conditions became more arid, these faunas became more depauperate -- lacking in number and diversity. Camels still dominated in these faunas, but the diversity of all ungulates took a big hit. Our study shows how ungulate faunas responded to a particular scenario of climate change which, now more than ever, is extremely relevant in understanding what is to come," said Morales-GarcÃ­a.
A study in All the models projected decreases in the aerial coverage of Antarctic sea ice over the 21st century under different greenhouse gas emission scenarios, but the amount of loss varied considerably between the emissions scenarios."I am really fascinated by Antarctic sea ice, which the models have struggled more with than Arctic sea ice," said lead author Lettie Roach, a postdoctoral researcher at the University of Washington. "Not as many people are living near the Antarctic and there haven't been as many measurements made in the Antarctic, making it hard to understand the recent changes in sea ice that we've observed through satellites."The models are known as coupled climate models, meaning they incorporate atmospheric, ocean, terrestrial and sea ice models to project what the future holds for our climate system. We are all familiar with the story of soon-to-be ice-free summers in the Arctic and the implications that may have on global trade. But what's driving change around Antarctic sea ice and what's expected in the future is less clear.This study's assessment of Antarctic sea ice in the new climate models is among the first."This project arose from a couple of workshops that were polar climate centered, but no one was leading an Antarctic sea ice group," said Roach. "I put my hand up and said I would do it. The opportunity to lead something like this was fun, and I'm grateful to collaborators across many institutions for co-creating this work."The Antarctic is characterized by extremes. The highest winds, largest glaciers and fastest ocean currents are all found there, and getting a handle on Antarctic sea ice, which annually grows and shrinks six-fold, is critically important. To put that into perspective, that area is roughly the size of Russia.The icy parts of our planet -- known as the cryosphere -- have an enormous effect on regulating the global climate. By improving the simulation of Antarctic sea ice in models, scientists can increase their understanding of the climate system globally and how it will change over time. Better sea ice models also shed light on dynamics at play in the Southern Ocean surrounding Antarctica, which is a major component of our southern hemisphere."The previous generation of models was released around 2012," says Roach. "We've been looking at all the new models released, and we are seeing improvements overall. The new simulations compare better to observations than we have seen before. There is a tightening up of model projections between this generation and the previous, and that is very good news."
Around the world, the migratory shorebirds that are a conspicuous feature of coastal habitats are losing access to the tidal flats -- the areas between dry land and the sea -- they rely on for food as they travel and prepare to breed. But a major puzzle has been that species' populations are plummeting several times faster than the rate at which coastal ecosystems are lost to development.Nowhere is the loss of tidal flats and shorebird species more acute than along the East Asia-Australasian Flyway (EAAF). An estimated 5 million migratory birds from 55 species use the flyway to travel from southern Australia to northern Siberia along the rapidly developing coast of China -- where tidal flats can be more than 6 miles wide -- at which birds stop to rest and refuel.Since the 1980s, the loss of tidal flats around the Yellow Sea has averaged 1.2% per year. Yet, the annual loss of the most endangered bird species has averaged between 5.1 and 7.5%, with populations of species such as the critically endangered spoon-billed sandpipers (Calidris pygmaea) climbing as high as 26% each year.In exploring this disparity, Princeton researchers Tong Mu and David Wilcove found a possible answer -- the birds don't use all parts of the tidal flat equally. They discovered that migratory shorebirds overwhelmingly rely on the upper tidal flats closest to dry land, which are the exact locations most often lost to development.They report in the journal The findings stress the need for integrating upper tidal flats into conservation plans focused on migratory shorebirds, the authors reported."This is a new insight into Asian shorebirds, but I suspect that the upper intertidal is disproportionately important to shorebirds in other places, too, such as the East and West coasts of North America," said Wilcove, who is a professor of ecology and evolutionary biology and public affairs and the Princeton Environmental Institute (PEI)."People start at the upper zone and work their way outward, so the best spots for the birds are the first to go," he said. "It would probably be best to extend current developments farther into the intertidal zone rather than keep building parallel to the coast, which consumes more of the upper intertidal."Think of it as advocating for a rectangle with the long side pointing into the sea versus a rectangle with the long side hugging the shore," Wilcove said.The study results also suggest that protecting species and their habitats may mean more than designating land for wildlife -- it may require identifying the right land to set aside by gaining a detailed understanding of exactly how animals interact with the landscape."Recognizing the importance of a kind of habitat to specific species or groups of species takes time, effort and thought," said Mu, who is the paper's first author and a Ph.D. candidate in ecology and evolutionary biology."Sometimes we just don't know what to look for, or looking requires challenging some prevalent and maybe false perceptions," he said. "But the situation is getting better and better. People are paying more attention to environmental issues, and the advances in technology are helping us gain more and newer insight into these questions."Mu conducted fieldwork between September 2016 and May 2017 at two well-known stopover sites -- one outside of Beijing, the other near Shanghai -- for migratory shorebirds in the Yellow Sea region. He focused on 17 species of birds, noting where along the tidal flat the animals preferred to feed.A key difference to his approach, Mu said, is that most previous research focused on the low-tide period when all the tidal flats are exposed and the full range of intertidal species can be observed."It makes sense from an ecological point of view. During the high tides when only a portion of the tidal flats is accessible, the relationship usually still holds for the exposed area," Mu said. "So, there's little incentive to look at the periods other than low tide when researchers can get a more complete picture."What Mu thinks was missed, however, was that the upper tidal flats provide the most amount of foraging time for birds that have places to be. Even if the lower half of a 6-mile wide mudflat is set aside for migratory birds, they're not getting the energy they need for the trip ahead during the high tide, he said."The value of the tidal flats comes from not only their size, but also how much foraging time they can provide," Mu said. "The upper tidal area is exposed for a longer period during tidal cycles, compared to the middle and lower areas, which I think permits shorebirds to forage for a longer time and thus get more energy."The preservation of shorebirds should be driven by how integral the animals are to the health of intertidal zones, Mu and Wilcove said. In turn, tidal flats are not only vital to other marine life, but also provide people with seafood such as clams and crabs and protection from storms and storm surges that cause coastal flooding."Shorebirds facilitate the energy and nutrient exchanges between land and sea," Mu said. "Because a lot of them are long-distance migrants, they also facilitate the energy and nutrient exchanges across different ecosystems and continents, something that is usually overlooked and underappreciated."Wilcove and Mu cited recent research showing that more than 15%, or more than 12,000 square miles, of the world's natural tidal flats were lost between 1984-2016."Some of the greatest travelers on Earth are the shorebirds that migrate from Siberia to Southeast Asia and Australia," Wilcove said. "Now, they're declining in response to the loss of the tidal areas, and the full range of benefits those tidal flats provide are in some way being diminished."
The reasons for these losses are more than disease and habitat fragmentation, deforestation or wildlife trade, according to researchers. Ultimately, the cause is rampant human population growth. And unless human behavior changes in unprecedented ways, these scientists warn that future communities of these mammals will never resemble those of the recent past or even today.The findings are based on a new study, "Disassembled food webs and messy projections: modern ungulate communities in the face of unabating human population growth," published June 9 in Joel Berger, lead author of the study and a professor at Colorado State University, said that the time for action is now, and that touting past conservation achievements does little to better humanity's future."We all must realize we're members of a broad, beautiful and living planet, and we must find ways to subsist in this together or suffer more severe consequences than what we already see," said Berger, also a senior scientist at the Wildlife Conservation Society (WCS). "For many assemblages of animals, we are nearing a moment in time, when, like Humpty Dumpty, we will not be able to put things back together again." Berger is also the Barbara Cox Anthony University Chair of Wildlife Conservation at CSU.In this study, the research team -- which also included Alejandro Vila, the director for Science for WCS's Patagonia Program; Cristobal Briceno, a professor and veterinarian at University of Chile; and Joanna Lambert, a professor at the University of Colorado Boulder -- analyzed direct and indirect disruptions that lead to the changing roles of mammals in global ecosystems and noted how the nature of ecological interactions has changed and will do so, on an even larger scale, in coming decades.More specifically, they looked at what has transpired with the huemul in Patagonia, takin in Bhutan, wild horses in deserts, wolves and coyotes in North America, and the inevitability of change in big ecosystems as large carnivores are extirpated.Scientists said this is happening as the human population increases it footprint on land."Even in the remote reaches of the Himalayas, stray and feral dogs, a direct result of human intrusions, wreak havoc on wild and domestic species of high economic value and cultural importance," said Tshewang Wangchuk, a study co-author, conservation biologist and president of the Bhutan Foundation.Humans only recently colonized parts of the Himalayas, areas where ice has receded due to warming temperatures. Yet, the authors also point to human population change at a global scale. In 1830 when Vice-Admiral Robert Fitzroy captained his ship, the Beagle, through the Magellan Straits of South America, fewer than 1.2 billion people inhabited Earth. By Earth Day in 1970, there were more than 3.5 billion.Today, only 50 years later the world's population approaches eight billion. Livestock and humans now constitute a staggering 97 percent of the planet's mammal biomass.The research team said worldwide food webs have become irretrievably altered by humans, with little hope to reconstitute even recent past conditions or to put back the ecological functions once created by native species.Feral pigs, for instance, exist today on every continent except Antarctica, and in 70 percent of the states in the United States. These animals disrupt fish, reptiles, birds and other small mammals, plants and soils. In addition, climate change warms the oceans, which in turn foments marine algal blooms, reducing fishery catches. With less demand for fish, a consequent uptick in wildlife poaching on land occurs.The scientists also documented how an appetite for fashion like cashmere increases imports to the west from Mongolia, India and China, resulting in economic incentives for desert pastoralists to produce more domestic goats in central Asia. These goats compete for food with native species and are in danger due to increasing numbers of dogs in these areas. The dogs are not only predators but also carry diseases, which jeopardizes endangered species like snow leopards, kiang and Przewalksi's gazelle.Berger and the study authors suggest that despite the grim findings, all is not yet lost.The world has remarkable protected areas including: Serengeti and Kruger National Park in Africa, Yellowstone and Wrangell-St. Elias National Park & Preserve in North America, Madidi National Park in Bolivia, the Patagonia Ice Fields of Chile and Argentina, Chang Tang Nature Reserve in China, and Northeast Greenland National Park, the world's largest national park.And although food webs with large mammals will be different from those of the past and operate differently today, there are options to shape the future."It is not too late and we simply do not have the luxury of time to mourn what we have lost," said Lambert. "We need to use our ecological grief to implement action and honor the exceptional biodiversity that remains. This can be done by protecting large tracts of the planet's wild places."
It found that about 15 percent of natural lands in California serve as climate refugia for the state's plants, including trees, shrubs, annuals and perennials. The mapping tool can help natural resource managers prioritize and plan climate-adaptive management efforts, such as wildlife habitat conservation and post-wildfire restoration.The study is published in a special issue of the journal As climate change intensifies, identifying and mapping areas of relative stability -- what the journal calls the "slow lane" for climate change -- marks a path toward conserving them and the habitat and services they provide to wildlife and humans."This paper shows that there are places where, if you retain what's standing there now, it would have a better chance of remaining for a longer period of time -- like a century -- under wetter and drier conditions," said lead author James Thorne, a research scientist with the UC Davis Department of Environmental Science and Policy.The northwest Klamath Mountains, northern Sierra Nevada and the Central Coast ranges contain large areas where existing vegetation types are expected to persist under both wetter and drier future climate conditions. These areas are called "consensus refugia."The three forest types occupying consensus refugia across large parts of Northern California include Klamath mixed conifer, Sierra mixed conifer and Douglas fir. Grasslands and coastal sage scrub cover much of the refugia in the Central Coast ranges.Vegetation with the largest portions (more than 50 percent) of their extent in climate refugia include montane chaparral and Klamath mixed conifer forests. A quarter of existing Douglas fir also occurs in consensus refugia.Other findings:- Elevation and latitude matter: Blue oak woodland and blue oak-foothill pine occurred less in consensus refugia than oaks at higher elevations.-Iconic coast redwood forests (0.4 percent of its current range), coast live oak woodland (3.8 percent) and red fir forests (2.3 percent) were poorly represented within the consensus refugia.If only 15 percent of California's natural lands have climate refugia characteristics for both a wetter and drier future, what does that mean for the remaining 85 percent? Thorne explains that it doesn't mean all other plants and trees will be outright destroyed. But they will likely face a higher level of climate stress than vegetation in refugia. Stress can affect rates of regeneration, reproduction and resilience under warming temperatures, drought, flood and fire.Previous work by Thorne modeled climate risk to California's native vegetation under various emissions-saving scenarios and found that half the state's native vegetation is at risk for climatic stress. This new paper assumes a business-as-usual climate scenario under which greenhouse gas emissions continue their current trajectory."California is one of the biodiversity hot spots of the world," Thorne said. "Our natural ecosystems help to support all of the people in the state as well as this incredible range of species. My hope is that we start to be proactive in our management of landscapes, understanding that climate change is going to bring impacts and that we have to change how we address them."
The team, from the University of Cambridge and Ghent University, has discovered a bath complex, market, temple, a public monument unlike anything seen before, and even the city's sprawling network of water pipes. By looking at different depths, the archaeologists can now study how the town evolved over hundreds of years.The research, published today in GPR works like regular radar, bouncing radio waves off objects and using the 'echo' to build up a picture at different depths.* By towing their GPR instruments behind a quad bike, the archaeologists surveyed all 30.5 hectares within the city's walls -- Falerii Novi was just under half the size of Pompeii -- taking a reading every 12.5cm.Located 50 km north of Rome and first occupied in 241 BC, Falerii Novi survived into the medieval period (until around AD 700). The team's GPR data can now start to reveal some of the physical changes experienced by the city in this time. They have already found evidence of stone robbing.The study also challenges certain assumptions about Roman urban design, showing that Falerii Novi's layout was less standardised than many other well-studied towns, like Pompeii. The temple, market building and bath complex discovered by the team are also more architecturally elaborate than would usually be expected in a small city.In a southern district, just within the city's walls, GPR revealed a large rectangular building connected to a series of water pipes which lead to the aqueduct. Remarkably, these pipes can be traced across much of Falerii Novi, running beneath its insulae (city blocks), and not just along its streets, as might normally be expected. The team believes that this structure was an open-air natatio or pool, forming part of a substantial public bathing complex.Even more unexpectedly, near the city's north gate, the team identified a pair of large structures facing each other within a porticus duplex (a covered passageway with central row of columns). They know of no direct parallel but believe these were part of an impressive public monument, and contributed to an intriguing sacred landscape on the city's edge.Corresponding author, Professor Martin Millett from the University of Cambridge's Faculty of Classics, said:"The astonishing level of detail which we have achieved at Falerii Novi, and the surprising features that GPR has revealed, suggest that this type of survey could transform the way archaeologists investigate urban sites, as total entities."Millett and his colleagues have already used GPR to survey Interamna Lirenas in Italy, and on a lesser scale, Alborough in North Yorkshire, but they now hope to see it deployed on far bigger sites."It is exciting and now realistic to imagine GPR being used to survey a major city such as Miletus in Turkey, Nicopolis in Greece or Cyrene in Libya," Millett said. "We still have so much to learn about Roman urban life and this technology should open up unprecedented opportunities for decades to come."The sheer wealth of data produced by such high-resolution mapping does, however, pose significant challenges. Traditional methods of manual data analysis are too time consuming, requiring around 20 hours to fully document a single hectare. It will be some time before the researchers finish examining Falerii Novi but to speed the process up they are developing new automated techniques.Falerii Novi is well documented in the historical record, is not covered by modern buildings and has been the subject of decades of analysis using other non-invasive techniques, such as magnetometry, but GPR has now revealed a far more complete picture.*GPR is so effective because it relies on the reflection of radio waves off items in the ground. Different materials reflect waves differently, which can be used to create maps of underground features. Although this principle has been employed since the 1910s, over the past few years technological advances have made the equipment faster and higher resolution.The project was funded by the AHRC. Lieven Verdonck, from Ghent University, was employed on a post-doctoral fellowship from the Fund for Scientific Research -- Flanders (FWO). The team is grateful for support from Soprintendenza Archeologia, Belle Arti e Paesaggio per l'Area Metropolitana di Roma, la Provincia di Viterbo e l'Etruria Meridionale.
The Paris Agreement aims to keep global temperature rise this century well below 2Â°C above pre-industrial levels and to pursue efforts to limit it to 1.5Â°C. Reaching these targets will require mitigation -- lowering the carbon dioxide (COHowever, while countries signed up to the Paris Agreement have individual quotas they need to meet in terms of mitigation and have individual plans for doing so, there are no agreed national quotas for CONow, in a paper published today in The team, from Imperial College London, the University of Girona, ETH ZÃ¼rich and the University of Cambridge, say countries need to start working together now to make sure enough COCo-author Dr Niall Mac Dowell, from the Centre for Environmental Policy and the Centre for Process Systems Engineering at Imperial, said: "Carbon dioxide removal is necessary to meet climate targets, since we have so far not done enough to mitigate our emissions. Both will be necessary going forward, but the longer we wait to start removing CO"It is imperative that nations have these conversations now, to determine how quotas could be allocated fairly and how countries could meet those quotas via cross-border cooperation. It will work best if we all work together."Co-author Dr David Reiner, from Judge Business School at the University of Cambridge, added: "Countries such as the UK and France have begun to adopt binding 'net-zero targets' and whereas there has been extensive focus on greenhouse gas emissions and emissions reductions, meeting these targets will require greater attention to the negative emissions or carbon dioxide removal side of the equation."A critical element in any negotiations will be to determine the fairest way to allocate quotas to different nations. Different methods have been used for determining previous quotas, such as the ability of a country to pay and its historic culpability (how much COThe team modelled several of these different methods and applied them to countries across Europe. While the quotas varied significantly, they found that only a handful of countries could meet any of the quotas using only their own resources.Co-lead author Dr Ãngel GalÃ¡n-MartÃ­n, from ETH ZÃ¼rich, said: "The exercise of allocating COCarbon dioxide removal can be achieved in several ways. Reforestation uses trees as natural absorbers of atmospheric COCCS is usually coupled with a fossil fuel power station to take the COHowever, different countries have varying abilities to deploy these COThe authors therefore suggest, after quotas have been determined, that a system of trading quotas could be established. For example, the UK has abundant space for CCS thanks to favourable geological formations in the North Sea, so could sell some of its capacity to other countries.This system would take a while to set up, so the authors urge nations to begin the process now. Co-lead author Dr Carlos Pozo from the University of Girona, said: "By 2050, the world needs to be carbon neutral -- taking out of the atmosphere as much CO"There are technological solutions ready to be deployed. Now it is time for international agreements to get the ball rolling so we can start making serious progress towards our climate goals."
New research, published in Changes from cloudier and wetter summers to longer periods of sunshine and drought have led to decreasing iron and nutrient supply to surface waters. This results in an increased period of suboptimal feeding conditions for zooplankton at a time of year when their metabolic demand is at its highest.In some areas, large phytoplankton are being almost completely replaced by picoplankton, especially the cyanobacterium Synechococcus, that flourishes when iron and nitrogen levels in surface waters are very low.However, its small size and lack of essential biomolecules mean it is unable to function in the same way as larger, more nutritious phytoplankton -- a vital primary producer of omega-3 -- and cannot sustain shelf sea food webs efficiently.With Synechococcus prominent from the tropics to the Arctic, and its abundance increasing worldwide, scientists suggest that competition for scarce summer nutrients will become a key force in structuring shelf sea food webs. Shelf seas provide around 80% of the world's wild-captured seafood, and changes in their productivity will have major effects on humans.The study was led by scientists at the University of Plymouth (funded through the Natural Environment Research Council's Shelf Sea Biogeochemistry Programme), working with colleagues from Plymouth Marine Laboratory, the Marine Biological Association, and the University of Southampton. It brought together experts from a range of fields including trace metal analysis, plankton taxonomy, and satellite data.Lead author Dr Katrin Schmidt, a plankton ecologist in the University of Plymouth's School of Geography, Earth and Environmental Sciences, said: "Zooplankton such as copepods are considered beacons of climate change, and the ~50% decline in their abundance over the last six decades is worrying. Our study is the first to provide a mechanism for such a wide-spread decline, and this understanding is essential to project future responses to climate change. We also need to explore the wider impacts and whether the changing nutrient supply could, for example, lead to reductions in omega-3 within the entire food chain."The study was based on an area measuring 2,000km by 1,500km in the North East Atlantic, and used a combination of data generated by satellites and the MBA's Continuous Plankton Recorder (CPR) survey. It allowed scientists to identify both longer and shorter-term trends, the spatial extent of any changes and the months that are most affected.It also used intensive field observations of the phytoplankton community and, by linking the two scales, provided a conceptual model of why the classical food web is increasingly under threat in temperate coastal and shelf areas.In combination, both satellite and CPR data show similar changes over the longer (1958-2017) and shorter (1997-2018) terms. Between May and August/September in those years, numbers of diatoms, dinoflagellates and total copepods have all declined, while the proportion of picophytoplankton has increased.Co-author Dr Luca Polimene, Senior Marine Ecosystem Modeller at Plymouth Marine Laboratory, said: "The increasing dominance of small phytoplankton species might have a broad impact on the marine ecosystem. Other than altering the food chain as suggested in this study, it could also change the biological carbon pump modifying the capacity of the ocean to store carbon. We need to make sure that the shift between large to small phytoplankton species is well captured by marine ecosystem models if we want to reliably simulate future oceans."David Johns, Head of the Continuous Plankton Recorder Survey, added: "While the CPR Survey samples the larger plankton community, declines in some key groups over past decades can be linked to changes in the smallest plankton that are driven by climate change. We have previously witnessed direct climate impacts on the plankton community, from seasonality (temporal) to large scale movements (spatial), via changes in temperature. This study demonstrates a knock-on effect through the food web, and it is only by continuing our monitoring that we will identify multiple stressors acting on our marine environment, and hopefully sustain and protect our productive oceans."
Findings from the study were published recently in "Changes in stock distribution affect where fish and shellfish can be caught and who has access to them over time," said Vincent Saba, a fishery biologist in the Ecosystems Dynamics and Assessment Branch at the Northeast Fisheries Science Center and a co-author of the study. "American lobster and sea scallop are two of the most economically valuable single-species fisheries in the entire United States. They are also important to the economic and cultural well-being of coastal communities in the Northeast. Any changes to their distribution and abundance will have major impacts," he said.Saba and study colleagues used a group of species distribution models and a high-resolution global climate model. They projected the possible impact of climate change on suitable habitat for the two species in the Northeast U.S. continental shelf large marine ecosystem. That ecosystem includes waters of the Gulf of Maine, Georges Bank, the Mid-Atlantic Bight, and Southern New England.The high-resolution global climate model is, known as NOAA's CM2.6. It generated projections of future ocean bottom temperatures and salinity conditions across the ecosystem, and identified where suitable habitat would occur for the two species. The CM2.6 model was developed by the NOAA Geophysical Fluid Dynamics Laboratory in Princeton, New Jersey, where Saba is located.To reduce bias and uncertainty in the model projections, the team used nearshore and offshore fisheries independent trawl survey data to train the habitat models. Those data were collected on multiple surveys over a wide geographic area from 1984 to 2016. The model combined this information with historical temperature and salinity data. It also incorporated 80 years of projected bottom temperature and salinity changes in response to a high greenhouse gas emissions scenario. That scenario has an annual 1 percent increase in atmospheric carbon dioxide.American lobster are large, mobile animals that migrate to find optimal biological and physical conditions. Sea scallops are bivalve mollusks that are largely sedentary, especially during their adult phase. Both species are affected by changes in water temperature, salinity, ocean currents, and other oceanographic conditions.Projected warming over the next 80 years showed deep areas in the Gulf of Maine becoming increasingly suitable lobster habitat. During the spring, western Long Island Sound and the area south of Rhode Island in the Southern New England region showed habitat suitability. That suitability decreased in the fall. Warmer water in these southern areas has led to a significant decline in the lobster fishery in recent decades.Sea scallop distribution showed a clear northerly trend, with declining habitat suitability in the Mid-Atlantic Bight, Southern New England, and Georges Bank areas."This study suggests that ocean warming due to climate change will act as a likely stressor to the ecosystem's southern lobster and sea scallop fisheries and continues to drive further contraction of sea scallop and lobster habitats into the northern areas," Saba said. "Our study only looked at ocean temperature and salinity, but other factors such as ocean acidification and changes in predation can also impact these species.""Ensemble modelling approaches like the one developed in this study can contribute to lobster and scallop assessments by improving the effectiveness of survey efforts and the precision of stock assessment models," Saba added. "It also provides a critical step toward establishing long-term adaptive management plans for these two valuable species."
This pilot study tested whether a drone could keep up with the tuna while also taking photographs that captured physical details of this fast-moving fish. The drone was equipped with a high-resolution digital still image camera. Results show that drones can capture images of both individual fish and schools. They may be a useful tool for remotely monitoring behavior and body conditions of the elusive fish.Individual fish lengths and widths, and the distance between fish near the sea surface, were measured to less than a centimeter of precision. We used an APH-22, a battery-powered, six-rotor drone. The pilot study was conducted in the Atlantic bluefin tuna's foraging grounds northeast of Cape Cod in the southern Gulf of Maine."Multi-rotor unmanned aerial systems won't replace shipboard surveys or the reliance on manned aircraft to cover a large area," said Mike Jech, an acoustics researcher at the Northeast Fisheries Science Center in Woods Hole, Massachusetts and lead author of the study. "They have a limited flight range due to battery power and can only collect data in bursts. Despite some limitations, they will be invaluable for collecting remote high-resolution images that can provide data at the accuracy and precision needed by managers for growth and ecosystem models of Atlantic bluefin tuna."Results from the APH-22 study were published in March 2020 in the Atlantic bluefin tuna is a commercially and ecologically important fish. The population size in the western Atlantic Ocean is unknown. Fishery managers need biological data about this population, but it is hard to get. Highly migratory species like Atlantic bluefin tuna often move faster than the vessels trying to sample them. The tuna are distributed across large areas, and can be found from the sea surface to hundreds of feet deep.Sampling with traditional gear -- nets and trawls -- is ineffective. Acoustical methods are useful but limited to sampling directly below a seagoing vessel with echosounders or within range of horizontal sonar.It is also difficult to estimate the number of tuna in a school from an airplane. Both fish availability and perception biases introduced by observers can affect results. Estimates of abundance and size of individuals within a school are hard to independently verify.Taking precision measurements of animals that are in constant motion near the surface proved easier with a drone that is lightweight, portable, and agile in flight. It can carry a high-quality digital still camera, and be deployed quickly from a small fishing boat.Short flight times limit a drone's ability to survey large areas. However, they can provide two-dimensional images of the shape of a fish school and data to count specific individuals just below the ocean surface.The APH-22 system has been tested and evaluated for measuring other marine animals. It's been used in a number of environments -- from Antarctica to the Pacific Ocean -- prior to its use in the northwest Atlantic Ocean. Previous studies estimated the abundance and size of penguins and leopard seals, and the size and identity of individual killer whales."The platform is ideal for accurately measuring fish length, width, and the distance between individuals in a school when you apply calibration settings and performance measures," Jech said. "We were able to locate the hexacopter in three-dimensional space and monitor its orientation to obtain images with a resolution that allowed us to make measurements of individual fish."As new unmanned aerial systems are developed, their use to remotely survey Atlantic bluefin tuna and other animals at the sea surface will evolve. It may minimize the reliance on manned aircraft or supplement shipboard surveys.The International Commission for the Conservation of Atlantic Tunas governs tuna fishing. It is entrusted to monitor and manage tuna and tuna-like species in the Atlantic Ocean and adjacent seas. NOAA Fisheries manages the Atlantic bluefin tuna fishery in the United States and sets regulations for the U.S. fishery based on conservation and management recommendations from the international commission.
The most recent study in "It turns out that this area has a very old fault system -- essentially cracks in bedrock that likely formed 250 million years ago. Craters and mounds appear along different fault structures in this system. These structures control the size, placement, and shape of the craters. The methane that is leaking through the seafloor originates from these deep structures and is coming up through these cracks." according to Malin Waage, a postdoc at CAGE, Centre for Arctic Gas Hydrate, Environment and Climate, and the first author of the study.The deep origin of craters and mounds was discovered using cutting edge 3D seismic technology which can penetrate deep into the ocean floor, and help scientists visualize the structures in the hard bedrock underneath."Our previous studies in the area hypothesized that climate warming and the retreat of the ice sheet some 20,000 years ago, caused the gas hydrates beneath the ice to melt leading to abrupt methane release and creating craters."Gas hydrates are a solid form of methane, among others, that is stable in cold temperatures and under pressure, which an enormous ice sheet provides. As the ocean warmed up, and the pressure of the ice sheet lifted, the methane ice in the seafloor melted and thus the craters were formed."This study, however, ads several layers to that picture, as we now see that there has been a structural weakness beneath these giant craters, for much longer than the last 20,000 years. Deep below the seafloor, the expansion of gas and release of water build up a muddy slurry which eventually erupted through the fractures and caused seafloor collapses and craters in the hard bedrock. Think of it as a building: A roof of a building can cave in if the ground structure is weak. We believe that this is what happened in the crater area after the last glaciation." says Waage.The exploration of petroleum resources in the Barents Sea is a hot topic in Norway and beyond as the area is a part of a vulnerable Arctic ecosystem. But the area's geological system is poorly understood."Our 3D survey covered approximately 20 percent of the entire crater area. We believe that it is important to understand if similar fault systems exist in the larger context of the Barents Sea because they potentially could pose a threat to marine operations."Some of the questions that scientists, society and the industry does not know the answer to are: Will these weak structures lead to unpredictable and explosive methane release? Can such release and related geohazards be triggered by drilling? And can the gas reach the atmosphere in case of abrupt blow-outs, adding to the greenhouse gas budget?"There is still very much that we don't know about this system. But we are currently collecting and analyzing new data in the Barents Sea, dominated by similar crater structures. This can help us map in bigger detail the fault systems and associated weakness. " says Waage.
Research for the study was led by Dr. Rikki Gumbs of the EDGE of Existence Programme at the Zoological Society of London and Imperial College London and Dr. James Rosindell of Imperial College London in collaboration with Prof. Shai Meiri of the School of Zoology at Tel Aviv University's George S. Wise Faculty of Life Sciences and Steinhardt Museum of Natural History and other colleagues. The study was published in "Being 'evolutionarily distinct' means that you have no close living relatives," explains Prof. Meiri, who generated and interpreted the reptile-related data for the study. "In other words, you are alone on your branch of the evolutionary tree of life. Aardvarks, crocodiles, and kiwis were all separated from their closest evolutionary relatives tens of millions of years ago and bear a unique evolutionary history."The new research will provide a clear understanding of how best to protect nature given the current threats to specific locations and endangered species."The researchers developed two new metrics that combine phylogenetic diversity and the extent of human pressure across the spatial distribution of species -- one metric valuing regions and another prioritizing species. They evaluated these metrics for reptiles, which have been largely neglected in previous studies, and contrasted these results with equivalent calculations for all terrestrial vertebrate groups. The researchers found that regions under high human pressure coincided with those containing irreplaceable reptilian diversity."Our analyses reveal the incomprehensible scale of the losses we face if we don't work harder to save global biodiversity," says Dr. Gumbs, the lead author on the paper. "To put some of the numbers into perspective, reptiles alone stand to lose at least 13 billion years of unique evolutionary history, roughly the same number of years as have passed since the beginning of the entire universe."Using extinction-risk data for around 25,000 species, the researchers found at least 50 billion years of evolutionary heritage to be under threat, as well as a large number of potentially threatened species for which we lack adequate extinction risk data. This suggests that the calculation underestimates the number of species that may be affected.According to the study's calculations, the Caribbean, the Western Ghats of India, and large parts of Southeast Asia -- regions that are home to the most unique evolutionary history -- are facing unprecedented levels of human-related devastation."This new study highlights which species should be prioritized for conservation, based on their evolutionary uniqueness and the intense human impact on environments where they are thought to dwell," Prof. Meiri says.According to the research, the greatest losses of evolutionary history will be driven by the extinction of entire groups of closely-related species, such as pangolins and tapirs, and by the loss of highly evolutionarily distinct species, such as the ancient Chinese crocodile lizard (The study highlights several unusual species as urgent conservation priorities, including the punk-haired Mary River turtle ("These are some of the most incredible and overlooked animals on Planet Earth," says Dr. Gumbs. "From legless lizards and tiny blind snakes to pink worm-like amphibians called caecilians, we know precious little about these fascinating creatures, many of which may be sliding silently toward extinction."The study also identifies regions where concentrations of irreplaceable diversity are currently under little to no human pressure, particularly across the Amazon rainforest, the highlands of Borneo, and parts of southern Africa.Co-author Dr. Rosindell concludes, "Our findings highlight the importance of acting urgently to conserve these extraordinary species and the remaining habitat that they occupy -- in the face of intense human pressures."
According to Kakani Katija, MBARI Principal Engineer and the lead author on the new paper, "Mucus is ubiquitous in the ocean, and complex mucus structures are made by animals for feeding, health, and protection. Now that we have a way to visualize these structures deep below the surface we can finally understand how they function and what roles they play in the ocean."For this study, the researchers focused on one of the most prolific mucus architects, deep-sea animals called larvaceans. Larvaceans are abundant throughout the world's ocean basins and range from less than one centimeter to about 10 centimeters in length. So-called "giant" larvaceans create balloon-like mucus webs that can be up to a meter across. Inside these outer filters are smaller, fist-sized inner filters that the animals use to feed on tiny particles and organisms, ranging from less than a micron to a few millimeters in size.Despite their insubstantial bodies, larvaceans remove vast amounts of carbon-rich food out of the surrounding water. When their mucus filters become clogged the animals release the mucus, which sinks rapidly to the seafloor. This helps the ocean remove carbon dioxide from the atmosphere and carries microplastics from the water column down to the seafloor.Researchers, like MBARI Senior Scientist and co-author Bruce Robison, have long been interested in how larvaceans can filter a wide variety of particles while processing very large volumes of water (up to 80 liters an hour). Previous studies have looked at smaller larvacean filters in the laboratory, but this is the first study to provide quantitative data about these mucus structures in the open ocean.To gather these data, Katija, who heads MBARI's Bioinspiration Lab, worked with a team of engineers, scientists, and submersible pilots to develop an instrument called DeepPIV (PIV stands for particle imaging velocimetry). Mounted on a remotely operated vehicle (ROV), the DeepPIV instrument projects a sheet of laser light that illuminates particles in the water, like dust motes in a sunbeam. By recording the movement of these particles in video, researchers can quantify tiny currents around marine animals as well as water flowing through their filters and their transparent bodies.During field deployments of the DeepPIV system, Katija and her colleagues discovered that, as the ROV moved back and forth, the sheet of laser light revealed a series of cross sections through the transparent, gelatinous bodies and the mucus filters of giant larvaceans. By assembling a series of these cross-sectional images, the team was able to create three-dimensional reconstructions of individual larvaceans and their filters, much as radiologists do following a CAT scan of a human body.Collecting high-fidelity video imagery required skilled piloting of MBARI's ROVs. "Using DeepPIV to collect these 3D cross sections is probably the hardest thing I've ever done with an ROV," said Knute Brekke, chief pilot for ROV Doc Ricketts. "We were using a 12,000 pound robot to move a millimeter-thick laser sheet back and forth through a larvacean and its fist-sized mucus filter that was drifting hundreds of meters below the ocean surface."Combining three-dimensional models of larvacean filters with observations of flow patterns through the filters, Katija and her collaborators were able, for the first time, to identify the shape and function of different parts of the larvacean's inner filter. Using 3D rendering software, they were able to virtually "fly through" the inner filter and study the flow of fluid and particles through different parts of the filter."Now we have a technique for understanding the form of these complex structures, and how they function," Katija explained. "No one has done in situ 3D reconstructions of mucus forms like this before.""Among other things, we're hoping to understand how larvaceans build and inflate these structures," she continued. "This could help us design better 3D printers or build complex inflatable structures that could be used in a number of environments," including underwater and in outer space.Expanding on this work, members of the Bioinspiration Lab are experimenting with new 3D plenoptic imaging systems that can capture highly-precise information about the intensity, color, and direction of light in a scene. They are also collaborating on the development of new underwater robots that will be able to follow gelatinous animals through the water for hours or days at a time."In this paper, we have demonstrated a new system that operates well with a variety of underwater vehicles and midwater organisms," said Katija. "Now that we have a tool to study the mucus filtering systems found throughout the ocean, we can finally bring to light some of nature's most complex structures.""DeepPIV has revealed a marvel of natural engineering in the structure of these complex and intricate filtering webs," said Robison. "And in DeepPIV, human engineering has produced a powerful new tool for investigating these and other mysteries of the deep ocean."
The authors say we may soon see this play out due to the COVID-19 pandemic lessening global fuel consumption; they predict the ocean will not continue its recent historic pattern of absorbing more carbon dioxide each year than the year before, and could even take up less in 2020 than in 2019."We didn't realize until we did this work that these external forcings, like changes in the growth of atmospheric carbon dioxide, dominate the variability in the global ocean on year-to-year timescales. That's a real surprise," said lead author Galen McKinley, a carbon cycle scientist at Columbia University's Lamont-Doherty Earth Observatory. "As we reduce our emissions and the growth rate of atmospheric carbon dioxide slows down, it's important to realize that the ocean carbon sink will respond by slowing down."The paper, published today in the journal A carbon sink is a natural system that absorbs excess carbon dioxide from the atmosphere and stores it away. Earth's largest carbon sink is the ocean. As a result, it plays a fundamental role in curbing the effects of human-caused climate change. Nearly 40 percent of the carbon dioxide added to the atmosphere by fossil fuel burning since the dawn of the industrial era has been taken up by the ocean.There's variability in the rate at which the ocean takes up carbon dioxide, which isn't fully understood. In particular, the scientific community has puzzled over why the ocean briefly absorbed more carbon dioxide in the early 1990s and then slowly took up less until 2001, a phenomenon verified by numerous ocean observations and models.McKinley and her coauthors addressed this question by using a diagnostic model to visualize and analyze different scenarios that could have driven greater and lesser ocean carbon uptake between 1980 and 2017. They found the reduced ocean carbon sink of the 1990s can be explained by the slowed growth rate of atmospheric carbon dioxide early in the decade. Efficiency improvements and the economic collapse of the Soviet Union and Eastern European countries are thought to be among the causes of this slowdown.But another event also affected the carbon sink: The massive eruption of Mount Pinatubo in the Philippines in 1991 caused the sink to temporarily become much larger coincident with the eruption."One of the key findings of this work is that the climate effects of volcanic eruptions such as those of Mount Pinatubo can play important roles in driving the variability of the ocean carbon sink," said coauthor Yassir Eddebbar, a postdoctoral scholar at Scripps Institution of Oceanography.Pinatubo was the second-largest volcanic eruption of the 20th century. The estimated 20 million tons of ash and gases it spewed high into the atmosphere had a significant impact on climate and the ocean carbon sink. The researchers found that Pinatubo's emissions caused the ocean to take up more carbon in 1992 and 1993. The carbon sink slowly declined until 2001, when human activity began pumping more carbon dioxide into the atmosphere. The ocean responded by absorbing these excess emissions."This study is important for a number of reasons, but I'm most interested in what it means for our ability to predict the near-term, one to ten years out, future for the ocean carbon sink," said coauthor said Nicole Lovenduski, an oceanographer at the University of Colorado Boulder. "The future external forcing is unknown. We don't know when the next big volcanic eruption will occur, for example. And the COVID-19-driven carbon dioxide emissions reduction was certainly not anticipated very far in advance."Investigating how the Pinatubo eruption impacted global climate, and thus the ocean carbon sink, and whether the drop in emissions due to COVID-19 is reflected in the ocean are among the research team's next plans.By understanding variability in the ocean carbon sink, the scientists can continue to refine projections of how the ocean system will slow down.McKinley cautions that as global emissions are cut, there will be an interim phase where the ocean carbon sink will slow down and not offset climate change as much as in the past. That extra carbon dioxide will remain in the atmosphere and contribute to additional warming, which may surprise some people, she said."We need to discuss this coming feedback. We want people to understand that there will be a time when the ocean will limit the effectiveness of mitigation actions, and this should also be accounted for in policymaking," she said.The study was coauthored by Amanda Fay and Lucas Gloege of Columbia University's Lamont-Doherty Earth Observatory.
A team of experts from the University of Exeter has conducted a major study of how land-use changes, such as deforestation and urbanisation, influence the spread of diseases from mammals to humans.Most new viruses and other pathogens that arise in humans are transmitted from other animals, as in the case of the virus that has caused Covid-19.In the new review study, the researchers pinpointed one of the key factors that affect this transmission -- the changes in land-use such as deforestation, urbanisation, and conversion to agriculture.The effect of these land-use changes on the behaviour of animals, including rodents, livestock and other mammals, and risk of disease spread to humans has been mainly studied within the context of urbanisation.The review, published in the journal Orly Razgour, co-author and from the University of Exeter, said: "In this review, we highlight major gaps in our understanding of how land-use change affects the spread of diseases from mammals to humans, in terms of how key hosts, like bats, are affected, and how important land-use changes, such as agriculture, impact wild mammals and their interaction with livestock. There is an urgent need for more studies that link animal ecology and responses to land-use change with pathogen ecology and disease spread."Around 75 per cent of emerging human pathogens, such as viruses, are transmitted from animals to humans. These include emerging infectious diseases (EIDs) -- newly recognised or reappearing diseases detected in a population for the first time and which spread rapidly, such as covid-19.While it is important to identify the source of the outbreak and the factors that allow these EID's to spread, the researchers claim that many methods for collecting such data are still under development.Crucially, while areas such as South America and Asia have been studied more extensively, along with the effects of urbanisation, large swathes of the world including Africa are less well studied.The researchers have called for more extensive studies to be conducted worldwide, to not only improve our understanding of how these diseases spread, but also to help policymakers identify the factors that alter the risk of emergence.Rebekah White, co-author and also from the University of Exeter, added: "We need reliable surveillance and an understanding of how zoonotic diseases are able to spread to humans, but our results show that this information is not yet available for all hosts and pathogens. In fact, the epidemiology of many zoonotic pathogens is yet to be considered in relation to land use change at all, despite evidence suggesting that these changes can increase the risk of a disease emerging."
In predicting the impact of climate change on current and future global distributions of invasive weed species, Dr Shabani also found that existing attempts to eradicate invasive populations are inadequate.Dr Shabani and an international team of researchers investigated 32 globally important Invasive Weed Species to assess whether climate alteration may lead to spatial changes in the overlapping of specific IWS globally."We aimed to evaluate the potential alterations -- whether that be a gain, loss or static -- in the number of potential ecoregion invasions by IWS, under climate change scenarios," says Dr Shabani. "We utilised all possible greenhouse gas concentration to examine a range of possible outcomes."The paper -- Invasive weed species' threats to global biodiversity: Future scenarios of changes in the number of invasive species in a changing climate, by Farzin Shabani, Mohsen Ahmadi, Lalit Kumar, Samaneh Solhjouy-fard, Mahyat Shafapour Tehrany, Fariborz Shabani, Bahareh Kalantar and Atefeh Esmaeili -- has been published in the journal Initially, the researchers modelled the current climatic suitability of habitat for each of the weeds, identifying those with a common spatial range of suitability. They then modelled the suitability of all 32 species under the projected climate for 2050, incorporating different scenarios.The final methodological step compared the extent of overlaps and alterations of weed habitats under the current and future projected climates."Under future climatic conditions, our results mainly predicted decrease on a global scale, with reduced areas of habitat suitable for most Invasive Weed Species -- but significantly this excluded European countries, northern Brazil, eastern US, and south-eastern Australia, which are all highly productive agricultural regions," says Dr Shabani.The study also revealed that Invasive Weed Species would most likely develop alterations in their habitat suitability in most parts of the world in the future."Even though our future projections indicate a decreasing rate in threats from invasive weeds in extensive areas across the world, the current distributions of many species still have a potential for expansion," says Dr Shabani."Many of these invasive weeds pose a threat in suitable habitats under both current and future climate conditions."Dr Shabani is concerned that Invasive Weed Species are rarely mentioned in biodiversity policy documents, except to focus on a few high-profile species. "There are no comprehensive national invasive species statutory controls, which is our concern," he says. "We believe that a national framework is needed for prevention and early detection, along with a coherent policy framework, a robust monitoring framework, a fund for strategic research, and a national training and action program."
Researchers from Florida Atlantic University's Harbor Branch Oceanographic Institute in collaboration with Seven Degrees of Mapping LLC, and Hubbs-SeaWorld Research Institute, are the first to use satellite telemetry on this dolphin population, providing unique insights into their behavioral ecology during the overnight hours. Detailed information about their nocturnal movements and habitat use will give scientists a more complete ecological understanding of this population. These dolphins face many direct and indirect threats including boat strikes, entanglements, and environmental contamination.Results of the study, published in the journal The study also highlights how much variation occurs within a population -- researchers found individual differences with almost every aspect studied in these dolphins. Individual spatial use varied by dolphin, with home ranges and core areas of different sizes spaced throughout the southern region of the lagoon. Researchers also discovered extensive individual variation in niche preferences."There are many possible reasons for the difference in space use and movement patterns, including prey preference and distribution such as traveling between nearby hotspots versus long distances between food sources or the size or age of the dolphins," said Greg O'Corry-Crowe, Ph.D., project lead and a research professor at FAU's Harbor Branch. "For example, two of the dolphins in our study were smaller and younger, while the other two were larger and older. The differences we observed could also be linked to more complex aspects that are influenced by social factors, differences in predator avoidance strategies, and individual response to human disturbance."One of the areas showing less variation was inlet use. Three out of four dolphins exhibited a strong nocturnal preference for habitats close to inlets, with one individual regularly using multiple inlets. Inlets may be important nocturnal foraging habitats as well as corridors for movement between ecosystems.Satellite telemetry is a powerful research tool that tracks the movement of an animal using orbiting satellites that detect signals emitted from a transmitter attached to the animal. For the study, the researchers attached satellite tags (SPOT 100 tags, Wildlife Computers) on the lower third of the trailing edge of the dorsal fin of four male dolphins, aged 6 to 21 years. The satellite tags recorded location data via the Argos satellite system. The tags were set to transmit constantly until 250 transmissions were reached in each 24-hour cycle. Satellite tags remained active between 129 and 140 days.O'Corry-Crowe, Elizabeth F. Hartel, M.S., lead author, Seven Degrees of Mapping LLC, and co-author Wendy Noke Durden, M.S., Hubbs-SeaWorld Research Institute, suggest that incorporating satellite telemetry into long-term studies of bottlenose dolphins in other regions may provide essential information about their movements and habitat use that is not otherwise readily available."Collectively, findings from our study highlight the need for greater consideration of the nocturnal habits of cetacean species when conducting risk assessments, developing conservation action, and planning new research," said O'Corry-Crowe.
The findings, published in Ranging from the Alaska-Canada border and down through the Strait of Georgia, the reefs play an essential role in water quality by filtering microbes and cycling nutrients through food chains. They also provide critical habitat for many fish and invertebrates, including rockfish, spot prawns, herring, halibut and sharks."Glass sponge reefs are 'living dinosaurs' thought to have been extinct for 40 million years before they were re-discovered in B.C. in 1986," said Angela Stevenson, who led the study as a postdoctoral fellow at UBC Zoology. "Their sheer size and tremendous filtration capacity put them at the heart of a lush and productive underwater system, so we wanted to examine how climate change might impact their survival."Although the reefs are subject to strong, ongoing conservation efforts focused on limiting damage to their delicate glass structures, scientists know little about how these sponges respond to environmental changes.For the study, Stevenson harvested Aphrocallistes vastus, one of three types of reef-building glass sponges, from Howe Sound and brought them to UBC where she ran the first successful long-term lab experiment involving live sponges by simulating their natural environment as closely as possible.She then tested their resilience by placing them in warmer and more acidic waters that mimicked future projected ocean conditions.Over a period of four months, Stevenson measured changes to their pumping capacity, body condition and skeletal strength, which are critical indicators of their ability to feed and build reefs.Within one month, ocean acidification and warming, alone and in combination, reduced the sponges' pumping capacity by more than 50 per cent and caused tissue losses of 10 to 25 per cent, which could starve the sponges."Most worryingly, pumping began to slow within two weeks of exposure to elevated temperatures," said Stevenson.The combination of acidification and warming also made their bodies weaker and more elastic by half. That could curtail reef formation and cause brittle reefs to collapse under the weight of growing sponges or animals walking and swimming among them.Year-long temperature data collected from Howe Sound reefs in 2016 suggest it's only a matter of time before sponges are exposed to conditions which exceed these thresholds."In Howe Sound, we want to figure out a way to track changes in sponge growth, size and area and area in the field so we can better understand potential climate implications at a larger scale," said co-author Jeff Marliave, senior research scientist at the Ocean Wise Research Institute. "We also want to understand the microbial food webs that support sponges and how they might be influenced by climate cycles."Stevenson credits bottom-up community-led efforts and strong collaborations with government for the healthy, viable state of the B.C. reefs today. Added support for such community efforts and educational programs will be key to relieving future pressures."When most people think about reefs, they think of tropical shallow-water reefs like the beautiful Great Barrier Reef in Australia," added Stevenson. "But we have these incredible deep-water reefs in our own backyard in Canada. If we don't do our best to stand up for them, it will be like discovering a herd of dinosaurs and then immediately dropping dynamite on them."The colossal reefs can grow to 19 metres in height and are built by larval sponges settling atop the fused dead skeletons of previous generations. In northern B.C. the reefs are found at depths of 90 to 300 metres, while in southern B.C., they can be found as shallow as 22 metres.The sponges feed by pumping sea water through their delicate bodies, filtering almost 80 per cent of microbes and particles and expelling clean water.It's estimated that the 19 known reefs in the Salish Sea can filter 100 billion litres of water every day, equivalent to one per cent of the total water volume in the Strait of Georgia and Howe Sound combined.
"Up until now we knew that many factors could have influenced the pace of reef fish evolution, but these factors were never examined altogether," said Alexandre Siqueira, the study's lead author from the ARC Centre of Excellence for Coral Reef Studies at James Cook University (Coral CoE at JCU)."By building an evolutionary 'tree of life' for nearly all fishes associated with reefs, we were able to examine the variation in rates of species formation and ask what drives it," said co-author Dr Peter Cowman, also from Coral CoE at JCU.The 'tree of life' contains more than 6,000 fish species that live on coral reefs across the globe. Ecological and geographical data -- such as diet and geographical range -- were also gathered for the majority of these species.The authors were surprised to find that what really matters in reef fish evolution isn't geography, but what fish eat and how big they get."We found that the fastest way to have more species, or biodiversity, on a reef is to be big and vegetarian," said co-author Professor David Bellwood, also from Coral CoE at JCU."Herbivores, such as surgeonfishes and parrotfishes, are key to the ecological diversity of coral reefs today."The study suggests these fishes also made way for today's coral reefs to evolve and flourish."By feeding on the algae that compete with corals, herbivorous fishes may have also helped corals to expand through time," Mr Siqueira said."In turn, this expansion in the corals allowed the diversification of other reef fish groups that depend on them."And these herbivorous fishes -- big and small -- still maintain coral reefs to this day.The study offers a new way of looking at reefs with a functional, rather than taxonomic, approach. Very little is known about the functional evolution of reefs: what they do and how they work. Scientists previously only looked at how many reefs there were and what species were present."In this study it was important to understand the origins of the functional role a fish species plays on a reef -- not just the species itself," Dr Cowman said.Today's coral reefs differ from their early counterparts. It was only during the Miocene, less than 23 million years ago, that herbivorous fish species developed features that allowed them to explore different areas of the reef."Because of this, today's reefs are highly dynamic and have a fast turnover. These herbivores are the key element that established modern coral reefs," Prof Bellwood said."Understanding how reefs are constructed throughout their evolution means we can reach a better understanding of the fundamental processes that maintain them in a healthy state today," Mr Siqueira said.
But Australia is not alone. Across the globe, several important agricultural and forested regions in the Amazon, Mediterranean and southern Africa can expect more frequent and intense rainfall droughts. While some regions like central Europe and the boreal forest zone are projected to get wetter and suffer fewer droughts, those droughts they do get are projected to be more intense when they occur.The research published in "We found the new models produced the most robust results for future droughts to date and that the degree of the increase in drought duration and intensity was directly linked to the amount of greenhouse gases emitted into the atmosphere," said lead author Dr Anna Ukkola."There were only slight changes to the areas of drought under a mid-range emissions scenario versus a high-emissions pathway. However, the change in the magnitude of drought with a higher emissions scenario was more marked, telling us that early mitigation of greenhouse gases matters."Much of the earlier research into future droughts only considered changes to average rainfall as the metric to determine how droughts would alter with global warming. This often produced a highly uncertain picture.But we also know that with climate change, rainfall is likely to become increasingly variable. Combining metrics on variability and mean rainfall, the study increased clarity around how droughts would change for some regions.The researchers found the duration of droughts was very closely aligned to changes in the average rainfall, but the intensity of droughts was much more closely connected to the combination of average rainfall and variability. Regions with declining average rainfall like the Mediterranean, Central America and the Amazon are projected to experience longer and more frequent droughts. Meanwhile, other regions, such as the boreal forests are expected to experience shorter droughts in line with increasing average rainfall.However, the situation is different for drought intensity alone with most regions projected to experience more intense rainfall droughts due to increasing rainfall variability. Importantly, the researchers were unable to locate any region that showed a reduction in future drought intensity. Even regions with long-term increases in rainfall, such as central Europe, can expect more intense droughts as rainfall becomes more variable."Predicting future changes in drought is one of the greatest challenges in climate science but with this latest generation of models and the opportunity to combine different drought metrics in a more meaningful way we can gain a clearer insight into the future impacts of climate change," said Dr Ukkola."However, while these insights grow clearer with each advance, the message they deliver remains the same -- the earlier we act on reducing our emissions, the less economic and social pain we will face in the future."
While pulling the anthropogenic, or human-made, carbon dioxide from the atmosphere is good for the earth's system, it leads to problems for the world's oceans as dissolved carbon dioxide becomes carbonic acid and leads to ocean acidification, changing the chemistry of the world's oceans and impacting some of the life forms within it. In particular, the organisms that use calcium to build their carbonate skeletons -- such as corals or mollusks -- will have a harder time under acidified conditions.To help determine the causes of ocean acidification on both coasts of North America, University of Delaware professor Wei-Jun Cai teamed with the National Oceanic and Atmospheric Administration (NOAA) scientists, as well as professors and professionals from numerous research institutes, to conduct an in-depth study that looks at carbon dioxide uptake and ocean acidification in the coastal oceans of North America.While ocean acidification in North America has been studied in smaller, specific areas before, this is the first time that researchers have compared data from the east coast, west coast and Gulf of Mexico locations.Through this work, researchers were able to identify the similarities and differences of ocean acidification on both coasts, as well as point out hot spots that will be particularly vulnerable to ocean acidification in the future. The results of that research were recently published in Cai said that in order to adequately research ocean acidification, the work cannot be done by just a few people from one region or even one country. This study involved researchers in the United States, Mexico and Canada."In North America, as well as globally, we're trying to get as many countries involved as possible," said Cai, the Mary A.S. Lighthipe Professor in the School of Marine Science and Policy in UD's College of Earth, Ocean and Environment.For this particular project, the goal was to synthesize their findings to show how ocean acidification works in general for coastal oceans in North America and how those interact with the more localized physical and biological processes."Ocean acidification is everywhere, but this paper basically shows that, depending on the location, it can manifest very differently," said Cai.Sampling the same latitudinal locations on the east and west coasts, as well as the Gulf of Mexico, over the course of several research cruises, allowed the researchers to see different patterns for the east coast and the west coast of North America.The near equilibrium of ocean waters with the atmospheric carbon dioxide controls the large pattern of ocean acidification on the east coast and Gulf of Mexico while on the west coast, the ocean acidification is enhanced by an additional process known as upwelling.In the ocean waters of the east coast, the northbound Gulf Stream Current system brings warm, high-salinity waters from the tropics while the southbound Labrador Current brings cold, low-salinity waters from the Arctic and subarctic regions.Northern waters on the east coast are particularly sensitive to atmospheric carbon dioxide uptake, as the colder ocean temperature allows the ocean to take more carbon dioxide from the atmosphere.Rising carbon dioxide levels upset the balance of carbonate ions in seawater, making it difficult for some organisms, which have shells composed of the mineral calcium carbonate, to form their shells. Many of the organisms that are affected are critical for ecosystem health."The northeast and western coastal communities are very aware of this potential harm that ocean acidification could bring to their region because the marine organisms become more vulnerable sooner in the northern waters," said Cai.In the east coast's warmer southern waters, the researchers observed lower levels of dissolved inorganic carbon and a higher mineral saturation state, meaning that acidity is lower here when compared to the northern waters.On the west coast, a section of the ocean is influenced by the California Current System (CCS), which extends from the United States and Canadian border to Baja California. The CCS is characterized by strong, cold currents, and wind-driven upwelling events.Upwelling brings colder, nutrient-rich subsurface waters to the ocean's surface to replace surface water that has been pushed away by winds. "The water from the subsurface has low pH and high carbon dioxide, which causes stress to the biological system," said co-author Richard Feely of NOAA's Pacific Marine Environmental Laboratory (PMEL). "So the combination of the uptake of anthropogenic carbon dioxide from the atmosphere and the upwelling of CO"We tried to give the community, particularly the shellfish community or the stakeholders that care about the large-scale ocean acidification, the sense that both the northern waters and at these upwelling centers are most vulnerable to atmospheric COAreas of concern include the CCS and northern-latitude coastal regions, such as the Gulf of Maine in the Atlantic and the Gulf of Alaska in the Pacific, as they are particularly sensitive and vulnerable to anthropogenic carbon dioxide forcing.The research cruises took place between 2007 and 2018 -- with future ones scheduled for summer of 2020, 2021 and 2022 -- and the researchers would be out on the water for 35 to 40 days at a time.Cai said that this data collection would not have been possible without the large numbers of international collaborators. He is hopeful that by putting all of this data together, it can be used for future ocean acidification research. Cai also would like to expand this analysis to global scale."The different regional collaboration and synthesis efforts to put data together is really important," said Cai. "We need more of this kind of synthesis work to teach us how these different processes create regions of high and low vulnerability of marine life to ocean acidification."
A recent study from the University of Washington explores the ways parasitism will respond to climate change, providing researchers new insights into disease transmission. The paper was published May 18 in The review builds upon previous research by adding nearly two decades of new evidence to build a framework showing the parasite-host relationship under climate oscillations. Traditionally, climate-related research is done over long timescales, however this unique approach examines how increasingly frequent "pulse warming" events alter parasite transmission."Much of what is known about how organisms and ecosystems can respond to climate change has focused on gradual warming," said lead author Danielle Claar, a postdoctoral researcher at the UW School of Aquatic and Fishery Sciences. "Climate change causes not only gradual warming over time, but also increases the frequency and magnitude of extreme events, like heat waves."Claar explained that both gradual warming and pulse warming can and have influenced ecosystems, but do so in different ways. Organisms may be able to adapt and keep pace with the gradual warming, but an acute pulse event can have sudden and profound impacts.The 2013-2015 "blob" is one such extreme heat pulse event which has been linked to a massive die-off of sea stars along the Pacific coast of the U.S. and Canada. Many species of sea stars, including the large sunflower sea star, were decimated by a sudden epidemic of wasting disease. Five years later, populations in the region are still struggling to recover. The abnormally warm waters associated with the blob are thought to have favored the spread of the sea star-associated densovirus, the suggested cause of the disease.The authors compare the prevalence of these marine diseases to a rising tide, an ebbing tide, or a tsunami. Disease transmission can rise or ebb in concert with gradual warming or a series of pulse warming events. However, a severe pulse warming event could result in a tsunami, "initiating either a deluge or drought of disease," as was observed with sea stars along the Pacific Northwest.However, not all pulse heat events will cause the same response. What may benefit a particular parasite or host in one system can be detrimental in another. Warming can alter a parasite's life cycle, limit the range of suitable host species, or even impair the host's immune response. Some flatworms which target wildlife and humans cannot survive as long in warmer waters, decreasing their window for infecting a host. Another recent UW study found that parasites commonly found in sushi are on the rise with their numbers increasing 283-fold in the past 40 years, though the relationship between heat pulse events and their abundance is not yet clear."The relationships between hosts, parasites, and their corresponding communities are complex and depend on many factors, making outcomes difficult to predict," said Claar, who recommends researchers make predictions on a case-by-case basis for their individual systems.The authors conclude that rather than a straightforward tidal prediction, they would expect pulse warming to cause "choppy seas with the occasional rogue wave.""It is important that we are able to understand and predict how parasitism and disease might respond to climate change, so we can prepare for, and mitigate, potential impacts to human and wildlife health," said Claar.
"Forest fires in this region of the Arctic used to happen about every hundred years and now we're seeing them every summer," said Bianca RodrÃ­guez-Cardona '20G, who just received a Ph.D. in UNH's natural resources and Earth system sciences program. "This increase in fires leads to more input of inorganic solutes into local streams which can alter the chemistry and trigger issues like increased algae blooms and bacteria that can be harmful to humans who depend on these waterways for drinking water, fishing and their livelihood."In the study, recently published in the journal Nature's Boreal forests, forests that grow in high latitudes at low temperatures, have been burning with greater frequency due to longer growing seasons, warmer temperatures and changing weather patterns adding additional uncertainty to how these ecosystems will be affected. While other studies have documented the effects of wildfires on stream chemistry, few have evaluated how these changes will impact the processing and export of nutrients from Arctic watersheds."Arctic rivers transfer large quantities of nutrients to the Arctic Ocean, and river water chemistry could be dramatically changed in the coming decades as permafrost thaws and wildfires become more frequent," said William McDowell, professor of environmental science and a co-author on the study. The researchers say even though responses of arctic watersheds can vary from region to region, this offers further understanding of what could happen in other areas of the Arctic, like Alaska, Canada, Norway or Sweden.
The study, led by the Scott Polar Research Institute at the University of Cambridge, used patterns of delicate wave-like ridges on the Antarctic seafloor to calculate how quickly the ice retreated roughly 12,000 years ago during regional deglaciation.The ridges were produced where the ice sheet began to float, and were caused by the ice squeezing the sediment on the seafloor as it moved up and down with the movement of the tides. The images of these landforms are at unprecedented sub-metre resolution and were acquired from an autonomous underwater vehicle (AUV) operating about 60 metres above the seabed. The results are reported in the journal While modern satellites are able to gather detailed information about the retreat and thinning rates of the ice around Antarctica, the data only goes back a few decades. Calculating the maximum speed at which an ice sheet can retreat, using sets of these seafloor ridges, reveals historic retreat rates that are almost ten times faster than the maximum observed rates of retreat today."By examining the past footprint of the ice sheet and looking at sets of ridges on the seafloor, we were able to obtain new evidence on maximum past ice retreat rates, which are very much faster than those observed in even the most sensitive parts of Antarctica today," said lead author Professor Julian Dowdeswell, Director of the Scott Polar Research Institute.The study was carried out as part of the Weddell Sea Expedition, which set out in early 2019 to undertake a science programme and to find Sir Ernest Shackleton's doomed ship Endurance. Although sea ice conditions at the time prevented the team from acquiring imagery of the legendary wreck, they were able to continue with their scientific work, including mapping of the seafloor close to the Larsen Ice Shelf, east of the Antarctic Peninsula.Using drones, satellites and AUVs, the researchers were able to study ice conditions in the Weddell Sea in unprecedented detail.Their goals were to investigate the present and past form and flow of the ice shelves, the massive floating sections of ice that skirt about 75% of the Antarctic coastline, where they act as a buttress against ice flow from inland.Like much of the rest of the ice in the polar regions, these buttresses are weakening in some parts of Antarctica, as witnessed most dramatically at the Larsen A and B ice shelves, which collapsed rapidly in 1998 and 2002, when roughly 1250 square miles of ice fragmented and collapsed in little over a month.The ice shelves are thinning because relatively warm water currents are eating away at them from below, but they're also melting from the top as summer air temperatures rise. Both these effects thin and weaken the ice shelves and, as they do, the glaciers they are holding back flow faster to the sea and their margins retreat.Using AUVs, the team were able to gather data on historic ice shelf fluctuations from the geological record on the Antarctic continental shelf."By examining landforms on the seafloor, we were able to make determinations about how the ice behaved in the past," said Dowdeswell, who was chief scientist on the Weddell Sea Expedition. "We knew these features were there, but we've never been able to examine them in such great detail before."The team identified a series of delicate wave-like ridges on the seafloor, each only about one metre high and spaced 20 to 25 metres apart, dating to the end of the last great deglaciation of the Antarctic continental shelf, roughly 12,000 years ago. The researchers have interpreted these ridges as formed at what was formerly the grounding line -- the zone where grounded ice sheet begins to float as an ice shelf.The researchers inferred that these small ridges were caused by the ice moving up and down with the tides, squeezing the sediment into well-preserved geological patterns, looking a little like the rungs of a ladder, as the ice retreated. Assuming a standard 12-hour cycle between high and low tide, and measuring the distance between the ridges, the researchers were then able to determine how fast the ice was retreating at the end of the last Ice Age.They calculated that the ice was retreating as much as 40 to 50 metres per day during this period, a rate that equates to more than 10 kilometres per year. In comparison, modern satellite images show that even the fastest-retreating grounding lines in Antarctica today, for example in Pine Island Bay, are much slower than these geological observations, at only about 1.6 kilometres per year."The deep marine environment is actually quite quiet offshore of Antarctica, allowing features such as these to be well-preserved through time on the seafloor," said Dowdeswell. "We now know that the ice is capable of retreating at speeds far higher than what we see today. Should climate change continue to weaken the ice shelves in the coming decades, we could see similar rates of retreat, with profound implications for global sea level rise."The research was funded in part by the Flotilla Foundation and Marine Archaeology Consultants Switzerland.
To understand what these groups are doing and why, researchers from McGill University, the University of Georgia, and the Leibniz Centre of Tropical Marine Research analyzed data from 679 environmental NGOs worldwide in a study for These organizations are usually thought to focus on environmental protection and conservation. However, in examining the mission statements of these groups, the researchers found that the importance of climate politics (engagement on climate change) and environmental justice (respect for nature and human rights) had been grossly underestimated in previous research. They calculated a power index for the NGOs based on their human and financial resources and found that more than 40% of the most powerful organizations focus on these areas in their mission."There are more powerful organizations working on climate issues than on issues of biodiversity loss or land degradation," says co-author Klara Winkler, a postdoctoral researcher from McGill University. "It is important to be aware that some environmental issues garner more attention than others because it means that these other issues risk being neglected or even forgotten."The study also shows regional disparities in human resources and financial capacity. Environmental NGOs in Africa and Oceania have the lowest median number of employees and African NGOs have the lowest median annual budgets. While organizations in North America and Europe have the highest median financial capacity, Latin America and the Caribbean has the highest median number of employees.According to the researchers, these differences likely reflect both labor costs and financial flows, where environmental NGOs in the Global South employ more people with less money while groups in the Global North handle more money with fewer employees. This disparity is also indicative of a global division of labor where Northern environmental NGOs act as donors or coordinators for large projects, while Southern organizations are subcontracted for implementation."The findings give us an indication of how feasible it is for NGOs to advocate and implement their agendas in practice. Seeing where the disparities and limitations are in different regions can help us better understand observed differences in environmental policies and politics," says co-author Stefan Partelow from the Leibniz Centre for Tropical Marine Research in Germany.
Understanding how changes in climate affect the ability of blue whales to feed gives researchers more insight into the whales' overall health and provides critical information for conservation and management, said Leigh Torres, an assistant professor and director of the Geospatial Ecology of Marine Megafauna Laboratory at OSU's Marine Mammal Institute."These whales don't move around at random. We found that the same ocean patterns that determine where whales are also determine where their prey are, under both typical and warm ocean conditions," Torres said. "The more we learn about what drives these whales' movement, the more we can help protect them from whatever threats they face."The researchers' findings were published today in the journal Torres, Barlow and colleagues recently documented this new population of New Zealand blue whales, which is genetically distinct from other blue whale populations and spends much of its time in the South Taranaki Bight between New Zealand's North and South Islands."The goal of our study is to understand the habitat use patterns of this population of blue whales -- why they are where they are and how they respond to changing ocean conditions," Barlow said. "We know this area is important to this population of whales, and we want to understand what it is about this spot that is desirable to them."The region is often rich in prey -- blue whales feast on patches of krill -- but the prey is patchy and influenced by changing ocean conditions, including warmer temperatures and changes in ocean properties. The South Taranaki Bight also sees frequent shipping traffic and activity from oil and gas exploration and production, Torres said.Using data collected during typical summer conditions in 2014 and 2017 and warmer than average conditions in 2016, the researchers analyzed how changing ocean conditions affect the blue whales' distribution in the region's waters and the availability and location of their prey within the water column.They found that during a regional marine heat wave in 2016, there were fewer aggregations of krill for the whales to dine on. With fewer options, the whales pursued the densest aggregations of krill they could find, Barlow said.The researchers also found that during both warm and more typical ocean conditions the whales were more likely to feed in areas where the water was cooler. During the marine heat wave, when even the coolest water temperatures were higher than normal conditions, the whales still sought the coolest waters available for feeding.In this region, cooler water temperatures represent deeper water that was pushed toward the surface in a process called upwelling and tends to be nutrient-rich, Torres said.The nutrient-rich water supports aggregations of krill, which in turn provide sustenance for the blue whales. In their study, the researchers were able to bring all of the pieces of this trophic pathway together to describe the relationships between oceanography, krill and whales.As warmer ocean conditions become more frequent, this new knowledge can be used to inform and adjust spatial management of human activities in the region in an effort to reduce impacts on New Zealand blue whales, Torres said."Documenting information like this can really help us understand how to reduce threats to these animals," Torres said. "We need continued monitoring to understand how these whales will respond to both the changing climate and human impacts."
Professor Seung-Ki Min and Dr. Seungmok Paik of Division of Environmental Science and Engineering at POSTECH and researchers from the French National Centre for Scientific Research, Swiss Federal Institute of Technology in Zurich, and University of Edinburgh have released new findings that the El NiÃ±o induced by volcanic eruptions plays a key role in the decrease in global precipitation. So far, studies have shown that volcanic activity reduces precipitation across the globe, but its specific mechanism had been unclear. These research results were recently published in Science Advances, a sister journal of Science.During the two to three years following Mount Pinatubo's eruption in 1991, the average global temperature fell by about 0.2 degrees. This is because the massive dust including sulfur dioxide emitted by the eruption reflected the light from the sun and blocked its heat from reaching the Earth's surface. Volcanic activities, along with this cooling effect, reduce the global terrestrial precipitation but its amplitude greatly varies depending on climate model simulations. For the first time, the joint research team confirmed that the main factor for the drop in precipitation after volcanic eruptions is the difference in El NiÃ±o's response.El NiÃ±o is a natural climate variability that occurs every three to eight years, with weakened trade winds in the equatorial Pacific Ocean and warmer sea surface temperatures in the equatorial eastern Pacific, causing extreme weather conditions across the globe including drought and heavy rains. Under El NiÃ±o's influence, precipitation reduction occurs especially in the global monsoon regions, including Southeast Asia, India, South Africa, Australia and northern South America.The team compared several climate model simulations and found that El NiÃ±o appeared in the year following a volcanic eruption in most models, with a significant drop in precipitation around the global monsoon region. In particular, the strength of El NiÃ±o was different for each simulation, and the stronger the El NiÃ±o, the more pronounced the reduction in precipitation occurred. The research team also found that the stronger the volcanic forcing and the greater the warm water volume in the western Pacific Ocean, a stronger El NiÃ±o developed, which in turn intensified the reduction in precipitation.These findings are expected to be used to identify the side effects of geoengineering techniques and to predict the climate of the later years. In particular, it suggests that if geoengineering techniques are used to reduce global warming by spraying sulfur dioxide -- the main component of volcanic ash -- in the lower stratosphere to imitate artificial volcanoes, they could produce unexpected side effect of changing the precipitation patterns across the globe.Professor Seung-Ki Min stated, "If geoengineering techniques are applied to mimic volcanoes and block sunlight, drought and water shortages may increase significantly in the monsoon regions -- home to two-thirds of the world's population."This research was supported by the Mid-career Researcher Program of the National Research Foundation of Korea.
Scientists have sought to understand the links between geology (the rock types that soils originate from), biogeochemistry (feedbacks between environmental conditions, nutrient cycling, and plants), biodiversity (the variety of life in an ecosystem), and biogeography (how trees are distributed across a landscape) to paint a more complete picture of how life coevolved with our planet. Now, in a new study published today in "We wanted to explore how long-term processes that shape the Earth's surface also act to control the organization of ecosystems across landscapes. Understanding these organizing processes requires the integration of concepts from across disciplines. The purpose of this study was to combine high-resolution airborne remote sensing datasets that contain information on both ecosystems and the morphology of landscapes, to understand how the two are interrelated on this iconic tropical mountain," said Dana Chadwick, lead author of the study.The study analyzed data from Mt. Kinabalu in Malaysian Borneo -- a 4,095-meter high mountain harboring a wide diversity of trees across topographically varied terrain. As tropical rains drench the mountain's surface, elevation differences between its shallow slopes and steep peaks create imbalances in soil erosion rates -- generally, the steeper the hill, the faster the rain rushes down its surface, taking soil with it. Soils carry nutrients needed by plants to grow, and erosion contributes to the distribution of these plant-required nutrients. Some areas become nutrient-rich and others become nutrient-poor, influencing the kinds of trees that can grow there. Adding to this dynamic process, some soil types are more or less prone to erosion than others depending upon their geological origins, and can also contain more nutrients plants need than others.To overcome limitations of previous studies conducted in tropical mountains at a local scale, the researchers used maps created by ASU's Global Airborne Observatory to collect large-scale data across 32 watersheds and at elevations ranging from 700 to 2800 meters. The maps included the concentrations of nutrients in the tropical forest canopy as well as the structure and architecture of the trees. This provided the researchers an unprecedented look at the forests of Mt. Kinabalu and its remote complex terrain."Although we originally deployed our airborne observatory to Borneo for conservation impact, such as the new protected area now under development, the opportunity to discover all-new patterns of biodiversity also presented itself in ultra-remote areas like Mt. Kinabalu," said Greg Asner, author of the study and director of ASU's Center for Global Discovery and Conservation Science.The chemical maps revealed that leaves from trees contained different amounts of nutrients depending upon both the elevation and geology of its environment. Along hillslopes, from ridge to valley, trees contain more nutrients while their ability to capture and utilize sunlight also increases. The researchers found that this trend was significantly impacted by changing erosion rates, highlighting the important role erosion plays in distributing fresh nutrients to the soil."The discovery of such strong and beautifully complex geologic control on forest composition gives us new insight into the fundamental make-up of Bornean forests, in ways that inspire even more exploration," Dr. Asner added.
Clark Rushing, Assistant Professor in the Department of Wildland Resources and Ecology Center, Quinney College of Natural Resources at Utah State University, and colleagues at the U.S. Geological Survey wanted to know how climate change has already affected where birds breed. They used data from the Breeding Bird Survey -- one of the oldest and longest citizen-science programs in the world -- to conduct their research. "Thousands of devoted volunteers, cooperators, and a joint U.S.-Canadian wildlife management team have contributed to the success of the surveys for the last 54 years," said Andy Royle, a USGS senior scientists and co-author of the study. "The Breeding Bird Survey is fundamental to our understanding and management of wild bird populations in North America."The research team combined Breeding Bird Survey data with powerful computer models to discover changes in breeding range for 32 species of birds found in eastern North America. What they found is surprising:Some birds' ranges are expanding. Birds that both breed and winter in North America are extending their ranges north to take advantage of new, warm places to breed. These birds are also maintaining their southern ranges. These results bring hope that some bird populations, such as Carolina wrens and red-bellied woodpeckers, may be resilient to future climate change.Some birds' ranges are shrinking. Neotropical migratory birds breed in North America during the summer and migrate to the Caribbean, Central America, and South America for the winter. Neotropical migrants include many species that people love and look forward to seeing each spring such as buntings, warblers, orioles, and flycatchers. The team's research shows that these birds are not expanding north and their southern ranges are shrinking.To make matters worse, over the past 50 years Neotropical bird populations have decreased by about 2.5 billion individuals. Rushing explained, "There's a real risk that, if these declines continue at their current pace, many species could face extinction within this century. Neotropical migrants are vulnerable to future climate change, putting them at risk of greater declines."Neotropical migrants already fly thousands of miles each year to breed, so why can't they go just a bit farther as the climate warms? The researchers suspect the conditions where the birds live during the winter might make this impossible. Migrations require immense reserves of energy, so migratory birds need high-quality winter habitat with abundant food and moisture. Unfortunately, many habitats in the Caribbean, Central America, and South America are being degraded. It is possible that Neotropical birds can't store enough energy during the winter, so they simply can't extend their journeys any farther."That's just one explanation," concluded Rushing, "and it highlights how little we know and how much more research is needed." And what the team does know wouldn't have been possible without the help of devoted citizen scientists.
New insight into coastal flows gleaned by an international research team led by George Haller, Professor of Nonlinear Dynamics at ETH Zurich, promises to enhance the search and rescue techniques currently in use. Using tools from dynamical systems theory and ocean data, the team has developed an algorithm to predict where objects and people floating in water will drift. "Our work has a clear potential to save lives," says Mattia Serra, former Ph.D. student at ETH and now a postdoctoral fellow at Harvard, who is the first author of a study recently published in In today's rescue operations at sea, elaborate models of ocean dynamics and weather forecasting are used to predict the path of drifting objects. For fast-changing coastal waters, however, such predictions are often inaccurate due to uncertain parameters and missing data. As a result, a search may be launched in the wrong location, causing a loss of precious time.Haller's research team obtained mathematical results predicting that objects floating on the ocean's surface should congregate along a few special curves which they call TRansient Attracting Profiles (TRAPs). These curves are invisible to the naked eye but can be extracted and tracked from instantaneous ocean surface current data using recent mathematical methods developed by the ETH team. This enables quick and precise planning of search paths that are less sensitive to uncertain-ties in the time and place of the accident.In collaboration with a team of MIT's Department of Mechanical Engineering, a group of the Woods Hole Oceanographic Institute and the US Coast Guard, the ETH team tested their new, TRAP-based search algorithm in two separate ocean experiments near Martha's Vineyard near the north-eastern coast of the United States. Working from the same real-time data available to the Coast Guard, the team successfully identified TRAPs in the region in real time. They found that buoys and manikins thrown in the water indeed quickly gathered along these evolving curves. "Of several competing approaches tested in this project, this was the only algorithm that consistently worked in situ," says Haller."Our results are rapidly obtained, easy to interpret and cheap to implement," points out Serra. He adds that the method they have developed also has the potential to predict the evolution of oil spills. The next plan of the research group is to test their new prediction tool in other ocean regions as well. As Haller stresses: "Our hope is that this method will become a standard part of the toolkit of coast guards everywhere."
Narwhals are difficult to study because they are notoriously shy and skittish and spend most of their time deep in the freezing Arctic Ocean. They tend to summer in glacial fjords around Greenland and Canada, but scientists often have trouble getting close enough to study them. Glacier fronts can be dangerous and hard to access, and the animals tend to swim off when approached by motorized boats.But Inuit hunters familiar with the mysterious cetaceans can get closer to the animals without disturbing them. In July 2019, researchers accompanied several Inuit whale hunting expeditions in Northwest Greenland to study the narwhals that summer there in more detail.Using underwater microphones attached to small boats, the researchers captured narwhal social calls and foraging sounds, getting as close as 25 meters (82 feet) to the elusive cetaceans.The recordings help the researchers provide a baseline of the kinds of sounds that permeate the narwhals' pristine habitat. In combination with sightings, they also show narwhals get closer to glacier ice than previously thought for this area and the animals do forage for food in summer, contrary to some previous findings."Their world is the soundscape of this glacial fjord," said Evgeny Podolskiy, a geophysicist at Hokkaido University in Sapporo, Japan and lead author of a new study detailing the findings in AGU's Podolskiy and his colleagues had been working in Greenland fjords for several years, studying the sounds made by melting glaciers. Coincidentally, a population of narwhals summers in the fjords they were studying, and Podolskiy saw an opportunity to study the wily creatures."I realized working in the area and not paying attention to the elephant in the room -- the key endemic legendary Arctic unicorn just flowing around our glacier -- was a big mistake," he said.The researchers tagged along on several Inuit hunting expeditions departing from the village of Qaanaaq, placing microphones underwater and recording the baseline sounds of the fjord.They captured several types of sounds made by narwhals, including social calls, or whistles, and clicks used for echolocation, the biological sonar used by dolphins, bats, some whales and other animals to navigate and find food.The closer narwhals get to their food, the faster they click, until the noise becomes a buzz not unlike that of a chainsaw. This terminal buzz helps the narwhals pinpoint the location of their prey."If you approach and target these fast fish, you better know precisely where they are; you need to gather this information more frequently," Podolskiy said.Few studies have documented narwhals feeding in the summertime. Because the microphones picked up terminal buzz, a sound associated with finding food, the new study provides further evidence that narwhals do forage in summer.Surprisingly, the researchers found narwhals come roughly within 1 kilometer (half a mile) of a glacier calving front, despite the fact that these areas are some of the noisiest places in the ocean and calving icebergs can be dangerous."There is so much cracking due to ice fracturing and bubbles melting out... it's like a fizzy drink underwater," Podolskiy said. "It seems we are dealing with animals living in one of the most noisy environments without having much trouble with that."
Andreas Sichert from the Max Planck Institute for Marine Microbiology dedicated his PhD to the question how brown algae can be such a good sink of carbon: "Main constituents of algal biomass are their cell walls -- a tight network of proteins and long-chained sugars. When the algae die, we actually have little clue about the fate of algal biomass in the ocean, for example which compounds are degraded fast or slowly."The Atlantic coast is not a cozy habitat. Tides, wind and waves demand special adaptations from the inhabitants of this harsh environment. Brown algae developed a special cell wall structure, making them both firm and flexible, and enabling the plant to successfully withstand heavy currents and waves. A major component of the cell walls is the polysaccharide fucoidan, a long-chained sugar accounting for about a quarter of algal dry mass. Likely, fucoidan can regulate the water content of the cell wall which protects brown algae from drying out at low tide.What role this sugar plays in the long degradation process of brown algae was analyzed by scientists from the research group Marine Glycobiology at the Max Planck Institute for Marine Microbiology and the MARUM, Center for Marine Environmental Sciences at the University of Bremen. For their study, they cooperated with colleagues from the Massachusetts Institute of Technology, from the University of Greifswald and from the University of Vienna. "It was already known that microbial communities hydrolyze fucoidan slower than other algal polysaccharides and thus fucoidan might act as carbon sink" says Andreas Sichert from the Max Planck Institute for Marine Microbiology, first author of the study, published in the scientific journal So far, the fucoidan degradation pathways were only partially known, but it was evident that they involve a substantial number of enzymes either distributed within a microbial community or housed within individual, highly specialized bacteria. The scientists from Bremen examined the latter theory and analyzed newly isolated bacteria of the genus Lentimonas, belonging to the phylum Verrucomicrobia. Even the isolation of these Lentimonas bacteria was challenging. "From initially more than thousand colonies, only one was able to degrade fucoidan in the end," remembers Christopher H. Corzett from the Massachusetts Institute of Technology, first author of the study next to Andreas Sichert."We could show that Lentimonas acquired a remarkably complex machinery for the degradation of fucoidan that uses about one hundred enzymes to liberate the sugar fucose -- a part of fucoidan," says Jan-Hendrik Hehemann, leader of the research group Marine Glycobiology. "This is probably one of the most complicated biochemical degradation pathways for natural material that we know of." Fucose is then metabolized via a bacterial microcompartment, a proteinaceous shell that shields the cell from the toxic intermediate lactaldehyde. "The need for such a complex catabolic pathway underpins the recalcitrance of fucoidans for most marine bacteria and it shows that only highly specialized organisms in the ocean are able to break down this algal sugar," says Hehemann. "This can explain the slower turnover of the algal biomass in the environment and suggests that fucoidans sequester carbon in the ocean."Scientists are also interested in enzymes for fucoidan degradation because it may be a pharmacologically active molecule that shows similar effects to heparin in blood clotting. "Enzymes that specifically fragment fucoidan and thus help to characterize its structure are of great scientific interest because they enable researchers to understand the effects of fucoidan and to open up these marine sugars for biotechnological applications," says Thomas Schweder, participating microbiologist from the University of Greifswald.
Reporting in the journal Despite rapid surface warming, the team found that global mean climate velocities in the deepest layers of the ocean (>1,000 m) have been 2 to nearly 4-fold faster than at surface over the second half of the 20th century. The authors point to the greater thermal homogeneity of the deep ocean environment as responsible for these larger velocities. Moreover, while climate velocities are projected to slow down under scenarios contemplating strong mitigation of greenhouse gas emissions (RCP2.6), they will continue to accelerate in the deep ocean."Our results suggest that deep sea biodiversity is likely to be at greater risk because they are adapted to much more stable thermal environments," says Jorge GarcÃ­a Molinos, a climate ecologist at Hokkaido University's Arctic Research Center, who contributed to the study. "The acceleration of climate velocity for the deep ocean is consistent through all tested greenhouse gas concentration scenarios. This provides strong motivation to consider the future impacts of ocean warming to deep ocean biodiversity, which remains worryingly understudied."Climate velocities in the mesopelagic layer of the ocean (200-1000 m) are projected to be between 4 to 11 times higher than current velocities at the surface by the end of this century. Marine life in the mesopelagic layer includes great abundance of small fish that are food for larger animals, including tuna and squid. This could present additional challenges for commercial fisheries if predators and their prey further down the water column do not follow similar range shifts.The authors also compared resulting spatial patterns of contemporary climate velocity with those of marine biodiversity for over 20,000 marine species to show potential areas of risk, where high biodiversity and velocity overlap. They found that, while risk areas for surface and intermediate layers dominate in tropical and subtropical latitudes, those of the deepest layers are widespread across all latitudes except for polar regions.The scientists caution that while uncertainty of the results increases with depth, life in the deep ocean is also limited by many factors other than temperature, such as pressure, light or oxygen concentrations. "Without knowing if and how well deep ocean species can adapt to these changes, we recommend to follow a precautionary approach that limits the negative effects from other human activities such as deep-sea mining and fishing, as well as planning for climate-smart networks of large Marine Protected Areas for the deeper ocean," says GarcÃ­a Molinos.
Maximizing the protection of life on Earth requires knowledge of the global patterns of biodiversity at multiple dimensions, from genetic diversity within species, to species and ecosystem diversity. Yet, the lack of genetic sequences with geographic information at global scale has so far hindered our ability to map genetic diversity, an important, but hard to detect, biodiversity dimension.In a new study, researchers from the Universities of Copenhagen and Adelaide have collected and georeferenced a massive amount of genetic data for terrestrial mammals and evaluated long-standing theories that could explain the global distribution of genetic diversity. They found that regions of the world rich in deep evolutionary history, such as Northern Andes, the Eastern Arc Mountains, Amazonia, the Brazilian Atlantic forest, the central America jungles, sub-Saharan Africa and south-eastern Asia are also strongholds of genetic diversity. They also show that the relatively stable climate in these regions during the past 21'000 years contributes significantly to this intraspecific richness."Genetic diversity within species is a critical component of biodiversity, playing two important roles at the same time. It reflects species evolutionary history and defines their capacity to adapt under future environmental change. However, and despite the predictions of major biodiversity theories, the actual global distribution of genetic diversity remained, so far, a mystery. Recent collective efforts to populate public databases with genetic sequences and their localities allowed us to evaluate these theories and generate the first global maps of genetic diversity in terrestrial mammal assemblages," says Spyros Theodoridis, Postdoctoral Researcher at the Center for Macroecology, Evolution and Climate, GLOBE Institute, and lead author of the study."The tropics, and more specifically tropical mountain regions, host large amounts of the global pool of genetic diversity. These arks of biodiversity are under a high pressure today due to climate and land-use change. The conservation of genetic diversity in these areas should be a priority in on-going conservation efforts," says David Nogues-Bravo, the senior author of the study and Associate Professor at the University of Copenhagen.The study also evaluated the effects of climate change during the last 21'000 years in shaping current patterns of genetic diversity. Regions of the world that experienced less severe change in temperature and precipitation harbor higher levels of genetic diversity, potentially due to reduced population extinctions. It also suggests that past inter-annual precipitation variability contributes to higher genetic diversity possibly through population adaptive divergence."While we show that areas of high genetic diversity tend to occur in regions where climates have remained relatively unchanged during past periods of global-scale climate change, many of these regions are forecast to experience major climate disturbances in the near future. Unfortunately, this is likely to lead to a loss of genetic diversity in many biodiversity hotspots," says Damien Fordham, Associate Professor at The University of Adelaide's Environment Institute and a coauthor of the study."The identified correlations of genetic diversity with evolutionary history and past climate change allowed us to develop predictive models at global scale, particularly in regions that lack sufficient data, such as the tropics. These predictions constitute a first step towards filling major gaps of knowledge for genetic diversity, and can inform and be further validated by field-work campaigns in data-poor regions of the Earth," says Carsten Rahbek, head of the Center for Macroecology, Evolution and Climate.The study is supported by the Danish National Research Foundation and the Australian Research Council and is published in the scientific journal 
A key finding of the study, published in The loss of 2,000 square miles (5,000 kmThe study used hundreds of sediment cores collected since the early 1990s to examine how marshes responded to a range of rates of sea-level rise during the past 8,500 years."Previous investigations have suggested that marshes can keep up with rates of sea-level rise as high as half an inch per year (10 mm/yr), but those studies were based on observations over very short time windows, typically a few decades or less," said TorbjÃ¶rn TÃ¶rnqvist, lead author and Vokes Geology Professor in the Tulane Department of Earth and Environmental Sciences."We have taken a much longer view by examining marsh response more than 7,000 years ago, when global rates of sea-level rise were very rapid but within the range of what is expected later this century."The researchers found that in the Mississippi Delta most marshes drown in a few centuries once the rate of sea-level rise exceeds about one-tenth of an inch per year (3 mm/yr). When the rate exceeds a quarter of an inch per year (7.5 mm/yr), drowning occurs in about half a century."The scary thing is that the present-day rate of global sea-level rise, due to climate change, has already exceeded the initial tipping point for marsh drowning," TÃ¶rnqvist said. "And as things stand right now, the rate of sea-level rise will continue to accelerate and put us on track for marshes to disappear even faster in the future."While these findings indicate that the loss of remaining marshes in coastal Louisiana is probably inevitable, there are still meaningful actions that can be taken to prevent the worst possible outcomes. The most important one, TÃ¶rnqvist said, is to drastically curb greenhouse gas emissions to prevent sea-level rise from ramping up to rates where marshes will drown within a matter of decades.The other one is to implement major river diversions as quickly as possible, so at least small portions of the Mississippi Delta can survive for a longer time. However, the window of opportunity for these actions to be effective is rapidly closing, he said.
The sea otters' recovery along the northwest coast of North America presents a challenge for coastal communities because both otters and humans like to eat shellfish, such as sea urchins, crabs, clams and abalone. Expanding populations of sea otters and their arrival in new areas are heavily impacting First Nations and Tribes that rely on harvesting shellfish.SFU lead author Jenn Burt says the study focused beyond the challenges to seek solutions going forward. "We documented Indigenous peoples' perspectives which illuminated key strategies to help improve sea otter management and overall coexistence with sea otters."Most research focuses on how sea otter recovery greatly reduces shellfish abundance or expands kelp forests, rather than on how Indigenous communities are impacted, or how they are adapting to the returning sea otters' threat to their food security, cultural traditions, and livelihoods.Recognizing that Indigenous perspectives were largely absent from dialogues about sea otter recovery and management, SFU researchers reached out to initiate the Coastal Voices collaboration.Coastal Voices is a partnership with Indigenous leaders and knowledge holders representing 19 First Nations and Tribes from Alaska to British Columbia.Based on information revealed in workshops, interviews, and multiple community surveys, SFU researchers and collaborating Indigenous leaders found that human-otter coexistence can be enabled by strengthening Indigenous governance authority and establishing locally designed, adaptive co-management plans for sea otters.The study, published this week in "Our people actively managed a balanced relationship with sea otters for millennia," says co-author and Haida matriarch Kii'iljuus (Barbara Wilson), a recent SFU alumnus."Our work with Coastal Voices and this study helps show how those rights and knowledge need to be recognized and be part of contemporary sea otter management."Anne Salomon, a professor in SFU's School of Resource and Environmental Management, co-authored the study and co-led the Coastal Voices research partnership."This research reveals that enhancing Indigenous people's ability to coexist with sea otters will require a transformation in the current governance of fisheries and marine spaces in Canada, if we are to navigate towards a system that is more ecologically sustainable and socially just," says Salomon.Despite challenges, the authors say transformation is possible. They found that adaptive governance and Indigenous co-management of marine mammals exist in other coastal regions in northern Canada and the U.S. They suggest that increasing Indigenous leadership and Canadian government commitments to Reconciliation may provide opportunities for new approaches and more collaborative marine resource management.
Anticipating where a fire is likely to ignite and how it might spread requires information about how much burnable plant material exists on the landscape and its dryness. Yet this information is surprisingly difficult to gather at the scale and speed necessary to aid wildfire management.Now, a team of experts in hydrology, remote sensing and environmental engineering have developed a deep-learning model that maps fuel moisture levels in fine detail across 12 western states, from Colorado, Montana, Texas and Wyoming to the Pacific Coast.The researchers describe their technique in the August 2020 issue of According to the paper's lead author, Krishna Rao, a PhD student in Earth system science at Stanford, the model needs more testing to figure into fire management decisions that put lives and homes on the line. But it's already illuminating previously invisible patterns. Just being able to see forest dryness unfold pixel by pixel over time, he said, can help reveal areas at greatest risk and "chart out candidate locations for prescribed burns."The work comes at a time of growing urgency for this kind of insight, as climate change extends and intensifies the wildfire season -- and as the ongoing COVID-19 pandemic complicates efforts to prevent large fires through controlled burns, prepare for mass evacuations and mobilize first responders.Fire agencies today typically gauge the amount of dried-out, flammable vegetation in an area based on samples from a small number of trees. Researchers chop and weigh tree branches, dry them out in an oven and then weigh them again. "You look at how much mass was lost in the oven, and that's all the water that was in there," said Konings, an assistant professor of Earth system science in Stanford's School of Earth, Energy & Environmental Sciences (Stanford Earth). "That's obviously really laborious, and you can only do that in a couple of different places, for only some of the species in a landscape."The U.S. Forest Service painstakingly collects this plant water content data at hundreds of sites nationwide and adds them to the National Fuel Moisture Database, which has amassed some 200,000 such measurements since the 1970s. Known as live fuel moisture content, the metric is well established as a factor that influences wildfire risk. Yet little is known about how it varies over time from one plant to another -- or from one ecosystem to another.For decades, scientists have estimated fuel moisture content indirectly, from informed but unproven guesses about relationships between temperature, precipitation, water in dead plants and the dryness of living ones. According to Rao, "Now, we are in a position where we can go back and test what we've been assuming for so long -- the link between weather and live fuel moisture -- in different ecosystems of the western United States."The new model uses what's called a recurrent neural network, an artificial intelligence system that can learn to recognize patterns in vast mountains of data. The scientists trained their model using field data from the National Fuel Moisture Database, then put it to work estimating fuel moisture from two types of measurements collected by spaceborne sensors. One involves measurements of visible light bouncing off Earth. The other, known as synthetic aperture radar (SAR), measures the return of microwave radar signals, which can penetrate through leafy branches all the way to the ground surface."One of our big breakthroughs was to look at a newer set of satellites that are using much longer wavelengths, which allows the observations to be sensitive to water much deeper into the forest canopy and be directly representative of the fuel moisture content," said Konings, who is also a center fellow, by courtesy, at Stanford Woods Institute for the Environment.To train and validate the model, the researchers fed it three years of data for 239 sites across the American west starting in 2015, when SAR data from the European Space Agency's Sentinel-1 satellites became available. They checked its fuel moisture predictions in six common types of land cover, including broadleaf deciduous forests, needleleaf evergreen forests, shrublands, grasslands and sparse vegetation, and found they were most accurate -- meaning the AI predictions most closely matched field measurements in the National Fuel Moisture Database -- in shrublands.Rich with aromatic herbs like rosemary and oregano, and often marked by short trees and steep, rocky slopes, shrublands occupy as much as 45 percent of the American West. They're not only the region's biggest ecosystem, Rao said, "they are also extremely susceptible to frequent fires since they grow back rapidly." In California, fires whipped to enormous size by Santa Ana winds burn in a type of shrubland known as chaparral. "This has led fire agencies to monitor them intensively," he said.The model's estimates feed into an interactive map that fire agencies may eventually be able to use to identify patterns and prioritize control measures. For now, the map offers a dive through history, showing fuel moisture content from 2016 to 2019, but the same method could be used to display current estimates. "Creating these maps was the first step in understanding how this new fuel moisture data might affect fire risk and predictions," Konings said. "Now we're trying to really pin down the best ways to use it for improved fire prediction."
The world's tropical forests store a quarter-century worth of fossil fuel emissions in their trees alone. There are fears that global heating can reduce this store if tree growth reduces or tree death increases, accelerating climate change.An international research team measured over half a million trees in 813 forests across the tropics to assess how much carbon is stored by forests growing under different climatic conditions today.The team reveal that tropical forests continue to store high levels of carbon under high temperatures, showing that in the long run these forests can handle heat up to an estimated threshold of 32 degrees Celsius in daytime temperature.Yet this positive finding is only possible if forests have time to adapt, they remain intact, and if global heating is strictly limited to avoid pushing global temperatures into conditions beyond the critical threshold.Lead author Dr Martin Sullivan, from the University of Leeds and Manchester Metropolitan University, said: "Our analysis reveals that up to a certain point of heating tropical forests are surprisingly resistant to small temperature differences. If we limit climate change they can continue to store a large amount of carbon in a warmer world."The 32 degree threshold highlights the critical importance of urgently cutting our emissions to avoid pushing too many forests beyond the safety zone."For example, if we limit global average temperatures to a 2Â°C increase above pre-industrial levels this pushes nearly three-quarters of tropical forests above the heat threshold we identified. Any further increases in temperature will lead to rapid losses of forest carbon."Forests release carbon dioxide into the atmosphere when the amount of carbon gained by tree growth is less than that lost through tree mortality and decay.The study is the first to analyse long-term climate sensitivity based on direct observation of whole forests across the topics. The research suggests that over the long-term, temperature has the greatest effect on forest carbon stocks by reducing growth, with drought killing trees the second key factor.The researchers conclude that tropical forests have long-term capacity to adapt to some climate change, in part because of their high biodiversity as tree species better able to tolerate new climatic conditions grow well and replace less well-adapted species over the long-term.But maximizing this potential climate resilience depends on keeping forests intact.Co-author Professor Beatriz Marimon from the State University of Mato Grosso in Brazil studies some of the world's hottest tropical forests in central Brazil. She noted: "Our results suggest that intact forests are able to withstand some climate change. Yet these heat-tolerant trees also face immediate threats from fire and fragmentation."Achieving climate adaptation means first of all protecting and connecting the forests that remain."Professor Marimon notes the clear limits to adaptation. "The study indicates a heat threshold of 32 degrees Celsius in daytime temperature. Above this point tropical forest carbon declines more quickly with higher temperatures, regardless of which species are present."Each degree increase above this 32 degree threshold releases four-times as much carbon dioxide as would have been released below the threshold."The insights into how the world's tropical forests respond to climate were only possible with decades of careful fieldwork, often in remote locations. The global team of 225 researchers combined forests observations across South America (RAINFOR), Africa (AfriTRON) and Asia (T-FORCES). In each monitoring plot the diameter of each tree and its height was used to calculate how much carbon they stored. Plots were revisited every few years to see how much carbon was being taken in, and how long it was stored before trees died.To calculate changes in carbon storage required identifying nearly 10,000 tree species and over two million measurements of tree diameter, across 24 tropical countries. According to Professor Simon Lewis of the University of Leeds and University College London: "The amount of carbon absorbed and stored by forests is a crucial element in how the Earth responds to climate change.""The study underlines why long-term research collaboration is essential for understanding the effects of environmental change. Scientists need to work together more than ever, as monitoring the health of our planet's great tropical forests is vital for all of us."Cutting carbon emissions enough to keep forests within the safety zone will be very challenging. Study author Professor Oliver Phillips of the University of Leeds said: "Keeping our planet and ourselves healthy has never been more important. Right now, humanity has a unique opportunity to make the transition toward a stable climate."By not simply returning to 'business as usual' after the current crisis we can ensure tropical forests remain huge stores of carbon. Protecting them from climate change, deforestation and wildlife exploitation needs to be front and centre of our global push for biosecurity."Imagine if we take this chance to reset how we treat our Earth. We can keep our home cool enough to protect these magnificent forests -- and keep all of us safer."
Many coral animals live in a fragile, mutually beneficial relationship, a 'symbiosis' with tiny algae embedded in their cells. The algae gain shelter, carbon dioxide and nutrients, while the corals receive photosynthetic products to fulfil their energy needs. If temperatures rise just 1?C above the usual summer maximum, this symbiosis breaks down; the algae are lost, the coral's white limestone skeleton shines through its transparent tissue and a damaging process known as 'coral bleaching' occurs.This condition can be fatal to the coral. Once its live tissue is gone, the skeleton is exposed to the eroding forces of the environment. Within a few years, an entire coral reef can break down and much of the biodiversity that depends on its complex structure is lost -- a scenario which currently threatens the future of reefs around the world.However, some bleaching corals undergo an, until now, mysterious transformation -- emitting a range of different bright neon colours. Why this happens has now been explained by a team of scientists from the University of Southampton's Coral Reef Laboratory, who have published their detailed insights in the journal The researchers conducted a series of controlled laboratory experiments at the coral aquarium facility of the University of Southampton. They found that during colourful bleaching events, corals produce what is effectively a sunscreen layer of their own, showing itself as a colourful display. Furthermore, it's thought this process encourages the coral symbionts to return.Professor JÃ¶rg Wiedenmann, head of the University of Southampton's Coral Reef Laboratory explains: "Our research shows colourful bleaching involves a self-regulating mechanism, a so-called optical feedback loop, which involves both partners of the symbiosis. In healthy corals, much of the sunlight is taken up by the photosynthetic pigments of the algal symbionts. When corals lose their symbionts, the excess light travels back and forth inside the animal tissue -reflected by the white coral skeleton. This increased internal light level is very stressful for the symbionts and may delay or even prevent their return after conditions return to normal."However, if the coral cells can still carry out at least some of their normal functions, despite the environmental stress that caused bleaching, the increased internal light levels will boost the production of colourful, photoprotective pigments. The resulting sunscreen layer will subsequently promote the return of the symbionts. As the recovering algal population starts taking up the light for their photosynthesis again, the light levels inside the coral will drop and the coral cells will lower the production of the colourful pigments to their normal level."The researchers believe corals which undergo this process are likely to have experienced episodes of mild or brief ocean-warming or disturbances in their nutrient environment -- rather than extreme events.Dr. Cecilia D'Angelo, Lecturer of Molecular Coral Biology at Southampton, comments: "Bleaching is not always a death sentence for corals, the coral animal can still be alive. If the stress event is mild enough, corals can re-establish the symbiosis with their algal partner. Unfortunately, recent episodes of global bleaching caused by unusually warm water have resulted in high coral mortality, leaving the world's coral reefs struggling for survival."Dr. Elena Bollati, Researcher at the National University Singapore, who studied this subject during her PhD training at the University of Southampton, adds: "We reconstructed the temperature history of known colourful bleaching events around the globe using satellite imagery. These data are in excellent agreement with the conclusions of our controlled laboratory experiments, suggesting that colourful bleaching occurs in association with brief or mild episodes of heat stress."The scientists are encouraged by recent reports suggesting colourful bleaching has occurred in some areas of the Great Barrier Reef during the most recent mass bleaching there in March-April 2020. They think this raises the hope that at least some patches of the world's largest reef system may have better recovery prospects than others, but emphasise that only a significant reduction of greenhouse gases at a global scale and sustained improvement in water quality at a regional level can save coral reefs beyond the 21st century.
Recent research suggests that there was enhanced storage of respired carbon in the deep ocean when levels of atmospheric carbon dioxide concentrations were lower than today's levels. But new research led by a Texas A&M University scientist has reached back even further, for the first time revealing insights into atmospheric carbon dioxide levels in the 50,000 years before the last ice age."One of the biggest unknowns about past climate is the cause of atmospheric carbon dioxide variability over global warm-cold cycles," said Franco Marcantonio, lead author of the study and professor and Jane and Ken R. Williams '45 Chair in the Department of Geology and Geophysics at Texas A&M. "Here we investigated the 'how' of varying carbon dioxide with the 'where' -- namely, the Eastern Equatorial Pacific Ocean, which is an important region of the world ocean where, today, significant carbon dioxide is exhaled into the atmosphere and the greatest rates phytoplankton growth are found."The National Science Foundation-funded research was recently published in To examine ancient carbon dioxide levels, Marcantonio and a team of researchers analyzed an ocean floor sediment core extracted from the deep Eastern Equatorial Pacific Ocean. The 10-meter long core spans about 180,000 years, and the chemistry of the layers of sediment provide scientists with a window into past climates. The chemical measurements they make serve as a proxy for oxygen levels of the deep sea.Measuring minute traces of uranium and thorium isotopes, the team was able to associate periods of increased storage of respired carbon (and low deep-sea oxygen levels) with periods of decreased global atmospheric carbon dioxide levels during the past 70,000 years."By comparing our high-resolution sediment record of deep-sea oxygenation in the Eastern Equatorial Pacific with other areas of the Pacific and Southern Ocean, we find that the Pacific Ocean, like the Southern Ocean, is a location for deep-ocean respired carbon storage during periods of decreased global atmospheric CO"Understanding the past dynamics of Earth's carbon cycle is of fundamental importance to informing and guiding societal policy-making in a warming world with increasing levels of atmospheric carbon dioxide."Co-authors of the study were Ryan Hostak, a former Texas A&M graduate student who earned his master's degree in geology in 2019; Jennifer E. Hertzberg, who received her Ph.D. in oceanography from Texas A&M in 2015 and is now a postdoctoral researcher in the Department of Earth, Ocean and Atmospheric Sciences at Old Dominion University; and Matthew W. Schmidt, associate professor of Ocean, Earth and Atmospheric Sciences at Old Dominion. Marcantonio and his colleagues designed the study, he and Hostak performed the isotope analyses, and the team interpreted the data."By performing similar studies in sediment covering a wider swath of the deep Pacific Ocean, we'll be able to spatially map the extent of this past deep pool of respired carbon," Marcantonio said, looking forward to future research.The study's radiogenic and trace element analyses were conducted in the College of Geosciences' R. Ken Williams Radiogenic Isotope Facility. The sediment core was extracted by Marcantonio and colleagues on an NSF-funded research cruise aboard the R/V Melville in 2010.
University of Queensland-led research has revealed that three quarters of migratory shorebird species in the region have been hunted since the 1970s.UQ PhD student Eduardo Gallo-Cajiao said the finding was deeply concerning, as these globetrotters were already under pressure from other human impacts."The Asia-Pacific is host to one of the most amazing animal migrations on earth," Mr Gallo-Cajiao said."Every year, hundreds of thousands of shorebirds, wetland-dependent species, breed across the Arctic and boreal regions, moving south to Southeast Asia, Australia, and New Zealand along a migration corridor known as the East Asian-Australasian Flyway."The Flyway spans 22 countries, through which 61 species of shorebirds complete their epic annual migrations some covering up to 25,000 km each year."But many of these fascinating birds are unfortunately declining, with several on the brink of extinction."Until now, habitat loss due to the expansion of coastal infrastructure had been identified as one of the main causes of their declines, particularly around the Yellow Sea region of China and the Korean peninsula, where many birds stop to rest and feed on their migrations."The scale and significance of hunting was unknown prior to this study, and it's clear that it's likely contributed to declines of migratory shorebirds in this region."The team worked for four years assembling all available evidence on hunting -- analysing hunting records from 14 countries, involving 46 species.But there are knowledge gaps, as they could not find data for eight countries.Currently, there are five shorebird species at high risk of extinction in this region, including the critically endangered spoon-billed sandpiper, of which fewer than 500 remain."Our study discovered that other threatened species that have been subject to hunting include the great knot, far eastern curlew, and spotted greenshank," Mr Gallo-Cajiao said.UQ's Professor Richard Fuller said managing hunting was complicated by the broad range of people involved, from recreational hunters to subsistence hunters and commercial traders."At least some hunting is driven by issues of food security, so sustainable development must be considered when developing alternatives for management," Professor Fuller said."There's no coordinated monitoring of how many shorebirds are taken annually across the region, which makes management really hard."Internationally coordinated approaches to address hunting are now underway, including through the UN Convention on Migratory Species, but these efforts need to be drastically ramped up to avoid extinctions and maintain healthy wildlife populations."Additional ground surveys and an international coordinated monitoring strategy are also urgently needed."
The team, involving researchers from the University of Cambridge and the British Antarctic Survey, combined satellite data with on-the-ground observations over two summers in Antarctica to detect and measure the green snow algae. Although each individual alga is microscopic in size, when they grow en masse they turn the snow bright green and can be seen from space. The study is published today in the journal "This is a significant advance in our understanding of land-based life on Antarctica, and how it might change in the coming years as the climate warms," said Dr Matt Davey in the University of Cambridge's Department of Plant Sciences, who led the study. "Snow algae are a key component of the continent's ability to capture carbon dioxide from the atmosphere through photosynthesis."Blooms of green snow algae are found around the Antarctic coastline, particularly on islands along the west coast of the Antarctic Peninsula. They grow in 'warmer' areas, where average temperatures are just above zero degrees Celsius during the austral summer -- the Southern Hemisphere's summer months of November to February. The Peninsula is the part of Antarctica that experienced the most rapid warming in the latter part of the last century.The team found that the distribution of green snow algae is also strongly influenced by marine birds and mammals, whose excrement acts as a highly nutritious natural fertiliser to accelerate algal growth. Over 60% of blooms were found within five kilometres of a penguin colony. Algae were also observed growing near the nesting sites of other birds, including skuas, and areas where seals come ashore.The team used images from the European Space Agency's Sentinel 2 satellite taken between 2017 and 2019, and combined these with measurements they made on the ground in Antarctica at Ryder Bay, Adelaide Island, and the Fildes Peninsula, King George Island."We identified 1679 separate blooms of green algae on the snow surface, which together covered an area of 1.9 km2, equating to a carbon sink of around 479 tonnes per year" said Davey. Put into context this is the same amount of carbon emitted by about 875,000 average petrol car journeys in the UK.Almost two thirds of the green algal blooms were on small, low-lying islands with no high ground. As the Antarctic Peninsula warms due to rising global temperatures, these islands may lose their summer snow cover and with it their snow algae. However, in terms of mass, the majority of snow algae is found in a small number of larger blooms in the north of the Peninsula and the South Shetland Islands, in areas where they can spread to higher ground as low-lying snow melts."As Antarctica warms, we predict the overall mass of snow algae will increase, as the spread to higher ground will significantly outweigh the loss of small island patches of algae," said Dr Andrew Gray, lead author of the paper, and a researcher at the University of Cambridge and NERC Field Spectroscopy Facility, Edinburgh.Photosynthesis is the process in which plants and algae generate their own energy, using sunlight to capture carbon dioxide from the atmosphere and release oxygen. There are many different types of algae, from the tiny, single-celled species measured in this study, to large leafy species like giant kelp. The majority of algae live in watery environments, and when excess nitrogen and phosphorus are available they can multiply rapidly to create visible algal blooms.The researchers say that the total amount of carbon held in Antarctic snow algae is likely to be much larger because carbon dioxide is also taken up by other red and orange algae, which could not be measured in this study. They plan further work to measure these other algal blooms, and also to measure the blooms across the whole of Antarctica using a mixture of field work and satellite images.Antarctica is the world's southernmost continent, typically known as a frozen land of snow and ice. But terrestrial life can be abundant, particularly along its coastline, and is responding rapidly to climate changes in the region. Mosses and lichens form the two biggest visible groups of photosynthesising organisms, and have been the most studied to date. This new study has found that microscopic algae also play an important role in Antarctica's ecosystem and its carbon cycling.
Southern right whales were hunted to near extinction after centuries of whaling. In the most comprehensive study of its kind, 30 researchers from 11 countries studied 15 skin samples from whales feeding around the sub-Antarctic island of South Georgia and compared them to 149 samples collected from around Argentina and Brazil and South Africa where the whales breed and give birth to their calves. New samples were collected from South Georgia during an expedition led by the British Antarctic Survey in 2018 and were combined with samples held by a network of collaborators across the globe.Using a new genetic tool, the team discovered that most of the animals visiting South Georgia were calved around South America and not South Africa. This had previously been suspected, but not confirmed.Lead author Dr Emma Carroll, from University of Auckland says: "Genetic methods are important in linking whale breeding grounds, areas that are closely monitored for population recovery, with feeding areas that are being and will be impacted by climate change. It is only by understanding these links that we can understand how whale populations will fare in a changing world."Collaborating with Chilean colleagues, the team also analysed the first ever DNA sample from the Critically Endangered Chile-Peru southern right whale population. They found genetically, the Chile-Peru whale is a mixture between Indo-Pacific and Atlantic calving grounds, suggesting Chile-Peru has acted as a 'stepping stone' between these two areas.Whale ecologist and senior author Dr Jennifer Jackson, at British Antarctic Survey, who led the project, says: "This is an important part of the jigsaw in understanding the geographical range of southern right whales. Identifying the migratory links of recovering whale populations is crucial to build accurate assessments of how well whale populations are recovering, and to understand how vulnerable these populations are to anthropogenic threats through their life cycle."There have been unexplained high whale calf mortalities around Argentina in the PenÃ­nsula ValdÃ©z region over the last 17 years, so there is a lot of work to be done to protect this species throughout their migratory range."The team are also tracking the movements of two South Georgia right whales in real time using satellite tags. One whale is already migrating towards the South American coast, providing further evidence of the migratory connection. Follow these whales here: 
Increasing aridity is already a clear trend across the western United States, where anthropogenic climate warming is contributing to declining river flows, drier soils, widespread tree death, stressed agricultural crops, catastrophic wildfires and protracted droughts, according to the authors of a Commentary article published online May 19 in At the same time, human-caused warming is also driving increased aridity eastward across North America, with no end in sight, according to climate scientists Jonathan Overpeck of the University of Michigan and Bradley Udall of Colorado State University."The impact of warming on the West's river flows, soils, and forests is now unequivocal," write Overpeck, dean of the U-M School for Environment and Sustainability, and Udall, senior water and climate scientist at Colorado State. "There is a clear longer-term trend toward greater aridification, a trend that only climate action can stop."The Commentary article responds to a PNAS paper, published May 11 by Justin Martin of the U.S. Geological Survey and his colleagues, that showed how warming is causing streamflow declines in the northern Rocky Mountains, including the nation's largest river basin, the Missouri.The Martin The study details the mechanisms of temperature-driven streamflow declines, and it "places more focus on how anthropogenic climate warming is progressively increasing the risk of hot drought and more arid conditions across an expanding swath of the United States," according to Overpeck and Udall.The Martin But that's a faulty assumption, one that ignores mounting evidence all around us, according to Overpeck and Udall."Anthropogenic climate change calls this assumption into question because we now know with high confidence that continued emissions of greenhouse gases into the atmosphere guarantees continued warming, and that this continued warming makes more widespread, prolonged and severe dry spells and droughts almost a sure bet," they write. "Greater aridity is redefining the West in many ways, and the costs to human and natural systems will only increase as we let the warming continue."Anticipated impacts in the Upper Missouri River Basin mirror changes already occurring in the Southwest, where the trend toward warming-driven aridification is clearest.Rivers in the Southwest provide the only large, sustainable water supply to more than 40 million people, yet flows have declined significantly since the late 20th century. Declining flows in the region's two most important rivers, the Colorado and the Rio Grande, have been attributed in part to increasing temperatures caused by human activities, most notably the burning of fossil fuels.Multiple processes tied to warming are likely implicated in the observed aridification of the West, according to Overpeck and Udall. For starters, warmer air can hold more water vapor, and this thirsty air draws moisture from water bodies and land surfaces through evaporation and evapotranspiration -- further drying soils, stressing plants and reducing streamflow.But the atmosphere's increased capacity to hold water vapor also boosts the potential for precipitation; rain and snow amounts are, in fact, rising in many regions of the United States outside the Southwest. However, the frequency and intensity of dry spells and droughts are expected to increase across much of the continent in coming decades, even if average annual precipitation levels rise, according to Overpeck and Udall."Perhaps most troubling is the growing co-occurrence of hot and dry summer conditions, and the likely expansion, absent climate change action, of these hot-dry extremes all the way to the East Coast of North America, north deep into Canada, and south into Mexico," they write."Other parts of North America likely won't see the widespread aridification and decadal to multi-decadal droughts of the West, but will nonetheless continue to see more frequent and severe arid events -- extreme dry spells, flash droughts and interannual droughts will become part of the new normal," according to Overpeck and Udall."Unfortunately, climate change and this aridification are likely irreversible on human time scales, so the sooner emissions of greenhouse gases to the atmosphere are halted, the sooner the aridification of North America will stop getting worse."
For the study, the researchers evaluated results from over 30 years of research on the environmental, economic and social consequences of oil palm cultivation in Africa, Asia and Latin America. They combined the results from the international literature with their own data from Indonesia, which they have been collecting since 2012 as part of an interdisciplinary German-Indonesian Collaborative Research Centre (CRC 990). Indonesia is the largest palm oil producer and exporter in the world. A large proportion of the palm oil produced in Indonesia is exported to Europe and the USA, where it is used by the food, fuel and cosmetics industries.The research data show that the expansion of oil palm in some regions of the world -- especially Indonesia and Malaysia -- contributes significantly to tropical deforestation and the loss of biodiversity. Clearing forestland also leads to substantial carbon emissions and other environmental problems. "However, banning palm oil production and trade would not be a sustainable solution," says Professor Matin Qaim, agricultural economist at the University of GÃ¶ttingen and first author of the study. "The reason is that oil palm produces three times more oil per hectare than soybean, rapeseed, or sunflower. This means that if palm oil was replaced with alternative vegetable oils, much more land would be needed for cultivation, with additional loss of forests and other natural habitats."Banning palm oil would also have negative economic and social consequences in the producing countries. "It is often assumed that oil palm is only grown on large industrial plantations," says Qaim. "In reality, however, around half of the world's palm oil is produced by smallholder farmers. Our data show that oil palm cultivation increases profits and incomes in the small farm sector, in addition to raising wages and creating additional employment for rural labourers. Although there are incidents of conflicts over land, overall the oil palm boom has significantly reduced rural poverty in Indonesia and other producing countries.""The goal should be to make palm oil production more environmentally and climate-friendly," says Professor Ingo Grass, agricultural ecologist at the University of Hohenheim and co-author of the study. "High yields on the already-cultivated land are important, in order to reduce additional deforestation. Mosaic landscapes, where oil palm is combined with patches of forest and other crops in agroforestry systems, could also help to protect biodiversity and ecosystem functions," he adds.The authors conclude that developing and implementing more sustainable production systems are challenges which require both innovative research and policymaking. Clearly and fairly defined land rights and improved access for smallholder farmers to training, credit and modern technologies would be important steps forward. Consumers can contribute by shopping for food, fuel, and cosmetics more consciously and avoiding waste wherever possible.
However, should the EU implement its most ambitious decarbonization agenda, while the rest of the world continues with the status quo, non-EU nations will end up emitting more greenhouse gases, thereby significantly offsetting the reductions of EU emissions. This is the conclusion of a new policy brief prepared by economics experts at the University of Copenhagen's Department of Food and Resource Economics.For every tonne of CO"Obviously, the EU's own climate footprint will be significantly reduced. But the EU's economy is intertwined with the rest of the world through trade relations, which would change as we implement a green transition in our energy sector, industries and ways of life. Part of the emissions that Europe "saves" through an extensive green transition could possibly be 'leaked' to the rest of the world through, among other things, trade mechanisms, depending on the climate policy of other countries," according to economist and brief co-author Professor Wusheng Yu, of the University of Copenhagen's Department of Food and Resource Economics."If the world beyond the EU does not follow suit and embark on a similar green transition, the decline in global greenhouse gas emissions will effectively be limited and well below the level agreed upon in EU climate policy," adds co-author, economist and Yu's department fellow, Francesco Clora.In the most ambitious 2050 scenario as calculated by the EUCalc model, the EU pulls all of the green levers for production and consumption in various sectors, including the industrial and energy sectors.In this scenario, a green transformation of COSimilarly, a phase-out of fossil fuels by the EU would lower global demand, thus making them cheaper. In response, non-EU countries would be likely to import and consume larger quantities of fossil fuels.Finally, more climate-friendly consumer behaviour in the EU could end up pushing part of the saved COShould Europe simply throw in the towel and drop its high ambitions for a better global climate? Certainly not. But we must make sure not to go it alone. Professor Wusheng Yu explains:"A green transition in the EU alone cannot significantly reduce global COTherefore, Professor Yu says that it is essential for the EU to formulate green strategies for each sector and every member state, while taking these economic mechanisms into account and carefully evaluating their impact, when it comes to encouraging other countries to pursue similar decarbonization strategies.
Published in the journal The research team found there would be a moderate impact across 85 percent of the Southern Ocean, with krill expected to move further south and shifts in the time of year when conditions are most favourable.The research was led by IMAS PhD student Devi Veytia and included scientists from the Australian Antarctic Division, ACE CRC and the British Antarctic Survey.Ms Veytia said the study's findings included a projected change in the seasonal distribution of krill habitat, particularly around northerly fishing grounds near the Antarctic Peninsula."Understanding how krill will respond to climate change and the ecological impacts of those changes is important to both conservation efforts and the management of the fishery, the largest in the Southern Ocean."Our study combined projections of sea surface temperatures and phytoplankton using climate change scenarios with an established krill growth model."We found that over the coming decades krill habitat quality can be expected to improve in spring, particularly further south and on the continental shelf."In summer, there was little net change, but good habitat redistributed, increasing at high and low latitudes and declining in mid-latitudes."Autumn saw the greatest decline in habitat quality and area, mainly in sub-Antarctic regions."In response, we expect krill habitat to move south into higher latitudes."At the same time there will be a change in the time of year when krill habitat is optimal, improving in spring, but declining in important regions during summer and autumn."Ms Veytia said the shift in seasonal habitat quality, especially around the Antarctic Peninsula, could disturb the synchronisation between krill and the annual cycle of this important ecosystem."Synchronisation usually allows krill to capitalize on seasonally available food sources, allowing growth, reproduction and storing of reserves to survive the winter."A temporal shift in habitat quality could create a timing mismatch, potentially affecting krill reproduction and population dynamics."The commercial fishery, which is currently centred on the Antarctic Peninsula and south Scotia Sea, could also be affected, leading to shifts in the distribution and timing of the fishing effort."The geographical shift of krill habitat towards more southerly waters is also likely to have ecosystem impacts, particularly for land-based predators at sub-Antarctic islands that have limited capacity to follow their preferred food source," she said.
Shane Rooyakkers, a postdoctoral scholar at GNS Science in New Zealand, grew up in the shadow of Mount Taranaki on the country's North Island, hiking on the island's many volcanoes. Today, his research is revealing hidden dangers that may have been beneath his feet all along.A new study, published yesterday in Rooyakkers, who is lead author on the study and completed the work while at McGill University, compared the composition of the quenched magma, which had formed smooth volcanic glass, with rocks from an eruption from that same volcano, Krafla, in 1724. Before his study, scientists thought the shallow magma they'd drilled into had been emplaced after a series of eruptions in the 1980s. No one expected the hidden magma to be related to the 1724 eruption, so what Rooyakkers found was a surprise."When we looked at the compositions from 1724, we found an almost perfect match for what was sampled during the drilling," Rooyakkers says. "That suggests that actually, this magma body has been there since 1724 and has previously been involved in an eruption at Krafla. So that raises the question of, 'Why did geophysics not pick it up?'"The answer is size. Most magma detection relies on seismic imaging, like oil companies use to detect reserves deep under the seafloor. When there's an earthquake, the instruments detect how long it takes for sound waves to travel through the crust. Depending on the density of the rocks, the soundwaves return at different times. So if there's water, oil, or magma stored underground, the soundwaves should reflect it. But these hidden magma chambers are too small for these instruments, as well as other detection tools, to find."In traditional approaches to volcano monitoring, a lot of emphasis is placed on knowing where magma is and which magma bodies are active," says Rooyakkers. "Krafla is one of the most intensely-monitored and instrumented volcanoes in the world. They've thrown everything but the kitchen sink at it in terms of geophysics. And yet we still didn't know there was this rhyolitic magma body sitting at just two kilometers' depth that's capable of producing a hazardous eruption."Studies like Rooyakkers' suggest that smaller, more widely-distributed magma bodies might be more common than previously thought, challenging the conventional view that most eruptions are fed from larger and deeper magma chambers that can be reliably detected.Beyond not being able to monitor magmatic activity, planning for eruptions and estimating risks becomes more difficult if scientists suspect that hidden magma bodies could be present. For example, the Krafla volcano is usually dominated by basalt, a type of magma that tends to erupt passively (like the recent eruption at Fagradallsfjall in Iceland) rather than in an explosion. But the hidden magma body at Krafla is made of rhyolite, a magma type that often creates violent explosions when it erupts."So the concern in this case would be that you have a shallow rhyolitic magma that you don't know about, so it hasn't been considered in hazards planning," Rooyakkers explains. "If it's hit by new magma moving up, you might have a much more explosive eruption than you were anticipating."As volcanologists become aware of the hazards associated with these shallow, distributed magma systems, they can work on improving monitoring, trying to capture these hidden magma pools. Covering a volcanic area in more detectors may be costly, but by improving the resolution of magma imaging, scientists may save a community or company far more than the cost of the study. The risks vary from volcano to volcano, but in general, as we learn more about these magma systems, scientists concerned with estimating hazards can be aware of the possibility of hidden magma.Despite the risks he's uncovering, will Rooyakkers still live around volcanoes?"Oh yeah, for sure," he says with a laugh. "I mean, there's risk with anything, isn't there?"
In a new study Zhang et al use the molecular remains of ancient algae (so-called biomarkers) to show that algae occupied an important role in marine ecosystems 1400 million years ago, some 600 million years earlier than previously recognized.The specific biomarkers explored by Zhang et al are a group of sterane molecules derived from sterols that are prominent components of cell membranes in eukaryotic organisms. A particular difficulty in analyzing for ancient steranes is that samples are easily contaminated with steranes from other sources. The sources of contamination range from steranes introduced during the sampling, transport and processing of the samples, to geological contamination of steranes as fluids have flow through the rocks.Zhang et al carefully controlled for each of the sources of contamination and found, as have others, that no steranes were liberated when using standard protocols to extract biomarkers from such ancient rocks, in this case the 1400 million-year-old Xiamaling Formation in North China.However, Shuichang Zhang, the lead author of the study speculated that "There is some fossil evidence for eukaryotic algae 1400 million years ago, or even earlier, so we wondered whether any steranes in these rocks might be more tightly bound to the kerogens and not easily released during standard biomarker extraction." Therefore, Zhang et al utilized a stepwise heating protocol where samples were slowly heated in gold tubes in 9 steps from 300Â°C to 490Â°C. The organic molecules liberated in each of the nine steps were extracted and steranes indicating the presence of both red and green algae were liberated, especially at the higher temperatures.Zhang continues "Many will be concerned that the steranes we found were a product of some kind of contamination. We were also worried about this, but we ran in parallel samples that have been heated to high temperatures during their geologic history and that, therefore, contained no biomarkers. We found no steranes in these. This means that our protocols were clean, and we are therefore confident that the steranes we found were indigenous to the rock."It's still not completely clear why the steranes were so tightly bound to the kerogen and not released during standard protocols. But, the findings of Zhang et al. show that both green and red algal groups were present in marine ecosystems by 1400 million years ago. This is 600 million years earlier than evident from previous biomarker studies. This work shows that the red and green algal lineages had certainly evolved by 1400 million years ago, and this should be a useful constraint in timing the overall history of eukaryote evolution. This work also shows that at least some ancient marine ecosystems functioned more similarly to modern ecosystems than previously thought, at least with respect to the types of photosynthetic organisms producing organic matter. This means furthermore that there was sufficient nutrients and oxygen available to drive the presence of algae-containing ecosystems.Professor Don Canfield, Nordic Center for Earth Evolution, University of Southern Denmark, a co-author on the study adds: "We hope that our study will inspire others to utilize similar techniques to better unravel the full history of eukaryote evolution through geologic time."
Micrometeorites have always fallen on our planet. These interplanetary dust particles from comets or asteroids are particles of a few tenths to hundredths of a millimetre that have passed through the atmosphere and reached the Earth's surface.To collect and analyse these micrometeorites, six expeditions led by CNRS researcher Jean Duprat have taken place over the last two decades near the Franco-Italian Concordia station (Dome C), which is located 1,100 kilometres off the coast of AdÃ©lie Land, in the heart of Antarctica. Dome C is an ideal collection spot due to the low accumulation rate of snow and the near absence of terrestrial dust.These expeditions have collected enough extraterrestrial particles (ranging from 30 to 200 micrometres in size), to measure their annual flux, which corresponds to the mass accreted on Earth per square metre per year.If these results are applied to the whole planet, the total annual flux of micrometeorites represents 5,200 tons per year. This is the main source of extraterrestrial matter on our planet, far ahead of larger objects such as meteorites, for which the flux is less than ten tons per year.A comparison of the flux of micrometeorites with theoretical predictions confirms that most micrometeorites probably come from comets (80%) and the rest from asteroids.This is valuable information to better understand the role played by these interplanetary dust particles in supplying water and carbonaceous molecules on the young Earth.
Until now, it was assumed that these lake deposits had settled on a stable crater floor. The same is assumed for crater deposits on Mars, although some of them show significantly inclined sediment strata. The layers of these crater fills appear on the surface as ring-shaped structures. However, a precise understanding of the underlying conditions and the temporal interrelationships of the deposits is important for reconstructing the chemical development of a crater lake and habitability for possible lifeforms that might have developed there in the past.For the first time, the researchers have now been able to detect a volcanic ash layer in the lake sediments of the 330-metre-thick crater filling in the Ries. "This is surprising, as volcanic rocks were not expected here since the circular basin was identified as an asteroid crater," says first author Professor Gernot Arp from the Geosciences Centre at the University of GÃ¶ttingen. "The ash was blown in from a volcano 760 kilometres further east in Hungary. The age of the ash can be dated to 14.2 million years ago," adds his colleague and co-author IstvÃ¡n Dunkl.The ash, which in the meantime has transformed into nitrogen-rich silicate minerals, reveals a surprisingly strong bowl-shaped geometry: at the edge of the basin the ash is found at the current ground surface, while in the centre of the basin it comes to rest at a depth of about 220 metres. A subsequent systematic evaluation of drillings and geological mapping has now also revealed an arrangement of concentric rings -- the "outcropping strata" -- for the Ries crater filling, with the oldest deposits at the rim and the most recent in the centre.Calculations show that this bedding geometry cannot be explained solely by the fact that the underlying lake sediments are settling. In fact, an additional subsidence of about 135 metres had to be accounted for. This can only be explained by subsidence phenomena of the crater bedrock, which is fractured kilometres deep. While further research is needed to explain the exact mechanisms of this subsidence of the crater floor, a simple model calculation can already show that subsidence of this magnitude is basically possible due to settlement phenomena of the fractured underground rocks. This means that inclined strata in the fillings of craters on Mars can now be better explained, at least for craters that show a close timely association of crater formation, flooding by water, and sedimentation.The study was funded by the German Research Foundation (DFG). In addition to geobiologists and sedimentologists from the University of GÃ¶ttingen, the Bavarian Environment Agency, and Brown University, Providence, USA, were also involved.
UW Department of Geology and Geophysics Professor Ken Sims and recent Ph.D. graduate Sean Scott are co-authors of an article, "An isotopically distinct Zealandia-Antarctic mantle domain in the Southern Ocean," published by the scientific journal "The Australian-Antarctic Ridge is the remotest mid-ocean ridge in the world's oceans and one of the last explored ridge segments, and, lo and behold, our isotope measurements of the samples we collected provided us with quite a surprise -- an entirely new domain in the Earth's mantle," Sims says.The two were part of a group investigating the Australian-Antarctic Ridge (AAR) that included researchers from the United States, South Korea and France. Known as the last gap in the mapping and sampling of seafloor spreading centers, AAR is a 1,200-mile expanse in the most remote parts of the ocean ridge system. Specifically, the team was looking to resolve questions surrounding the boundaries of Earth's mantle domains as seen in ocean basalt formations created during mantle melting.Those basalt formations are pushed up from the Earth's mantle beneath the Indian and Pacific oceans through the ridges and have distinct isotopic compositions. That has created a long-accepted boundary at the Australian-Antarctic Discordance along the Southeast Indian Ridge. This boundary has been widely used to place constraints on large-scale patterns of the mantle flow and composition in the Earth's upper mantle. However, sampling between the Indian and Pacific ridges was lacking, because of difficulty in obtaining samples.Now, Sims, Scott and company present data from the region that show the ridge has isotopic compositions distinct from both the Pacific and Indian mantle domains. The data define a separate Zealandia-Antarctic domain that appears to have formed in response to the deep mantle upwelling and ensuing volcanism that led to the breakup of ancient supercontinent Gondwana around 90 million years ago. The Zealandia-Antarctic domain currently persists at the margins of the Antarctic continent.The group surmises that the relatively shallow depths of the AAR may be the result of this deep mantle upwelling, and large offset transformations to the east may be its boundary with the Pacific domain.
Scientists want to know how long life has existed on Earth. If it has been around for almost as long as the planet, this suggests it is easy for life to originate and life should be common in the Universe. If it takes a long time to originate, this suggests there were very special conditions that had to occur. Dinosaurs, whose bones are presented in museums around the world, were preceded by billions of years by microbes. While microbes have left some physical evidence of their presence in the ancient geological record, they do not fossilize well, thus scientists use other methods for understanding whether life was present in the geological record.Presently, the oldest evidence of microbial life on Earth comes to us in the form of stable isotopes. The chemical elements charted on the periodic are defined by the number of protons in their nuclei, for example, hydrogen atoms have one proton, helium atoms have two, carbon atoms contain six. In addition to protons, most atomic nuclei also contain neutrons, which are about as heavy as protons, but which don't bear an electric charge. Atoms which contain the same number of protons, but variable numbers of neutrons are known as isotopes. While many isotopes are radioactive and thus decay into other elements, some do not undergo such reactions; these are known as "stable" isotopes. For example, the stable isotopes of carbon include carbon 12 (written as 12C for short, with 6 protons and 6 neutrons) and carbon 13 (13C, with 6 protons and 7 neutrons).All living things, including humans, "eat and excrete." That is to say, they take in food and expel waste. Microbes often eat simple compounds made available by the environment. For example, some are able to take in carbon dioxide (COBesides carbon there are other chemical elements essential for living things. For example, sulfur, with 16 protons, has three naturally abundant stable isotopes, 32S (with 16 neutrons), 33S (with 17 neutrons) and 34S (with 18 neutrons). Sulfur isotope patterns left behind by microbes thus record the history of biological metabolism based on sulfur-containing compounds back to around 3.5 billion years ago. Hundreds of previous studies have examined wide variations in ancient and contemporary sulfur isotope ratios resulting from sulfate (a naturally occurring sulfur compound bonded to four oxygen atoms) metabolism. Many microbes are able to use sulfate as a fuel, and in the process excrete sulfide, another sulfur compound. The sulfide "waste" of ancient microbial metabolism is then stored in the geological record, and its isotope ratios can be measured by analyzing minerals such as the FeS2 mineral pyrite.This new study reveals a primary biological control step in microbial sulfur metabolism, and clarifies which cellular states lead to which types of sulfur isotope fractionation. This allows scientists to link metabolism to isotopes: by knowing how metabolism changes stable isotope ratios, scientists can predict the isotopic signature organisms should leave behind. This study provides some of the first information regarding how robustly ancient life was metabolizing. Microbial sulfate metabolism is recorded in over a three billion years of sulfur isotope ratios that are in line with this study's predictions, which suggest life was in fact thriving in the ancient oceans. This work opens up a new field of research, which ELSI Associate Professor Shawn McGlynn calls "evolutionary and isotopic enzymology." Using this type of data, scientists can now proceed to other elements, such as carbon and nitrogen, and more completely link the geochemical record with cellular states and ecology via an understanding of enzyme evolution and Earth history.
Called Hydrothermarchaeota, this group of microbes lives in such an extreme environment that they have never been cultivated in a laboratory for study. A research team from Bigelow Laboratory for Ocean Sciences, the University of Hawai'i at Manoa, and the Department of Energy Joint Genome Institute bypassed the problem of cultivation with genetic sequencing methods called genomics, a suite of novel techniques used to sequence large groups of genetic information. They found that Hydrothermarchaeota may obtain energy by processing carbon monoxide and sulfate, which is an overlooked metabolic strategy. The microbes use energy from this process to grow as a form of chemosynthesis."The majority of life on Earth is microbial, and most microbes have never been cultivated," said Beth Orcutt, a senior research scientist at Bigelow Laboratory and one of the study's senior authors. "These findings emphasize why single cell genomics are such important tools for discovering how a huge proportion of life functions."Analyzing Hydrothermarchaeota genomes revealed that these microbes belong to the group of single-celled life known as archaea and evolved early in the history of life on Earth -- as did their unusual metabolic processes. These observations suggest that the subsurface ocean crust is an important habitat for understanding how life evolved on Earth, and potentially other planets.The researchers also found genetic evidence that Hydrothermarchaeota have the ability to move on their own. Motility offers a valuable survival strategy for the extreme environment they call home, which has a limited supply of nutrients essential to life."Studying these unique microbes can give us insights into both the history of Earth and the potential strategies of life on other planets," said Stephanie Carr, first author on the paper and a former postdoctoral researcher with Orcutt who is now an assistant professor at Hartwick College. "Their survival strategies make them incredibly versatile, and they play an important, overlooked role in the subsurface environments where they live."In 2011, Orcutt and other project scientists sailed to the flank of the Juan de Fuca Ridge, a mid-ocean ridge off the coast of Washington where two ocean plates are separating and generating new oceanic crust. They used Woods Hole Oceanographic Institution's deep-diving robot Jason to travel 2.6 km to the seafloor and collect samples of the fluid that flows through the deep crust.These crustal fluids contained microbes that had never before been studied. Working in partnership with the Department of Energy Joint Genome Institute, the researchers sorted and analyzed the microbes in the Single Cell Genomics Center at Bigelow Laboratory. This cutting-edge research facility is directed by Ramunas Stepanauskas, a senior research scientist and study author. The project team also analyzed the microbes using metagenomics, a technique that extracts genomic information directly from environmental samples. These analyses yielded insights into the genetic blueprints of Hydrothermarchaeota, their relationship to other archaea, and the strategies they have evolved to survive in the subseafloor.The researchers will build upon this discovery when they return to the Juan de Fuca Ridge in May 2019 to continue investigating the extreme microbes thriving below the seafloor. Orcutt will lead a cruise using ROV Jason with this team of researchers to further explore the subseafloor environment, leveraging funding from the National Science Foundation and NASA."The microbes living 'buried alive' below the seafloor are really intriguing to us, since they can survive on low amounts of energy," Orcutt said. "We hope that our experiments on these weird microbes can show how they do this, so we can imagine how life might exist on other planets."
Using a combination of ultrasonic techniques and a large volume press apparatus, GRC researchers were successful in measuring the sound velocities of CaSiO3 perovskite (CaPv), an important mineral of the mantle at depths below 560 km. This result allowed them to directly interpret seismic observations by a comparison with their velocity profiles obtained in the laboratory, and derived some composition models for the regions across the 660 km depth discontinuity that marks the boundary between the upper and lower mantle.The scientific article that presents their results was published on January 10 in the journal CaPv constitutes 7-10 vol% of the pyrolitic mantle and up to 30 vol% of subducted basaltic rocks below ~560 km depth and therefore is an important constituent mineral in both the mantle transition region (MTR; 410-660 km in depth) and lower mantle (660-2900 km in depth). CaPv also plays an important role in immobilizing heavy elements such as rare earth elements or actinides in the mantle due to its large calcium site, which can easily accommodate such large elements. But despite such importance, no measurements of sound velocities have been made CaPv at high temperatures, because this phase is unstable at ambient conditions and hence there was no adequate sample for such measurements."Because CaPv is only stable at pressure and temperature conditions of the mantle, we designed an experiment that allows us to synthesize this phase with the adequate shape and dimension under high pressure, then subsequently send an acoustic wave directly into the pressurized sample. Using this new approach, we can study high-pressure minerals, which are not stable at atmospheric conditions, such as CaPv." says Steeve GrÃ©aux, the researcher leading this project.Professor Irifune and his team already demonstrated in 2008, that pyrolite, a hypothetical rock composition derived as a mixture of basalt and peridotite agree well with geophysical observations at depths down to 560 km, which was also reported in "We did find that the cubic form of CaPv, which is most likely to be present in the mantle, has lower velocities than what was formerly predicted by theoretical studies. This result refutes previous models that proposed formation of CaPv in pyrolite could explain the steep velocity gradient above a depth of 660 km. On the other hand, it is in good agreement with a former study proposing the presence of basalts beneath a depth of 660 km on the basis of density measurements." says Tetsuo Irifune.These new results indeed show that the presence of subducted oceanic crust can explain the magnitude of the reduction of shear velocity below a depth of 660 km, as observed beneath North America. Incidentally, the model they proposed is very consistent with the recent discovery, in 2018, of CaPv in a natural diamond, which provides evidence for the presence of oceanic crust material in the uppermost lower mantle. It is also compatible with global-scale geodynamics calculations that predicted basalt enrichment beneath 660 km would stabilize the subducted slab in this region.The authors conclude "CaPv, which was once called "invisible" in the lower mantle as this phase was predicted to have velocities similar to those of the most abundant mineral (MgSiO3 perovskite or bridgmanite) in fact holds velocities substantially lower than those of bridgmanite at depths of 660-800 km, which should greatly contribute to tracing the existence and recycling of the former oceanic crust in the Earth's lower mantle.."
Global temperatures in 2018 were 1.5 degrees Fahrenheit (0.83 degrees Celsius) warmer than the 1951 to 1980 mean, according to scientists at NASA's Goddard Institute for Space Studies (GISS) in New York. Globally, 2018's temperatures rank behind those of 2016, 2017 and 2015. The past five years are, collectively, the warmest years in the modern record."2018 is yet again an extremely warm year on top of a long-term global warming trend," said GISS Director Gavin Schmidt.Since the 1880s, the average global surface temperature has risen about 2 degrees Fahrenheit (1 degree Celsius). This warming has been driven in large part by increased emissions into the atmosphere of carbon dioxide and other greenhouse gases caused by human activities, according to Schmidt.Weather dynamics often affect regional temperatures, so not every region on Earth experienced similar amounts of warming. NOAA found the 2018 annual mean temperature for the contiguous 48 United States was the 14th warmest on record.Warming trends are strongest in the Arctic region, where 2018 saw the continued loss of sea ice. In addition, mass loss from the Greenland and Antarctic ice sheets continued to contribute to sea level rise. Increasing temperatures can also contribute to longer fire seasons and some extreme weather events, according to Schmidt."The impacts of long-term global warming are already being felt -- in coastal flooding, heat waves, intense precipitation and ecosystem change," said Schmidt.NASA's temperature analyses incorporate surface temperature measurements from 6,300 weather stations, ship- and buoy-based observations of sea surface temperatures, and temperature measurements from Antarctic research stations.These raw measurements are analyzed using an algorithm that considers the varied spacing of temperature stations around the globe and urban heat island effects that could skew the conclusions. These calculations produce the global average temperature deviations from the baseline period of 1951 to 1980.Because weather station locations and measurement practices change over time, the interpretation of specific year-to-year global mean temperature differences has some uncertainties. Taking this into account, NASA estimates that 2018's global mean change is accurate to within 0.1 degree Fahrenheit, with a 95 percent certainty level.NOAA scientists used much of the same raw temperature data, but with a different baseline period and different interpolation into Earth's polar and other data poor regions. NOAA's analysis found 2018 global temperatures were 1.42 degrees Fahrenheit (0.79 degrees Celsius) above the 20th century average.NASA's full 2018 surface temperature data set -- and the complete methodology used to make the temperature calculation -- are available at:GISS is a laboratory within the Earth Sciences Division of NASA's Goddard Space Flight Center in Greenbelt, Maryland. The laboratory is affiliated with Columbia University's Earth Institute and School of Engineering and Applied Science in New York.
In astrobiology, there is an increasing interest in whether life as we know it is a quirk of the particular evolutionary history of the Earth or, instead, if life might be governed by more general organizing principles.If general principles exist that can explain properties common to all life on Earth, scientists hypothesize, then they may be universal to all life, even life on other planets. If a "universal biology" exists, it would have important implications for the search for life beyond Earth, for engineering synthetic life in the lab, and for solving the origin of life, enabling scientists to predict at least some properties of alien life.Previous research in this area has primarily focused on specific levels of organization within biology such as individual organisms or ecological communities. These levels form a hierarchy where individuals are composed of interacting molecules and ecosystems are composed of interacting individuals.An interdisciplinary team of researchers at Arizona State University (ASU) has gone beyond focusing on individual levels in this hierarchy to study the hierarchy itself, focusing on the biosphere as a whole. The results of their study have been recently published "To understand the general principles governing biology, we must understand how living systems organize across levels, not just within a given level," says lead author Hyunju Kim of ASU's Beyond Center and the School of Earth and Space Exploration.Through this study, the team found that biochemistry, both at the level of organisms and ecosystems, is governed by general organizing principles. "This means there is a logic to the planetary-scale organization of biochemistry," says co-lead author Harrison Smith of ASU's School of Earth and Space Exploration. "Scientists have talked about this type of logic for a long time, but until now they have struggled to quantify it. Quantifying it can help us constrain the way that life arises on a planet."For this research, the team constructed biochemical networks using a global database of 28,146 annotated genomes and metagenomes and 8,658 catalogued biochemical reactions. In so doing, they uncovered scaling laws governing biochemical diversity and network structure that are shared across levels of organization from individuals to ecosystems, to the biosphere as a whole."Quantifying general principles of life -- not restricted to a domain on the tree of life, or a particular ecosystem -- is a challenge," says Smith. "We were able to do that by combining tools from network science and scaling theory, while simultaneously leveraging large genomic datasets that researchers have been cataloging."The research team, led by Kim and Smith under supervision of Sara Walker of the ASU School of Earth and Space Exploration and the Beyond Center, also includes Cole Mathis of the Beyond Center and the ASU Department of Physics (now at the University of Glasgow), and Jason Raymond of the School of Earth and Space Exploration."Understanding the organizing principles of biochemistry at a global scale better enables us to understand how life operates as a planetary process," says Walker. "The ability to more rigorously identify universal properties of life on Earth will also provide astrobiologists with new quantitative tools to guide our search for alien life -- both in the lab on other worlds."
Yet for scientists the exact process by which the Isthmus of Panama came into being still remains largely contentious.In a new study published today in the journal The Isthmus of Panama is a narrow piece of land that lies between the Caribbean Sea and the Pacific Ocean and links North and South America. It is believed to have fully formed around 2.8m years ago, yet scientists are still unsure about the processes and timescales that led up to this.Up until now researchers have favoured a model in that the Isthmus of Panama was created through the collision of two of Earth's tectonic plates -- the South American Plate and the Caribbean Plate -- which pushed underwater volcanoes up from the sea floor and eventually forced some areas above sea level.However, new geochemical and geochronological data taken from the Panama Canal and field investigation of old volcanoes in this area have provided evidence that there was significant volcanic activity taking place during a critical phase of the emergence of the Isthmus of Panama around 25 million years ago.The growth of volcanoes in the Panama Canal area is thought to have been particularly significant for the formation of the Isthmus because the Canal was constructed in a shallow area of Panama, which is believed to have remained underwater for the major part of the geological history of the region.This suggests that the formation of the volcanoes along the Canal could have played an important role in the rise of the Isthmus above sea level.Scientists are keen to discover exactly how the Isthmus of Panama formed given its significant role in shaping both weather patterns and biodiversity across the world.Before a landmass existed between North and South America, water had moved freely between the Atlantic and Pacific oceans, but this changed when Panama formed, forcing warm Caribbean waters northwards to form what we now know as the Gulf Stream, thus creating much warmer climates in north-western Europe.The formation of the Isthmus of Panama also played a major role in Earth's biodiversity, making it easier for animals and plants to migrate between the continents. In North America, the opossum, armadillo and porcupine all trace back to ancestors that came across the land bridge from South America. Likewise, the ancestors of bears, cats, dogs, horses, llamas, and raccoons all made the trek south across the Isthmus of Panama.Lead author of the study Dr David Buchs, from Cardiff University's School of Earth and Ocean Sciences, said: "The formation of the Isthmus of Panama is without doubt one of the most significant geological events to have happened on Earth, particularly because of its role in shaping large scale weather patterns, creating the Arctic ice cap and triggering widespread biodiversity across continents."We've provided evidence to show that volcanic activity was critical to the formation of the Isthmus of Panama and responsible for many of the geological features that we see around the region to this day."
"There is geologic data that suggests the ice sheet was more sensitive to warming and temperature variations in the past million years, and not so much in the more recent past," said David Pollard, research professor in the Earth and Environmental Systems Institute at Penn State.Too much warming will cause Greenland to lose most or all of its ice over the coming centuries, but most research indicates that the threshold warmth for complete ice loss has not been reached yet.Paleoclimatic records indicate that most of Greenland was ice-free within the last 1.1 million years even though temperatures then were not much warmer than conditions today. To explain this, the researchers point to there being more heat beneath the ice sheet in the past than today.Data show that when the Iceland hot spot -- the heat source that feeds volcanoes on Iceland -- passed under north-central Greenland 80 to 35 million years ago, it left molten rock deep underground but did not break through the upper mantle and crust to form volcanoes as it had in the west and east. The Earth's climate then was too warm for Greenland to have an ice sheet, but once it cooled the ice sheet formed, growing and shrinking successive with ice ages."The idea is that the loading and unloading, flexing and unflexing from ice ages tapped into slightly melted rock that was left deep under Greenland by the Iceland hot spot and brought that melt up," said Richard Alley, Evan Pugh University Professor of Geosciences at Penn State.Changes to the ice sheet allowed the molten rock to move closer to the Earth's surface, even to the base of the ice. The hotter bed melted more ice from below, lubricating the ice sheet so it was thinner and easier to melt from above.The melted rock wants to come up, according to Alley. As the ice sheet grows and shrinks, it essentially shakes the melt, drawing it up in pulses."The first shakes usually do the most moving," Alley said.The effect would have been largest when the first big ice sheet grew and then shrank, he added. More recent changes to the ice sheet also affect geothermal fluxes, but not as much as they had in the past."The hypothesis does not change the reality that if we make it hot, Greenland's ice melts, and no one will like that," Alley said. "It does not even really tell us whether geology just at this moment is making it harder or easier for the ice to melt. The ability of the ice to melt got easier in the past and is sort of bumpily getting harder, and we do not know where on the bumps we are."Pollard tested the team's hypothesis using a numerical, three-dimensional ice-sheet model. The researchers report their results in the "The Greenland ice sheet is very likely to melt a lot and retreat, and contribute to sea level in the next few centuries," Pollard said. "This study is part of the puzzle of figuring out how much it will melt and retreat. We are using past geologic data to validate the models that are being used for the future."If Greenland's ice sheet were to completely melt today, global sea levels would rise nearly 23 feet and flood coastal areas. Parts of cities like New York would be underwater. The team says future studies should integrate geologic and geophysical data as well as glaciological, atmospheric, oceanic and paleoclimatic information to better project how much and how fast the ice sheet will melt and its effect on sea-level rise."If you had a better idea of how much and how fast sea level rises from warming, you could make wiser decisions," Alley said. "This research is a piece of the effort to provide policymakers and planners with the background information that will allow them to make good decisions."
"All higher animal life forms, including us humans, produce cholesterol. Algae and bacteria produce their own characteristic fat molecules," says first author Lennart van Maldegem from Max Planck Institute (MPI) for Biogeochemistry, who recently moved to the Australian National University in Canberra, Australia. "Such fat molecules can survive in rocks for millions of years, as the oldest (chemical) remnants of organisms, and tell us now what type of life thrived in the former oceans long ago."But the fossil fats the researchers recently discovered in Brazilian rocks, deposited just after the last Snowball glaciation, were not what they suspected. "Absolutely not," says team-leader Christian Hallmann from MPI for Biogeochemistry. "We were completely puzzled, because these molecules looked quite different from what we've ever seen before!"Using sophisticated separation techniques, the team managed to purify minuscule amounts of the mysterious molecule and identify its structure by nuclear magnetic resonance in the NMR department of Christian Griesinger at Max Planck Institute for Biophysical Chemistry. "This is highly remarkable itself," according to Klaus Wolkenstein from MPI for Biophysical Chemistry and the Geoscience Centre of the University of GÃ¶ttingen. "Never has a structure been elucidated with such a small amount of such an old molecule." The structure was chemically identified as 25,28-bisnorgammacerane -- abbreviated as BNG, as van Maldegem suggests.Yet the origin of the compound remained enigmatic. "We of course looked if we could find it elsewhere," says van Maldegem, who then studied hundreds of ancient rock samples, with rather surprising success. "In particular the Grand Canyon rocks really were an eye-opener," says Hallmann. Although nowadays mostly sweltering hot, these rocks had also been buried under kilometres of glacial ice around 700 million years ago. Detailed additional analyses of molecules in Grand Canyon rocks -- including presumed BNG-precursors, the distribution of steroids and stable carbon isotopic patterns -- led the authors to conclude that the new BNG molecule most likely derives from heterotrophic plankton, marine microbes that rely on consuming other organisms for gaining energy. "Unlike for example green algae that engage in photosynthesis and thus belong to autotrophic organisms, these heterotrophic microorganisms were true predators that gained energy by hunting and devouring other algae and bacteria," according to van Maldegem.While predation is common amongst plankton in modern oceans, the discovery that it was so prominent 635 million years ago, exactly after the Snowball Earth glaciation, is a big deal for the science community. "Parallel to the occurrence of the enigmatic BNG molecule we observe the transition from a world whose oceans contained virtually only bacteria, to a more modern Earth system containing many more algae. We think that massive predation helped to 'clear' out the bacteria-dominated oceans and make space for algae," says van Maldegem. The resulting more complex feeding networks provided the dietary requirements for larger, more intricate lifeforms to evolve -- including the lineages that all animals, and eventually we humans, derive from. The massive onset of predation probably played a crucial role in the transformation of our planet and its ecosystems to its present state.
About 252 million years ago, with the planet's continental crust mashed into the supercontinent called Pangaea, volcanoes in modern-day Siberia began erupting. Spewing carbon and methane into the atmosphere for roughly 2 million years, the eruption helped extinguish about 96 percent of oceanic life and 70 percent of land-based vertebrates -- the largest extinction event in Earth's history.Yet the new study suggests that a byproduct of the eruption -- nickel -- may have driven some Australian plant life to extinction nearly 400,000 years before most marine species perished."That's big news," said lead author Christopher Fielding, professor of Earth and atmospheric sciences. "People have hinted at that, but nobody's previously pinned it down. Now we have a timeline."The researchers reached the conclusion by studying fossilized pollen, the chemical composition and age of rock, and the layering of sediment on the southeastern cliffsides of Australia. There they discovered surprisingly high concentrations of nickel in the Sydney Basin's mud-rock -- surprising because there are no local sources of the element.Tracy Frank, professor and chair of Earth and atmospheric sciences, said the finding points to the eruption of lava through nickel deposits in Siberia. That volcanism could have converted the nickel into an aerosol that drifted thousands of miles southward before descending on, and poisoning, much of the plant life there. Similar spikes in nickel have been recorded in other parts of the world, she said."So it was a combination of circumstances," Fielding said. "And that's a recurring theme through all five of the major mass extinctions in Earth's history."If true, the phenomenon may have triggered a series of others: herbivores dying from the lack of plants, carnivores dying from a lack of herbivores, and toxic sediment eventually flushing into seas already reeling from rising carbon dioxide, acidification and temperatures.One of three married couples on the research team, Fielding and Frank also found evidence for another surprise. Much of the previous research into the Great Dying -- often conducted at sites now near the equator -- has unearthed abrupt coloration changes in sediment deposited during that span.Shifts from grey to red sediment generally indicate that the volcanism's ejection of ash and greenhouse gases altered the world's climate in major ways, the researchers said. Yet that grey-red gradient is much more gradual at the Sydney Basin, Fielding said, suggesting that its distance from the eruption initially helped buffer it against the intense rises in temperature and aridity found elsewhere.Though the time scale and magnitude of the Great Dying exceeded the planet's current ecological crises, Frank said the emerging similarities -- especially the spikes in greenhouse gases and continuous disappearance of species -- make it a lesson worth studying."Looking back at these events in Earth's history is useful because it lets us see what's possible," she said. "How has the Earth's system been perturbed in the past? What happened where? How fast were the changes? It gives us a foundation to work from -- a context for what's happening now."The researchers detailed their findings in the journal The National Science Foundation and the Swedish Research Council funded the team's work.
More than 3.8 billion years ago, in a time period called the Hadean eon, our planet Earth was constantly bombarded by asteroids, which caused the large-scale melting of its surface rocks. Most of these surface rocks were basalts, and the asteroid impacts produced large pools of superheated impact melt of such composition. These basaltic pools were tens of kilometres thick, and thousands of kilometres in diameter."If you want to get an idea of what the surface of Earth looked like at that time, you can just look at the surface of the Moon which is covered by a vast amount of large impact craters," says Professor Rais Latypov from the School of Geosciences of the University of the Witwatersrand in South Africa.The subsequent fate of these ancient, giant melt sheet remains, however, highly debatable. It has been argued that, on cooling, they may have crystallized back into magmatic bodies of the same, broadly basaltic composition. In this scenario, asteroid impacts are supposed to play no role in the formation of the Earth's early evolved crust.An alternative model suggests that these sheets may undergo large-scale chemical change to produce layered magmatic intrusions, such as the Bushveld Complex in South Africa. In this scenario, asteroid impacts may have played an important role in producing various igneous rocks in the early Earth's crust and therefore they may have contributed to its chemical evolution.There is no direct way to rigorously test these two competing scenarios because the ancient Hadean impact melts have been later obliterated by plate tectonics. However, by studying the younger impact melt sheet of the Sudbury Igneous Complex (SIC) in Canada, Latypov and his research team have inferred that ancient asteroid impacts were capable of producing various rock types from the earlier Earth's basaltic crust. Most importantly, these impacts may have made the crust compositionally more evolved, i.e. silica-rich in composition. Their research has been published in a paper in The SIC is the largest, best exposed and accessible asteroid impact melt sheet on Earth, which has resulted from a large asteroid impact 1.85 billion years ago. This impact produced a superheated melt sheet of up to 5 km thick. The SIC now shows a remarkable magmatic stratigraphy, with various layers of igneous rocks."Our field and geochemical observations -- especially the discovery of large discrete bodies of melanorites throughout the entire stratigraphy of the SIC -- allowed us to reassess current models for the formation of the SIC and firmly conclude that its conspicuous magmatic stratigraphy is the result of large-scale fractional crystallization," says Latypov."An important implication is that more ancient and primitive Hadean impact melt sheets on the early Earth and other terrestrial planets would also have undergone near-surface, large-volume differentiation to produce compositionally stratified bodies. The detachment of dense primitive layers from these bodies and their sinking into the mantle would leave behind substantial volumes of evolved rocks (buoyant crustal blocks) in the Hadean crust. This would make the crust compositionally layered and increasingly more evolved from its base towards the Earth's surface.""These impacts made the crust compositionally more evolved -- in other words, silica-rich in composition," says Latypov. "Traditionally, researchers believe that such silica-rich evolved rocks -- which are essentially building buoyant blocks of our continents -- can only be generated deep in the Earth, but we now argue that such blocks can be produced at new-surface conditions within impact melt pools."
The rift in Larsen C is likely to lead to one of the largest icebergs ever recorded. It is being monitored by researchers from the UK's Project Midas, led by Swansea University.Professor Adrian Luckman of Swansea University College of Science, head of Project Midas, described the latest findings:"In the largest jump since January, the rift in the Larsen C Ice Shelf has grown an additional 17 km (11 miles) between May 25 and May 31 2017. This has moved the rift tip to within 13 km (8 miles) of breaking all the way through to the ice front, producing one of the largest ever recorded icebergs.The rift tip appears also to have turned significantly towards the ice front, indicating that the time of calving is probably very close.The rift has now fully breached the zone of soft 'suture' ice originating at the Cole Peninsula and there appears to be very little to prevent the iceberg from breaking away completely."Researchers say the loss of a piece a quarter of the size of Wales will leave the whole shelf vulnerable to future break-up.Larsen C is approximately 350m thick and floats on the seas at the edge of West Antarctica, holding back the flow of glaciers that feed into it.Professor Luckman added, "When it calves, the Larsen C Ice Shelf will lose more than 10% of its area to leave the ice front at its most retreated position ever recorded; this event will fundamentally change the landscape of the Antarctic Peninsula.We have previously shown that the new configuration will be less stable than it was prior to the rift, and that Larsen C may eventually follow the example of its neighbour Larsen B, which disintegrated in 2002 following a similar rift-induced calving event.The MIDAS Project will continue to monitor the development of the rift and assess its ongoing impact on the ice shelf. Further updates will be available on our blog (The team say they have no evidence to link the growth of this rift, and the eventual calving, to climate change. However, it is widely accepted that warming ocean and atmospheric temperatures have been a factor in earlier disintegrations of ice shelves elsewhere on the Antarctic Peninsula, most notably Larsen A (1995) and Larsen B (2002).They point out that this is one of the fastest warming places on Earth, a feature which will certainly not have hindered the development of the rift in Larsen C.
Large reservoirs of magma stored deep in Earth's crust are key to producing some of Earth's most powerful volcanic eruptions, new research has shown.In a new study, an international team of scientists claim that the most powerful volcanic eruptions, dubbed 'super-eruptions', are triggered by a slow and steady drip feed of magma from large reservoirs deep within Earth's crust into smaller reservoirs closer to the surface.These large reservoirs draw in hot magma from Earth's mantle and exist as large volumes of partially molten rock that are able to store magma like a sponge.By conducting a number of numerical simulations of this process, the research team showed that these large reservoirs are crucial to generating the largest volcanic eruptions on Earth.The team also showed that these large reservoirs can take millions of years to form, hence why 'super-eruptions' happen so rarely.It is believed that these findings could help to understanding why some volcanoes erupt frequently and at certain magnitudes.The study has been published in the journal The amount of magma that is stored in the upper layer of Earth's crust determines the frequency and magnitude of volcanic eruptions. Small eruptions that erupt less than one cubic kilometre of material occur very frequently (daily to yearly), whilst the largest eruptions that erupt hundreds of cubic kilometres of material are infrequent, with hundreds of thousands of years between them.Co-author of the study Dr Wim Degruyter, from Cardiff University's School of Earth and Ocean Sciences, said: "Our current understanding tells us that hot magma can be injected from Earth's lower crust into colder surroundings near the surface. At this point, the magma can either erupt or cool down to such a point that the magma solidifies and an eruption does not occur.""Up until now, this theory hasn't been able to explain how the magma can maintain its heat in these near-surface reservoirs and thus produce extremely powerful eruptions.""Our study has shown that the key to this is much larger reservoirs deeper below the surface that are able to slowly increase the temperature in the upper part of the crust such that it becomes more amenable to the storage of magma. When the crust has become fully mature, giant reservoirs are able to form in the upper crust and thus we see extremely powerful eruptions."Previous research has revealed that a deeper magma body connects to a magma reservoir in the upper part of the crust underneath Yellowstone -- one of the world's largest supervolcanoes. The deeper magma body sits 12 to 28 miles below the surface and it's believed that the hot molten rock could fill the 1,000-cubic-mile Grand Canyon 11.2 times. The last known eruptions from Yellowstone were 2m, 1.2m and 640,000 years ago, and it is believed that these were fed by the volcanic plumbing system that sits beneath it."Our calculations appear to agree with the observations that have been made at Yellowstone," Dr Degruyter continued.The study, Lifetime and size of shallow magma bodies controlled by crustal-scale magmatism, was led by researchers at ETH Zurich, and also included researchers from the Georgia Institute of Technology.
Scientists have often linked the annihilation of life at the Triassic-Jurassic boundary with the emission of gas during the volcanic activity of the Central Atlantic Magmatic Province, a huge volcanic province that erupted around the same time. Geological studies, however, have questioned this hypothesis since the flood basalt eruptions from the igneous province are too young to be responsible for the mass extinction. The scientists, among them a team from UNIGE, therefore went to look for traces of magmatic activity that may be older, proving the role of magmatic activity in mass extinctions that hit the history of Earth during this period of time.The geologists identified large areas covered by flood basalts assigned to the Central Atlantic Magmatic Province (CAMP), which extends over several million km2 from Northern to Southern America, and from Europe to Africa. They also discovered vertical fissures that extend over hundreds of kilometres and large intrusions. "We therefore erected the hypothesis that these fissures and intrusions are older or coeval to the mass extinction at the Triassic-Jurassic boundary, and we have verified this applying our high-precision dating techniques," explains Joshua Davies, research fellow at the Department of Earth Sciences of the Faculty of Science at the University of Geneva (UNIGE).The basalts enclose the mineral zircon in tiny quantities, which itself contains uranium. Uranium has the particularity of disintegrating itself over time into lead at a known rate. "It's because of this, by measuring relative concentrations of uranium and lead, we can determine the age of crystallization of minerals in a rock to about 30'000 years, which is extremely precise for a period of time 200 million years ago," adds Urs Schaltegger, professor at the Department of Earth Sciences of the Faculty of Science at the University of Geneva (UNIGE).To carry out precise age determinations is a complicated exercise, only around four laboratories are capable of at this level of precision, among them the laboratory at UNIGE. The geologists were particularly interested to date basalts that can be found in the Amazonian sedimentary basin, an huge reservoir of coal and oil. And indeed, the results of their age determinations confirm that the age of these basalts correlates with the mass extinction at the Triassic-Jurassic boundary. This result allows the scientists to link this magmatic activity with the thermally induced release of immense volumes of CO
This widely accepted textbook geology is being challenged by Colorado State University biogeochemists in a new study published June 1 in "You know you might have a big story when you discover something that will result in people having to rewrite textbooks," Borch said. "Our results may introduce a paradigm shift in the way we think about ore genesis and mining -- from implications for human health, to restoration practices, to how mining companies calculate how much they can earn from a given site."Conventional wisdom has told us that uranium within ore deposits is mostly found in the form of uraninite, a crystalline mineral. In recent years, scientists had uncovered new evidence that bacteria - living microorganisms -- could generate a different kind of reduced uranium that is non-crystalline and has very different physical and chemical properties. Borch, working on an unrelated experiment studying the composition of uranium at mined and unmined sites in Wyoming, surmised that this biogenic (of biological origin), non-crystalline uranium might occur naturally within ore deposits.To find out, Borch's team analyzed samples from the Wyoming roll front, using new techniques including synchrotron radiation-based spectroscopy and isotope fingerprinting. They found that up to 89 percent of the uranium from their 650-foot-deep samples wasn't crystalline uraninite at all, but rather, a non-crystalline uranium that was bound to organic matter or inorganic carbonate. Most of the uranium they found in that unmined site is estimated to be 3 million years old, and formed via reduction by microorganisms - microbes that respire not on oxygen, but on uranium.To verify their results, the team partnered with experts from the U.S. Geological Survey, Institute for Mineralogy at Leibniz University in Germany, and the Swiss Federal Institute of Technology in Lausanne, all of whom became paper co-authors.Abundance of this biogenic non-crystalline uranium has implications for environmental remediation of mining sites, and for mining practices in general. For instance, biogenic non-crystalline uranium is much more likely to oxidize into a water-soluble form than its crystalline counterparts. This could impact the compound's environmental mobility and its likelihood for contaminating a drinking water aquifer, Borch said.Borch says that most states require spent mines to be restored to pre-mining conditions. "In order to get back to pre-mining conditions, we had better understand those pre-mining conditions," Borch said. "The baseline may not be what we thought it was."Though there is now strong evidence for microbial origins of roll-front uranium, what's less clear is whether the microbes making uranium today are the same as those that formed it in the Earth's crust 3 million years ago. "But we do know through isotopic fingerprinting that the uranium formed via microbial reduction," Borch said.Borch's co-authors include Rizlan Bernier-Latmani, a scientist in Switzerland who developed the isotopic fingerprinting techniques to differentiate between uranium formed via microbial or chemical means.Borch and colleagues hope to explore the origins of roll-front uranium deposits at other sites, in order to evaluate the global significance of their findings.
In the article, a Washington University scientist and his colleagues describe what happened when pulses of atmospheric carbon dioxide and sulfate aerosols were intermixed at the end of the Ordivician geological period more than 440 million years ago.The counterpart of the tumult in the skies was death in the seas. At a time when most of the planet north of the tropics was covered by an ocean and most complex multicellular organisms lived in the sea, 85 percent of marine animal species disappeared forever. The end Ordivician extinction, as this event was called, was one of the five largest mass extinctions in Earth's history.Although the gases were injected into the atmosphere by massive volcanism rather than prodigious burning of fossil fuels and under circumstances that will never be exactly repeated, they provide a worrying case history that reveals the potential instability of planetary-scale climate dynamics.Figuring out what caused the end Ordivician extinction or any of the other mass extinctions in Earth's history is notoriously difficult, said David Fike, associate professor of earth and planetary sciences in Arts & Sciences and a co-author on the paper.Because the ancient atmospheres and oceans have long since been altered beyond recognition, scientists have to work from proxies, such as variations in oxygen isotopes in ancient rock, to learn about climates long past. The trouble with most proxies, said Fike, who specializes in interpreting the chemical signatures of biological and geological activity in the rock record, is that most elements in rock participate in so many chemical reactions that a signal can often be interpreted in more than one way.But a team led by David Jones, an earth scientist at Amherst College, was able to bypass this problem by measuring the abundance of mercury. Today, the primary sources of mercury are coal-burning power plants and other anthropocentric activities; during the Ordivician, however, the main source was volcanism.Volcanism coincides with mass extinctions with suspicious frequency, Fike said. He is speaking not about an isolated volcano but rather about massive eruptions that covered thousands of square kilometers with thick lava flows, creating large igneous provinces (LIPs). The most famous U.S. example of a LIP is the Columbia River Basalt province, which covers most of the southeastern part of the state of Washington and extends to the Pacific and into Oregon.Volcanoes are plausible climate forcers, or change agents, because they release both carbon dioxide that can produce long-term greenhouse warming and sulfur dioxide that can cause short-term reflective cooling. In addition, the weathering of vast plains of newly exposed rock can draw down atmospheric carbon dioxide and bury it as limestone minerals in the oceans, also causing cooling.When Jones analyzed samples of rock of Ordivician age from south China and the Monitor Range in Nevada, he found anomalously high mercury concentrations. Some samples held 500 times more mercury than the background concentration. The mercury arrived in three pulses, before and during the mass extinction.But what happened? It had to have been an unusual sequence of events because the extinction (atypically) coincided with glaciation and also happened in two pulses.As the scientists began to piece together the story, they began to wonder if the first wave of eruptions didn't push Earth's climate into a particularly vulnerable state, setting it up for a climate catastrophe triggered by later eruptions.The first wave of eruptions laid down a LIP whose weathering then drew down atmospheric carbon dioxide. The climate cooled and glaciers formed on the supercontinent of Gondwana, which was then located in the southern hemisphere.The cooling might have lowered the tropopause, the boundary between two layers of the atmosphere with different temperature gradients. The second wave of volcanic eruptions then injected prodigious amounts of sulfur dioxide above the tropopause, abruptly increasing Earth's albedo, or the amount of sunlight it reflected.This led to the first and largest pulse of extinctions. As ice sheets grew, sea level dropped and the seas became colder, causing many species to perish.During the second wave of volcanism, the greenhouse warming from carbon dioxide overtook the cooling caused by sulfur dioxide and the climate warmed, the ice melted and sea levels rose. Many of the survivors of the first pulse of extinctions died in the ensuing flooding of habitat with warmer, oxygen-poor waters.The take-home, said Fike, is that the different factors that affect Earth's climate can interact in unanticipated ways and it is possible that events that might not seem extreme in themselves can put the climate system into a precarious state where additional perturbations have catastrophic consequences."It's something to keep in mind when we contemplate geoengineering schemes to mitigate global warming," said Fike, who teaches a course where students examine such schemes and then evaluate their willingness to deploy them.
"While we can currently make fairly reliable weather predictions, as, for example, five-day forecasts, we do not have good predictive power on sub-seasonal to seasonal time scale, which is essential for food security," Gentine says. "By more accurately observing and modeling the feedbacks between photosynthesis and the atmosphere, as we did in our paper, we should be able to improve climate forecasts on longer timescales."Vegetation can affect climate and weather patterns due to the release of water vapor during photosynthesis. The release of vapor into the air alters the surface energy fluxes and leads to potential cloud formation. Clouds alter the amount of sunlight, or radiation, that can reach Earth, affecting Earth's energy balance, and in some areas can lead to precipitation. "But, until our study, researchers have not been able to exactly quantify in observations how much photosynthesis, and the biosphere more generally, can affect weather and climate," says Julia Green, Gentine's PhD student and the paper's lead author.Recent advancements in satellite observations of solar-induced fluorescence, a proxy for photosynthesis, enabled the team to infer vegetation activity. They used remote sensing data for precipitation, radiation, and temperature to represent the atmosphere. They then applied a statistical technique to understand the cause and feedback loop between the biosphere and the atmosphere. Theirs is the first study investigating land-atmosphere interactions to determine both the strength of the predictive mechanism between variables and the time scale over which these links occur.The researchers found that substantial vegetation-precipitation feedback loops often occur in semi-arid or monsoonal regions, in effect hotspots that are transitional between energy and water limitation. In addition, strong biosphere-radiation feedbacks are often present in several moderately wet regions, for instance in the Eastern U.S. and in the Mediterranean, where precipitation and radiation increase vegetation growth. Vegetation growth enhances heat transfer and increases the height of Earth's boundary layer, the lowest part of the atmosphere that is highly responsive to surface radiation. This increase in turn affects cloudiness and surface radiation."Current Earth system models underestimate these precipitation and radiation feedbacks mainly because they underestimate the biosphere response to radiation and water stress response," Green says. "We found that biosphere-atmosphere feedbacks cluster in hotspots, in specific climatic regions that also coincide with areas that are major continental CO2 sources and sinks. Our research demonstrates that those feedbacks are also essential for the global carbon cycle -- they help determine the net CO2 balance of the biosphere and have implications for improving critical management decisions in agriculture, security, climate change, and so much more."Gentine and his team are now exploring ways to model how biosphere-atmosphere interactions may change with a shifting climate, as well as learning more about the drivers of photosynthesis, in order to better understand atmospheric variability.Paul Dirmeyer, a professor in the department of atmospheric, oceanic and earth sciences at George Mason University who was not involved in the study, notes: "Green et al. put forward an intriguing and exciting new idea, expanding our measures of land-atmospheric feedbacks from mainly a phenomenon of the water and energy cycles to include the biosphere, both as a response to climate forcing and a forcing to climate response."
X-ray studies at the Department of Energy's Lawrence Berkeley National Laboratory (Berkeley Lab) have helped scientists to solve this mystery by scanning inside samples of lightweight, glassy, and porous volcanic rocks known as pumice stones. The X-ray experiments were performed at Berkeley Lab's Advanced Light Source, an X-ray source known as a synchrotron.The surprisingly long-lived buoyancy of these rocks -- which can form miles-long debris patches on the ocean known as pumice rafts that can travel for thousands of miles -- can help scientists discover underwater volcano eruptions.And, beyond that, learning about its flotation can help us understand how it spreads species around the planet; pumice is nutrient rich and readily serves as a seafaring carrier of plant life and other organisms. Floating pumice can also be a hazard for boats, as the ashy mixture of ground-up pumice can clog engines."The question of floating pumice has been around the literature for a long time, and it hadn't been resolved," said Kristen E. Fauria, a UC Berkeley graduate student who led the study, published in While scientists have known that pumice can float because of pockets of gas in its pores, it was unknown how those gases remain trapped inside the pumice for prolonged periods. If you soak up enough water in a sponge, for example, it will sink."It was originally thought that the pumice's porosity is essentially sealed," Fauria said, like a corked bottle floating in the sea. But pumice's pores are actually largely open and connected -- more like an uncorked bottle. "If you leave the cap off and it still floats ... what's going on?"Some pumice stones have even been observed to "bob" in the laboratory -- sinking during the evening and surfacing during the day.To understand what's at work in these rocks, the team used wax to coat bits of water-exposed pumice sampled from Medicine Lake Volcano near Mount Shasta in Northern California and Santa MarÃ­a Volcano in Guatemala.They then used an X-ray imaging technique at the ALS known as microtomography to study concentrations of water and gas -- in detail measured in microns, or thousandths of a millimeter -- within preheated and room-temperature pumice samples.The detailed 3-D images produced by the technique are very data-intensive, which posed a challenge in quickly identifying the concentrations of gas and water present in the pumice samples' pores.To tackle this problem, Zihan Wei, a visiting undergraduate researcher from Peking University, used a data-analysis software tool that incorporates machine learning to automatically identify the gas and water components in the images.Researchers found that the gas-trapping processes that are in play in the pumice stones relates to "surface tension," a chemical interaction between the water's surface and the air above it that acts like a thin skin -- this allows some creatures, including insects and lizards, to actually walk on water."The process that's controlling this floating happens on the scale of human hair," Fauria said. "Many of the pores are really, really small, like thin straws all wound up together. So surface tension really dominates."The team also found that a mathematical formulation known as percolation theory, which helps to understand how a liquid enters a porous material, provides a good fit for the gas-trapping process in pumice. And gas diffusion -- which describes how gas molecules seek areas of lower concentration -- explains the eventual loss of these gases that causes the stones to sink.Michael Manga, a staff scientist in Berkeley Lab's Energy Geosciences Division and a professor in the Department of Earth and Planetary Science at UC Berkeley who participated in the study, said, "There are two different processes: one that lets pumice float and one that makes it sink," and the X-ray studies helped to quantify these processes for the first time. The study showed that previous estimates for flotation time were in some cases off by several orders of magnitude."Kristen had the idea that in hindsight is obvious," Manga said, "that water is filling up only some of the pore space." The water surrounds and traps gases in the pumice, forming bubbles that make the stones buoyant. Surface tension serves to keep these bubbles locked inside for prolonged periods. The bobbing observed in laboratory experiments of pumice floatation is explained by trapped gas expanding during the heat of day, which causes the stones to temporarily float until the temperature drops.The X-ray work at the ALS, coupled with studies of small pieces of pumice floating in water in Manga's UC Berkeley lab, helped researchers to develop a formula for predicting how long a pumice stone will typically float based on its size. Manga has also used an X-ray technique at the ALS called microdiffraction, which is useful for studying the origins of crystals in volcanic rocks.Dula Parkinson, a research scientist at Berkeley Lab's ALS who assisted with the team's microtomography experiments, said, "I'm always amazed at how much information Michael Manga and his collaborators are able to extract from the images they collect at ALS, and how they're able to join that information with other pieces to solve really complicated puzzles."The recent study triggered more questions about floating pumice, Fauria said, such as how pumice, ejected from deep underwater volcanoes, finds its way to the surface. Her research team has also conducted X-ray experiments at the ALS to study samples from so-called "giant" pumice that measured more than a meter long.That stone was recovered from the sea floor in the area of an active underwater volcano by a 2015 research expedition that Fauria and Manga participated in. The expedition, to a site hundreds of miles north of New Zealand, was co-led by Rebecca Carey, a scientist formerly affiliated with the Lab's ALS.Underwater volcano eruptions are not as easy to track down as eruptions on land, and floating pumice spotted by a passenger on a commercial aircraft actually helped researchers track down the source of a major underwater eruption that occurred in 2012 and motivated the research expedition. Pumice stones spewed from underwater volcano eruptions vary widely in size but can typically be about the size of an apple, while pumice stones from volcanoes on land tend to be smaller than a golf ball."We're trying to understand how this giant pumice rock was made," Manga said. "We don't understand well how submarine eruptions work. This volcano erupted completely different than we hypothesized. Our hope is that we can use this one example to understand the process."Fauria agreed that there is much to learn from underwater volcano studies, and she noted that X-ray studies at the ALS will play an ongoing role in her team's work.
Researchers have found that carbon particles released into the air from burning trees and other organic matter are much more likely than previously thought to travel to the upper levels of the atmosphere, where they can interfere with rays from the sun -- sometimes cooling the air and at other times warming it."Most of the brown carbon released into the air stays in the lower atmosphere, but a fraction of it does get up into the upper atmosphere, where it has a disproportionately large effect on the planetary radiation balance -- much stronger than if it was all at the surface," said Rodney Weber, a professor in Georgia Tech's School of Earth & Atmospheric Sciences.The study, which was published May 22 in the journal The researchers analyzed air samples collected in 2012 and 2013 by NASA aircraft from the upper troposphere -- about seven miles above the earth's surface -- at locations across the United States. They found surprising levels of brown carbon in the samples but much less black carbon.While black carbon can be seen in the dark smoke plumes rising above burning fossil or biomass fuels at high temperature, brown carbon is produced from the incomplete combustion that occurs when grasses, wood or other biological matter smolders, as is typical for wildfires. As particulate matter in the atmosphere, both can interfere with solar radiation by absorbing and scattering the sun's rays.The climate is more sensitive to those particulates as their altitude increases. The researchers found that brown carbon appears much more likely than black carbon to travel through the air to the higher levels of the atmosphere where it can have a greater impact on climate."People have always assumed that when you emit this brown carbon, over time it goes away," said Athanasios Nenes, a professor and Georgia Power Scholar in the School of Earth & Atmospheric Sciences and the School of Chemical & Biomolecular Engineering.After the brown carbon is carried by smoke plumes into the lower atmosphere, it mixes with clouds. Then it hitches a ride on the deep convection forces that exist in clouds to travel to the upper atmosphere.Although the researchers couldn't explain how, they also found that during the journey through the clouds, the brown carbon became more concentrated relative to black carbon."The surprise here is that the brown carbon gets promoted when you go through the cloud, compared to black carbon," Nenes said. "This suggests that there may be in-cloud production of brown carbon that we were not aware of before."
The study, led by Esteban Gazel, an assistant professor with Virginia Tech's Department of Geosciences, and his doctoral student Jarek Trela of Deer Park, Illinois, is published in the latest issue of The Archean Eon -- covering from 2.5 to 4 billion years ago -- is one of the most enigmatic times in the evolution of our planet, Gazel said. During this time period, the temperature of Earth's mantle -- the silicate region between the crust and the outer core -- was hotter than it is today, owing to a higher amount of radioactive heat produced from the decay of elements such as potassium, thorium, and uranium. Because Earth was hotter during this period, this interval of geologic time is marked by the widespread of occurrence of a unique rock known as komatiite."Komatiites are basically superhot versions of Hawaiian style lava flows," Gazel said. "You can imagine a Hawaiian lava flow, only komatiites were so hot that they glowed white instead of red, and they flowed on a planetary surface with very different atmospheric conditions, more similar to Venus than the planet we live on today."Earth essentially stopped producing abundant hot komatiites after the Archean era because the mantle has cooled during the past 4.5 billion years due to convective cooling and a decrease in radioactive heat production, Gazel said.However, Gazel and a team made what they call an astonishing discovery while studying the chemistry of ancient Galapagos-related lava flows, preserved today in Central America: a suite of lavas that shows conditions of melting and crystallization similar to the mysterious Archean komatiites.Gazel and collaborators studied a set of rocks from the 90 million-year-old Tortugal Suite in Costa Rica and found that they had magnesium concentrations as high as Archean komatiites, as well as textural evidence for extremely hot lava flow temperatures."Experimental studies tell us that that the magnesium concentration of basalts and komatiites is related to the initial temperature of the melt," Gazel said. "They higher the temperature, the higher the magnesium content of a basalt."The team also studied the composition olivine, the first mineral that crystallized from these lavas. Olivine -- a light green mineral that Gazel has obsessively explored many volcanoes and magmatic regions to search for -- is an extremely useful tool to study a number of conditions related to origin of a lava flow because it is the first mineral phase that crystallizes when a mantle melt cools. Olivines also carry inclusions of glass -- that once was melt -- and other smaller minerals that are helpful to decipher the secrets of the deep Earth."We used the composition of olivine as another thermometer to corroborate how hot these lavas were when they began to cool," Gazel said. "You can determine the temperature that basaltic lava began crystallizing by analyzing the composition of olivine and inclusions of another mineral called spinel. At higher temperatures, olivine will incorporate more aluminum into its structure and spinel will incorporate more chromium. If you know how much of these elements are present in each mineral, then you know the temperature at which they crystallized."The team found that Tortugal olivines crystallized at temperature nearing 2,900 degrees Fahrenheit (1,600 degrees Celsius) -- as high as temperatures recorded by olivines from komatiites -- making this a new record on lava temperatures in the past 2.5 billion years.Gazel and collaborators suggest in their study that Earth may still be capable of producing komatiite-like melts. Their results suggest that Tortugal lavas most likely originated from the hot core of the Galapagos mantle plume that started producing melts nearly 90 million years ago and has remained active ever since.A mantle plume is a deep-earth structure that likely originates at the core-mantle boundary of the planet. When it nears the surface of the planet it begins to melt, forming features known as hotspots such as those found in Hawaii or Galapagos. Geologists can then study these hotspot lava flows and use their geochemical information as a window into the deep Earth."What is really fascinating about this study is that we show that the planet is still capable of producing lavas as hot as during Archean time period," Gazel said. "Based on our results from Tortugal lavas, we think that mantle plumes are 'tapping' a deep, hot region of the mantle that hasn't cooled very much since the Archean. We think that this region is probably being sustained by heat from the crystallizing core of the planet.""This is a really interesting discovery and we are going to keep investigating Tortugal," said Trela, a doctoral student and the first author of the paper. "Although the Tortugal Suite was first discovered and documented more than 20 years ago, it wasn't until now that we have the technology and experimental support to better understand the global implications of this location."Trela added, "Our new data suggest that this suite of rocks offers tremendous opportunity to answer key questions regarding the accretion of Earth, its thermal evolution, and the geochemical messages that mantle plumes bring to the surface of the planet."
The study, published May 22 in the open-access journal "Understanding how the Earth transitioned from a hothouse climate in the age of the dinosaurs to today could help us better understand long-term consequences of future climate change," said corresponding author Joshua Krissansen-Totton, a UW doctoral student in Earth and space sciences.The current understanding is that Earth's climate is controlled over periods of millions of years by a natural thermostat related to the weathering of rocks. Carbon dioxide is released into the air by volcanoes, and this gas may then dissolve into rainwater and react with silicon-rich continental rocks, causing chemical weathering of the rocks. This dissolved carbon then flows down rivers into the ocean, where it ultimately gets locked up in carbon-containing limestone on the seafloor.As a potent greenhouse gas, atmospheric carbon dioxide also traps heat from the sun. And a warmer Earth increases the rate of chemical weathering both by causing more rainfall and by speeding up the chemical reactions between rainwater and rock. Over time, reducing the amount of carbon dioxide in the air by this method cools the planet, eventually returning the climate to more moderate temperatures -- or so goes the textbook picture."The general idea has been that if more carbon dioxide is released, the rate of weathering increases, and carbon dioxide levels and temperature are moderated," co-author David Catling, a UW professor of Earth and space sciences. "It's a sort of long-term thermostat that protects the Earth from getting too warm or too cold."The new study began when researchers set out to determine conditions during the earliest life on Earth, some 3.5 billion to 4 billion years ago. They first tested their ideas on what they believed to be a fairly well-understood time period: the past 100 million years, when rock and fossil records of temperatures, carbon dioxide levels and other environmental variables exist.Earth's climate 100 million years ago was very different from today. During the mid-Cretaceous, the poles were 20 to 40 degrees Celsius warmer than the present. Carbon dioxide in the air was more than double today's concentrations. Seas were 100 meters (330 feet) higher, and dinosaurs roamed near the ice-free poles.The researchers created a computer simulation of the flows of carbon required to match all the geologic records, thus reproducing the dramatic transition from the warm mid-Cretaceous times to today."We found that to be able to explain all the data -- temperature, COGeologists had previously estimated that a temperature increase of 7 C would double the rate of chemical weathering. But the new results show that more than three times that temperature jump, or 24 C, is required to double the rate at which rock is washed away."It's just a much less efficient thermostat," Krissansen-Totton said.The authors suggest that another mechanism controlling the rate of weathering may be how much land is exposed above sea level and the steepness of Earth's surface. When the Tibetan Plateau was formed some 50 million year ago, the steeper surfaces may have increased the global rateof chemical weathering, drawing down more CO"In retrospect, our results make a lot of sense," Catling said. "Rocks tell us that Earth has had large swings in temperature over geological history, so Earth's natural thermostat can't be a very tight one."Their calculations also indicate a stronger relationship between atmospheric COThough not the final word, researchers said, these numbers are bad news for today's climate shifts."What all this means is that in the very long term, our distant descendants can expect more warming for far longer if carbon dioxide levels and temperatures continue to rise," Catling said.The researchers will now apply their calculations to other periods of the geologic past."This is going to have implications for the carbon cycles for other times in Earth's history and into its future, and potentially for other rocky planets beyond the solar system," Krissansen-Totton said.
The area south of the Pyrenees is particularly suitable for studying sedimentary layers. Rocks are exposed over large distances, allowing researchers to undertake direct observation. Turbidites can be seen here: large sediment deposits formed in the past by underwater avalanches consisting of sand and gravel. "We noticed that these turbidites returned periodically, about every million years. We then wondered what the reasons for this cyclicity were," explains SÃ©bastien Castelltort, professor in the department of earth sciences in UNIGE's faculty of sciences.The geologists focused their attention on Eocene sedimentary rocks (about 50 million years ago), which was particularly hot, and undertook the isotopic profiling of the sedimentary layers. "We took a sample every 10 metres," says Louis Honegger, a researcher at UNIGE, "measuring the ratio between 13C (heavy carbon stable isotope) and 12C (light carbon stable isotope). The ratio between the two tells us about the amount of organic matter, the main consumer of 12C, which is greater when the sea level is high. The variations in the ratio helped us explore the possible link with the sea level." The research team found that the turbidite-rich intervals were associated with high 12C levels, and almost always corresponded to periods when the sea level was low. It seems that sedimentary cycles are mainly caused by the rise and fall of the sea level and not by the episodic growth of mountains.When the sea level is high, continental margins are flooded under a layer of shallow water. Since the rivers are no longer able to flow, they begin to deposit the sediments they carry there. This is why so little material reaches the deep basins downstream. When the sea level is low, however, rivers erode their beds to lower the elevation of their mouth; they transfer their sediment directly to the continental slopes of the deep basins, creating an avalanche of sand and gravel. Consequently, if the variations of the sea level are known, it is possible to predict the presence of large sedimentary accumulations created by turbidites, which often contain large volumes of hydrocarbons, one of the holy grails of exploration geology.The research provides a new role for the use of carbon isotopes. "From now on, continues Castelltort, we know that by calculating the ratio between 13C and 12C sampled in similar slope deposits close to continents, we can have an indication of the sea level, which means it's possible to better predict the distribution of sedimentary rocks in our subsurface." In addition, this measurement is relatively simple to perform and it provides accurate data -- a real asset for science and mining companies. The study also highlights the importance of sea levels, which are a real metronome for Earth's sedimentary history. "Of course," concludes Honegger, "tectonic deformation and erosion are important factors in the formation of sedimentary layers; but they play a secondary role in the formation of turbidite accumulations, which are mainly linked to changes in the sea level."
Climate models and past-climate studies show that, as the Earth warms in response to an increase in greenhouse gases in the atmosphere, temperatures rise faster at the poles than in other parts of the planet. This is known as polar amplification. But this amplified warming is not the same at both poles."On average, warming for the entire Antarctic continent has been much slower than Arctic warming so far. Moreover, climate models suggest that, by the end of this century, Antarctica will have warmed less compared to the Arctic," says Marc Salzmann, a researcher at the Institute for Meteorology, University of Leipzig in Germany.A possible cause for the accelerated Arctic warming is the melting of the region's sea ice, which reduces the icy, bright area that can reflect sunlight back out into space, resulting in more solar radiation being absorbed by the dark Arctic waters. Scientists believe this is an important contribution to warming in the region, but it's not the only one.Changes to the transport of heat by the Earth's atmosphere and oceans to the poles have also been suggested as a possible contributor to the steep rise in Arctic temperatures. In addition, the cold temperatures and the way air is mixed close to the surface at the poles mean that the surface has to warm more to radiate additional heat back to space. These effects may not only lead to stronger warming at the north of our planet, but also at the south polar region."I wondered why some of the reasons to explain Arctic warming have not yet caused strongly amplified warming in all of Antarctica as well," says Salzmann, the author of the "I thought that land height could be a game changer that might help explain why the Arctic has thus far warmed faster than Antarctica," he says.With an average elevation of about 2,500 m, Antarctica is the highest continent on Earth, much due to a thick layer of ice covering the bedrock. The continent also has high mountains, such as Mount Vinson, which rises almost 4,900 m above sea level.To test his idea, Salzmann used a computer model of the Earth system to find out how the climate would react to a doubling of the atmospheric carbon-dioxide concentration. He also ran the same experiment in a flat-Antarctica world, where he artificially decreased the land height over the entire southern continent to one metre, a value similar to the surface height in the Arctic. This allowed him to compare how differently the Earth would react to an increase in greenhouse-gas concentrations in the atmosphere if Antarctica was assumed flat.The experiments showed that, if Antarctica's land height is reduced, temperatures in the region respond more strongly to a rise in the concentration of greenhouse gases over the continent. This contributes to an increase in Antarctic warming, which reduces the difference in polar amplification between the Arctic and the Antarctic.The most significant factor, however, was a change in the way heat is transported in the atmosphere from the equator to the poles in the flat Antarctica world compared to the reference model. "Assuming a flat Antarctica allows for more transport of warm air from lower latitudes," Salzmann explains. "This is consistent with the existing view that when the altitude of the ice is lowered, it becomes more prone to melting," Salzmann explains.In the long term, this could contribute to accelerate Antarctic warming in the real world. As the region warms due to increased greenhouse-gas emissions, ice melts, reducing Antarctica's elevation over centuries or thousands of years. This, in turn, would contribute to even more warming.
In their study just published online in the Geological Society of America Bulletin, A.K. Shah and colleagues examine rare earth mineral resource potential within heavy mineral sands in the southeastern United States.Using geophysical and geochemical data that cover this very wide region, the team mapped the areas most likely to host accumulations of these minerals. Additionally, their analyses of co-minerals provide constraints on broad sedimentary provenance. These constraints suggest that a large percentage of the heavy mineral sands are derived from a relatively small part of the Piedmont province via coastal processes during Atlantic opening, and that a much smaller amount of heavy mineral sands are delivered via rivers and streams.
